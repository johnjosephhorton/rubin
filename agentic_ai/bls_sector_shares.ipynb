{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc7fc397",
   "metadata": {},
   "source": [
    "#### By: Peyman Shahidi\n",
    "#### Created: Oct 29, 2025\n",
    "#### Last Edit: Nov 3, 2025\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10366af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python\n",
    "import getpass\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "import random \n",
    "\n",
    "## formatting number to appear comma separated and with two digits after decimal: e.g, 1000 shown as 1,000.00\n",
    "pd.set_option('float_format', \"{:,.2f}\".format)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "#from matplotlib.legend import Legend\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "519e43cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder_path = \"..\"\n",
    "input_data_path = f\"{main_folder_path}/data\"\n",
    "output_data_path = f'{input_data_path}/computed_objects'\n",
    "output_plot_path = f\"{main_folder_path}/writeup/plots\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84e6e6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories if they don't exist\n",
    "import os\n",
    "\n",
    "for path in [output_data_path, output_plot_path]:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43a275a",
   "metadata": {},
   "source": [
    "## Create Employment Shares from BLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aeaea6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bls_orig_df = pd.read_excel(f\"{main_folder_path}/data/oesm23all/all_data_M_2023.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e013796a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length before dropping TOT_EMP == \"**\": 177501\n",
      "Length After dropping TOT_EMP == \"**\": 169536\n"
     ]
    }
   ],
   "source": [
    "# Get a copy of the original dataframe to work with\n",
    "bls_df = bls_orig_df.copy()\n",
    "\n",
    "# Keep only national-level data\n",
    "bls_df = bls_df[bls_df.AREA == 99]\n",
    "\n",
    "# Drop rows whose TOT_EMP and PCT_TOTAL are both NaN\n",
    "print('Length before dropping TOT_EMP == \"**\":', len(bls_df))\n",
    "bls_df = bls_df[bls_df.TOT_EMP != '**']\n",
    "print('Length After dropping TOT_EMP == \"**\":', len(bls_df))\n",
    "\n",
    "# Get sector shares and drop aggregate occupation codes\n",
    "sector_total_shares_df = bls_df[bls_df.OCC_CODE == '00-0000'][['NAICS', 'TOT_EMP']]\n",
    "sector_total_shares_df = sector_total_shares_df.rename(columns={'TOT_EMP': 'totalSectorEmp'})\n",
    "sector_total_shares_df['sectorEmpShare'] = sector_total_shares_df['totalSectorEmp'] / sector_total_shares_df['totalSectorEmp'].sum()\n",
    "\n",
    "# Drop aggregate occupation codes\n",
    "bls_df = bls_df[bls_df.OCC_CODE != '00-0000']\n",
    "\n",
    "# Keep only relevant columns\n",
    "cols = ['NAICS', 'NAICS_TITLE', 'I_GROUP', 'OCC_CODE', 'OCC_TITLE', 'O_GROUP', 'TOT_EMP']\n",
    "bls_df = bls_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6cec669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ sector-level BLS data at major ONET Level saved with 424 rows\n",
      "✓ sector-level BLS data at minor ONET Level saved with 1,597 rows\n",
      "✓ sector-level BLS data at broad ONET Level saved with 5,504 rows\n",
      "✓ sector-level BLS data at detailed ONET Level saved with 8,153 rows\n",
      "✓ 3-digit-level BLS data at major ONET Level saved with 1,783 rows\n",
      "✓ 3-digit-level BLS data at minor ONET Level saved with 5,607 rows\n",
      "✓ 3-digit-level BLS data at broad ONET Level saved with 15,774 rows\n",
      "✓ 3-digit-level BLS data at detailed ONET Level saved with 21,770 rows\n",
      "✓ 4-digit-level BLS data at major ONET Level saved with 4,580 rows\n",
      "✓ 4-digit-level BLS data at minor ONET Level saved with 13,512 rows\n",
      "✓ 4-digit-level BLS data at broad ONET Level saved with 33,156 rows\n",
      "✓ 4-digit-level BLS data at detailed ONET Level saved with 43,562 rows\n",
      "✓ 5-digit-level BLS data at major ONET Level saved with 805 rows\n",
      "✓ 5-digit-level BLS data at minor ONET Level saved with 2,133 rows\n",
      "✓ 5-digit-level BLS data at broad ONET Level saved with 5,116 rows\n",
      "✓ 5-digit-level BLS data at detailed ONET Level saved with 6,473 rows\n",
      "✓ 6-digit-level BLS data at major ONET Level saved with 119 rows\n",
      "✓ 6-digit-level BLS data at minor ONET Level saved with 292 rows\n",
      "✓ 6-digit-level BLS data at broad ONET Level saved with 572 rows\n",
      "✓ 6-digit-level BLS data at detailed ONET Level saved with 655 rows\n"
     ]
    }
   ],
   "source": [
    "# Specify sector and ONET levels of interest\n",
    "bls_sector_levels = ['sector', '3-digit', '4-digit', '5-digit', '6-digit']\n",
    "onet_levels = ['major', 'minor', 'broad', 'detailed']\n",
    "\n",
    "for my_sector in bls_sector_levels:\n",
    "    for my_onet_level in onet_levels:\n",
    "        # Subset to BLS industry and O*NET level of interest\n",
    "        sector_df = bls_df[(bls_df['I_GROUP'] == my_sector) & (bls_df['O_GROUP'] == my_onet_level)].copy()\n",
    "        sector_df = sector_df.drop_duplicates()\n",
    "\n",
    "        # Clean TOT_EMP: coerce to numeric, set non-integer and NaN values to 0\n",
    "        sector_df['TOT_EMP'] = pd.to_numeric(sector_df['TOT_EMP'], errors='coerce')\n",
    "        # Identify non-integer entries (fractional values) and set them to 0\n",
    "        non_integer_mask = sector_df['TOT_EMP'].notna() & (sector_df['TOT_EMP'] % 1 != 0)\n",
    "        if non_integer_mask.any():\n",
    "            num_non_int = non_integer_mask.sum()\n",
    "            print(f\"Setting {num_non_int} non-integer TOT_EMP values to 0\")\n",
    "            sector_df.loc[non_integer_mask, 'TOT_EMP'] = 0\n",
    "\n",
    "        # Replace remaining NaN with 0 and cast to integer\n",
    "        sector_df['TOT_EMP'] = sector_df['TOT_EMP'].fillna(0).astype(int)\n",
    "\n",
    "        # percentiles to compute\n",
    "        pct = [0.01, 1, 5, 10, 25, 50, 75, 90, 99, 99.9, 99.99]\n",
    "\n",
    "        # prepare the series: coerce to numeric and drop NaNs\n",
    "        vals = pd.to_numeric(sector_df[sector_df['TOT_EMP'] > 0]['TOT_EMP'], errors='coerce').dropna()\n",
    "\n",
    "        if len(vals) == 0:\n",
    "            print(\"No numeric TOT_EMP values found in sector_df.\")\n",
    "        else:\n",
    "            # Using pandas quantile (q expects [0-1])\n",
    "            qs = [p / 100.0 for p in pct]\n",
    "            pct_values = vals.quantile(q=qs)\n",
    "\n",
    "            # Print nicely\n",
    "            # for p, v in zip(pct, pct_values):\n",
    "            #     print(f\"{p}th percentile: {v:,.0f}\")\n",
    "\n",
    "            # Optional: save to CSV (per-sector file)\n",
    "            out = pd.DataFrame({\n",
    "                'percentile': pct,\n",
    "                'TOT_EMP': pct_values.values\n",
    "            })\n",
    "            out_dir = f'{output_data_path}/BLS_ONET_empShares/percentiles'\n",
    "            os.makedirs(out_dir, exist_ok=True)\n",
    "            out_file = os.path.join(out_dir, f'TOTEMP_pctle_BLS{my_sector}_ONET{my_onet_level}.csv')\n",
    "            out.to_csv(out_file, index=False)\n",
    "            # print(f\"Saved percentiles to {out_file}\")\n",
    "\n",
    "        # Compute employment shares\n",
    "        # 1) add total sector employment and sector shares\n",
    "        sector_df = sector_df.merge(sector_total_shares_df, on='NAICS', how='left')\n",
    "\n",
    "        # 2) occ_sectorEmpShare: share of employment within the NAICS / NAICS_TITLE group\n",
    "        group_cols = ['NAICS', 'NAICS_TITLE']\n",
    "        group_total = sector_df.groupby(group_cols)['totalSectorEmp'].transform('first')\n",
    "        sector_df['occ_sectorEmpShare'] = (sector_df['TOT_EMP'] / group_total).fillna(0)\n",
    "\n",
    "        # 3) occ_totalEmpShare: share of employment across the entire economy\n",
    "        total_emp = sector_total_shares_df[['NAICS', 'totalSectorEmp']].drop_duplicates().sum()['totalSectorEmp']\n",
    "        sector_df['occ_totalEmpShare'] = sector_df['TOT_EMP'] / total_emp\n",
    "\n",
    "        # Save sector_df for further analysis (overwrites previous file)\n",
    "        out_dir = f'{output_data_path}/BLS_ONET_empShares'\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        sector_df.to_csv(f'{out_dir}/BLS{my_sector}_ONET{my_onet_level}_empShares.csv', index=False)\n",
    "        print(f\"✓ {my_sector}-level BLS data at {my_onet_level} ONET Level saved with {sector_df.shape[0]:,} rows\")\n",
    "\n",
    "        # # Calculate counts per occupation title grouped by NAICS, I_GROUP, OCC_TITLE, OCC_CODE\n",
    "        # # - row_count: total rows in sector_df for the group\n",
    "        # # - unique_OCC_CODE: number of unique OCC_CODE per (NAICS, I_GROUP, OCC_TITLE) (if OCC_CODE exists)\n",
    "\n",
    "        # required_cols = ['NAICS', 'OCC_TITLE', 'OCC_CODE']\n",
    "\n",
    "        # # Count rows per exact group (OCC_TITLE, OCC_CODE)\n",
    "        # counts_df = sector_df.groupby(['NAICS', 'OCC_TITLE', 'OCC_CODE']).size().rename('row_count').reset_index()\n",
    "\n",
    "        # # Sort by row_count descending\n",
    "        # counts_df = counts_df.sort_values(by=['row_count'], ascending=False).reset_index(drop=True)\n",
    "\n",
    "        # # Sanity check -- max row count must be one\n",
    "        # max_unique_occ_codes = counts_df['row_count'].max()\n",
    "        # print(f\"Max unique OCC_CODE per (NAICS, OCC_TITLE): {max_unique_occ_codes}\")\n",
    "\n",
    "        # # Calculate NAICS per occupation code\n",
    "        # naics_per_occ_code = sector_df.groupby(['OCC_TITLE', 'OCC_CODE'])['NAICS'].nunique().reset_index()\n",
    "        # naics_per_occ_code = naics_per_occ_code.rename(columns={'NAICS': 'num_unique_NAICS_per_OCC_CODE'})\n",
    "        # naics_per_occ_code = naics_per_occ_code.sort_values(by=['num_unique_NAICS_per_OCC_CODE', 'OCC_CODE'], ascending=[False, True]).reset_index(drop=True)\n",
    "\n",
    "        # # Save the NAICS per OCC_CODE data\n",
    "        # # naics_per_occ_code.to_csv(f'{output_data_path}/naics_per_occ_code_counts.csv', index=False)\n",
    "        # print(f\"✓ NAICS per OCC_CODE data saved with {naics_per_occ_code.shape[0]:,} rows\")\n",
    "        # display(naics_per_occ_code.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891563ec",
   "metadata": {},
   "source": [
    "### Reshuffle TOT_EMP Values 1000 Times to Randomize Weights at (sector-detailed) Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81be8f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshuffling iteration 0...\n",
      "Reshuffling iteration 50...\n",
      "Reshuffling iteration 100...\n",
      "Reshuffling iteration 150...\n",
      "Reshuffling iteration 200...\n",
      "Reshuffling iteration 250...\n",
      "Reshuffling iteration 300...\n",
      "Reshuffling iteration 350...\n",
      "Reshuffling iteration 400...\n",
      "Reshuffling iteration 450...\n",
      "Reshuffling iteration 500...\n",
      "Reshuffling iteration 550...\n",
      "Reshuffling iteration 600...\n",
      "Reshuffling iteration 650...\n",
      "Reshuffling iteration 700...\n",
      "Reshuffling iteration 750...\n",
      "Reshuffling iteration 800...\n",
      "Reshuffling iteration 850...\n",
      "Reshuffling iteration 900...\n",
      "Reshuffling iteration 950...\n"
     ]
    }
   ],
   "source": [
    "my_sector = 'sector' \n",
    "my_onet_level = 'detailed' \n",
    "sector_df = bls_df[(bls_df['I_GROUP'] == my_sector) & (bls_df['O_GROUP'] == my_onet_level)].copy()\n",
    "sector_df = sector_df.drop_duplicates()\n",
    "\n",
    "# Set variables\n",
    "iterations = 1000\n",
    "\n",
    "output_dir = f'{output_data_path}/BLS_ONET_empShares/BLS{my_sector}_ONET{my_onet_level}_reshuffledWeights'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "results = []\n",
    "for i in range(iterations):\n",
    "    output_path = f\"{output_dir}/BLS{my_sector}_ONET{my_onet_level}_empShares_iter{i+1}.csv\"\n",
    "    if os.path.exists(output_path):\n",
    "        continue\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        print(f\"Reshuffling iteration {i}\")\n",
    "\n",
    "    # shuffle TOT_EMP values\n",
    "    shuffled = np.random.permutation(sector_df['TOT_EMP'].values)\n",
    "    \n",
    "    # Make a copy with shuffled values\n",
    "    shuffled_df = sector_df.copy()\n",
    "    shuffled_df['TOT_EMP'] = shuffled\n",
    "\n",
    "    # Save reshuffled data\n",
    "    shuffled_df.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
