{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc7fc397",
   "metadata": {},
   "source": [
    "#### By: Peyman Shahidi\n",
    "#### Created: Nov 10, 2025\n",
    "#### Last Edit: Nov 10, 2025\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10366af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python\n",
    "import getpass\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "import random \n",
    "\n",
    "## formatting number to appear comma separated and with two digits after decimal: e.g, 1000 shown as 1,000.00\n",
    "pd.set_option('float_format', \"{:,.2f}\".format)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "#from matplotlib.legend import Legend\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519e43cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder_path = \"..\"\n",
    "input_data_path = f\"{main_folder_path}/data\"\n",
    "output_data_path = f'{input_data_path}/computed_objects'\n",
    "output_plot_path = f\"{main_folder_path}/writeup/plots\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e6e6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories if they don't exist\n",
    "import os\n",
    "\n",
    "for path in [output_data_path, output_plot_path]:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2038cb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the merged data\n",
    "merged_data = pd.read_csv(f\"{input_data_path}/computed_objects/ONET_Eloundou_Anthropic_GPT/ONET_Eloundou_Anthropic_GPT.csv\")\n",
    "merged_data = merged_data[['O*NET-SOC Code', 'Occupation Title', 'Task ID', 'Task Title',\n",
    "       'Task Position', 'Task Type', \n",
    "       'Major_Group_Code', 'Major_Group_Title', \n",
    "       'Minor_Group_Code', 'Minor_Group_Title',\n",
    "       'Broad_Occupation_Code', 'Broad_Occupation_Title',\n",
    "       'Detailed_Occupation_Code', 'Detailed_Occupation_Title',\n",
    "       'gpt4_exposure', 'human_labels', \n",
    "       'automation', 'augmentation', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0340c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drop the supplemental tasks\n",
    "# merged_data = merged_data[merged_data['Task Type'] != 'Supplemental'].reset_index(drop=True)\n",
    "\n",
    "# # Drop rows whose Occupation Title includes 'Teachers, Postsecondary'\n",
    "# merged_data = merged_data[~merged_data['Occupation Title'].str.contains('Teachers, Postsecondary')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617af65e",
   "metadata": {},
   "source": [
    "## Determine AI Chains using one of two definitions:\n",
    "1) Treat all AI tasks the same\n",
    "2) Model definition: starts with Automation and terminated by Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6363b238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Chain Definition 1: treat Augmentation and Automation as AI tasks\n",
    "group_cols = ['O*NET-SOC Code', 'Occupation Title']\n",
    "\n",
    "# Determine AI chains\n",
    "def create_ai_chains_df_def1(df, group_cols):\n",
    "    # Create is_ai column\n",
    "    ai_chains_df = df.copy()\n",
    "    ai_chains_df = ai_chains_df.sort_values(by=group_cols + ['Task Position']).reset_index(drop=True)\n",
    "    ai_chains_df['is_ai'] = ai_chains_df['label'].isin(['Augmentation', 'Automation']).astype(int)\n",
    "\n",
    "    # Create next_is_ai column within occupation groups\n",
    "    ai_chains_df['next_is_ai'] = ai_chains_df.groupby(group_cols)['is_ai'].shift(-1).fillna(0).astype(int)\n",
    "\n",
    "    # Determine if task is part of an AI chain\n",
    "    ai_chains_df['ai_chain'] = 0\n",
    "    ai_chain_logic = (ai_chains_df['is_ai'] == 1) & (ai_chains_df['next_is_ai'] == 1)\n",
    "    ai_chains_df.loc[ai_chain_logic, 'ai_chain'] = 1\n",
    "\n",
    "    # Flag for switching from AI chain to non-AI task\n",
    "    ai_chains_df['ai_chain_end'] = 0\n",
    "    ai_chains_df.loc[(ai_chains_df['is_ai'] == 1) & (ai_chains_df['next_is_ai'] == 0), 'ai_chain_end'] = 1\n",
    "\n",
    "\n",
    "    # Calculate AI chain ids and lengths\n",
    "    # Approach: within each occupation, detect starts of contiguous runs of is_ai (current is_ai==1 and previous is_ai!=1),\n",
    "    # assign an incrementing chain id for those runs, then compute the length of each chain and the number of chains per occupation.\n",
    "    # previous task's is_ai (within occupation)\n",
    "    ai_chains_df['prev_is_ai'] = ai_chains_df.groupby(group_cols)['is_ai'].shift(1).fillna(0).astype(int)\n",
    "    # mark start of a new chain when current is AI and previous is not\n",
    "    ai_chains_df['start_chain'] = ((ai_chains_df['is_ai'] == 1) & (ai_chains_df['prev_is_ai'] == 0)).astype(int)\n",
    "    # cumulative sum of starts per occupation gives a chain id (0 if never started)\n",
    "    ai_chains_df['chain_id'] = ai_chains_df.groupby(group_cols)['start_chain'].cumsum()\n",
    "    # Non-AI tasks shouldn't have a chain id; set to NA for clarity\n",
    "    ai_chains_df.loc[ai_chains_df['is_ai'] == 0, 'chain_id'] = pd.NA\n",
    "\n",
    "\n",
    "    # Compute chain lengths (only for AI tasks/chain ids)\n",
    "    chain_lengths = (\n",
    "        ai_chains_df[ai_chains_df['is_ai'] == 1]\n",
    "        .groupby(group_cols + ['chain_id'])\n",
    "        .size()\n",
    "        .reset_index(name='chain_length')\n",
    "    )\n",
    "    # Attach chain lengths back to the main df\n",
    "    ai_chains_df = ai_chains_df.merge(chain_lengths, on=group_cols + ['chain_id'], how='left')\n",
    "\n",
    "    # Number of AI chains per occupation\n",
    "    num_chains = (\n",
    "        chain_lengths.groupby(group_cols)['chain_id']\n",
    "        .nunique()\n",
    "        .reset_index(name='num_ai_chains')\n",
    "    )\n",
    "    ai_chains_df = ai_chains_df.merge(num_chains, on=group_cols, how='left')\n",
    "    ai_chains_df['num_ai_chains'] = ai_chains_df['num_ai_chains'].fillna(0).astype(int)\n",
    "\n",
    "    # For convenience: fill chain_length = 0 for non-AI rows\n",
    "    ai_chains_df['chain_length'] = ai_chains_df['chain_length'].fillna(0).astype(int)\n",
    "\n",
    "    # Remove irrelevant columns\n",
    "    ai_chains_df = ai_chains_df.drop(columns=['prev_is_ai','start_chain'])\n",
    "\n",
    "    # Calculate mean length of AI chains and number of AI chains across entire dataset\n",
    "    mean_chain_length = chain_lengths['chain_length'].mean()\n",
    "    num_ai_chains = ai_chains_df['num_ai_chains'].sum()\n",
    "\n",
    "    return ai_chains_df, chain_lengths, mean_chain_length, num_ai_chains\n",
    "\n",
    "\n",
    "# Run\n",
    "ai_chains_df, chain_lengths, mean_chain_length, num_ai_chains = create_ai_chains_df_def1(merged_data, group_cols)\n",
    "print(f'Mean AI Chain Length (treating all AI tasks the same) is: {mean_chain_length:.2f}')\n",
    "print(f'Number of AI Chains (treating all AI tasks the same) is: {num_ai_chains}')\n",
    "\n",
    "# # Show sample occupation to verify (15-1251.00)\n",
    "# display_cols = ['O*NET-SOC Code', 'Occupation Title', 'Task ID', 'Task Title', 'Task Position', 'label', 'ai_chain', 'chain_id', 'chain_length', 'num_ai_chains']\n",
    "# display(ai_chains_df[ai_chains_df['O*NET-SOC Code'] == '15-1251.00'][display_cols].head(30))\n",
    "\n",
    "# Summarise distribution of chain lengths across occupations\n",
    "chain_summary = chain_lengths.groupby('chain_length').size().reset_index(name='count')\n",
    "chain_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e5ab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Chain Definition 2: starts with Automation and terminated by Augmentation task\n",
    "group_cols = ['O*NET-SOC Code', 'Occupation Title']\n",
    "\n",
    "# Determine AI chains\n",
    "def create_ai_chains_df_def2(df, group_cols):\n",
    "    # Create is_automated and is_augmented columns\n",
    "    ai_chains_df = df.copy()\n",
    "    ai_chains_df = ai_chains_df.sort_values(by=group_cols + ['Task Position']).reset_index(drop=True)\n",
    "    ai_chains_df['is_automated'] = ai_chains_df['label'].isin(['Automation']).astype(int)\n",
    "    ai_chains_df['is_augmented'] = ai_chains_df['label'].isin(['Augmentation']).astype(int)\n",
    "\n",
    "    # Create next_is_automated column within occupation groups\n",
    "    ai_chains_df['next_is_automated'] = ai_chains_df.groupby(['O*NET-SOC Code', 'Occupation Title'])['is_automated'].shift(-1).fillna(0).astype(int)\n",
    "    ai_chains_df['next_is_augmented'] = ai_chains_df.groupby(['O*NET-SOC Code', 'Occupation Title'])['is_augmented'].shift(-1).fillna(0).astype(int)\n",
    "\n",
    "    # Determine if task is part of an AI chain\n",
    "    ai_chains_df['ai_chain'] = 0\n",
    "    ai_chain_logic = (ai_chains_df['is_augmented'] == 1) | ((ai_chains_df['is_automated'] == 1) & ((ai_chains_df['next_is_automated'] == 1) | (ai_chains_df['next_is_augmented'] == 1)))\n",
    "    ai_chains_df.loc[ai_chain_logic, 'ai_chain'] = 1\n",
    "\n",
    "    # Flag for switching from AI chain to non-AI task\n",
    "    ai_chains_df['ai_chain_end'] = ai_chains_df['is_augmented']\n",
    "\n",
    "\n",
    "    # Calculate AI chain ids and lengths\n",
    "    # Assign an incrementing chain id for those runs, then compute the length of each chain and the number of chains per occupation.\n",
    "    # previous task's is_ai (within occupation)\n",
    "    ai_chains_df['prev_is_ai_chain'] = ai_chains_df.groupby(group_cols)['ai_chain'].shift(1).fillna(0).astype(int)\n",
    "    ai_chains_df['prev_ai_chain_ends'] = ai_chains_df.groupby(group_cols)['ai_chain_end'].shift(1).fillna(0).astype(int)\n",
    "    # mark start of a new chain when current is AI and previous is not\n",
    "    ai_chains_df['start_chain'] = (((ai_chains_df['ai_chain'] == 1) & (ai_chains_df['prev_is_ai_chain'] == 0)) | (ai_chains_df['ai_chain'] == 1) & (ai_chains_df['prev_is_ai_chain'] == 1) & (ai_chains_df['prev_ai_chain_ends'] == 1)).astype(int)\n",
    "    # cumulative sum of starts per occupation gives a chain id (0 if never started)\n",
    "    ai_chains_df['chain_id'] = ai_chains_df.groupby(group_cols)['start_chain'].cumsum()\n",
    "    # Non-AI tasks shouldn't have a chain id; set to NA for clarity\n",
    "    ai_chains_df.loc[ai_chains_df['ai_chain'] == 0, 'chain_id'] = pd.NA\n",
    "\n",
    "    # Compute chain lengths (only for AI tasks/chain ids)\n",
    "    chain_lengths = (\n",
    "        ai_chains_df[(ai_chains_df['ai_chain'] == 1)]\n",
    "        .groupby(group_cols + ['chain_id'])\n",
    "        .size()\n",
    "        .reset_index(name='chain_length')\n",
    "    )\n",
    "    # Attach chain lengths back to the main df\n",
    "    ai_chains_df = ai_chains_df.merge(chain_lengths, on=group_cols + ['chain_id'], how='left')\n",
    "\n",
    "    # Number of AI chains per occupation\n",
    "    num_chains = (\n",
    "        chain_lengths.groupby(group_cols)['chain_id']\n",
    "        .nunique()\n",
    "        .reset_index(name='num_ai_chains')\n",
    "    )\n",
    "    ai_chains_df = ai_chains_df.merge(num_chains, on=group_cols, how='left')\n",
    "    ai_chains_df['num_ai_chains'] = ai_chains_df['num_ai_chains'].fillna(0).astype(int)\n",
    "\n",
    "    # For convenience: fill chain_length = 0 for non-AI rows\n",
    "    ai_chains_df['chain_length'] = ai_chains_df['chain_length'].fillna(0).astype(int)\n",
    "\n",
    "    # Remove irrelevant columns\n",
    "    ai_chains_df = ai_chains_df.drop(columns=['is_automated','is_augmented', 'prev_is_ai_chain', 'prev_ai_chain_ends', 'start_chain', 'ai_chain_end'])\n",
    "\n",
    "    # Calculate mean length of AI chains and number of AI chains across entire dataset\n",
    "    mean_chain_length = chain_lengths['chain_length'].mean()\n",
    "    num_ai_chains = ai_chains_df['num_ai_chains'].sum()\n",
    "\n",
    "    return ai_chains_df, chain_lengths, mean_chain_length, num_ai_chains\n",
    "\n",
    "\n",
    "# Run\n",
    "ai_chains_df, chain_lengths, mean_chain_length, num_ai_chains = create_ai_chains_df_def2(merged_data, group_cols)\n",
    "print(f'Mean AI Chain Length (treating all AI tasks the same) is: {mean_chain_length:.2f}')\n",
    "print(f'Number of AI Chains (treating all AI tasks the same) is: {num_ai_chains}')\n",
    "\n",
    "# # Show sample occupation to verify (15-1251.00)\n",
    "# display_cols = ['O*NET-SOC Code', 'Occupation Title', 'Task ID', 'Task Title', 'Task Position', 'label', 'ai_chain', 'chain_id', 'chain_length', 'num_ai_chains']\n",
    "# display(ai_chains_df[ai_chains_df['O*NET-SOC Code'] == '15-1251.00'][display_cols].head(30))\n",
    "\n",
    "# Summarise distribution of chain lengths across occupations\n",
    "chain_summary = chain_lengths.groupby('chain_length').size().reset_index(name='count')\n",
    "chain_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9489f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshuffle Task Positions within each occupation and recompute AI chain statistics\n",
    "n_shuffles = 1000\n",
    "\n",
    "results_d1 = []\n",
    "results_d2 = []\n",
    "\n",
    "# Original run\n",
    "ai_chains_df, chain_lengths, mean_chain_length, num_ai_chains = create_ai_chains_df_def1(merged_data, group_cols)\n",
    "results_d1.append({\n",
    "    'shuffle_index': 0,\n",
    "    'mean_chain_length': mean_chain_length,\n",
    "    'num_ai_chains': num_ai_chains\n",
    "})\n",
    "\n",
    "ai_chains_df, chain_lengths, mean_chain_length, num_ai_chains = create_ai_chains_df_def2(merged_data, group_cols)\n",
    "results_d2.append({\n",
    "    'shuffle_index': 0,\n",
    "    'mean_chain_length': mean_chain_length,\n",
    "    'num_ai_chains': num_ai_chains\n",
    "})\n",
    "\n",
    "# Save mean_chain_length and num_ai_chains for plotting later\n",
    "mean_chain_length_list = [results_d1[0]['mean_chain_length'], results_d2[0]['mean_chain_length']]\n",
    "num_ai_chains_list = [results_d1[0]['num_ai_chains'], results_d2[0]['num_ai_chains']]\n",
    "\n",
    "\n",
    "# Run shuffles\n",
    "for i in range(1, n_shuffles + 1):\n",
    "    if i % 50 == 0:\n",
    "        print(f'Processing shuffle {i} out of {n_shuffles}')\n",
    "\n",
    "    seed = 42 + i\n",
    "\n",
    "    # Prepared shuffled dataframe\n",
    "    df_shuf = merged_data.copy()\n",
    "    df_shuf['Task Position'] = df_shuf.groupby(group_cols)['Task Position'].transform(\n",
    "        lambda x: x.sample(frac=1, random_state=seed).values\n",
    "    )\n",
    "\n",
    "    # Definition 1:\n",
    "    ai_chains_df_shuf_def1, chain_lengths_shuf_def1, mean_chain_length_shuf_def1, num_ai_chains_shuf_def1 = create_ai_chains_df_def1(df_shuf, group_cols)\n",
    "    results_d1.append({\n",
    "        'shuffle_index': i,\n",
    "        'mean_chain_length': mean_chain_length_shuf_def1,\n",
    "        'num_ai_chains': num_ai_chains_shuf_def1\n",
    "    })\n",
    "\n",
    "    # Definition 2:\n",
    "    ai_chains_df_shuf_def2, chain_lengths_shuf_def2, mean_chain_length_shuf_def2, num_ai_chains_shuf_def2 = create_ai_chains_df_def2(df_shuf, group_cols)\n",
    "    results_d2.append({\n",
    "        'shuffle_index': i,\n",
    "        'mean_chain_length': mean_chain_length_shuf_def2,\n",
    "        'num_ai_chains': num_ai_chains_shuf_def2\n",
    "    })\n",
    "\n",
    "# Save results\n",
    "results_df_def1 = pd.DataFrame(results_d1)\n",
    "results_df_def2 = pd.DataFrame(results_d2)\n",
    "results_df_def1.to_csv(f\"{output_data_path}/aiChains_results_definition1.csv\", index=False)\n",
    "results_df_def2.to_csv(f\"{output_data_path}/aiChains_results_definition2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bf07e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plot_titles = ['Any Contiguous Sequence of AI Tasks', 'Starts with Automation or Augmentation and Ends with first Augmentation after Start']\n",
    "\n",
    "\n",
    "for def_idx, results_df in enumerate([results_df_def1, results_df_def2]):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "    num_ai_chains = results_df['num_ai_chains'].mean()\n",
    "    mean_chain_length = results_df['mean_chain_length'].mean()\n",
    "\n",
    "    # ---- Left plot: Number of AI Chains ----\n",
    "    axes[0].hist(results_df['num_ai_chains'], bins=30, color='steelblue', edgecolor='black')\n",
    "    axes[0].axvline(x=num_ai_chains_list[def_idx], color='red', linestyle='dashed', linewidth=2,\n",
    "                    label=f'Observed Number of AI Chains = {num_ai_chains_list[def_idx]}')\n",
    "    axes[0].set_xlabel('Number of AI Chains')\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "    axes[0].legend()\n",
    "    # axes[0].set_xlim(35000, 41000)\n",
    "\n",
    "    # ---- Right plot: Mean Chain Length ----\n",
    "    axes[1].hist(results_df['mean_chain_length'], bins=30, color='orange', edgecolor='black')\n",
    "    axes[1].axvline(x=mean_chain_length_list[def_idx], color='red', linestyle='dashed', linewidth=2,\n",
    "                    label=f'Observed Mean Chain Length = {mean_chain_length_list[def_idx]:.2f}')\n",
    "    axes[1].set_xlabel('Mean AI Chain Length')\n",
    "    axes[1].set_ylabel('Frequency')\n",
    "    axes[1].legend()\n",
    "    # axes[1].set_xlim(1, 1.5)\n",
    "\n",
    "    fig.suptitle(f'Reshuffled vs. Observed AI Chain Measures (n={n_shuffles})\\n\\nAI Chain Definition: {plot_titles[def_idx]}', fontsize=16, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_plot_path}/aiChains_count_length_definition{def_idx}.png\", dpi=300)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
