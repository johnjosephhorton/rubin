{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc7fc397",
   "metadata": {},
   "source": [
    "#### By: Peyman Shahidi\n",
    "#### Created: Nov 10, 2025\n",
    "#### Last Edit: Jan 30, 2026\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10366af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python\n",
    "import getpass\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "import random \n",
    "\n",
    "## formatting number to appear comma separated and with two digits after decimal: e.g, 1000 shown as 1,000.00\n",
    "pd.set_option('float_format', \"{:,.2f}\".format)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "#from matplotlib.legend import Legend\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "519e43cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder_path = \"..\"\n",
    "input_data_path = f\"{main_folder_path}/data\"\n",
    "output_data_path = f'{input_data_path}/computed_objects/aiChain_length_count'\n",
    "output_plot_path = f\"{main_folder_path}/writeup/plots/aiChain_length_count\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84e6e6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories if they don't exist\n",
    "import os\n",
    "\n",
    "for path in [output_data_path, output_plot_path]:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2038cb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the merged data\n",
    "merged_data = pd.read_csv(f\"{input_data_path}/computed_objects/ONET_Eloundou_Anthropic_GPT/ONET_Eloundou_Anthropic_GPT.csv\")\n",
    "merged_data = merged_data[['O*NET-SOC Code', 'Occupation Title', 'Task ID', 'Task Title',\n",
    "       'Task Position', 'Task Type', \n",
    "       'Major_Group_Code', 'Major_Group_Title', \n",
    "       'Minor_Group_Code', 'Minor_Group_Title',\n",
    "       'Broad_Occupation_Code', 'Broad_Occupation_Title',\n",
    "       'Detailed_Occupation_Code', 'Detailed_Occupation_Title',\n",
    "       'gpt4_exposure', 'human_labels', \n",
    "       'automation', 'augmentation', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da0340c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drop the supplemental tasks\n",
    "# merged_data = merged_data[merged_data['Task Type'] != 'Supplemental'].reset_index(drop=True)\n",
    "\n",
    "# # Drop rows whose Occupation Title includes 'Teachers, Postsecondary'\n",
    "# merged_data = merged_data[~merged_data['Occupation Title'].str.contains('Teachers, Postsecondary')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617af65e",
   "metadata": {},
   "source": [
    "## Determine AI Chains using one of two definitions:\n",
    "1) Treat all AI tasks the same\n",
    "2) Model definition: starts with Automation and terminated by Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6363b238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average AI Chain Length (treating all AI tasks the same) is: 1.45\n",
      "Average Average Number of AI Chains (treating all AI tasks the same) is: 2.0986889818688983\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chain_length</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chain_length  count\n",
       "0             1   1154\n",
       "1             2    308\n",
       "2             3     96\n",
       "3             4     43\n",
       "4             5     16\n",
       "5             6      2\n",
       "6             7      2\n",
       "7            11      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AI Chain Definition 1: treat Augmentation and Automation as AI tasks\n",
    "group_cols = ['O*NET-SOC Code', 'Occupation Title']\n",
    "\n",
    "# Determine AI chains\n",
    "def create_ai_chains_df_def1(df, group_cols):\n",
    "    # Create is_ai column\n",
    "    ai_chains_df = df.copy()\n",
    "    ai_chains_df = ai_chains_df.sort_values(by=group_cols + ['Task Position']).reset_index(drop=True)\n",
    "    ai_chains_df['is_ai'] = ai_chains_df['label'].isin(['Augmentation', 'Automation']).astype(int)\n",
    "\n",
    "    # Create next_is_ai column within occupation groups\n",
    "    ai_chains_df['next_is_ai'] = ai_chains_df.groupby(group_cols)['is_ai'].shift(-1).fillna(0).astype(int)\n",
    "\n",
    "    # Determine if task is part of an AI chain\n",
    "    ai_chains_df['ai_chain'] = 0\n",
    "    ai_chain_logic = (ai_chains_df['is_ai'] == 1) & (ai_chains_df['next_is_ai'] == 1)\n",
    "    ai_chains_df.loc[ai_chain_logic, 'ai_chain'] = 1\n",
    "\n",
    "    # Flag for switching from AI chain to non-AI task\n",
    "    ai_chains_df['ai_chain_end'] = 0\n",
    "    ai_chains_df.loc[(ai_chains_df['is_ai'] == 1) & (ai_chains_df['next_is_ai'] == 0), 'ai_chain_end'] = 1\n",
    "\n",
    "\n",
    "    # Calculate AI chain ids and lengths\n",
    "    # Approach: within each occupation, detect starts of contiguous runs of is_ai (current is_ai==1 and previous is_ai!=1),\n",
    "    # assign an incrementing chain id for those runs, then compute the length of each chain and the number of chains per occupation.\n",
    "    # previous task's is_ai (within occupation)\n",
    "    ai_chains_df['prev_is_ai'] = ai_chains_df.groupby(group_cols)['is_ai'].shift(1).fillna(0).astype(int)\n",
    "    # mark start of a new chain when current is AI and previous is not\n",
    "    ai_chains_df['start_chain'] = ((ai_chains_df['is_ai'] == 1) & (ai_chains_df['prev_is_ai'] == 0)).astype(int)\n",
    "    # cumulative sum of starts per occupation gives a chain id (0 if never started)\n",
    "    ai_chains_df['chain_id'] = ai_chains_df.groupby(group_cols)['start_chain'].cumsum()\n",
    "    # Non-AI tasks shouldn't have a chain id; set to NA for clarity\n",
    "    ai_chains_df.loc[ai_chains_df['is_ai'] == 0, 'chain_id'] = pd.NA\n",
    "\n",
    "\n",
    "    # Compute chain lengths (only for AI tasks/chain ids)\n",
    "    chain_lengths = (\n",
    "        ai_chains_df[ai_chains_df['is_ai'] == 1]\n",
    "        .groupby(group_cols + ['chain_id'])\n",
    "        .size()\n",
    "        .reset_index(name='chain_length')\n",
    "    )\n",
    "    # Attach chain lengths back to the main df\n",
    "    ai_chains_df = ai_chains_df.merge(chain_lengths, on=group_cols + ['chain_id'], how='left')\n",
    "\n",
    "    # Average Number of AI Chains per occupation\n",
    "    num_chains = (\n",
    "        chain_lengths.groupby(group_cols)['chain_id']\n",
    "        .nunique()\n",
    "        .reset_index(name='num_ai_chains')\n",
    "    )\n",
    "    ai_chains_df = ai_chains_df.merge(num_chains, on=group_cols, how='left')\n",
    "    ai_chains_df['num_ai_chains'] = ai_chains_df['num_ai_chains'].fillna(0).astype(int)\n",
    "\n",
    "    # For convenience: fill chain_length = 0 for non-AI rows\n",
    "    ai_chains_df['chain_length'] = ai_chains_df['chain_length'].fillna(0).astype(int)\n",
    "\n",
    "    # Remove irrelevant columns\n",
    "    ai_chains_df = ai_chains_df.drop(columns=['prev_is_ai','start_chain'])\n",
    "\n",
    "    # Calculate mean length of AI chains and Average Number of AI Chains across entire dataset\n",
    "    mean_chain_length = chain_lengths['chain_length'].mean()\n",
    "    num_ai_chains = ai_chains_df['num_ai_chains'].mean()\n",
    "\n",
    "    return ai_chains_df, chain_lengths, mean_chain_length, num_ai_chains\n",
    "\n",
    "\n",
    "# Run\n",
    "ai_chains_df, chain_lengths, mean_chain_length, num_ai_chains = create_ai_chains_df_def1(merged_data, group_cols)\n",
    "print(f'Average AI Chain Length (treating all AI tasks the same) is: {mean_chain_length:.2f}')\n",
    "print(f'Average Average Number of AI Chains (treating all AI tasks the same) is: {num_ai_chains}')\n",
    "\n",
    "# # Show sample occupation to verify (15-1251.00)\n",
    "# display_cols = ['O*NET-SOC Code', 'Occupation Title', 'Task ID', 'Task Title', 'Task Position', 'label', 'ai_chain', 'chain_id', 'chain_length', 'num_ai_chains']\n",
    "# display(ai_chains_df[ai_chains_df['O*NET-SOC Code'] == '15-1251.00'][display_cols].head(30))\n",
    "\n",
    "# Summarise distribution of chain lengths across occupations\n",
    "chain_summary = chain_lengths.groupby('chain_length').size().reset_index(name='count')\n",
    "chain_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5e5ab4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average AI Chain Length (treating all AI tasks the same) is: 1.09\n",
      "Average Number of AI Chains (treating all AI tasks the same) is: 2.184937238493724\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chain_length</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chain_length  count\n",
       "0             1   1585\n",
       "1             2    100\n",
       "2             3     22\n",
       "3             4      6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AI Chain Definition 2: starts with Automation and terminated by Augmentation task\n",
    "group_cols = ['O*NET-SOC Code', 'Occupation Title']\n",
    "\n",
    "# Determine AI chains\n",
    "def create_ai_chains_df_def2(df, group_cols):\n",
    "    # Create is_automated and is_augmented columns\n",
    "    ai_chains_df = df.copy()\n",
    "    ai_chains_df = ai_chains_df.sort_values(by=group_cols + ['Task Position']).reset_index(drop=True)\n",
    "    ai_chains_df['is_automated'] = ai_chains_df['label'].isin(['Automation']).astype(int)\n",
    "    ai_chains_df['is_augmented'] = ai_chains_df['label'].isin(['Augmentation']).astype(int)\n",
    "\n",
    "    # Create next_is_automated column within occupation groups\n",
    "    ai_chains_df['next_is_automated'] = ai_chains_df.groupby(['O*NET-SOC Code', 'Occupation Title'])['is_automated'].shift(-1).fillna(0).astype(int)\n",
    "    ai_chains_df['next_is_augmented'] = ai_chains_df.groupby(['O*NET-SOC Code', 'Occupation Title'])['is_augmented'].shift(-1).fillna(0).astype(int)\n",
    "\n",
    "    # Determine if task is part of an AI chain\n",
    "    ai_chains_df['ai_chain'] = 0\n",
    "    ai_chain_logic = (ai_chains_df['is_augmented'] == 1) | ((ai_chains_df['is_automated'] == 1) & ((ai_chains_df['next_is_automated'] == 1) | (ai_chains_df['next_is_augmented'] == 1)))\n",
    "    ai_chains_df.loc[ai_chain_logic, 'ai_chain'] = 1\n",
    "\n",
    "    # Flag for switching from AI chain to non-AI task\n",
    "    ai_chains_df['ai_chain_end'] = ai_chains_df['is_augmented']\n",
    "\n",
    "\n",
    "    # Calculate AI chain ids and lengths\n",
    "    # Assign an incrementing chain id for those runs, then compute the length of each chain and the number of chains per occupation.\n",
    "    # previous task's is_ai (within occupation)\n",
    "    ai_chains_df['prev_is_ai_chain'] = ai_chains_df.groupby(group_cols)['ai_chain'].shift(1).fillna(0).astype(int)\n",
    "    ai_chains_df['prev_ai_chain_ends'] = ai_chains_df.groupby(group_cols)['ai_chain_end'].shift(1).fillna(0).astype(int)\n",
    "    # mark start of a new chain when current is AI and previous is not\n",
    "    ai_chains_df['start_chain'] = (((ai_chains_df['ai_chain'] == 1) & (ai_chains_df['prev_is_ai_chain'] == 0)) | (ai_chains_df['ai_chain'] == 1) & (ai_chains_df['prev_is_ai_chain'] == 1) & (ai_chains_df['prev_ai_chain_ends'] == 1)).astype(int)\n",
    "    # cumulative sum of starts per occupation gives a chain id (0 if never started)\n",
    "    ai_chains_df['chain_id'] = ai_chains_df.groupby(group_cols)['start_chain'].cumsum()\n",
    "    # Non-AI tasks shouldn't have a chain id; set to NA for clarity\n",
    "    ai_chains_df.loc[ai_chains_df['ai_chain'] == 0, 'chain_id'] = pd.NA\n",
    "\n",
    "    # Compute chain lengths (only for AI tasks/chain ids)\n",
    "    chain_lengths = (\n",
    "        ai_chains_df[(ai_chains_df['ai_chain'] == 1)]\n",
    "        .groupby(group_cols + ['chain_id'])\n",
    "        .size()\n",
    "        .reset_index(name='chain_length')\n",
    "    )\n",
    "    # Attach chain lengths back to the main df\n",
    "    ai_chains_df = ai_chains_df.merge(chain_lengths, on=group_cols + ['chain_id'], how='left')\n",
    "\n",
    "    # Average Number of AI Chains per occupation\n",
    "    num_chains = (\n",
    "        chain_lengths.groupby(group_cols)['chain_id']\n",
    "        .nunique()\n",
    "        .reset_index(name='num_ai_chains')\n",
    "    )\n",
    "    ai_chains_df = ai_chains_df.merge(num_chains, on=group_cols, how='left')\n",
    "    ai_chains_df['num_ai_chains'] = ai_chains_df['num_ai_chains'].fillna(0).astype(int)\n",
    "\n",
    "    # For convenience: fill chain_length = 0 for non-AI rows\n",
    "    ai_chains_df['chain_length'] = ai_chains_df['chain_length'].fillna(0).astype(int)\n",
    "\n",
    "    # Remove irrelevant columns\n",
    "    ai_chains_df = ai_chains_df.drop(columns=['is_automated','is_augmented', 'prev_is_ai_chain', 'prev_ai_chain_ends', 'start_chain', 'ai_chain_end'])\n",
    "\n",
    "    # Calculate mean length of AI chains and Average Number of AI Chains across entire dataset\n",
    "    mean_chain_length = chain_lengths['chain_length'].mean()\n",
    "    num_ai_chains = ai_chains_df['num_ai_chains'].mean()\n",
    "\n",
    "    return ai_chains_df, chain_lengths, mean_chain_length, num_ai_chains\n",
    "\n",
    "\n",
    "# Run\n",
    "ai_chains_df, chain_lengths, mean_chain_length, num_ai_chains = create_ai_chains_df_def2(merged_data, group_cols)\n",
    "print(f'Average AI Chain Length (treating all AI tasks the same) is: {mean_chain_length:.2f}')\n",
    "print(f'Average Number of AI Chains (treating all AI tasks the same) is: {num_ai_chains}')\n",
    "\n",
    "# # Show sample occupation to verify (15-1251.00)\n",
    "# display_cols = ['O*NET-SOC Code', 'Occupation Title', 'Task ID', 'Task Title', 'Task Position', 'label', 'ai_chain', 'chain_id', 'chain_length', 'num_ai_chains']\n",
    "# display(ai_chains_df[ai_chains_df['O*NET-SOC Code'] == '15-1251.00'][display_cols].head(30))\n",
    "\n",
    "# Summarise distribution of chain lengths across occupations\n",
    "chain_summary = chain_lengths.groupby('chain_length').size().reset_index(name='count')\n",
    "chain_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e744405",
   "metadata": {},
   "source": [
    "## Reshuffle Task Positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce9489f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshuffle Task Positions within each occupation and recompute AI chain statistics\n",
    "n_shuffles = 1000\n",
    "\n",
    "first_output_file = f\"{output_data_path}/aiChains_taskPositionReshuffle_definition1.csv\"\n",
    "second_output_file = f\"{output_data_path}/aiChains_taskPositionReshuffle_definition2.csv\"\n",
    "\n",
    "# Run shuffles if output files do not already exist\n",
    "if not os.path.exists(first_output_file) or not os.path.exists(second_output_file):\n",
    "    results_d1 = []\n",
    "    results_d2 = []\n",
    "\n",
    "    # Original run\n",
    "    ai_chains_df, chain_lengths, mean_chain_length, num_ai_chains = create_ai_chains_df_def1(merged_data, group_cols)\n",
    "    results_d1.append({\n",
    "        'shuffle_index': 0,\n",
    "        'mean_chain_length': mean_chain_length,\n",
    "        'num_ai_chains': num_ai_chains\n",
    "    })\n",
    "\n",
    "    ai_chains_df, chain_lengths, mean_chain_length, num_ai_chains = create_ai_chains_df_def2(merged_data, group_cols)\n",
    "    results_d2.append({\n",
    "        'shuffle_index': 0,\n",
    "        'mean_chain_length': mean_chain_length,\n",
    "        'num_ai_chains': num_ai_chains\n",
    "    })\n",
    "\n",
    "    # Run shuffles\n",
    "    for i in range(1, n_shuffles + 1):\n",
    "        if i % 50 == 0:\n",
    "            print(f'Processing shuffle {i} out of {n_shuffles}')\n",
    "\n",
    "        seed = 42 + i\n",
    "\n",
    "        # Prepared shuffled dataframe\n",
    "        df_shuf = merged_data.copy()\n",
    "        df_shuf['Task Position'] = df_shuf.groupby(group_cols)['Task Position'].transform(\n",
    "            lambda x: x.sample(frac=1, random_state=seed).values\n",
    "        )\n",
    "\n",
    "        # Definition 1:\n",
    "        ai_chains_df_shuf_def1, chain_lengths_shuf_def1, mean_chain_length_shuf_def1, num_ai_chains_shuf_def1 = create_ai_chains_df_def1(df_shuf, group_cols)\n",
    "        results_d1.append({\n",
    "            'shuffle_index': i,\n",
    "            'mean_chain_length': mean_chain_length_shuf_def1,\n",
    "            'num_ai_chains': num_ai_chains_shuf_def1\n",
    "        })\n",
    "\n",
    "        # Definition 2:\n",
    "        ai_chains_df_shuf_def2, chain_lengths_shuf_def2, mean_chain_length_shuf_def2, num_ai_chains_shuf_def2 = create_ai_chains_df_def2(df_shuf, group_cols)\n",
    "        results_d2.append({\n",
    "            'shuffle_index': i,\n",
    "            'mean_chain_length': mean_chain_length_shuf_def2,\n",
    "            'num_ai_chains': num_ai_chains_shuf_def2\n",
    "        })\n",
    "\n",
    "    # Save results\n",
    "    results_df_def1 = pd.DataFrame(results_d1)\n",
    "    results_df_def2 = pd.DataFrame(results_d2)\n",
    "    results_df_def1.to_csv(first_output_file, index=False)\n",
    "    results_df_def2.to_csv(second_output_file, index=False)\n",
    "else:\n",
    "    # Load results\n",
    "    results_df_def1 = pd.read_csv(first_output_file)\n",
    "    results_df_def2 = pd.read_csv(second_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4bf07e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "\n",
    "plot_titles = ['(#1): Any Contiguous Sequence of AI Tasks',\n",
    "               '(#2): Starts with Automation/Augmentation and Ends with first Augmentation after Start']\n",
    "\n",
    "for def_idx, results_df in enumerate([results_df_def1, results_df_def2]):\n",
    "\n",
    "    # =========================\n",
    "    # FIGURE 1 — num_ai_chains\n",
    "    # =========================\n",
    "    vals_left = results_df[1:]['num_ai_chains'] # Exclude first row as it's a repetition of original run\n",
    "    obs_left = results_df.iloc[0]['num_ai_chains']\n",
    "    pct_left = (vals_left < obs_left).mean() * 100\n",
    "\n",
    "    fig1, ax1 = plt.subplots(figsize=(8, 6))\n",
    "    ax1.xaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "\n",
    "    ax1.hist(vals_left, bins=30, color='steelblue', edgecolor='black',\n",
    "             label='Shuffled Task Positions')\n",
    "\n",
    "    ax1.axvline(obs_left, color='red', linestyle='dashed', linewidth=2,\n",
    "                label=f'Observed = {obs_left:.2f}')\n",
    "\n",
    "    ax1.set_xlabel('Average Number of AI Chains', fontsize=14)\n",
    "    ax1.set_ylabel('Frequency', fontsize=14)\n",
    "    ax1.legend(fontsize=14)\n",
    "    ax1.set_xlim(2.08, 2.32)\n",
    "\n",
    "    fig1.tight_layout()\n",
    "    fig1.savefig(\n",
    "        f\"{output_plot_path}/aiChains_numChains_taskPositionReshuffle_definition{def_idx+1}.png\",\n",
    "        dpi=300\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "    # =========================\n",
    "    # FIGURE 2 — mean_chain_length\n",
    "    # =========================\n",
    "    vals_right = results_df[1:]['mean_chain_length'] # Exclude first row as it's a repetition of original run\n",
    "    obs_right = results_df.iloc[0]['mean_chain_length']\n",
    "    pct_right = (vals_right < obs_right).mean() * 100\n",
    "\n",
    "    fig2, ax2 = plt.subplots(figsize=(8, 6))\n",
    "    ax2.xaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "    \n",
    "    ax2.hist(vals_right, bins=30, color='orange', edgecolor='black',\n",
    "             label='Shuffled Task Positions')\n",
    "\n",
    "    ax2.axvline(obs_right, color='red', linestyle='dashed', linewidth=2,\n",
    "                label=f'Observed = {obs_right:.2f}')\n",
    "\n",
    "    ax2.set_xlabel('Average AI Chain Length', fontsize=14)\n",
    "    ax2.set_ylabel('Frequency', fontsize=14)\n",
    "    ax2.legend(fontsize=14)\n",
    "\n",
    "    if def_idx == 0:\n",
    "        ax2.set_xlim(1.28, 1.47)\n",
    "    else:\n",
    "        ax2.set_xlim(1.05, 1.15)\n",
    "\n",
    "    fig2.tight_layout()\n",
    "    fig2.savefig(\n",
    "        f\"{output_plot_path}/aiChains_chainLength_taskPositionReshuffle_definition{def_idx+1}.png\",\n",
    "        dpi=300\n",
    "    )\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94951ff7",
   "metadata": {},
   "source": [
    "## Reshuffle Task Assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79f6284d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshuffle Task Positions within each occupation and recompute AI chain statistics\n",
    "n_shuffles = 1000\n",
    "\n",
    "first_output_file = f\"{output_data_path}/aiChains_taskAssignmentReshuffle_definition1.csv\"\n",
    "second_output_file = f\"{output_data_path}/aiChains_taskAssignmentReshuffle_definition2.csv\"\n",
    "\n",
    "# Run shuffles if output files do not already exist\n",
    "if not os.path.exists(first_output_file) or not os.path.exists(second_output_file):\n",
    "    results_d1 = []\n",
    "    results_d2 = []\n",
    "\n",
    "    # Original run\n",
    "    ai_chains_df, chain_lengths, mean_chain_length, num_ai_chains = create_ai_chains_df_def1(merged_data, group_cols)\n",
    "    results_d1.append({\n",
    "        'shuffle_index': 0,\n",
    "        'mean_chain_length': mean_chain_length,\n",
    "        'num_ai_chains': num_ai_chains\n",
    "    })\n",
    "\n",
    "    ai_chains_df, chain_lengths, mean_chain_length, num_ai_chains = create_ai_chains_df_def2(merged_data, group_cols)\n",
    "    results_d2.append({\n",
    "        'shuffle_index': 0,\n",
    "        'mean_chain_length': mean_chain_length,\n",
    "        'num_ai_chains': num_ai_chains\n",
    "    })\n",
    "\n",
    "    # Run shuffles\n",
    "    for i in range(n_shuffles):\n",
    "        if i % 50 == 0:\n",
    "            print(f'Processing shuffle {i} out of {n_shuffles}')\n",
    "\n",
    "        seed = 42 + i\n",
    "\n",
    "        # Prepared shuffled dataframe\n",
    "        reshuffled_merged_data = pd.read_csv(f'{input_data_path}/computed_objects/ONET_Eloundou_Anthropic_GPT/taskReshuffled_preserveCounts/ONET_Eloundou_Anthropic_GPT_iter{i+1}.csv')\n",
    "        df_shuf = reshuffled_merged_data.copy()\n",
    "\n",
    "        # Definition 1:\n",
    "        ai_chains_df_shuf_def1, chain_lengths_shuf_def1, mean_chain_length_shuf_def1, num_ai_chains_shuf_def1 = create_ai_chains_df_def1(df_shuf, group_cols)\n",
    "        results_d1.append({\n",
    "            'shuffle_index': i,\n",
    "            'mean_chain_length': mean_chain_length_shuf_def1,\n",
    "            'num_ai_chains': num_ai_chains_shuf_def1\n",
    "        })\n",
    "\n",
    "        # Definition 2:\n",
    "        ai_chains_df_shuf_def2, chain_lengths_shuf_def2, mean_chain_length_shuf_def2, num_ai_chains_shuf_def2 = create_ai_chains_df_def2(df_shuf, group_cols)\n",
    "        results_d2.append({\n",
    "            'shuffle_index': i,\n",
    "            'mean_chain_length': mean_chain_length_shuf_def2,\n",
    "            'num_ai_chains': num_ai_chains_shuf_def2\n",
    "        })\n",
    "\n",
    "    # Save results\n",
    "    results_df_def1 = pd.DataFrame(results_d1)\n",
    "    results_df_def2 = pd.DataFrame(results_d2)\n",
    "    results_df_def1.to_csv(first_output_file, index=False)\n",
    "    results_df_def2.to_csv(second_output_file, index=False)\n",
    "else:\n",
    "    # Load results\n",
    "    results_df_def1 = pd.read_csv(first_output_file)\n",
    "    results_df_def2 = pd.read_csv(second_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38da75d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_titles = ['(#1): Any Contiguous Sequence of AI Tasks',\n",
    "               '(#2): Starts with Automation/Augmentation and Ends with first Augmentation after Start']\n",
    "\n",
    "for def_idx, results_df in enumerate([results_df_def1, results_df_def2]): # Exclude first row if it's a repetition of original run\n",
    "\n",
    "    # =========================\n",
    "    # FIGURE 1 — num_ai_chains\n",
    "    # =========================\n",
    "    vals_left = results_df[1:]['num_ai_chains'] # Exclude first row as it's a repetition of original run\n",
    "    obs_left = results_df.iloc[0]['num_ai_chains']\n",
    "    pct_left = (vals_left < obs_left).mean() * 100\n",
    "\n",
    "    fig1, ax1 = plt.subplots(figsize=(8, 6))\n",
    "    ax1.xaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "\n",
    "    ax1.hist(vals_left, bins=30, color='steelblue', edgecolor='black',\n",
    "             label='Shuffled Task Execution Labels')\n",
    "\n",
    "    ax1.axvline(obs_left, color='red', linestyle='dashed', linewidth=2,\n",
    "                label=f'Observed = {obs_left:.2f}')\n",
    "\n",
    "    ax1.set_xlabel('Average Number of AI Chains', fontsize=14)\n",
    "    ax1.set_ylabel('Frequency', fontsize=14)\n",
    "    ax1.legend(fontsize=14)\n",
    "    ax1.set_xlim(2.08, 2.32)\n",
    "\n",
    "    fig1.tight_layout()\n",
    "    fig1.savefig(\n",
    "        f\"{output_plot_path}/aiChains_numChains_taskAssignmentReshuffle_definition{def_idx+1}.png\",\n",
    "        dpi=300\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "    # =========================\n",
    "    # FIGURE 2 — mean_chain_length\n",
    "    # =========================\n",
    "    vals_right = results_df[1:]['mean_chain_length'] # Exclude first row as it's a repetition of original run\n",
    "    obs_right = results_df.iloc[0]['mean_chain_length']\n",
    "    pct_right = (vals_right < obs_right).mean() * 100\n",
    "\n",
    "    fig2, ax2 = plt.subplots(figsize=(8, 6))\n",
    "    ax2.xaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "\n",
    "    ax2.hist(vals_right, bins=30, color='orange', edgecolor='black',\n",
    "             label='Shuffled Task Execution Labels')\n",
    "\n",
    "    ax2.axvline(obs_right, color='red', linestyle='dashed', linewidth=2,\n",
    "                label=f'Observed = {obs_right:.2f}')\n",
    "\n",
    "    ax2.set_xlabel('Average AI Chain Length', fontsize=14)\n",
    "    ax2.set_ylabel('Frequency', fontsize=14)\n",
    "    ax2.legend(fontsize=14)\n",
    "\n",
    "    if def_idx == 0:\n",
    "        ax2.set_xlim(1.28, 1.47)\n",
    "    else:\n",
    "        ax2.set_xlim(1.05, 1.15)\n",
    "\n",
    "    fig2.tight_layout()\n",
    "    fig2.savefig(\n",
    "        f\"{output_plot_path}/aiChains_chainLength_taskAssignmentReshuffle_definition{def_idx+1}.png\",\n",
    "        dpi=300\n",
    "    )\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
