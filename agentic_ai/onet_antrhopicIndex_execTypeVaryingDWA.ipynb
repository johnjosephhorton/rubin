{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc7fc397",
   "metadata": {},
   "source": [
    "#### By: Peyman Shahidi\n",
    "#### Created: Oct 19, 2025\n",
    "#### Last Edit: Dec 6, 2025\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10366af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python\n",
    "import getpass\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "import random \n",
    "\n",
    "## formatting number to appear comma separated and with two digits after decimal: e.g, 1000 shown as 1,000.00\n",
    "pd.set_option('float_format', \"{:,.2f}\".format)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "#from matplotlib.legend import Legend\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519e43cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder_path = \"..\"\n",
    "input_data_path = f\"{main_folder_path}/data\"\n",
    "output_data_path = f'{input_data_path}/computed_objects/execTypeVaryingDWA_anthropicIndex'\n",
    "output_plot_path = f\"{main_folder_path}/writeup/plots/execTypeVaryingDWA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e6e6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories if they don't exist\n",
    "import os\n",
    "\n",
    "for path in [output_data_path, output_plot_path]:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ac02f0",
   "metadata": {},
   "source": [
    "## Set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d28924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of reshuffles\n",
    "n_shuffles = 1000\n",
    "\n",
    "\n",
    "# dependent_var = 'is_ai'\n",
    "# plot_title_variable = 'Task is AI'\n",
    "dependent_var = 'is_automated'\n",
    "plot_title_variable = 'Task is Automated'\n",
    "\n",
    "\n",
    "TARGET_REGS = ['prev2_is_ai', 'prev_is_ai', 'next_is_ai', 'next2_is_ai']\n",
    "SPECS = ['no_fe', 'fe_MajorGroup', 'fe_MinorGroup']\n",
    "\n",
    "PLOT_TITLES = ['Task Before Previous Task', 'Previous Task', 'Next Task', 'Task After Next Task']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d887655d",
   "metadata": {},
   "source": [
    "### Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cd68c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of DWAs with tasks in multiple occupations\n",
    "dwa_list_path = f\"{input_data_path}/computed_objects/similar_dwa_tasks/similarTasks\"\n",
    "\n",
    "# Read all CSV files\n",
    "import glob\n",
    "dwa_csv_files = glob.glob(os.path.join(dwa_list_path, \"*.csv\"))\n",
    "print(f\"Found {len(dwa_csv_files)} DWA CSV files.\")\n",
    "\n",
    "# Load them into DataFrames, skipping 1-row files\n",
    "dwa_dfs = []\n",
    "skipped_files_count = 0\n",
    "for f in dwa_csv_files:\n",
    "    df = pd.read_csv(f)\n",
    "    if len(df) > 1: # Skip if DWA contains only one task\n",
    "        dwa_dfs.append(df)\n",
    "    else:\n",
    "        skipped_files_count += 1\n",
    "print(f\"Skipped {skipped_files_count} DWA files with only one task.\")\n",
    "    \n",
    "\n",
    "# Combine into one DataFrame\n",
    "df_all = pd.concat(dwa_dfs, ignore_index=True)\n",
    "repetitive_dwa_task_ids = df_all['Task ID'].unique().tolist()\n",
    "repetitive_dwa_task_titles = df_all['Task Title'].unique().tolist()\n",
    "print(f\"Found {len(repetitive_dwa_task_ids)} tasks related to these DWAs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee8b7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with all tasks that have survived the DWA task similarity procedure\n",
    "survived_tasks_count_df = df_all.groupby('DWA ID')['Task ID'].nunique().reset_index(name='num_tasks_survived')\n",
    "survived_tasks_count_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91f2ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DWA-level dataset with number of tasks and occupations per DWA, as well as fraction of manual, automation, and augmentation tasks per DWA\n",
    "merged_data = pd.read_csv(f\"{input_data_path}/computed_objects/ONET_Eloundou_Anthropic_GPT/ONET_Eloundou_Anthropic_GPT.csv\")\n",
    "merged_data['is_manual'] = merged_data['label'] == 'Manual'\n",
    "merged_data['is_automation'] = merged_data['label'] == 'Automation'\n",
    "merged_data['is_augmentation'] = merged_data['label'] == 'Augmentation'\n",
    "\n",
    "\n",
    "# Merge back DWA ID and DWA Titles to the merged_data\n",
    "dwa_task_mapping = pd.read_csv(f\"{input_data_path}/computed_objects/similar_dwa_tasks/dwa_task_mapping.csv\")\n",
    "print(f'Length of merged_data before merging DWA info: {merged_data.shape[0]}')\n",
    "merged_data = merged_data.merge(dwa_task_mapping, on=['Task ID', 'Task Title', 'O*NET-SOC Code', 'Occupation Title'], how='left')\n",
    "print(f'Length of merged_data after merging DWA info: {merged_data.shape[0]}')\n",
    "\n",
    "\n",
    "# Aggregate to get fractions\n",
    "dwa_grouped = merged_data.groupby(['DWA ID', 'DWA Title']).agg(\n",
    "    num_tasks = ('Task ID', 'nunique'),\n",
    "    num_occupations = ('O*NET-SOC Code', 'nunique'),\n",
    "    fraction_manual = ('is_manual', 'mean'),\n",
    "    fraction_automation = ('is_automation', 'mean'),\n",
    "    fraction_augmentation = ('is_augmentation', 'mean'),\n",
    ").reset_index()\n",
    "print(f\"Created DWA-level dataset with {dwa_grouped.shape[0]} DWAs.\")\n",
    "\n",
    "# Keep only DWAs with variation in terms of execution type across occupations\n",
    "dwa_grouped_filtered = dwa_grouped[\n",
    "     (dwa_grouped['num_occupations'] > 1) & (dwa_grouped['fraction_manual'] > 0) & (dwa_grouped['fraction_manual'] < 1)\n",
    "].copy()\n",
    "display(dwa_grouped_filtered)\n",
    "\n",
    "# Create list of DWAs with varying execution types\n",
    "dwas_varying_exec_types_ids = dwa_grouped_filtered['DWA ID'].unique().tolist()\n",
    "dwas_varying_exec_types_titles = dwa_grouped_filtered['DWA Title'].unique().tolist()\n",
    "print(f\"Identified {len(dwas_varying_exec_types_ids)} DWAs with varying execution types across occupations.\")\n",
    "\n",
    "# Merge back the number of tasks survived info\n",
    "dwa_grouped_filtered = dwa_grouped_filtered.merge(survived_tasks_count_df, left_on='DWA ID', right_on='DWA ID', how='left')\n",
    "\n",
    "# Save output\n",
    "dwa_grouped_filtered.to_csv(f\"{output_data_path}/dwas_varying_execution_types.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a84d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the merged data\n",
    "merged_data = pd.read_csv(f\"{input_data_path}/computed_objects/ONET_Eloundou_Anthropic_GPT/ONET_Eloundou_Anthropic_GPT.csv\")\n",
    "merged_data = merged_data[['O*NET-SOC Code', 'Occupation Title', 'Task ID', 'Task Title',\n",
    "       'Task Position', 'Task Type', \n",
    "       'Major_Group_Code', 'Major_Group_Title', \n",
    "       'Minor_Group_Code', 'Minor_Group_Title',\n",
    "       'Broad_Occupation_Code', 'Broad_Occupation_Title',\n",
    "       'Detailed_Occupation_Code', 'Detailed_Occupation_Title',\n",
    "       'gpt4_exposure', 'human_labels', \n",
    "       'automation', 'augmentation', 'label']]\n",
    "\n",
    "\n",
    "# Create is_ai and is_automated flags in merged_data\n",
    "merged_data['is_ai'] = merged_data['label'].isin(['Augmentation','Automation']).astype(int)\n",
    "merged_data['is_automated'] = merged_data['label'].isin(['Automation']).astype(int)\n",
    "merged_data['is_exposed'] = merged_data['human_labels'].isin(['E1']).astype(int)\n",
    "\n",
    "\n",
    "# Step 1: Add occupation's number of tasks info\n",
    "num_tasks_per_occupation = merged_data.groupby('O*NET-SOC Code')['Task ID'].nunique().reset_index()\n",
    "num_tasks_per_occupation = num_tasks_per_occupation.rename(columns={'Task ID': 'num_tasks'})\n",
    "merged_data = merged_data.merge(num_tasks_per_occupation, on='O*NET-SOC Code', how='left')\n",
    "\n",
    "\n",
    "# Step 2: Create flags for previous/next tasks is AI within occupation groups\n",
    "# Sort by occupation and position when possible\n",
    "merged_data['Task Position'] = pd.to_numeric(merged_data['Task Position'], errors='coerce')\n",
    "merged_data = merged_data.sort_values(['O*NET-SOC Code', 'Task Position']).reset_index(drop=True)\n",
    "group_col = 'O*NET-SOC Code'\n",
    "\n",
    "# Compute neighbor flags (prev/next) within occupation groups when possible\n",
    "merged_data['prev_is_ai'] = 0\n",
    "merged_data['prev2_is_ai'] = 0\n",
    "merged_data['next_is_ai'] = 0\n",
    "merged_data['next2_is_ai'] = 0\n",
    "pos_col = 'Task Position'\n",
    "\n",
    "def add_neighbor_flags(df):\n",
    "    df = df.copy()\n",
    "    df['Task Position'] = pd.to_numeric(df['Task Position'], errors='coerce')\n",
    "    df = df.sort_values(['O*NET-SOC Code','Task Position']).reset_index(drop=True)\n",
    "    def _add_flags(g):\n",
    "        g = g.sort_values('Task Position')\n",
    "        g['prev_is_ai'] = g['is_ai'].shift(1).fillna(0).astype(int)\n",
    "        g['prev2_is_ai'] = g['is_ai'].shift(2).fillna(0).astype(int)\n",
    "        # g['prev2_is_ai'] = ((g['prev2_is_ai'] == 1) & (g['prev_is_ai'] == 1)).astype(int)\n",
    "        g['next_is_ai'] = g['is_ai'].shift(-1).fillna(0).astype(int)\n",
    "        g['next2_is_ai'] = g['is_ai'].shift(-2).fillna(0).astype(int)\n",
    "        # g['next2_is_ai'] = ((g['next2_is_ai'] == 1) & (g['next_is_ai'] == 1)).astype(int)\n",
    "        return g\n",
    "    return df.groupby('O*NET-SOC Code', group_keys=False).apply(_add_flags).reset_index(drop=True)\n",
    "merged_data = merged_data.groupby(group_col, group_keys=False).apply(add_neighbor_flags).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "# Step 3: Add back DWA info\n",
    "# Merge back DWA ID and DWA Titles to the merged_data\n",
    "dwa_task_mapping = pd.read_csv(f\"{input_data_path}/computed_objects/similar_dwa_tasks/dwa_task_mapping.csv\")\n",
    "merged_data = merged_data.merge(dwa_task_mapping, on=['Task ID', 'Task Title', 'O*NET-SOC Code', 'Occupation Title'], how='left')\n",
    "# Note that the merge might map multiple DWAs to the same task\n",
    "\n",
    "\n",
    "# Step 4: Flag \"similar\" tasks across occupations\n",
    "merged_data['dwa_execType_varying'] = (\n",
    "    (merged_data['DWA ID'].isin(dwas_varying_exec_types_ids)\n",
    "    & \n",
    "    merged_data['Task ID'].isin(repetitive_dwa_task_ids)\n",
    "    )\n",
    "    & ~(merged_data['DWA ID'].isna())\n",
    ").astype(int)\n",
    "\n",
    "# Remove duplicates in terms of (O*NET-SOC Code, Task ID) if any\n",
    "print(f'Length of merged_data before dropping duplicates: {merged_data.shape[0]}')\n",
    "merged_data = merged_data.drop_duplicates(subset=['O*NET-SOC Code', 'Task ID'])\n",
    "print(f'Length of merged_data after dropping duplicates: {merged_data.shape[0]}')\n",
    "# Save the updated merged_data with flags\n",
    "merged_data[merged_data['dwa_execType_varying'] == 1].to_csv(f\"{output_data_path}/merged_data_DWAexecVaryingTypes.csv\", index=False)\n",
    "\n",
    "\n",
    "# Summary for flagged DWA rows\n",
    "mask = merged_data['dwa_execType_varying'] == 1\n",
    "n_flagged = int(mask.sum())\n",
    "print(f'\\nNumber of dwa_execType_varying rows: {n_flagged}')\n",
    "if n_flagged > 0:\n",
    "    for c in ['prev2_is_ai', 'prev_is_ai', 'next_is_ai', 'next2_is_ai']:\n",
    "        s = int(merged_data.loc[mask, c].sum())\n",
    "        frac = merged_data.loc[mask, c].mean()\n",
    "        print(f'{c}: {s} of {n_flagged} flagged rows (fraction={frac:.3f})')\n",
    "    try:\n",
    "        display(merged_data.loc[mask].head())\n",
    "    except Exception:\n",
    "        print(merged_data.loc[mask].head().to_string(index=False))\n",
    "else:\n",
    "    print('No flagged rows to summarize.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e805dee",
   "metadata": {},
   "source": [
    "## Run regression of multiple-execution-type DWA tasks against execution type of neighboring tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf153cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.stats import norm\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Configuration ---\n",
    "TARGET_REGS = ['prev2_is_ai', 'prev_is_ai', 'next_is_ai', 'next2_is_ai']\n",
    "\n",
    "# Labels to match your desired output format\n",
    "VAR_LABELS = {\n",
    "    'prev2_is_ai': '($t-2$) Task AI',\n",
    "    'prev_is_ai': '($t-1$) Task AI',\n",
    "    'next_is_ai': '($t+1$) Task AI',\n",
    "    'next2_is_ai': '($t+2$) Task AI'\n",
    "}\n",
    "\n",
    "# ==========================================\n",
    "# 1. Robust AME Extractor\n",
    "# ==========================================\n",
    "def build_ame_df(res, dataset_name, model_name, target_regs, fe_label):\n",
    "    try:\n",
    "        # --- Calculate Model Statistics ---\n",
    "        pr2 = res.prsquared\n",
    "        k = res.params.shape[0]\n",
    "        adj_pr2 = 1 - (res.llf - k) / res.llnull\n",
    "        nobs = res.nobs\n",
    "\n",
    "        # --- Calculate AME ---\n",
    "        margeff = res.get_margeff(at='overall', method='dydx', dummy=True)\n",
    "        summary = margeff.summary_frame()\n",
    "        \n",
    "        summary = summary.reset_index().rename(columns={'index': 'term'})\n",
    "        \n",
    "        rename_map = {\n",
    "            'dy/dx': 'ame_coef',\n",
    "            'std err': 'ame_se', 'Std. Err.': 'ame_se',\n",
    "            'P>|z|': 'p_value', 'z': 'z_score'\n",
    "        }\n",
    "        summary = summary.rename(columns=rename_map)\n",
    "        \n",
    "        if 'ame_se' not in summary.columns and summary.shape[1] >= 2:\n",
    "             summary['ame_se'] = summary.iloc[:, 1]\n",
    "\n",
    "        summary = summary[summary['term'].isin(target_regs)].copy()\n",
    "        if summary.empty: return pd.DataFrame()\n",
    "\n",
    "        # --- Manual P-Value Calculation ---\n",
    "        summary['ame_coef'] = pd.to_numeric(summary['ame_coef'], errors='coerce')\n",
    "        summary['ame_se'] = pd.to_numeric(summary['ame_se'], errors='coerce')\n",
    "        \n",
    "        if 'p_value' not in summary.columns or summary['p_value'].isnull().any():\n",
    "            z_stat = summary['ame_coef'] / summary['ame_se']\n",
    "            summary['p_value'] = 2 * (1 - norm.cdf(np.abs(z_stat)))\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            'dataset': dataset_name,\n",
    "            'model': model_name,\n",
    "            'fe_label': fe_label,\n",
    "            'nobs': nobs,\n",
    "            'r2_pseudo': pr2,\n",
    "            'r2_adj_pseudo': adj_pr2,\n",
    "            'term': summary['term'],\n",
    "            'ame_coef': summary['ame_coef'],\n",
    "            'ame_se': summary['ame_se'],\n",
    "            'p_value': summary['p_value']\n",
    "        })\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating AME for {model_name}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# ==========================================\n",
    "# 2. Regression Runner (FIXED)\n",
    "# ==========================================\n",
    "def run_regressions_on(df, dataset_name, dependent_var, regressors):\n",
    "    df = df.copy()\n",
    "    all_cols = regressors + [dependent_var, 'is_exposed', 'num_tasks']\n",
    "    existing_cols = [c for c in all_cols if c in df.columns]\n",
    "    df[existing_cols] = df[existing_cols].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "\n",
    "    base_formula = f'{dependent_var} ~ ' + ' + '.join(regressors)\n",
    "    ame_list = []\n",
    "    models = {} # We store models here\n",
    "\n",
    "    # 1) No FE\n",
    "    try:\n",
    "        formula = base_formula + ' + is_exposed + num_tasks'\n",
    "        res = smf.logit(formula, data=df).fit(\n",
    "        disp=False, \n",
    "        cov_type='cluster',\n",
    "        cov_kwds={'groups': df['DWA ID'],\n",
    "                  'use_correction': True}\n",
    "        )\n",
    "        models['no_fe'] = res\n",
    "        ame_list.append(build_ame_df(res, dataset_name, 'no_fe', regressors, fe_label=\"None\"))\n",
    "        # print(f\"[{dataset_name}] No-FE model converged.\")\n",
    "    except Exception as e: \n",
    "        print(f\"[{dataset_name}] No-FE failed: {e}\")\n",
    "\n",
    "    # 2) Fixed Effects\n",
    "    fe_cols = [('Major_Group_Code', 'MajorGroup', 'Major Group'), \n",
    "               ('Minor_Group_Code', 'MinorGroup', 'Minor Group')]\n",
    "    \n",
    "    for col, short, nice_label in fe_cols:\n",
    "        if col not in df.columns: continue\n",
    "        try:\n",
    "            formula = base_formula + f' + C({col}) + is_exposed + num_tasks'\n",
    "            df_fe = df.groupby(col).filter(lambda g: g[dependent_var].nunique() == 2 and len(g) >= 10)\n",
    "            res = smf.logit(formula, data=df_fe).fit(\n",
    "            disp=False, \n",
    "            cov_type='cluster',\n",
    "            cov_kwds={'groups': df_fe['DWA ID'],\n",
    "                      'use_correction': True}\n",
    "            )\n",
    "            models[f'fe_{short}'] = res\n",
    "            ame_list.append(build_ame_df(res, dataset_name, f'fe_{short}', regressors, fe_label=nice_label))\n",
    "            # print(f\"[{dataset_name}] FE {short} converged.\")\n",
    "        except Exception as e:\n",
    "            print(f\"[{dataset_name}] FE {short} failed: {e}\")\n",
    "\n",
    "    # FIXED RETURN: Returns tuple (models, dataframe)\n",
    "    combined = pd.concat(ame_list, ignore_index=True) if ame_list else pd.DataFrame()\n",
    "\n",
    "    # Save results to CSV\n",
    "    out_path = f'{output_data_path}/regression_summaries_{dependent_var}'\n",
    "    os.makedirs(out_path, exist_ok=True)\n",
    "    combined.to_csv(f'{out_path}/regression_ame_results_{dataset_name}.csv', index=False)\n",
    "\n",
    "    return models, combined\n",
    "\n",
    "# ==========================================\n",
    "# 3. LaTeX Table Generator\n",
    "# ==========================================\n",
    "def generate_latex_table(df_results):\n",
    "    if df_results.empty:\n",
    "        print(\"No results to tabulate.\")\n",
    "        return\n",
    "\n",
    "    # Filter for one dataset\n",
    "    dataset_to_show = df_results['dataset'].unique()[0]\n",
    "    subset = df_results[df_results['dataset'] == dataset_to_show].copy()\n",
    "    \n",
    "    print(f\"\\n% --- LaTeX Table for {dataset_to_show} ---\")\n",
    "\n",
    "    # --- Formatting ---\n",
    "    def fmt(row):\n",
    "        stars = \"\"\n",
    "        p = row['p_value']\n",
    "        if pd.notna(p):\n",
    "            if p < 0.01: stars = \"***\"\n",
    "            elif p < 0.05: stars = \"**\"\n",
    "            elif p < 0.10: stars = \"*\"\n",
    "        return f\"{row['ame_coef']:.2f}{stars}\", f\"({row['ame_se']:.2f})\"\n",
    "\n",
    "    formatted = subset.apply(fmt, axis=1, result_type='expand')\n",
    "    subset['coef_str'] = formatted[0]\n",
    "    subset['se_str'] = formatted[1]\n",
    "\n",
    "    # Pivot\n",
    "    pivot_coef = subset.pivot(index='term', columns='model', values='coef_str')\n",
    "    pivot_se = subset.pivot(index='term', columns='model', values='se_str')\n",
    "\n",
    "    # Ordering\n",
    "    valid_vars = [v for v in TARGET_REGS if v in pivot_coef.index]\n",
    "    pivot_coef = pivot_coef.reindex(valid_vars)\n",
    "    pivot_se = pivot_se.reindex(valid_vars)\n",
    "    \n",
    "    model_order = ['no_fe', 'fe_MajorGroup', 'fe_MinorGroup']\n",
    "    valid_models = [m for m in model_order if m in pivot_coef.columns]\n",
    "\n",
    "    # Extract Footer Stats\n",
    "    stats = subset[['model', 'nobs', 'r2_pseudo', 'r2_adj_pseudo', 'fe_label']].drop_duplicates('model').set_index('model')\n",
    "\n",
    "    # --- Print LaTeX ---\n",
    "    col_def = \"l\" + \"c\" * len(valid_models) \n",
    "    \n",
    "    print(f\"\\\\begin{{tabular}}{{{col_def}}}\")\n",
    "    print(r\"\\toprule\")\n",
    "    \n",
    "    # Header\n",
    "    header_nums = [f\"({i+1})\" for i in range(len(valid_models))]\n",
    "    print(f\"Specification & \" + \" & \".join(header_nums) + r\" \\\\\")\n",
    "    print(r\"\\midrule\")\n",
    "\n",
    "    # Body (Variables)\n",
    "    for var in valid_vars:\n",
    "        label = VAR_LABELS.get(var, var.replace('_', ' '))\n",
    "        \n",
    "        # Coefficient Row\n",
    "        c_vals = [pivot_coef.loc[var, m] if pd.notna(pivot_coef.loc[var, m]) else \"\" for m in valid_models]\n",
    "        print(f\"{label} & \" + \" & \".join(c_vals) + r\" \\\\\")\n",
    "        \n",
    "        # SE Row\n",
    "        s_vals = [pivot_se.loc[var, m] if pd.notna(pivot_se.loc[var, m]) else \"\" for m in valid_models]\n",
    "        print(f\" & \" + \" & \".join(s_vals) + r\" \\\\\")\n",
    "        print(r\"\\addlinespace\")\n",
    "\n",
    "    print(r\"\\midrule\")\n",
    "    \n",
    "    # --- Footer ---\n",
    "    \n",
    "    # Pseudo R2\n",
    "    r2_vals = [f\"{stats.loc[m, 'r2_pseudo']:.3f}\" if m in stats.index else \"\" for m in valid_models]\n",
    "    print(f\"Pseudo $R^2$ & \" + \" & \".join(r2_vals) + r\" \\\\\")\n",
    "    \n",
    "    # Adj Pseudo R2\n",
    "    adj_r2_vals = [f\"{stats.loc[m, 'r2_adj_pseudo']:.3f}\" if m in stats.index else \"\" for m in valid_models]\n",
    "    print(f\"Adj. Pseudo $R^2$ & \" + \" & \".join(adj_r2_vals) + r\" \\\\\")\n",
    "    \n",
    "    # Observations\n",
    "    obs_vals = [f\"{int(stats.loc[m, 'nobs']):,}\" if m in stats.index else \"\" for m in valid_models]\n",
    "    print(f\"Observations & \" + \" & \".join(obs_vals) + r\" \\\\\")\n",
    "\n",
    "    # Fixed Effects\n",
    "    fe_vals = []\n",
    "    for m in valid_models:\n",
    "        if m in stats.index:\n",
    "            label = stats.loc[m, 'fe_label']\n",
    "            if pd.isna(label) or str(label) == \"None\":\n",
    "                fe_vals.append(\"\")\n",
    "            else:\n",
    "                fe_vals.append(str(label)[:5])\n",
    "        else:\n",
    "            fe_vals.append(\"\")\n",
    "\n",
    "    print(f\"SOC Group Fixed Effects & \" + \" & \".join(fe_vals) + r\" \\\\\")\n",
    "    \n",
    "    print(r\"\\bottomrule\")\n",
    "    print(r\"\\footnotesize{Standard errors in parentheses (clustered at DWA level). *** p$<$0.01, ** p$<$0.05, * p$<$0.1}\")\n",
    "    print(r\"\\end{tabular}\")\n",
    "\n",
    "# ==========================================\n",
    "# 4. Execution Block\n",
    "# ==========================================\n",
    "\n",
    "# dependent_var = 'is_ai'\n",
    "\n",
    "# print(\">>> Running Regressions on Full Data...\")\n",
    "# models_full, res_full = run_regressions_on(merged_data, 'full_0', dependent_var, TARGET_REGS)\n",
    "\n",
    "print(\">>> Running Regressions on Filtered Data...\")\n",
    "filtered = merged_data[merged_data['dwa_execType_varying'] == 1].reset_index(drop=True)\n",
    "models_filt, res_filt = run_regressions_on(filtered, 'filtered_0', dependent_var, TARGET_REGS)\n",
    "\n",
    "# Generate Tables\n",
    "# print(\"\\n\\n\")\n",
    "# generate_latex_table(res_full)\n",
    "# print(\"\\n\\n\")\n",
    "generate_latex_table(res_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69796c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered[['O*NET-SOC Code', 'Occupation Title', 'Task ID', 'Task Title', 'Task Position', 'label', 'human_labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd05f169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the specifications we expect to see\n",
    "SPECS = ['no_fe', 'fe_MajorGroup', 'fe_MinorGroup']\n",
    "\n",
    "# ======================================================\n",
    "# 1. Helper: Extract AME directly (No Transformation)\n",
    "# ======================================================\n",
    "def results_to_dict(df_results):\n",
    "    \"\"\"\n",
    "    Reads the dataframe output from run_regressions_on and converts\n",
    "    the 'ame_coef' column into a dictionary structure. Also returns\n",
    "    'ame_se' values as a separate dict.\n",
    "    Returns: (coef_dict, se_dict) with structure coef_dict[spec][term]\n",
    "    \"\"\"\n",
    "    coef_out = {spec: {term: np.nan for term in TARGET_REGS} for spec in SPECS}\n",
    "    se_out = {spec: {term: np.nan for term in TARGET_REGS} for spec in SPECS}\n",
    "    \n",
    "    if df_results is None or (hasattr(df_results, 'empty') and df_results.empty):\n",
    "        return coef_out, se_out\n",
    "\n",
    "    for _, row in df_results.iterrows():\n",
    "        spec = row.get('model')\n",
    "        term = row.get('term')\n",
    "        if spec in coef_out and term in coef_out[spec]:\n",
    "            if 'ame_coef' in row and pd.notna(row['ame_coef']):\n",
    "                coef_out[spec][term] = row['ame_coef']\n",
    "            if 'ame_se' in row and pd.notna(row['ame_se']):\n",
    "                se_out[spec][term] = row['ame_se']\n",
    "    return coef_out, se_out\n",
    "\n",
    "# Store observed values\n",
    "# obs_dict_full, obs_se_full = results_to_dict(res_full)\n",
    "obs_dict_filt, obs_se_filt = results_to_dict(res_filt)\n",
    "\n",
    "# ======================================================\n",
    "# 2. Reshuffling Loop\n",
    "# ======================================================\n",
    "# Prepare containers for reshuffled AMEs\n",
    "resh_full = {spec: {t: [] for t in TARGET_REGS} for spec in SPECS}\n",
    "resh_filt = {spec: {t: [] for t in TARGET_REGS} for spec in SPECS}\n",
    "\n",
    "# Assuming n_shuffles is defined (e.g., 1000)\n",
    "print(f'Running {n_shuffles} reshuffles to generate Null Distribution of AMEs...')\n",
    "\n",
    "for i in range(n_shuffles):\n",
    "    seed = 42 + i\n",
    "    \n",
    "    # CHANGED FILENAME: Use '_ame_summary.csv' to avoid loading old cached raw-coef files\n",
    "    # fname_full = f\"{output_data_path}/regression_summaries_{dependent_var}/regression_ame_results_full_{i}.csv\"\n",
    "    fname_filt = f\"{output_data_path}/regression_summaries_{dependent_var}/regression_ame_results_filtered_{i}.csv\"\n",
    "\n",
    "    # --- Load or Compute ---\n",
    "    # if Path(fname_full).exists() and Path(fname_filt).exists():\n",
    "    if Path(fname_filt).exists():\n",
    "        # Load existing results (CSV produced by run_regressions_on)\n",
    "        res_shuf_filt = pd.read_csv(fname_filt)\n",
    "    else:\n",
    "        # Create Shuffled Data\n",
    "        df_shuf = merged_data.copy()\n",
    "        # Shuffle Task Position within O*NET Code\n",
    "        df_shuf['Task Position'] = df_shuf.groupby('O*NET-SOC Code')['Task Position'].transform(\n",
    "            lambda x: x.sample(frac=1, random_state=seed).values\n",
    "        )\n",
    "        \n",
    "        # Re-calculate neighbor flags based on shuffled positions\n",
    "        df_shuf = add_neighbor_flags(df_shuf)\n",
    "        \n",
    "        # Run Regressions (Filtered)\n",
    "        df_shuf_filt = df_shuf[df_shuf['dwa_execType_varying'] == 1].reset_index(drop=True)\n",
    "        _, res_shuf_filt = run_regressions_on(df_shuf_filt, f'filtered_{i}', dependent_var=dependent_var, regressors=TARGET_REGS)\n",
    "    # --- Store Results ---\n",
    "    d_filt, d_filt_se = results_to_dict(res_shuf_filt)\n",
    "\n",
    "    # Append to lists\n",
    "    for spec in SPECS:\n",
    "        for t in TARGET_REGS:\n",
    "            resh_filt[spec][t].append(d_filt[spec][t])\n",
    "\n",
    "    if (i+1) % 50 == 0:\n",
    "        print(f'  Completed {i+1}/{n_shuffles}')\n",
    "\n",
    "print('Reshuffles complete; Marginal Effects stored in resh_full and resh_filt.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55545e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import os # Ensure os is imported for makedirs\n",
    "\n",
    "# --- Plotting: distributions of Marginal Effects (AME) ---\n",
    "def plot_comparison_hist(resh_dict, obs_dict, obs_se_dict, title, out_name, plot_title_variable, bins=30):\n",
    "    \"\"\"Create the multi-row comparison histogram and also save each row (spec) as a separate image.\n",
    "\n",
    "    Args:\n",
    "        resh_dict: dict of reshuffled AMEs per spec and term\n",
    "        obs_dict: dict of observed AMEs per spec and term\n",
    "        obs_se_dict: dict of observed AME standard errors per spec and term\n",
    "        title: title string to include in saved figures\n",
    "        out_name: filename for the full multi-row figure\n",
    "        plot_title_variable: human-readable dependent var name for titles\n",
    "        bins: histogram bins\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- 1. Calculate Global Bounds for X-Axis ---\n",
    "    all_resh_vals = [v \n",
    "                     for inner_dict in resh_dict.values()\n",
    "                     for values_list in inner_dict.values()\n",
    "                     for v in values_list if not np.isnan(v)]\n",
    "    \n",
    "    all_obs_vals = [v \n",
    "                    for inner_dict in obs_dict.values()\n",
    "                    for v in inner_dict.values() if not np.isnan(v)]\n",
    "    \n",
    "    total_vals = all_resh_vals + all_obs_vals\n",
    "    if not total_vals:\n",
    "        print(\"Warning: No valid data found to plot.\")\n",
    "        return\n",
    "\n",
    "    g_min, g_max = min(total_vals), max(total_vals)\n",
    "    symmetric_bound = max(abs(g_min), abs(g_max))\n",
    "    span = 2 * symmetric_bound\n",
    "    if span == 0: span = 0.1\n",
    "    x_limit_min = -symmetric_bound - (span * 0.125)\n",
    "    x_limit_max = symmetric_bound + (span * 0.125)\n",
    "\n",
    "    # --- 2. Setup Plot ---\n",
    "    colors = [plt.cm.tab10(i % 10) for i in range(len(SPECS))]\n",
    "    fig, axes = plt.subplots(nrows=len(SPECS), ncols=len(TARGET_REGS), \n",
    "                             figsize=(6*len(TARGET_REGS), 5*len(SPECS)), \n",
    "                             sharey='col')\n",
    "\n",
    "    if len(SPECS) == 1:\n",
    "        axes = np.array([axes])\n",
    "\n",
    "    for r, spec in enumerate(SPECS):\n",
    "        color_row = colors[r]\n",
    "        for c, term in enumerate(TARGET_REGS):\n",
    "            ax = axes[r, c]\n",
    "            vals = np.array(resh_dict[spec][term], dtype=float)\n",
    "            vals_clean = vals[~np.isnan(vals)]\n",
    "\n",
    "            if len(vals_clean):\n",
    "                # # Shade reshuffle 95% CI behind the histogram\n",
    "                # lo, hi = np.percentile(vals_clean, [2.5, 97.5])\n",
    "                # # Clip to x-limits\n",
    "                # lo = max(lo, x_limit_min)\n",
    "                # hi = min(hi, x_limit_max)\n",
    "                # if hi <= lo:\n",
    "                #     eps = 1e-8 if abs(lo) > 0 else 1e-4\n",
    "                #     lo, hi = lo - eps, hi + eps\n",
    "                # ax.axvspan(lo, hi, color=color_row, alpha=0.12, zorder=0)\n",
    "\n",
    "                # Draw histogram on top of the shaded CI\n",
    "                ax.hist(vals_clean, bins=bins, color=color_row, alpha=0.7, edgecolor='k', label='Task Position Reshuffled AMEs', zorder=2)\n",
    "            else:\n",
    "                ax.text(0.5, 0.5, 'no estimates', ha='center', va='center')\n",
    "\n",
    "            # Observed AME (red dashed) and Â±1.645*SE (vertical lines/shade)\n",
    "            obs_val = obs_dict.get(spec, {}).get(term, np.nan)\n",
    "            if not np.isnan(obs_val):\n",
    "                obs_se = obs_se_dict.get(spec, {}).get(term, np.nan)\n",
    "                if not np.isnan(obs_se):\n",
    "                    se_band = 1.645 * obs_se\n",
    "                    # Shade observed SE band slightly above histogram but under the observed line\n",
    "                    ax.axvspan(obs_val - se_band, obs_val + se_band, color='red', alpha=0.08, zorder=1)\n",
    "                    # Also draw thin boundary lines for the observed SE band\n",
    "                    ax.axvline(obs_val - se_band, color='red', linestyle='--', linewidth=1, alpha=0.9, zorder=3)\n",
    "                    ax.axvline(obs_val + se_band, color='red', linestyle='--', linewidth=1, alpha=0.9, zorder=3)\n",
    "                # Observed center line on top\n",
    "                ax.axvline(obs_val, color='red', linestyle='--', linewidth=3, label=f'Observed = {obs_val:.3f}', zorder=4)\n",
    "\n",
    "            # Baseline (No Effect) set to 0\n",
    "            ax.axvline(0.0, color='black', linestyle='-', linewidth=1.5, alpha=0.5, zorder=4)\n",
    "\n",
    "            # Titles and Labels\n",
    "            if r == 0:\n",
    "                clean_title = VAR_LABELS.get(term, term) if 'VAR_LABELS' in globals() else PLOT_TITLES[c]\n",
    "                ax.set_title(clean_title, fontsize=15, fontweight='bold')\n",
    "            if r == len(SPECS) - 1:\n",
    "                ax.set_xlabel('Average Marginal Effect', fontsize=15)\n",
    "            if c == 0:\n",
    "                clean_spec = spec.replace('fe_', '').replace('_', ' ').title()\n",
    "                ax.set_ylabel(f'{clean_spec}\\nCount', fontsize=15)\n",
    "\n",
    "            # Apply consistent X-limits and grid\n",
    "            ax.set_xlim(x_limit_min, x_limit_max)\n",
    "            ax.grid(axis='y', linestyle=':', alpha=0.5)\n",
    "            ax.legend(loc='best', fontsize=10)\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Ensure output dir exists\n",
    "    Path(output_plot_path).mkdir(parents=True, exist_ok=True)\n",
    "    out_dir = f'{output_plot_path}/{dependent_var}'\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    out_path = f'{out_dir}/{out_name}'\n",
    "    fig.savefig(out_path, dpi=300, bbox_inches='tight')\n",
    "    print('Saved full multi-row plot to', out_path)\n",
    "\n",
    "    # --- 3. Save Individual Rows ---\n",
    "    base_name = out_name.rsplit('.', 1)[0]\n",
    "    for r, spec in enumerate(SPECS):\n",
    "        fig_row, axs_row = plt.subplots(nrows=1, ncols=len(TARGET_REGS), figsize=(24, 5), sharey=False)\n",
    "        if len(TARGET_REGS) == 1: axs_row = [axs_row]\n",
    "        color_row = colors[r]\n",
    "        for c, term in enumerate(TARGET_REGS):\n",
    "            axr = axs_row[c]\n",
    "            vals = np.array(resh_dict[spec][term], dtype=float)\n",
    "            vals_clean = vals[~np.isnan(vals)]\n",
    "\n",
    "            if len(vals_clean):\n",
    "                # lo, hi = np.percentile(vals_clean, [2.5, 97.5])\n",
    "                # lo = max(lo, x_limit_min)\n",
    "                # hi = min(hi, x_limit_max)\n",
    "                # if hi <= lo:\n",
    "                #     eps = 1e-8 if abs(lo) > 0 else 1e-4\n",
    "                #     lo, hi = lo - eps, hi + eps\n",
    "                # axr.axvspan(lo, hi, color=color_row, alpha=0.12, zorder=0)\n",
    "                axr.hist(vals_clean, bins=bins, color=color_row, alpha=0.7, edgecolor='k', label='Task Position Reshuffled AMEs', zorder=2)\n",
    "            else:\n",
    "                axr.text(0.5, 0.5, 'no estimates', ha='center', va='center')\n",
    "\n",
    "            obs_val = obs_dict.get(spec, {}).get(term, np.nan)\n",
    "            if not np.isnan(obs_val):\n",
    "                obs_se = obs_se_dict.get(spec, {}).get(term, np.nan)\n",
    "                if not np.isnan(obs_se):\n",
    "                    se_band = 1.645 * obs_se\n",
    "                    axr.axvspan(obs_val - se_band, obs_val + se_band, color='red', alpha=0.08, zorder=1)\n",
    "                    axr.axvline(obs_val - se_band, color='red', linestyle='--', linewidth=1, alpha=0.9, zorder=3)\n",
    "                    axr.axvline(obs_val + se_band, color='red', linestyle='--', linewidth=1, alpha=0.9, zorder=3)\n",
    "                axr.axvline(obs_val, color='red', linestyle='--', linewidth=3, label=f'Observed = {obs_val:.3f}', zorder=4)\n",
    "\n",
    "            # Zero line\n",
    "            axr.axvline(0.0, color='black', linestyle='-', linewidth=1.5, alpha=0.5, zorder=4)\n",
    "            clean_title = VAR_LABELS.get(term, term) if 'VAR_LABELS' in globals() else PLOT_TITLES[c]\n",
    "            axr.set_title(clean_title, fontsize=15)\n",
    "            if c == 0:\n",
    "                axr.set_ylabel('Count', fontsize=15)\n",
    "            axr.grid(axis='y', linestyle=':', alpha=0.5)\n",
    "            axr.set_xlim(x_limit_min, x_limit_max)\n",
    "            axr.set_xlabel('Average Marginal Effect', fontsize=15)\n",
    "            axr.legend(loc='best', fontsize=10)\n",
    "\n",
    "        fig_row.tight_layout()\n",
    "        out_path_row = f'{out_dir}/{base_name}_{spec}.png'\n",
    "        fig_row.savefig(out_path_row, dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig_row)\n",
    "        print('Saved row plot to', out_path_row)\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "Path(output_plot_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "plot_comparison_hist(\n",
    "    resh_filt, \n",
    "    obs_dict_filt, \n",
    "    obs_se_filt, \n",
    "    f'FILTERED Dataset (n={n_shuffles})', \n",
    "    f'AME_filtered_{dependent_var}.png', \n",
    "    plot_title_variable\n",
    ")\n",
    "\n",
    "print('All done: comparative Marginal Effect histogram figures created.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
