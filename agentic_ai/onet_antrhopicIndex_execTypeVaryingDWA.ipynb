{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc7fc397",
   "metadata": {},
   "source": [
    "#### By: Peyman Shahidi\n",
    "#### Created: Oct 19, 2025\n",
    "#### Last Edit: Nov 18, 2025\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10366af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python\n",
    "import getpass\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "import random \n",
    "\n",
    "## formatting number to appear comma separated and with two digits after decimal: e.g, 1000 shown as 1,000.00\n",
    "pd.set_option('float_format', \"{:,.2f}\".format)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "#from matplotlib.legend import Legend\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "519e43cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder_path = \"..\"\n",
    "input_data_path = f\"{main_folder_path}/data\"\n",
    "output_data_path = f'{input_data_path}/computed_objects/execTypeVaryingDWA_anthropicIndex'\n",
    "output_plot_path = f\"{main_folder_path}/writeup/plots/execTypeVaryingDWA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84e6e6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories if they don't exist\n",
    "import os\n",
    "\n",
    "for path in [output_data_path, output_plot_path]:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ac02f0",
   "metadata": {},
   "source": [
    "## Set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85d28924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of reshuffles\n",
    "n_shuffles = 1000\n",
    "\n",
    "\n",
    "# dependent_var = 'is_ai'\n",
    "# plot_title_variable = 'Task is AI'\n",
    "dependent_var = 'is_automated'\n",
    "plot_title_variable = 'Task is Automated'\n",
    "\n",
    "\n",
    "TARGET_REGS = ['prev2_is_ai', 'prev_is_ai', 'next_is_ai', 'next2_is_ai']\n",
    "SPECS = ['no_fe', 'fe_MajorGroup', 'fe_MinorGroup']\n",
    "\n",
    "PLOT_TITLES = ['Task Before Previous Task', 'Previous Task', 'Next Task', 'Task After Next Task']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d887655d",
   "metadata": {},
   "source": [
    "### Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69cd68c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2047 DWA CSV files.\n",
      "Skipped 47 DWA files with only one task.\n",
      "Found 13535 tasks related to these DWAs.\n"
     ]
    }
   ],
   "source": [
    "# Get list of DWAs with tasks in multiple occupations\n",
    "dwa_list_path = f\"{input_data_path}/computed_objects/similar_dwa_tasks/similarTasks\"\n",
    "\n",
    "# Read all CSV files\n",
    "import glob\n",
    "dwa_csv_files = glob.glob(os.path.join(dwa_list_path, \"*.csv\"))\n",
    "print(f\"Found {len(dwa_csv_files)} DWA CSV files.\")\n",
    "\n",
    "# Load them into DataFrames, skipping 1-row files\n",
    "dwa_dfs = []\n",
    "skipped_files_count = 0\n",
    "for f in dwa_csv_files:\n",
    "    df = pd.read_csv(f)\n",
    "    if len(df) > 1: # Skip if DWA contains only one task\n",
    "        dwa_dfs.append(df)\n",
    "    else:\n",
    "        skipped_files_count += 1\n",
    "print(f\"Skipped {skipped_files_count} DWA files with only one task.\")\n",
    "    \n",
    "\n",
    "# Combine into one DataFrame\n",
    "df_all = pd.concat(dwa_dfs, ignore_index=True)\n",
    "repetitive_dwa_task_ids = df_all['Task ID'].unique().tolist()\n",
    "repetitive_dwa_task_titles = df_all['Task Title'].unique().tolist()\n",
    "print(f\"Found {len(repetitive_dwa_task_ids)} tasks related to these DWAs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ee8b7dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DWA ID</th>\n",
       "      <th>num_tasks_survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.A.1.a.1.I01.D01</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.A.1.a.1.I01.D02</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.A.1.a.1.I01.D03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.A.1.a.1.I01.D04</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.A.1.a.1.I02.D01</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>4.A.4.c.3.I07.D01</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>4.A.4.c.3.I07.D02</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>4.A.4.c.3.I07.D03</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>4.A.4.c.3.I07.D04</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>4.A.4.c.3.I07.D05</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 DWA ID  num_tasks_survived\n",
       "0     4.A.1.a.1.I01.D01                   3\n",
       "1     4.A.1.a.1.I01.D02                   2\n",
       "2     4.A.1.a.1.I01.D03                   2\n",
       "3     4.A.1.a.1.I01.D04                   7\n",
       "4     4.A.1.a.1.I02.D01                   4\n",
       "...                 ...                 ...\n",
       "1995  4.A.4.c.3.I07.D01                   9\n",
       "1996  4.A.4.c.3.I07.D02                   4\n",
       "1997  4.A.4.c.3.I07.D03                  10\n",
       "1998  4.A.4.c.3.I07.D04                  19\n",
       "1999  4.A.4.c.3.I07.D05                   4\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe with all tasks that have survived the DWA task similarity procedure\n",
    "survived_tasks_count_df = df_all.groupby('DWA ID')['Task ID'].nunique().reset_index(name='num_tasks_survived')\n",
    "survived_tasks_count_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c91f2ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of merged_data before merging DWA info: 17925\n",
      "Length of merged_data after merging DWA info: 22267\n",
      "Created DWA-level dataset with 2081 DWAs.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DWA ID</th>\n",
       "      <th>DWA Title</th>\n",
       "      <th>num_tasks</th>\n",
       "      <th>num_occupations</th>\n",
       "      <th>fraction_manual</th>\n",
       "      <th>fraction_automation</th>\n",
       "      <th>fraction_augmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.A.1.a.1.I01.D01</td>\n",
       "      <td>Review art or design materials.</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.A.1.a.1.I01.D03</td>\n",
       "      <td>Review production information to determine cos...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.A.1.a.1.I01.D04</td>\n",
       "      <td>Study scripts to determine project requirements.</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.A.1.a.1.I02.D01</td>\n",
       "      <td>Read materials to determine needed actions.</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.A.1.a.1.I02.D02</td>\n",
       "      <td>Read maps to determine routes.</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>4.A.4.c.3.I05.D03</td>\n",
       "      <td>Purchase materials, equipment, or other resour...</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069</th>\n",
       "      <td>4.A.4.c.3.I05.D06</td>\n",
       "      <td>Purchase products or services.</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072</th>\n",
       "      <td>4.A.4.c.3.I06.D01</td>\n",
       "      <td>Prescribe treatments or therapies.</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2074</th>\n",
       "      <td>4.A.4.c.3.I06.D03</td>\n",
       "      <td>Prescribe medications.</td>\n",
       "      <td>31</td>\n",
       "      <td>26</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2078</th>\n",
       "      <td>4.A.4.c.3.I07.D03</td>\n",
       "      <td>Inventory medical supplies or equipment.</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>831 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 DWA ID                                          DWA Title  \\\n",
       "0     4.A.1.a.1.I01.D01                    Review art or design materials.   \n",
       "2     4.A.1.a.1.I01.D03  Review production information to determine cos...   \n",
       "3     4.A.1.a.1.I01.D04   Study scripts to determine project requirements.   \n",
       "4     4.A.1.a.1.I02.D01        Read materials to determine needed actions.   \n",
       "5     4.A.1.a.1.I02.D02                     Read maps to determine routes.   \n",
       "...                 ...                                                ...   \n",
       "2066  4.A.4.c.3.I05.D03  Purchase materials, equipment, or other resour...   \n",
       "2069  4.A.4.c.3.I05.D06                     Purchase products or services.   \n",
       "2072  4.A.4.c.3.I06.D01                 Prescribe treatments or therapies.   \n",
       "2074  4.A.4.c.3.I06.D03                             Prescribe medications.   \n",
       "2078  4.A.4.c.3.I07.D03           Inventory medical supplies or equipment.   \n",
       "\n",
       "      num_tasks  num_occupations  fraction_manual  fraction_automation  \\\n",
       "0             6                4             0.83                 0.00   \n",
       "2             6                2             0.83                 0.00   \n",
       "3             9                8             0.33                 0.56   \n",
       "4             4                4             0.75                 0.25   \n",
       "5             4                4             0.75                 0.00   \n",
       "...         ...              ...              ...                  ...   \n",
       "2066         22               20             0.95                 0.00   \n",
       "2069         15               10             0.93                 0.07   \n",
       "2072         19               16             0.89                 0.00   \n",
       "2074         31               26             0.97                 0.00   \n",
       "2078         13               10             0.92                 0.08   \n",
       "\n",
       "      fraction_augmentation  \n",
       "0                      0.17  \n",
       "2                      0.17  \n",
       "3                      0.11  \n",
       "4                      0.00  \n",
       "5                      0.25  \n",
       "...                     ...  \n",
       "2066                   0.05  \n",
       "2069                   0.00  \n",
       "2072                   0.11  \n",
       "2074                   0.03  \n",
       "2078                   0.00  \n",
       "\n",
       "[831 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified 831 DWAs with varying execution types across occupations.\n"
     ]
    }
   ],
   "source": [
    "# Create a DWA-level dataset with number of tasks and occupations per DWA, as well as fraction of manual, automation, and augmentation tasks per DWA\n",
    "merged_data = pd.read_csv(f\"{input_data_path}/computed_objects/ONET_Eloundou_Anthropic_GPT/ONET_Eloundou_Anthropic_GPT.csv\")\n",
    "merged_data['is_manual'] = merged_data['label'] == 'Manual'\n",
    "merged_data['is_automation'] = merged_data['label'] == 'Automation'\n",
    "merged_data['is_augmentation'] = merged_data['label'] == 'Augmentation'\n",
    "\n",
    "\n",
    "# Merge back DWA ID and DWA Titles to the merged_data\n",
    "dwa_task_mapping = pd.read_csv(f\"{input_data_path}/computed_objects/similar_dwa_tasks/dwa_task_mapping.csv\")\n",
    "print(f'Length of merged_data before merging DWA info: {merged_data.shape[0]}')\n",
    "merged_data = merged_data.merge(dwa_task_mapping, on=['Task ID', 'Task Title', 'O*NET-SOC Code', 'Occupation Title'], how='left')\n",
    "print(f'Length of merged_data after merging DWA info: {merged_data.shape[0]}')\n",
    "\n",
    "\n",
    "# Aggregate to get fractions\n",
    "dwa_grouped = merged_data.groupby(['DWA ID', 'DWA Title']).agg(\n",
    "    num_tasks = ('Task ID', 'nunique'),\n",
    "    num_occupations = ('O*NET-SOC Code', 'nunique'),\n",
    "    fraction_manual = ('is_manual', 'mean'),\n",
    "    fraction_automation = ('is_automation', 'mean'),\n",
    "    fraction_augmentation = ('is_augmentation', 'mean'),\n",
    ").reset_index()\n",
    "print(f\"Created DWA-level dataset with {dwa_grouped.shape[0]} DWAs.\")\n",
    "\n",
    "# Keep only DWAs with variation in terms of execution type across occupations\n",
    "dwa_grouped_filtered = dwa_grouped[\n",
    "     (dwa_grouped['num_occupations'] > 1) & (dwa_grouped['fraction_manual'] > 0) & (dwa_grouped['fraction_manual'] < 1)\n",
    "].copy()\n",
    "display(dwa_grouped_filtered)\n",
    "\n",
    "# Create list of DWAs with varying execution types\n",
    "dwas_varying_exec_types_ids = dwa_grouped_filtered['DWA ID'].unique().tolist()\n",
    "dwas_varying_exec_types_titles = dwa_grouped_filtered['DWA Title'].unique().tolist()\n",
    "print(f\"Identified {len(dwas_varying_exec_types_ids)} DWAs with varying execution types across occupations.\")\n",
    "\n",
    "# Merge back the number of tasks survived info\n",
    "dwa_grouped_filtered = dwa_grouped_filtered.merge(survived_tasks_count_df, left_on='DWA ID', right_on='DWA ID', how='left')\n",
    "\n",
    "# Save output\n",
    "dwa_grouped_filtered.to_csv(f\"{output_data_path}/dwas_varying_execution_types.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "04a84d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of merged_data before dropping duplicates: 22267\n",
      "Length of merged_data after dropping duplicates: 17920\n",
      "\n",
      "Number of dwa_execType_varying rows: 6675\n",
      "prev2_is_ai: 1140 of 6675 flagged rows (fraction=0.171)\n",
      "prev_is_ai: 1283 of 6675 flagged rows (fraction=0.192)\n",
      "next_is_ai: 1247 of 6675 flagged rows (fraction=0.187)\n",
      "next2_is_ai: 1142 of 6675 flagged rows (fraction=0.171)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O*NET-SOC Code</th>\n",
       "      <th>Occupation Title</th>\n",
       "      <th>Task ID</th>\n",
       "      <th>Task Title</th>\n",
       "      <th>Task Position</th>\n",
       "      <th>Task Type</th>\n",
       "      <th>Major_Group_Code</th>\n",
       "      <th>Major_Group_Title</th>\n",
       "      <th>Minor_Group_Code</th>\n",
       "      <th>Minor_Group_Title</th>\n",
       "      <th>...</th>\n",
       "      <th>is_automated</th>\n",
       "      <th>is_exposed</th>\n",
       "      <th>num_tasks</th>\n",
       "      <th>prev_is_ai</th>\n",
       "      <th>prev2_is_ai</th>\n",
       "      <th>next_is_ai</th>\n",
       "      <th>next2_is_ai</th>\n",
       "      <th>DWA ID</th>\n",
       "      <th>DWA Title</th>\n",
       "      <th>dwa_execType_varying</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>20461</td>\n",
       "      <td>Review and analyze legislation, laws, or publi...</td>\n",
       "      <td>1</td>\n",
       "      <td>Core</td>\n",
       "      <td>11-0000</td>\n",
       "      <td>Management Occupations</td>\n",
       "      <td>11-1000</td>\n",
       "      <td>Top Executives</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.A.2.a.4.I09.D03</td>\n",
       "      <td>Analyze impact of legal or regulatory changes.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>8825</td>\n",
       "      <td>Analyze operations to evaluate performance of ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Core</td>\n",
       "      <td>11-0000</td>\n",
       "      <td>Management Occupations</td>\n",
       "      <td>11-1000</td>\n",
       "      <td>Top Executives</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.A.2.a.4.I07.D09</td>\n",
       "      <td>Analyze data to assess operational or project ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>8824</td>\n",
       "      <td>Confer with board members, organization offici...</td>\n",
       "      <td>4</td>\n",
       "      <td>Core</td>\n",
       "      <td>11-0000</td>\n",
       "      <td>Management Occupations</td>\n",
       "      <td>11-1000</td>\n",
       "      <td>Top Executives</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.A.4.a.2.I03.D14</td>\n",
       "      <td>Confer with organizational members to accompli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>8826</td>\n",
       "      <td>Direct, plan, or implement policies, objective...</td>\n",
       "      <td>6</td>\n",
       "      <td>Core</td>\n",
       "      <td>11-0000</td>\n",
       "      <td>Management Occupations</td>\n",
       "      <td>11-1000</td>\n",
       "      <td>Top Executives</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.A.2.b.1.I09.D01</td>\n",
       "      <td>Implement organizational process or policy cha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>8827</td>\n",
       "      <td>Prepare budgets for approval, including those ...</td>\n",
       "      <td>10</td>\n",
       "      <td>Core</td>\n",
       "      <td>11-0000</td>\n",
       "      <td>Management Occupations</td>\n",
       "      <td>11-1000</td>\n",
       "      <td>Top Executives</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.A.4.b.4.I09.D04</td>\n",
       "      <td>Prepare operational budgets.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   O*NET-SOC Code  Occupation Title  Task ID  \\\n",
       "0      11-1011.00  Chief Executives    20461   \n",
       "3      11-1011.00  Chief Executives     8825   \n",
       "4      11-1011.00  Chief Executives     8824   \n",
       "6      11-1011.00  Chief Executives     8826   \n",
       "12     11-1011.00  Chief Executives     8827   \n",
       "\n",
       "                                           Task Title  Task Position  \\\n",
       "0   Review and analyze legislation, laws, or publi...              1   \n",
       "3   Analyze operations to evaluate performance of ...              3   \n",
       "4   Confer with board members, organization offici...              4   \n",
       "6   Direct, plan, or implement policies, objective...              6   \n",
       "12  Prepare budgets for approval, including those ...             10   \n",
       "\n",
       "   Task Type Major_Group_Code       Major_Group_Title Minor_Group_Code  \\\n",
       "0       Core          11-0000  Management Occupations          11-1000   \n",
       "3       Core          11-0000  Management Occupations          11-1000   \n",
       "4       Core          11-0000  Management Occupations          11-1000   \n",
       "6       Core          11-0000  Management Occupations          11-1000   \n",
       "12      Core          11-0000  Management Occupations          11-1000   \n",
       "\n",
       "   Minor_Group_Title  ... is_automated is_exposed num_tasks prev_is_ai  \\\n",
       "0     Top Executives  ...            0          0        31          0   \n",
       "3     Top Executives  ...            0          0        31          0   \n",
       "4     Top Executives  ...            0          0        31          1   \n",
       "6     Top Executives  ...            0          0        31          0   \n",
       "12    Top Executives  ...            0          0        31          0   \n",
       "\n",
       "   prev2_is_ai next_is_ai  next2_is_ai             DWA ID  \\\n",
       "0            0          0            1  4.A.2.a.4.I09.D03   \n",
       "3            1          1            0  4.A.2.a.4.I07.D09   \n",
       "4            0          0            0  4.A.4.a.2.I03.D14   \n",
       "6            1          1            0  4.A.2.b.1.I09.D01   \n",
       "12           0          0            1  4.A.4.b.4.I09.D04   \n",
       "\n",
       "                                            DWA Title  dwa_execType_varying  \n",
       "0      Analyze impact of legal or regulatory changes.                     1  \n",
       "3   Analyze data to assess operational or project ...                     1  \n",
       "4   Confer with organizational members to accompli...                     1  \n",
       "6   Implement organizational process or policy cha...                     1  \n",
       "12                       Prepare operational budgets.                     1  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read the merged data\n",
    "merged_data = pd.read_csv(f\"{input_data_path}/computed_objects/ONET_Eloundou_Anthropic_GPT/ONET_Eloundou_Anthropic_GPT.csv\")\n",
    "merged_data = merged_data[['O*NET-SOC Code', 'Occupation Title', 'Task ID', 'Task Title',\n",
    "       'Task Position', 'Task Type', \n",
    "       'Major_Group_Code', 'Major_Group_Title', \n",
    "       'Minor_Group_Code', 'Minor_Group_Title',\n",
    "       'Broad_Occupation_Code', 'Broad_Occupation_Title',\n",
    "       'Detailed_Occupation_Code', 'Detailed_Occupation_Title',\n",
    "       'gpt4_exposure', 'human_labels', \n",
    "       'automation', 'augmentation', 'label']]\n",
    "\n",
    "\n",
    "# Create is_ai and is_automated flags in merged_data\n",
    "merged_data['is_ai'] = merged_data['label'].isin(['Augmentation','Automation']).astype(int)\n",
    "merged_data['is_automated'] = merged_data['label'].isin(['Automation']).astype(int)\n",
    "merged_data['is_exposed'] = merged_data['human_labels'].isin(['E1']).astype(int)\n",
    "\n",
    "\n",
    "# Step 1: Add occupation's number of tasks info\n",
    "num_tasks_per_occupation = merged_data.groupby('O*NET-SOC Code')['Task ID'].nunique().reset_index()\n",
    "num_tasks_per_occupation = num_tasks_per_occupation.rename(columns={'Task ID': 'num_tasks'})\n",
    "merged_data = merged_data.merge(num_tasks_per_occupation, on='O*NET-SOC Code', how='left')\n",
    "\n",
    "\n",
    "# Step 2: Create flags for previous/next tasks is AI within occupation groups\n",
    "# Sort by occupation and position when possible\n",
    "merged_data['Task Position'] = pd.to_numeric(merged_data['Task Position'], errors='coerce')\n",
    "merged_data = merged_data.sort_values(['O*NET-SOC Code', 'Task Position']).reset_index(drop=True)\n",
    "group_col = 'O*NET-SOC Code'\n",
    "\n",
    "# Compute neighbor flags (prev/next) within occupation groups when possible\n",
    "merged_data['prev_is_ai'] = 0\n",
    "merged_data['prev2_is_ai'] = 0\n",
    "merged_data['next_is_ai'] = 0\n",
    "merged_data['next2_is_ai'] = 0\n",
    "pos_col = 'Task Position'\n",
    "\n",
    "def add_neighbor_flags(df):\n",
    "    df = df.copy()\n",
    "    df['Task Position'] = pd.to_numeric(df['Task Position'], errors='coerce')\n",
    "    df = df.sort_values(['O*NET-SOC Code','Task Position']).reset_index(drop=True)\n",
    "    def _add_flags(g):\n",
    "        g = g.sort_values('Task Position')\n",
    "        g['prev_is_ai'] = g['is_ai'].shift(1).fillna(0).astype(int)\n",
    "        g['prev2_is_ai'] = g['is_ai'].shift(2).fillna(0).astype(int)\n",
    "        # g['prev2_is_ai'] = ((g['prev2_is_ai'] == 1) & (g['prev_is_ai'] == 1)).astype(int)\n",
    "        g['next_is_ai'] = g['is_ai'].shift(-1).fillna(0).astype(int)\n",
    "        g['next2_is_ai'] = g['is_ai'].shift(-2).fillna(0).astype(int)\n",
    "        # g['next2_is_ai'] = ((g['next2_is_ai'] == 1) & (g['next_is_ai'] == 1)).astype(int)\n",
    "        return g\n",
    "    return df.groupby('O*NET-SOC Code', group_keys=False).apply(_add_flags).reset_index(drop=True)\n",
    "merged_data = merged_data.groupby(group_col, group_keys=False).apply(add_neighbor_flags).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "# Step 3: Add back DWA info\n",
    "# Merge back DWA ID and DWA Titles to the merged_data\n",
    "dwa_task_mapping = pd.read_csv(f\"{input_data_path}/computed_objects/similar_dwa_tasks/dwa_task_mapping.csv\")\n",
    "merged_data = merged_data.merge(dwa_task_mapping, on=['Task ID', 'Task Title', 'O*NET-SOC Code', 'Occupation Title'], how='left')\n",
    "# Note that the merge might map multiple DWAs to the same task\n",
    "\n",
    "\n",
    "# Step 4: Flag \"similar\" tasks across occupations\n",
    "merged_data['dwa_execType_varying'] = (\n",
    "    (merged_data['DWA ID'].isin(dwas_varying_exec_types_ids)\n",
    "    & \n",
    "    merged_data['Task ID'].isin(repetitive_dwa_task_ids)\n",
    "    )\n",
    "    & ~(merged_data['DWA ID'].isna())\n",
    ").astype(int)\n",
    "\n",
    "# Remove duplicates in terms of (O*NET-SOC Code, Task ID) if any\n",
    "print(f'Length of merged_data before dropping duplicates: {merged_data.shape[0]}')\n",
    "merged_data = merged_data.drop_duplicates(subset=['O*NET-SOC Code', 'Task ID'])\n",
    "print(f'Length of merged_data after dropping duplicates: {merged_data.shape[0]}')\n",
    "# Save the updated merged_data with flags\n",
    "merged_data[merged_data['dwa_execType_varying'] == 1].to_csv(f\"{output_data_path}/merged_data_DWAexecVaryingTypes.csv\", index=False)\n",
    "\n",
    "\n",
    "# Summary for flagged DWA rows\n",
    "mask = merged_data['dwa_execType_varying'] == 1\n",
    "n_flagged = int(mask.sum())\n",
    "print(f'\\nNumber of dwa_execType_varying rows: {n_flagged}')\n",
    "if n_flagged > 0:\n",
    "    for c in ['prev2_is_ai', 'prev_is_ai', 'next_is_ai', 'next2_is_ai']:\n",
    "        s = int(merged_data.loc[mask, c].sum())\n",
    "        frac = merged_data.loc[mask, c].mean()\n",
    "        print(f'{c}: {s} of {n_flagged} flagged rows (fraction={frac:.3f})')\n",
    "    try:\n",
    "        display(merged_data.loc[mask].head())\n",
    "    except Exception:\n",
    "        print(merged_data.loc[mask].head().to_string(index=False))\n",
    "else:\n",
    "    print('No flagged rows to summarize.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e805dee",
   "metadata": {},
   "source": [
    "## Run regression of multiple-execution-type DWA tasks against execution type of neighboring tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "cf153cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Running Regressions on Filtered Data...\n",
      "\n",
      "% --- LaTeX Table for filtered_0 ---\n",
      "\\begin{tabular}{lccc}\n",
      "\\toprule\n",
      "Specification & (1) & (2) & (3) \\\\\n",
      "\\midrule\n",
      "($t-2$) Task AI & 0.02* & -0.01 & -0.01 \\\\\n",
      " & (0.01) & (0.01) & (0.01) \\\\\n",
      "\\addlinespace\n",
      "($t-1$) Task AI & 0.05*** & 0.02** & 0.02** \\\\\n",
      " & (0.01) & (0.01) & (0.01) \\\\\n",
      "\\addlinespace\n",
      "($t+1$) Task AI & 0.05*** & 0.02*** & 0.02** \\\\\n",
      " & (0.01) & (0.01) & (0.01) \\\\\n",
      "\\addlinespace\n",
      "($t+2$) Task AI & 0.01 & -0.01 & -0.01 \\\\\n",
      " & (0.01) & (0.01) & (0.01) \\\\\n",
      "\\addlinespace\n",
      "\\midrule\n",
      "Pseudo $R^2$ & 0.039 & 0.107 & 0.105 \\\\\n",
      "Adj. Pseudo $R^2$ & 0.035 & 0.091 & 0.063 \\\\\n",
      "Observations & 6,675 & 6,662 & 5,961 \\\\\n",
      "SOC Group Fixed Effects &  & Major & Minor \\\\\n",
      "\\bottomrule\n",
      "\\footnotesize{Robust standard errors in parentheses. *** p$<$0.01, ** p$<$0.05, * p$<$0.1}\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.stats import norm\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Configuration ---\n",
    "TARGET_REGS = ['prev2_is_ai', 'prev_is_ai', 'next_is_ai', 'next2_is_ai']\n",
    "\n",
    "# Labels to match your desired output format\n",
    "VAR_LABELS = {\n",
    "    'prev2_is_ai': '($t-2$) Task AI',\n",
    "    'prev_is_ai': '($t-1$) Task AI',\n",
    "    'next_is_ai': '($t+1$) Task AI',\n",
    "    'next2_is_ai': '($t+2$) Task AI'\n",
    "}\n",
    "\n",
    "# ==========================================\n",
    "# 1. Robust AME Extractor\n",
    "# ==========================================\n",
    "def build_ame_df(res, dataset_name, model_name, target_regs, fe_label):\n",
    "    try:\n",
    "        # --- Calculate Model Statistics ---\n",
    "        pr2 = res.prsquared\n",
    "        k = res.params.shape[0]\n",
    "        adj_pr2 = 1 - (res.llf - k) / res.llnull\n",
    "        nobs = res.nobs\n",
    "\n",
    "        # --- Calculate AME ---\n",
    "        margeff = res.get_margeff(at='overall', method='dydx', dummy=True)\n",
    "        summary = margeff.summary_frame()\n",
    "        \n",
    "        summary = summary.reset_index().rename(columns={'index': 'term'})\n",
    "        \n",
    "        rename_map = {\n",
    "            'dy/dx': 'ame_coef',\n",
    "            'std err': 'ame_se', 'Std. Err.': 'ame_se',\n",
    "            'P>|z|': 'p_value', 'z': 'z_score'\n",
    "        }\n",
    "        summary = summary.rename(columns=rename_map)\n",
    "        \n",
    "        if 'ame_se' not in summary.columns and summary.shape[1] >= 2:\n",
    "             summary['ame_se'] = summary.iloc[:, 1]\n",
    "\n",
    "        summary = summary[summary['term'].isin(target_regs)].copy()\n",
    "        if summary.empty: return pd.DataFrame()\n",
    "\n",
    "        # --- Manual P-Value Calculation ---\n",
    "        summary['ame_coef'] = pd.to_numeric(summary['ame_coef'], errors='coerce')\n",
    "        summary['ame_se'] = pd.to_numeric(summary['ame_se'], errors='coerce')\n",
    "        \n",
    "        if 'p_value' not in summary.columns or summary['p_value'].isnull().any():\n",
    "            z_stat = summary['ame_coef'] / summary['ame_se']\n",
    "            summary['p_value'] = 2 * (1 - norm.cdf(np.abs(z_stat)))\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            'dataset': dataset_name,\n",
    "            'model': model_name,\n",
    "            'fe_label': fe_label,\n",
    "            'nobs': nobs,\n",
    "            'r2_pseudo': pr2,\n",
    "            'r2_adj_pseudo': adj_pr2,\n",
    "            'term': summary['term'],\n",
    "            'ame_coef': summary['ame_coef'],\n",
    "            'ame_se': summary['ame_se'],\n",
    "            'p_value': summary['p_value']\n",
    "        })\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating AME for {model_name}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# ==========================================\n",
    "# 2. Regression Runner (FIXED)\n",
    "# ==========================================\n",
    "def run_regressions_on(df, dataset_name, dependent_var, regressors):\n",
    "    df = df.copy()\n",
    "    all_cols = regressors + [dependent_var, 'is_exposed', 'num_tasks']\n",
    "    existing_cols = [c for c in all_cols if c in df.columns]\n",
    "    df[existing_cols] = df[existing_cols].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "\n",
    "    base_formula = f'{dependent_var} ~ ' + ' + '.join(regressors)\n",
    "    ame_list = []\n",
    "    models = {} # We store models here\n",
    "\n",
    "    # 1) No FE\n",
    "    try:\n",
    "        formula = base_formula + ' + is_exposed + num_tasks'\n",
    "        res = smf.logit(formula, data=df).fit(disp=False, cov_type='HC1')\n",
    "        models['no_fe'] = res\n",
    "        ame_list.append(build_ame_df(res, dataset_name, 'no_fe', regressors, fe_label=\"None\"))\n",
    "        # print(f\"[{dataset_name}] No-FE model converged.\")\n",
    "    except Exception as e: \n",
    "        print(f\"[{dataset_name}] No-FE failed: {e}\")\n",
    "\n",
    "    # 2) Fixed Effects\n",
    "    fe_cols = [('Major_Group_Code', 'MajorGroup', 'Major Group'), \n",
    "               ('Minor_Group_Code', 'MinorGroup', 'Minor Group')]\n",
    "    \n",
    "    for col, short, nice_label in fe_cols:\n",
    "        if col not in df.columns: continue\n",
    "        try:\n",
    "            formula = base_formula + f' + C({col}) + is_exposed + num_tasks'\n",
    "            df_fe = df.groupby(col).filter(lambda g: g[dependent_var].nunique() == 2 and len(g) >= 10)\n",
    "            res = smf.logit(formula, data=df_fe).fit(disp=False, cov_type='HC1')\n",
    "            models[f'fe_{short}'] = res\n",
    "            ame_list.append(build_ame_df(res, dataset_name, f'fe_{short}', regressors, fe_label=nice_label))\n",
    "            # print(f\"[{dataset_name}] FE {short} converged.\")\n",
    "        except Exception as e:\n",
    "            print(f\"[{dataset_name}] FE {short} failed: {e}\")\n",
    "\n",
    "    # FIXED RETURN: Returns tuple (models, dataframe)\n",
    "    combined = pd.concat(ame_list, ignore_index=True) if ame_list else pd.DataFrame()\n",
    "\n",
    "    # Save results to CSV\n",
    "    out_path = f'{output_data_path}/regression_summaries_{dependent_var}'\n",
    "    os.makedirs(out_path, exist_ok=True)\n",
    "    combined.to_csv(f'{out_path}/regression_ame_results_{dataset_name}.csv', index=False)\n",
    "\n",
    "    return models, combined\n",
    "\n",
    "# ==========================================\n",
    "# 3. LaTeX Table Generator\n",
    "# ==========================================\n",
    "def generate_latex_table(df_results):\n",
    "    if df_results.empty:\n",
    "        print(\"No results to tabulate.\")\n",
    "        return\n",
    "\n",
    "    # Filter for one dataset\n",
    "    dataset_to_show = df_results['dataset'].unique()[0]\n",
    "    subset = df_results[df_results['dataset'] == dataset_to_show].copy()\n",
    "    \n",
    "    print(f\"\\n% --- LaTeX Table for {dataset_to_show} ---\")\n",
    "\n",
    "    # --- Formatting ---\n",
    "    def fmt(row):\n",
    "        stars = \"\"\n",
    "        p = row['p_value']\n",
    "        if pd.notna(p):\n",
    "            if p < 0.01: stars = \"***\"\n",
    "            elif p < 0.05: stars = \"**\"\n",
    "            elif p < 0.10: stars = \"*\"\n",
    "        return f\"{row['ame_coef']:.2f}{stars}\", f\"({row['ame_se']:.2f})\"\n",
    "\n",
    "    formatted = subset.apply(fmt, axis=1, result_type='expand')\n",
    "    subset['coef_str'] = formatted[0]\n",
    "    subset['se_str'] = formatted[1]\n",
    "\n",
    "    # Pivot\n",
    "    pivot_coef = subset.pivot(index='term', columns='model', values='coef_str')\n",
    "    pivot_se = subset.pivot(index='term', columns='model', values='se_str')\n",
    "\n",
    "    # Ordering\n",
    "    valid_vars = [v for v in TARGET_REGS if v in pivot_coef.index]\n",
    "    pivot_coef = pivot_coef.reindex(valid_vars)\n",
    "    pivot_se = pivot_se.reindex(valid_vars)\n",
    "    \n",
    "    model_order = ['no_fe', 'fe_MajorGroup', 'fe_MinorGroup']\n",
    "    valid_models = [m for m in model_order if m in pivot_coef.columns]\n",
    "\n",
    "    # Extract Footer Stats\n",
    "    stats = subset[['model', 'nobs', 'r2_pseudo', 'r2_adj_pseudo', 'fe_label']].drop_duplicates('model').set_index('model')\n",
    "\n",
    "    # --- Print LaTeX ---\n",
    "    col_def = \"l\" + \"c\" * len(valid_models) \n",
    "    \n",
    "    print(f\"\\\\begin{{tabular}}{{{col_def}}}\")\n",
    "    print(r\"\\toprule\")\n",
    "    \n",
    "    # Header\n",
    "    header_nums = [f\"({i+1})\" for i in range(len(valid_models))]\n",
    "    print(f\"Specification & \" + \" & \".join(header_nums) + r\" \\\\\")\n",
    "    print(r\"\\midrule\")\n",
    "\n",
    "    # Body (Variables)\n",
    "    for var in valid_vars:\n",
    "        label = VAR_LABELS.get(var, var.replace('_', ' '))\n",
    "        \n",
    "        # Coefficient Row\n",
    "        c_vals = [pivot_coef.loc[var, m] if pd.notna(pivot_coef.loc[var, m]) else \"\" for m in valid_models]\n",
    "        print(f\"{label} & \" + \" & \".join(c_vals) + r\" \\\\\")\n",
    "        \n",
    "        # SE Row\n",
    "        s_vals = [pivot_se.loc[var, m] if pd.notna(pivot_se.loc[var, m]) else \"\" for m in valid_models]\n",
    "        print(f\" & \" + \" & \".join(s_vals) + r\" \\\\\")\n",
    "        print(r\"\\addlinespace\")\n",
    "\n",
    "    print(r\"\\midrule\")\n",
    "    \n",
    "    # --- Footer ---\n",
    "    \n",
    "    # Pseudo R2\n",
    "    r2_vals = [f\"{stats.loc[m, 'r2_pseudo']:.3f}\" if m in stats.index else \"\" for m in valid_models]\n",
    "    print(f\"Pseudo $R^2$ & \" + \" & \".join(r2_vals) + r\" \\\\\")\n",
    "    \n",
    "    # Adj Pseudo R2\n",
    "    adj_r2_vals = [f\"{stats.loc[m, 'r2_adj_pseudo']:.3f}\" if m in stats.index else \"\" for m in valid_models]\n",
    "    print(f\"Adj. Pseudo $R^2$ & \" + \" & \".join(adj_r2_vals) + r\" \\\\\")\n",
    "    \n",
    "    # Observations\n",
    "    obs_vals = [f\"{int(stats.loc[m, 'nobs']):,}\" if m in stats.index else \"\" for m in valid_models]\n",
    "    print(f\"Observations & \" + \" & \".join(obs_vals) + r\" \\\\\")\n",
    "\n",
    "    # Fixed Effects\n",
    "    fe_vals = []\n",
    "    for m in valid_models:\n",
    "        if m in stats.index:\n",
    "            label = stats.loc[m, 'fe_label']\n",
    "            if pd.isna(label) or str(label) == \"None\":\n",
    "                fe_vals.append(\"\")\n",
    "            else:\n",
    "                fe_vals.append(str(label)[:5])\n",
    "        else:\n",
    "            fe_vals.append(\"\")\n",
    "\n",
    "    print(f\"SOC Group Fixed Effects & \" + \" & \".join(fe_vals) + r\" \\\\\")\n",
    "    \n",
    "    print(r\"\\bottomrule\")\n",
    "    print(r\"\\footnotesize{Robust standard errors in parentheses. *** p$<$0.01, ** p$<$0.05, * p$<$0.1}\")\n",
    "    print(r\"\\end{tabular}\")\n",
    "\n",
    "# ==========================================\n",
    "# 4. Execution Block\n",
    "# ==========================================\n",
    "\n",
    "# dependent_var = 'is_ai'\n",
    "\n",
    "# print(\">>> Running Regressions on Full Data...\")\n",
    "# models_full, res_full = run_regressions_on(merged_data, 'full_0', dependent_var, TARGET_REGS)\n",
    "\n",
    "print(\">>> Running Regressions on Filtered Data...\")\n",
    "filtered = merged_data[merged_data['dwa_execType_varying'] == 1].reset_index(drop=True)\n",
    "models_filt, res_filt = run_regressions_on(filtered, 'filtered_0', dependent_var, TARGET_REGS)\n",
    "\n",
    "# Generate Tables\n",
    "# print(\"\\n\\n\")\n",
    "# generate_latex_table(res_full)\n",
    "# print(\"\\n\\n\")\n",
    "generate_latex_table(res_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "69796c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O*NET-SOC Code</th>\n",
       "      <th>Occupation Title</th>\n",
       "      <th>Task ID</th>\n",
       "      <th>Task Title</th>\n",
       "      <th>Task Position</th>\n",
       "      <th>label</th>\n",
       "      <th>human_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>20461</td>\n",
       "      <td>Review and analyze legislation, laws, or publi...</td>\n",
       "      <td>1</td>\n",
       "      <td>Augmentation</td>\n",
       "      <td>E2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>8825</td>\n",
       "      <td>Analyze operations to evaluate performance of ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Augmentation</td>\n",
       "      <td>E2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>8824</td>\n",
       "      <td>Confer with board members, organization offici...</td>\n",
       "      <td>4</td>\n",
       "      <td>Augmentation</td>\n",
       "      <td>E0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>8826</td>\n",
       "      <td>Direct, plan, or implement policies, objective...</td>\n",
       "      <td>6</td>\n",
       "      <td>Manual</td>\n",
       "      <td>E0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>8827</td>\n",
       "      <td>Prepare budgets for approval, including those ...</td>\n",
       "      <td>10</td>\n",
       "      <td>Manual</td>\n",
       "      <td>E2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6670</th>\n",
       "      <td>53-7081.00</td>\n",
       "      <td>Refuse and Recyclable Material Collectors</td>\n",
       "      <td>7172</td>\n",
       "      <td>Fill out defective equipment reports.</td>\n",
       "      <td>4</td>\n",
       "      <td>Manual</td>\n",
       "      <td>E2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6671</th>\n",
       "      <td>53-7081.00</td>\n",
       "      <td>Refuse and Recyclable Material Collectors</td>\n",
       "      <td>7171</td>\n",
       "      <td>Refuel trucks or add other fluids, such as oil...</td>\n",
       "      <td>5</td>\n",
       "      <td>Manual</td>\n",
       "      <td>E0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6672</th>\n",
       "      <td>53-7081.00</td>\n",
       "      <td>Refuse and Recyclable Material Collectors</td>\n",
       "      <td>7184</td>\n",
       "      <td>Provide quotes for refuse collection contracts.</td>\n",
       "      <td>16</td>\n",
       "      <td>Manual</td>\n",
       "      <td>E2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6673</th>\n",
       "      <td>53-7121.00</td>\n",
       "      <td>Tank Car, Truck, and Ship Loaders</td>\n",
       "      <td>12792</td>\n",
       "      <td>Verify tank car, barge, or truck load numbers ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Manual</td>\n",
       "      <td>E2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6674</th>\n",
       "      <td>53-7121.00</td>\n",
       "      <td>Tank Car, Truck, and Ship Loaders</td>\n",
       "      <td>12801</td>\n",
       "      <td>Test samples for specific gravity, using hydro...</td>\n",
       "      <td>15</td>\n",
       "      <td>Manual</td>\n",
       "      <td>E0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6675 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     O*NET-SOC Code                           Occupation Title  Task ID  \\\n",
       "0        11-1011.00                           Chief Executives    20461   \n",
       "1        11-1011.00                           Chief Executives     8825   \n",
       "2        11-1011.00                           Chief Executives     8824   \n",
       "3        11-1011.00                           Chief Executives     8826   \n",
       "4        11-1011.00                           Chief Executives     8827   \n",
       "...             ...                                        ...      ...   \n",
       "6670     53-7081.00  Refuse and Recyclable Material Collectors     7172   \n",
       "6671     53-7081.00  Refuse and Recyclable Material Collectors     7171   \n",
       "6672     53-7081.00  Refuse and Recyclable Material Collectors     7184   \n",
       "6673     53-7121.00          Tank Car, Truck, and Ship Loaders    12792   \n",
       "6674     53-7121.00          Tank Car, Truck, and Ship Loaders    12801   \n",
       "\n",
       "                                             Task Title  Task Position  \\\n",
       "0     Review and analyze legislation, laws, or publi...              1   \n",
       "1     Analyze operations to evaluate performance of ...              3   \n",
       "2     Confer with board members, organization offici...              4   \n",
       "3     Direct, plan, or implement policies, objective...              6   \n",
       "4     Prepare budgets for approval, including those ...             10   \n",
       "...                                                 ...            ...   \n",
       "6670              Fill out defective equipment reports.              4   \n",
       "6671  Refuel trucks or add other fluids, such as oil...              5   \n",
       "6672    Provide quotes for refuse collection contracts.             16   \n",
       "6673  Verify tank car, barge, or truck load numbers ...              1   \n",
       "6674  Test samples for specific gravity, using hydro...             15   \n",
       "\n",
       "             label human_labels  \n",
       "0     Augmentation           E2  \n",
       "1     Augmentation           E2  \n",
       "2     Augmentation           E0  \n",
       "3           Manual           E0  \n",
       "4           Manual           E2  \n",
       "...            ...          ...  \n",
       "6670        Manual           E2  \n",
       "6671        Manual           E0  \n",
       "6672        Manual           E2  \n",
       "6673        Manual           E2  \n",
       "6674        Manual           E0  \n",
       "\n",
       "[6675 rows x 7 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered[['O*NET-SOC Code', 'Occupation Title', 'Task ID', 'Task Title', 'Task Position', 'label', 'human_labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "dd05f169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 1000 reshuffles to generate Null Distribution of AMEs...\n",
      "  Completed 50/1000\n",
      "  Completed 100/1000\n",
      "  Completed 150/1000\n",
      "  Completed 200/1000\n",
      "  Completed 250/1000\n",
      "  Completed 300/1000\n",
      "  Completed 350/1000\n",
      "  Completed 400/1000\n",
      "  Completed 450/1000\n",
      "  Completed 500/1000\n",
      "  Completed 550/1000\n",
      "  Completed 600/1000\n",
      "  Completed 650/1000\n",
      "  Completed 700/1000\n",
      "  Completed 750/1000\n",
      "  Completed 800/1000\n",
      "  Completed 850/1000\n",
      "  Completed 900/1000\n",
      "  Completed 950/1000\n",
      "  Completed 1000/1000\n",
      "Reshuffles complete; Marginal Effects stored in resh_full and resh_filt.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the specifications we expect to see\n",
    "SPECS = ['no_fe', 'fe_MajorGroup', 'fe_MinorGroup']\n",
    "\n",
    "# ======================================================\n",
    "# 1. Helper: Extract AME directly (No Transformation)\n",
    "# ======================================================\n",
    "def results_to_dict(df_results):\n",
    "    \"\"\"\n",
    "    Reads the dataframe output from run_regressions_on and converts\n",
    "    the 'ame_coef' column into a dictionary structure.\n",
    "    \"\"\"\n",
    "    out = {spec: {term: np.nan for term in TARGET_REGS} for spec in SPECS}\n",
    "    \n",
    "    if df_results is None or df_results.empty:\n",
    "        return out\n",
    "\n",
    "    for _, row in df_results.iterrows():\n",
    "        spec = row['model']\n",
    "        term = row['term']\n",
    "        \n",
    "        if spec in out and term in out[spec]:\n",
    "            # CRITICAL CHANGE: Use 'ame_coef' directly.\n",
    "            # Do NOT apply logistic transformation to a marginal effect.\n",
    "            if 'ame_coef' in row and pd.notna(row['ame_coef']):\n",
    "                out[spec][term] = row['ame_coef']\n",
    "                \n",
    "    return out\n",
    "\n",
    "# Store observed values\n",
    "# obs_dict_full = results_to_dict(res_full)\n",
    "obs_dict_filt = results_to_dict(res_filt)\n",
    "\n",
    "# ======================================================\n",
    "# 2. Reshuffling Loop\n",
    "# ======================================================\n",
    "# Prepare containers for reshuffled AMEs\n",
    "resh_full = {spec: {t: [] for t in TARGET_REGS} for spec in SPECS}\n",
    "resh_filt = {spec: {t: [] for t in TARGET_REGS} for spec in SPECS}\n",
    "\n",
    "# Assuming n_shuffles is defined (e.g., 1000)\n",
    "print(f'Running {n_shuffles} reshuffles to generate Null Distribution of AMEs...')\n",
    "\n",
    "for i in range(n_shuffles):\n",
    "    seed = 42 + i\n",
    "    \n",
    "    # CHANGED FILENAME: Use '_ame_summary.csv' to avoid loading old cached raw-coef files\n",
    "    # fname_full = f\"{output_data_path}/regression_summaries_{dependent_var}/regression_ame_results_full_{i}.csv\"\n",
    "    fname_filt = f\"{output_data_path}/regression_summaries_{dependent_var}/regression_ame_results_filtered_{i}.csv\"\n",
    "\n",
    "    # --- Load or Compute ---\n",
    "    # if Path(fname_full).exists() and Path(fname_filt).exists():\n",
    "    if Path(fname_filt).exists():\n",
    "        # Load existing results\n",
    "        # res_shuf_full = pd.read_csv(fname_full)\n",
    "        res_shuf_filt = pd.read_csv(fname_filt)\n",
    "    else:\n",
    "        # Create Shuffled Data\n",
    "        df_shuf = merged_data.copy()\n",
    "        # Shuffle Task Position within O*NET Code\n",
    "        df_shuf['Task Position'] = df_shuf.groupby('O*NET-SOC Code')['Task Position'].transform(\n",
    "            lambda x: x.sample(frac=1, random_state=seed).values\n",
    "        )\n",
    "        \n",
    "        # Re-calculate neighbor flags based on shuffled positions\n",
    "        # (Assuming add_neighbor_flags function exists in your scope)\n",
    "        df_shuf = add_neighbor_flags(df_shuf)\n",
    "        \n",
    "        # Run Regressions (Full)\n",
    "        # _, res_shuf_full = run_regressions_on(df_shuf, f'full_{i}', dependent_var=dependent_var, regressors=TARGET_REGS)\n",
    "        \n",
    "        # Run Regressions (Filtered)\n",
    "        df_shuf_filt = df_shuf[df_shuf['dwa_execType_varying'] == 1].reset_index(drop=True)\n",
    "        _, res_shuf_filt = run_regressions_on(df_shuf_filt, f'filtered_{i}', dependent_var=dependent_var, regressors=TARGET_REGS)\n",
    "    # --- Store Results ---\n",
    "    # d_full = results_to_dict(res_shuf_full)\n",
    "    d_filt = results_to_dict(res_shuf_filt)\n",
    "\n",
    "    # Append to lists\n",
    "    for spec in SPECS:\n",
    "        for t in TARGET_REGS:\n",
    "            # resh_full[spec][t].append(d_full[spec][t])\n",
    "            resh_filt[spec][t].append(d_filt[spec][t])\n",
    "\n",
    "    if (i+1) % 50 == 0:\n",
    "        print(f'  Completed {i+1}/{n_shuffles}')\n",
    "\n",
    "print('Reshuffles complete; Marginal Effects stored in resh_full and resh_filt.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "55545e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved full multi-row plot to ../writeup/plots/execTypeVaryingDWA/is_automated/AME_filtered_is_automated.png\n",
      "Saved row plot to ../writeup/plots/execTypeVaryingDWA/is_automated/AME_filtered_is_automated_no_fe.png\n",
      "Saved row plot to ../writeup/plots/execTypeVaryingDWA/is_automated/AME_filtered_is_automated_fe_MajorGroup.png\n",
      "Saved row plot to ../writeup/plots/execTypeVaryingDWA/is_automated/AME_filtered_is_automated_fe_MinorGroup.png\n",
      "All done: comparative Marginal Effect histogram figures created.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import os # Ensure os is imported for makedirs\n",
    "\n",
    "# --- Plotting: distributions of Marginal Effects (AME) ---\n",
    "def plot_comparison_hist(resh_dict, obs_dict, title, out_name, plot_title_variable, bins=30):\n",
    "    \"\"\"Create the multi-row comparison histogram and also save each row (spec) as a separate image.\n",
    "\n",
    "    Args:\n",
    "        resh_dict: dict of reshuffled AMEs per spec and term\n",
    "        obs_dict: dict of observed AMEs per spec and term\n",
    "        title: title string to include in saved figures\n",
    "        out_name: filename for the full multi-row figure\n",
    "        plot_title_variable: human-readable dependent var name for titles\n",
    "        bins: histogram bins\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- 1. Calculate Global Bounds for X-Axis ---\n",
    "    # We collect all reshuffled AND observed values to ensure the plot \n",
    "    # covers the entire range of data plus the red observed line.\n",
    "    all_resh_vals = [v \n",
    "                     for inner_dict in resh_dict.values()\n",
    "                     for values_list in inner_dict.values()\n",
    "                     for v in values_list if not np.isnan(v)]\n",
    "    \n",
    "    all_obs_vals = [v \n",
    "                    for inner_dict in obs_dict.values()\n",
    "                    for v in inner_dict.values() if not np.isnan(v)]\n",
    "    \n",
    "    total_vals = all_resh_vals + all_obs_vals\n",
    "    \n",
    "    if not total_vals:\n",
    "        print(\"Warning: No valid data found to plot.\")\n",
    "        return\n",
    "\n",
    "    g_min, g_max = min(total_vals), max(total_vals)\n",
    "    \n",
    "    # Add 10% padding to the range (handles negative and positive numbers correctly)\n",
    "    span = g_max - g_min\n",
    "    if span == 0: span = 0.1 # Prevent crash if single point\n",
    "    x_limit_min = g_min - (span * 0.1)\n",
    "    x_limit_max = g_max + (span * 0.1)\n",
    "\n",
    "    # --- 2. Setup Plot ---\n",
    "    colors = [plt.cm.tab10(i % 10) for i in range(len(SPECS))]\n",
    "    fig, axes = plt.subplots(nrows=len(SPECS), ncols=len(TARGET_REGS), \n",
    "                             figsize=(6*len(TARGET_REGS), 5*len(SPECS)), \n",
    "                             sharey='col')\n",
    "\n",
    "    # Handle case where there is only 1 row (axes is 1D array)\n",
    "    if len(SPECS) == 1:\n",
    "        axes = np.array([axes])\n",
    "\n",
    "    for r, spec in enumerate(SPECS):\n",
    "        color_row = colors[r]\n",
    "        for c, term in enumerate(TARGET_REGS):\n",
    "            ax = axes[r, c]\n",
    "            vals = np.array(resh_dict[spec][term], dtype=float)\n",
    "            vals_clean = vals[~np.isnan(vals)]\n",
    "\n",
    "            if len(vals_clean):\n",
    "                ax.hist(vals_clean, bins=bins, color=color_row, alpha=0.7, edgecolor='k', label='Task Position Reshuffled AMEs')\n",
    "                lo, hi = np.percentile(vals_clean, [2.5, 97.5])\n",
    "                ax.axvline(lo, color=color_row, linestyle=':', alpha=0.8)\n",
    "                ax.axvline(hi, color=color_row, linestyle=':', alpha=0.8)\n",
    "                ax.axvline(np.mean(vals_clean), color=color_row, linestyle='-', alpha=0.9)\n",
    "            else:\n",
    "                ax.text(0.5, 0.5, 'no estimates', ha='center', va='center')\n",
    "\n",
    "            # Observed AME (red dashed)\n",
    "            obs_val = obs_dict.get(spec, {}).get(term, np.nan)\n",
    "            if not np.isnan(obs_val):\n",
    "                ax.axvline(obs_val, color='red', linestyle='--', linewidth=3, label=f'Observed = {obs_val:.3f}')\n",
    "\n",
    "            # --- CHANGE: Baseline is now 0.0 (No Effect), not 0.5 ---\n",
    "            ax.axvline(0.0, color='black', linestyle='-', linewidth=1.5, alpha=0.5, label='Zero Effect')\n",
    "\n",
    "            # Titles and Labels\n",
    "            if r == 0:\n",
    "                # Use the formatted labels from your VAR_LABELS dict if available\n",
    "                clean_title = VAR_LABELS.get(term, term) if 'VAR_LABELS' in globals() else PLOT_TITLES[c]\n",
    "                ax.set_title(clean_title, fontsize=14, fontweight='bold')\n",
    "            \n",
    "            if r == len(SPECS) - 1:\n",
    "                ax.set_xlabel('Average Marginal Effect', fontsize=12)\n",
    "            \n",
    "            if c == 0:\n",
    "                clean_spec = spec.replace('fe_', '').replace('_', ' ').title()\n",
    "                ax.set_ylabel(f'{clean_spec}\\nCount', fontsize=12)\n",
    "\n",
    "            # Apply consistent X-limits\n",
    "            ax.set_xlim(x_limit_min, x_limit_max)\n",
    "            ax.grid(axis='y', linestyle=':', alpha=0.5)\n",
    "            \n",
    "            # Only show legend on the first subplot to avoid clutter\n",
    "            ax.legend(loc='best')\n",
    "\n",
    "    # fig.suptitle(f'Reshuffled vs. Observed Marginal Effects (Outcome: {plot_title_variable})',\n",
    "    #              fontsize=16, fontweight='bold', y=1.02)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Ensure output dir exists\n",
    "    Path(output_plot_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Save full multi-row figure\n",
    "    out_dir = f'{output_plot_path}/{dependent_var}'\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    out_path = f'{out_dir}/{out_name}'\n",
    "    fig.savefig(out_path, dpi=150, bbox_inches='tight')\n",
    "    print('Saved full multi-row plot to', out_path)\n",
    "\n",
    "    # --- 3. Save Individual Rows ---\n",
    "    base_name = out_name.rsplit('.', 1)[0]\n",
    "    for r, spec in enumerate(SPECS):\n",
    "        fig_row, axs_row = plt.subplots(nrows=1, ncols=len(TARGET_REGS), figsize=(24, 5), sharey=False)\n",
    "        if len(TARGET_REGS) == 1: axs_row = [axs_row] # Normalize to list\n",
    "        \n",
    "        color_row = colors[r]\n",
    "        for c, term in enumerate(TARGET_REGS):\n",
    "            axr = axs_row[c]\n",
    "            vals = np.array(resh_dict[spec][term], dtype=float)\n",
    "            vals_clean = vals[~np.isnan(vals)]\n",
    "\n",
    "            if len(vals_clean):\n",
    "                axr.hist(vals_clean, bins=bins, color=color_row, alpha=0.7, edgecolor='k', label='Task Position Reshuffled AMEs')\n",
    "                lo, hi = np.percentile(vals_clean, [2.5, 97.5])\n",
    "                axr.axvline(lo, color=color_row, linestyle=':', alpha=0.8)\n",
    "                axr.axvline(hi, color=color_row, linestyle=':', alpha=0.8)\n",
    "                axr.axvline(np.mean(vals_clean), color=color_row, linestyle='-', alpha=0.9)\n",
    "            else:\n",
    "                axr.text(0.5, 0.5, 'no estimates', ha='center', va='center')\n",
    "\n",
    "            obs_val = obs_dict.get(spec, {}).get(term, np.nan)\n",
    "            if not np.isnan(obs_val):\n",
    "                axr.axvline(obs_val, color='red', linestyle='--', linewidth=3, label=f'Observed = {obs_val:.3f}')\n",
    "\n",
    "            # Zero line\n",
    "            axr.axvline(0.0, color='black', linestyle='-', linewidth=1.5, alpha=0.5)\n",
    "            \n",
    "            clean_title = VAR_LABELS.get(term, term) if 'VAR_LABELS' in globals() else PLOT_TITLES[c]\n",
    "            axr.set_title(clean_title, fontsize=12)\n",
    "            \n",
    "            if c == 0:\n",
    "                axr.set_ylabel('Count', fontsize=12)\n",
    "            \n",
    "            axr.grid(axis='y', linestyle=':', alpha=0.5)\n",
    "            axr.set_xlim(x_limit_min, x_limit_max)\n",
    "            axr.set_xlabel('Average Marginal Effect', fontsize=12)\n",
    "            axr.legend(loc='best')\n",
    "\n",
    "        # fig_row.suptitle(f'{spec} — Reshuffled vs. Observed AME', fontsize=14)\n",
    "        fig_row.tight_layout()\n",
    "        \n",
    "        out_path_row = f'{out_dir}/{base_name}_{spec}.png'\n",
    "        fig_row.savefig(out_path_row, dpi=150, bbox_inches='tight')\n",
    "        plt.close(fig_row)\n",
    "        print('Saved row plot to', out_path_row)\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "# --- Run plots (Updated Filenames) ---\n",
    "Path(output_plot_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Updated filenames to reflect AME\n",
    "# plot_comparison_hist(\n",
    "#     resh_full, \n",
    "#     obs_dict_full, \n",
    "#     f'FULL Dataset (n={n_shuffles})', \n",
    "#     f'AME_full_{dependent_var}.png', \n",
    "#     plot_title_variable\n",
    "# )\n",
    "\n",
    "plot_comparison_hist(\n",
    "    resh_filt, \n",
    "    obs_dict_filt, \n",
    "    f'FILTERED Dataset (n={n_shuffles})', \n",
    "    f'AME_filtered_{dependent_var}.png', \n",
    "    plot_title_variable\n",
    ")\n",
    "\n",
    "print('All done: comparative Marginal Effect histogram figures created.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
