{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc7fc397",
   "metadata": {},
   "source": [
    "#### By: Peyman Shahidi\n",
    "#### Created: Oct 19, 2025\n",
    "#### Last Edit: Nov 12, 2025\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "10366af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python\n",
    "import getpass\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "import random \n",
    "\n",
    "## formatting number to appear comma separated and with two digits after decimal: e.g, 1000 shown as 1,000.00\n",
    "pd.set_option('float_format', \"{:,.2f}\".format)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "#from matplotlib.legend import Legend\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "519e43cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder_path = \"..\"\n",
    "input_data_path = f\"{main_folder_path}/data\"\n",
    "output_data_path = f'{input_data_path}/computed_objects/execTypeVaryingDWA_anthropicIndex'\n",
    "output_plot_path = f\"{main_folder_path}/writeup/plots/execTypeVaryingDWA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "84e6e6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories if they don't exist\n",
    "import os\n",
    "\n",
    "for path in [output_data_path, output_plot_path]:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ac02f0",
   "metadata": {},
   "source": [
    "## Set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "85d28924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of reshuffles\n",
    "n_shuffles = 1000\n",
    "\n",
    "\n",
    "dependent_var = 'is_ai'\n",
    "plot_title_variable = 'Task is AI'\n",
    "# dependent_var = 'is_automated'\n",
    "# plot_title_variable = 'Task is Automated'\n",
    "\n",
    "\n",
    "TARGET_REGS = ['prev2_is_ai', 'prev_is_ai', 'next_is_ai', 'next2_is_ai']\n",
    "SPECS = ['no_fe', 'fe_MajorGroup', 'fe_MinorGroup']\n",
    "\n",
    "PLOT_TITLE = ['Task Before Previous Task', 'Previous Task', 'Next Task', 'Task After Next Task']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d887655d",
   "metadata": {},
   "source": [
    "### Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "69cd68c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2047 DWA CSV files.\n",
      "Skipped 47 DWA files with only one task.\n",
      "Found 13535 tasks related to these DWAs.\n"
     ]
    }
   ],
   "source": [
    "# Get list of DWAs with tasks in multiple occupations\n",
    "dwa_list_path = f\"{input_data_path}/computed_objects/similar_dwa_tasks/similarTasks\"\n",
    "\n",
    "# Read all CSV files\n",
    "import glob\n",
    "dwa_csv_files = glob.glob(os.path.join(dwa_list_path, \"*.csv\"))\n",
    "print(f\"Found {len(dwa_csv_files)} DWA CSV files.\")\n",
    "\n",
    "# Load them into DataFrames, skipping 1-row files\n",
    "dwa_dfs = []\n",
    "skipped_files_count = 0\n",
    "for f in dwa_csv_files:\n",
    "    df = pd.read_csv(f)\n",
    "    if len(df) > 1: # Skip if DWA contains only one task\n",
    "        dwa_dfs.append(df)\n",
    "    else:\n",
    "        skipped_files_count += 1\n",
    "print(f\"Skipped {skipped_files_count} DWA files with only one task.\")\n",
    "    \n",
    "\n",
    "# Combine into one DataFrame\n",
    "df_all = pd.concat(dwa_dfs, ignore_index=True)\n",
    "repetitive_dwa_task_ids = df_all['Task ID'].unique().tolist()\n",
    "repetitive_dwa_task_titles = df_all['Task Title'].unique().tolist()\n",
    "print(f\"Found {len(repetitive_dwa_task_ids)} tasks related to these DWAs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c91f2ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of merged_data before merging DWA info: 17925\n",
      "Length of merged_data after merging DWA info: 22267\n",
      "Created DWA-level dataset with 2081 DWAs.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DWA ID</th>\n",
       "      <th>DWA Title</th>\n",
       "      <th>num_tasks</th>\n",
       "      <th>num_occupations</th>\n",
       "      <th>fraction_manual</th>\n",
       "      <th>fraction_automation</th>\n",
       "      <th>fraction_augmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.A.1.a.1.I01.D01</td>\n",
       "      <td>Review art or design materials.</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.A.1.a.1.I01.D03</td>\n",
       "      <td>Review production information to determine cos...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.A.1.a.1.I01.D04</td>\n",
       "      <td>Study scripts to determine project requirements.</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.A.1.a.1.I02.D01</td>\n",
       "      <td>Read materials to determine needed actions.</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.A.1.a.1.I02.D02</td>\n",
       "      <td>Read maps to determine routes.</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>4.A.4.c.3.I05.D03</td>\n",
       "      <td>Purchase materials, equipment, or other resour...</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069</th>\n",
       "      <td>4.A.4.c.3.I05.D06</td>\n",
       "      <td>Purchase products or services.</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072</th>\n",
       "      <td>4.A.4.c.3.I06.D01</td>\n",
       "      <td>Prescribe treatments or therapies.</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2074</th>\n",
       "      <td>4.A.4.c.3.I06.D03</td>\n",
       "      <td>Prescribe medications.</td>\n",
       "      <td>31</td>\n",
       "      <td>26</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2078</th>\n",
       "      <td>4.A.4.c.3.I07.D03</td>\n",
       "      <td>Inventory medical supplies or equipment.</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>831 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 DWA ID                                          DWA Title  \\\n",
       "0     4.A.1.a.1.I01.D01                    Review art or design materials.   \n",
       "2     4.A.1.a.1.I01.D03  Review production information to determine cos...   \n",
       "3     4.A.1.a.1.I01.D04   Study scripts to determine project requirements.   \n",
       "4     4.A.1.a.1.I02.D01        Read materials to determine needed actions.   \n",
       "5     4.A.1.a.1.I02.D02                     Read maps to determine routes.   \n",
       "...                 ...                                                ...   \n",
       "2066  4.A.4.c.3.I05.D03  Purchase materials, equipment, or other resour...   \n",
       "2069  4.A.4.c.3.I05.D06                     Purchase products or services.   \n",
       "2072  4.A.4.c.3.I06.D01                 Prescribe treatments or therapies.   \n",
       "2074  4.A.4.c.3.I06.D03                             Prescribe medications.   \n",
       "2078  4.A.4.c.3.I07.D03           Inventory medical supplies or equipment.   \n",
       "\n",
       "      num_tasks  num_occupations  fraction_manual  fraction_automation  \\\n",
       "0             6                4             0.83                 0.00   \n",
       "2             6                2             0.83                 0.00   \n",
       "3             9                8             0.33                 0.56   \n",
       "4             4                4             0.75                 0.25   \n",
       "5             4                4             0.75                 0.00   \n",
       "...         ...              ...              ...                  ...   \n",
       "2066         22               20             0.95                 0.00   \n",
       "2069         15               10             0.93                 0.07   \n",
       "2072         19               16             0.89                 0.00   \n",
       "2074         31               26             0.97                 0.00   \n",
       "2078         13               10             0.92                 0.08   \n",
       "\n",
       "      fraction_augmentation  \n",
       "0                      0.17  \n",
       "2                      0.17  \n",
       "3                      0.11  \n",
       "4                      0.00  \n",
       "5                      0.25  \n",
       "...                     ...  \n",
       "2066                   0.05  \n",
       "2069                   0.00  \n",
       "2072                   0.11  \n",
       "2074                   0.03  \n",
       "2078                   0.00  \n",
       "\n",
       "[831 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified 831 DWAs with varying execution types across occupations.\n"
     ]
    }
   ],
   "source": [
    "# Create a DWA-level dataset with number of tasks and occupations per DWA, as well as fraction of manual, automation, and augmentation tasks per DWA\n",
    "merged_data = pd.read_csv(f\"{input_data_path}/computed_objects/ONET_Eloundou_Anthropic_GPT/ONET_Eloundou_Anthropic_GPT.csv\")\n",
    "merged_data['is_manual'] = merged_data['label'] == 'Manual'\n",
    "merged_data['is_automation'] = merged_data['label'] == 'Automation'\n",
    "merged_data['is_augmentation'] = merged_data['label'] == 'Augmentation'\n",
    "\n",
    "\n",
    "# Merge back DWA ID and DWA Titles to the merged_data\n",
    "dwa_task_mapping = pd.read_csv(f\"{input_data_path}/computed_objects/similar_dwa_tasks/dwa_task_mapping.csv\")\n",
    "print(f'Length of merged_data before merging DWA info: {merged_data.shape[0]}')\n",
    "merged_data = merged_data.merge(dwa_task_mapping, on=['Task ID', 'Task Title', 'O*NET-SOC Code', 'Occupation Title'], how='left')\n",
    "print(f'Length of merged_data after merging DWA info: {merged_data.shape[0]}')\n",
    "\n",
    "\n",
    "# Aggregate to get fractions\n",
    "dwa_grouped = merged_data.groupby(['DWA ID', 'DWA Title']).agg(\n",
    "    num_tasks = ('Task ID', 'nunique'),\n",
    "    num_occupations = ('O*NET-SOC Code', 'nunique'),\n",
    "    fraction_manual = ('is_manual', 'mean'),\n",
    "    fraction_automation = ('is_automation', 'mean'),\n",
    "    fraction_augmentation = ('is_augmentation', 'mean'),\n",
    ").reset_index()\n",
    "print(f\"Created DWA-level dataset with {dwa_grouped.shape[0]} DWAs.\")\n",
    "\n",
    "# Keep only DWAs with variation in terms of execution type across occupations\n",
    "dwa_grouped_filtered = dwa_grouped[\n",
    "     (dwa_grouped['num_occupations'] > 1) & (dwa_grouped['fraction_manual'] > 0) & (dwa_grouped['fraction_manual'] < 1)\n",
    "].copy()\n",
    "display(dwa_grouped_filtered)\n",
    "\n",
    "# Create list of DWAs with varying execution types\n",
    "dwas_varying_exec_types_ids = dwa_grouped_filtered['DWA ID'].unique().tolist()\n",
    "dwas_varying_exec_types_titles = dwa_grouped_filtered['DWA Title'].unique().tolist()\n",
    "print(f\"Identified {len(dwas_varying_exec_types_ids)} DWAs with varying execution types across occupations.\")\n",
    "\n",
    "# Save output\n",
    "dwa_grouped_filtered.to_csv(f\"{output_data_path}/dwas_varying_execution_types.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "04a84d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of merged_data before dropping duplicates: 22267\n",
      "Length of merged_data after dropping duplicates: 17920\n",
      "\n",
      "Number of dwa_execType_varying rows: 8694\n",
      "prev2_is_ai: 1582 of 8694 flagged rows (fraction=0.182)\n",
      "prev_is_ai: 1717 of 8694 flagged rows (fraction=0.197)\n",
      "next_is_ai: 1681 of 8694 flagged rows (fraction=0.193)\n",
      "next2_is_ai: 1528 of 8694 flagged rows (fraction=0.176)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O*NET-SOC Code</th>\n",
       "      <th>Occupation Title</th>\n",
       "      <th>Task ID</th>\n",
       "      <th>Task Title</th>\n",
       "      <th>Task Position</th>\n",
       "      <th>Task Type</th>\n",
       "      <th>Major_Group_Code</th>\n",
       "      <th>Major_Group_Title</th>\n",
       "      <th>Minor_Group_Code</th>\n",
       "      <th>Minor_Group_Title</th>\n",
       "      <th>...</th>\n",
       "      <th>is_automated</th>\n",
       "      <th>is_exposed</th>\n",
       "      <th>num_tasks</th>\n",
       "      <th>prev_is_ai</th>\n",
       "      <th>prev2_is_ai</th>\n",
       "      <th>next_is_ai</th>\n",
       "      <th>next2_is_ai</th>\n",
       "      <th>DWA ID</th>\n",
       "      <th>DWA Title</th>\n",
       "      <th>dwa_execType_varying</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>20461</td>\n",
       "      <td>Review and analyze legislation, laws, or publi...</td>\n",
       "      <td>1</td>\n",
       "      <td>Core</td>\n",
       "      <td>11-0000</td>\n",
       "      <td>Management Occupations</td>\n",
       "      <td>11-1000</td>\n",
       "      <td>Top Executives</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.A.2.a.4.I09.D03</td>\n",
       "      <td>Analyze impact of legal or regulatory changes.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>8825</td>\n",
       "      <td>Analyze operations to evaluate performance of ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Core</td>\n",
       "      <td>11-0000</td>\n",
       "      <td>Management Occupations</td>\n",
       "      <td>11-1000</td>\n",
       "      <td>Top Executives</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.A.2.a.4.I07.D09</td>\n",
       "      <td>Analyze data to assess operational or project ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>8824</td>\n",
       "      <td>Confer with board members, organization offici...</td>\n",
       "      <td>4</td>\n",
       "      <td>Core</td>\n",
       "      <td>11-0000</td>\n",
       "      <td>Management Occupations</td>\n",
       "      <td>11-1000</td>\n",
       "      <td>Top Executives</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.A.4.a.2.I03.D14</td>\n",
       "      <td>Confer with organizational members to accompli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>8826</td>\n",
       "      <td>Direct, plan, or implement policies, objective...</td>\n",
       "      <td>6</td>\n",
       "      <td>Core</td>\n",
       "      <td>11-0000</td>\n",
       "      <td>Management Occupations</td>\n",
       "      <td>11-1000</td>\n",
       "      <td>Top Executives</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.A.2.b.1.I09.D01</td>\n",
       "      <td>Implement organizational process or policy cha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>8843</td>\n",
       "      <td>Interpret and explain policies, rules, regulat...</td>\n",
       "      <td>7</td>\n",
       "      <td>Core</td>\n",
       "      <td>11-0000</td>\n",
       "      <td>Management Occupations</td>\n",
       "      <td>11-1000</td>\n",
       "      <td>Top Executives</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.A.4.a.1.I02.D03</td>\n",
       "      <td>Communicate organizational policies and proced...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  O*NET-SOC Code  Occupation Title  Task ID  \\\n",
       "0     11-1011.00  Chief Executives    20461   \n",
       "3     11-1011.00  Chief Executives     8825   \n",
       "4     11-1011.00  Chief Executives     8824   \n",
       "6     11-1011.00  Chief Executives     8826   \n",
       "9     11-1011.00  Chief Executives     8843   \n",
       "\n",
       "                                          Task Title  Task Position Task Type  \\\n",
       "0  Review and analyze legislation, laws, or publi...              1      Core   \n",
       "3  Analyze operations to evaluate performance of ...              3      Core   \n",
       "4  Confer with board members, organization offici...              4      Core   \n",
       "6  Direct, plan, or implement policies, objective...              6      Core   \n",
       "9  Interpret and explain policies, rules, regulat...              7      Core   \n",
       "\n",
       "  Major_Group_Code       Major_Group_Title Minor_Group_Code Minor_Group_Title  \\\n",
       "0          11-0000  Management Occupations          11-1000    Top Executives   \n",
       "3          11-0000  Management Occupations          11-1000    Top Executives   \n",
       "4          11-0000  Management Occupations          11-1000    Top Executives   \n",
       "6          11-0000  Management Occupations          11-1000    Top Executives   \n",
       "9          11-0000  Management Occupations          11-1000    Top Executives   \n",
       "\n",
       "   ... is_automated is_exposed num_tasks prev_is_ai prev2_is_ai next_is_ai  \\\n",
       "0  ...            0          0        31          0           0          0   \n",
       "3  ...            0          0        31          0           1          1   \n",
       "4  ...            0          0        31          1           0          0   \n",
       "6  ...            0          0        31          0           1          1   \n",
       "9  ...            0          1        31          0           0          0   \n",
       "\n",
       "   next2_is_ai             DWA ID  \\\n",
       "0            1  4.A.2.a.4.I09.D03   \n",
       "3            0  4.A.2.a.4.I07.D09   \n",
       "4            0  4.A.4.a.2.I03.D14   \n",
       "6            0  4.A.2.b.1.I09.D01   \n",
       "9            0  4.A.4.a.1.I02.D03   \n",
       "\n",
       "                                           DWA Title  dwa_execType_varying  \n",
       "0     Analyze impact of legal or regulatory changes.                     1  \n",
       "3  Analyze data to assess operational or project ...                     1  \n",
       "4  Confer with organizational members to accompli...                     1  \n",
       "6  Implement organizational process or policy cha...                     1  \n",
       "9  Communicate organizational policies and proced...                     1  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read the merged data\n",
    "merged_data = pd.read_csv(f\"{input_data_path}/computed_objects/ONET_Eloundou_Anthropic_GPT/ONET_Eloundou_Anthropic_GPT.csv\")\n",
    "merged_data = merged_data[['O*NET-SOC Code', 'Occupation Title', 'Task ID', 'Task Title',\n",
    "       'Task Position', 'Task Type', \n",
    "       'Major_Group_Code', 'Major_Group_Title', \n",
    "       'Minor_Group_Code', 'Minor_Group_Title',\n",
    "       'Broad_Occupation_Code', 'Broad_Occupation_Title',\n",
    "       'Detailed_Occupation_Code', 'Detailed_Occupation_Title',\n",
    "       'gpt4_exposure', 'human_labels', \n",
    "       'automation', 'augmentation', 'label']]\n",
    "\n",
    "\n",
    "# Create is_ai and is_automated flags in merged_data\n",
    "merged_data['is_ai'] = merged_data['label'].isin(['Augmentation','Automation']).astype(int)\n",
    "merged_data['is_automated'] = merged_data['label'].isin(['Automation']).astype(int)\n",
    "merged_data['is_exposed'] = merged_data['human_labels'].isin(['E1']).astype(int)\n",
    "\n",
    "\n",
    "# Step 1: Add occupation's number of tasks info\n",
    "num_tasks_per_occupation = merged_data.groupby('O*NET-SOC Code')['Task ID'].nunique().reset_index()\n",
    "num_tasks_per_occupation = num_tasks_per_occupation.rename(columns={'Task ID': 'num_tasks'})\n",
    "merged_data = merged_data.merge(num_tasks_per_occupation, on='O*NET-SOC Code', how='left')\n",
    "\n",
    "\n",
    "# Step 2: Create flags for previous/next tasks is AI within occupation groups\n",
    "# Sort by occupation and position when possible\n",
    "merged_data['Task Position'] = pd.to_numeric(merged_data['Task Position'], errors='coerce')\n",
    "merged_data = merged_data.sort_values(['O*NET-SOC Code', 'Task Position']).reset_index(drop=True)\n",
    "group_col = 'O*NET-SOC Code'\n",
    "\n",
    "# Compute neighbor flags (prev/next) within occupation groups when possible\n",
    "merged_data['prev_is_ai'] = 0\n",
    "merged_data['prev2_is_ai'] = 0\n",
    "merged_data['next_is_ai'] = 0\n",
    "merged_data['next2_is_ai'] = 0\n",
    "pos_col = 'Task Position'\n",
    "\n",
    "def add_neighbor_flags(df):\n",
    "    df = df.copy()\n",
    "    df['Task Position'] = pd.to_numeric(df['Task Position'], errors='coerce')\n",
    "    df = df.sort_values(['O*NET-SOC Code','Task Position']).reset_index(drop=True)\n",
    "    def _add_flags(g):\n",
    "        g = g.sort_values('Task Position')\n",
    "        g['prev_is_ai'] = g['is_ai'].shift(1).fillna(0).astype(int)\n",
    "        g['prev2_is_ai'] = g['is_ai'].shift(2).fillna(0).astype(int)\n",
    "        # g['prev2_is_ai'] = ((g['prev2_is_ai'] == 1) & (g['prev_is_ai'] == 1)).astype(int)\n",
    "        g['next_is_ai'] = g['is_ai'].shift(-1).fillna(0).astype(int)\n",
    "        g['next2_is_ai'] = g['is_ai'].shift(-2).fillna(0).astype(int)\n",
    "        # g['next2_is_ai'] = ((g['next2_is_ai'] == 1) & (g['next_is_ai'] == 1)).astype(int)\n",
    "        return g\n",
    "    return df.groupby('O*NET-SOC Code', group_keys=False).apply(_add_flags).reset_index(drop=True)\n",
    "merged_data = merged_data.groupby(group_col, group_keys=False).apply(add_neighbor_flags).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "# Step 3: Add back DWA info\n",
    "# Merge back DWA ID and DWA Titles to the merged_data\n",
    "dwa_task_mapping = pd.read_csv(f\"{input_data_path}/computed_objects/similar_dwa_tasks/dwa_task_mapping.csv\")\n",
    "merged_data = merged_data.merge(dwa_task_mapping, on=['Task ID', 'Task Title', 'O*NET-SOC Code', 'Occupation Title'], how='left')\n",
    "# Note that the merge might map multiple DWAs to the same task\n",
    "\n",
    "\n",
    "# Step 4: Flag tasks whose DWA ID appears in dwa_execTypeVarying_id_list\n",
    "merged_data['dwa_execType_varying'] = merged_data.get('DWA ID', pd.Series()).isin(dwas_varying_exec_types_ids).fillna(False).astype(int)\n",
    "\n",
    "# Remove duplicates in terms of (O*NET-SOC Code, Task ID) if any\n",
    "print(f'Length of merged_data before dropping duplicates: {merged_data.shape[0]}')\n",
    "merged_data = merged_data.drop_duplicates(subset=['O*NET-SOC Code', 'Task ID'])\n",
    "print(f'Length of merged_data after dropping duplicates: {merged_data.shape[0]}')\n",
    "\n",
    "\n",
    "# Summary for flagged DWA rows\n",
    "mask = merged_data['dwa_execType_varying'] == 1\n",
    "n_flagged = int(mask.sum())\n",
    "print(f'\\nNumber of dwa_execType_varying rows: {n_flagged}')\n",
    "if n_flagged > 0:\n",
    "    for c in ['prev2_is_ai', 'prev_is_ai', 'next_is_ai', 'next2_is_ai']:\n",
    "        s = int(merged_data.loc[mask, c].sum())\n",
    "        frac = merged_data.loc[mask, c].mean()\n",
    "        print(f'{c}: {s} of {n_flagged} flagged rows (fraction={frac:.3f})')\n",
    "    try:\n",
    "        display(merged_data.loc[mask].head())\n",
    "    except Exception:\n",
    "        print(merged_data.loc[mask].head().to_string(index=False))\n",
    "else:\n",
    "    print('No flagged rows to summarize.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e805dee",
   "metadata": {},
   "source": [
    "### Run regression of multiple-execution-type DWA tasks against execution type of neighboring tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a8edcfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regressions: neighbor flags on is_ai (Logit, no FE + several FE models)\n",
    "# Assumption: dependent variable = 'is_ai' and regressors are the four neighbor flags\n",
    "# (prev2_is_ai, prev_is_ai, next_is_ai, next2_is_ai).\n",
    "# Runs on full `merged_data` and on filtered subset where dwa_execType_varying==1.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "from pathlib import Path\n",
    "from statsmodels.stats.sandwich_covariance import cov_hc1\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "# ------- helpers -------\n",
    "# Extract params, robust SEs (HC1) and model sample/df info\n",
    "def extract_coef_series(res):\n",
    "    try:\n",
    "        if hasattr(res, 'get_robustcov_results'):\n",
    "            r = res.get_robustcov_results(cov_type='HC1')\n",
    "            nobs = getattr(r, 'nobs', getattr(res, 'nobs', np.nan))\n",
    "            df_resid = getattr(r, 'df_resid', getattr(res, 'df_resid', np.nan))\n",
    "            return r.params, r.bse, r.pvalues, nobs, df_resid\n",
    "        else:\n",
    "            params = res.params\n",
    "            try:\n",
    "                robust_cov = cov_hc1(res)\n",
    "                bse_arr = np.sqrt(np.diag(robust_cov))\n",
    "                z_scores = params.values / bse_arr\n",
    "                pvals = 2 * (1 - norm.cdf(np.abs(z_scores)))\n",
    "                bse = pd.Series(bse_arr, index=params.index)\n",
    "                pvalues = pd.Series(pvals, index=params.index)\n",
    "                nobs = getattr(res, 'nobs', np.nan)\n",
    "                df_resid = getattr(res, 'df_resid', np.nan)\n",
    "                return params, bse, pvalues, nobs, df_resid\n",
    "            except Exception:\n",
    "                bse = getattr(res, 'bse', pd.Series(np.nan, index=params.index))\n",
    "                pvalues = getattr(res, 'pvalues', pd.Series(np.nan, index=params.index))\n",
    "                nobs = getattr(res, 'nobs', np.nan)\n",
    "                df_resid = getattr(res, 'df_resid', np.nan)\n",
    "                return params, bse, pvalues, nobs, df_resid\n",
    "    except Exception:\n",
    "        params = getattr(res, 'params', pd.Series())\n",
    "        bse = getattr(res, 'bse', pd.Series())\n",
    "        pvalues = getattr(res, 'pvalues', pd.Series())\n",
    "        nobs = getattr(res, 'nobs', np.nan)\n",
    "        df_resid = getattr(res, 'df_resid', np.nan)\n",
    "        return params, bse, pvalues, nobs, df_resid\n",
    "\n",
    "# Build tidy coef dataframe for target regs\n",
    "def build_tidy_coefs(res, dataset_name, model_name):\n",
    "    params, bse, pvalues, nobs, df_resid = extract_coef_series(res)\n",
    "    if len(params) == 0:\n",
    "        return pd.DataFrame(columns=['dataset','model','term','coef','std_err','p_value','nobs','df_resid'])\n",
    "    df = pd.DataFrame({\n",
    "        'term': params.index.astype(str),\n",
    "        'coef': params.values,\n",
    "        'std_err': bse.values if hasattr(bse, 'values') else np.array(bse),\n",
    "        'p_value': pvalues.values if hasattr(pvalues, 'values') else np.array(pvalues)\n",
    "    })\n",
    "    df['model'] = model_name\n",
    "    df['dataset'] = dataset_name\n",
    "    df['nobs'] = nobs\n",
    "    df['df_resid'] = df_resid\n",
    "    df = df[df['term'].isin(TARGET_REGS)].reset_index(drop=True)\n",
    "    df = df[['dataset','model','nobs','df_resid','term','coef','std_err','p_value']]\n",
    "    return df\n",
    "\n",
    "# Drop FE groups with no within-group variation in y or too small size\n",
    "def keep_var_groups(df, fe_col, y, min_size=2):\n",
    "    return df.groupby(fe_col).filter(lambda g: g[y].nunique() == 2 and len(g) >= min_size)\n",
    "\n",
    "# Core function to run requested regressions on a DataFrame\n",
    "def run_regressions_on(df, dataset_name, dependent_var, regressors):\n",
    "    df = df.copy()\n",
    "\n",
    "    # make sure regressors and outcome exist and are numeric\n",
    "    regs = TARGET_REGS\n",
    "    for r in regs + [dependent_var]:\n",
    "        if r not in df.columns:\n",
    "            raise KeyError(f'Required column {r} not found in dataset {dataset_name}')\n",
    "    df[regs] = df[regs].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "    df[dependent_var] = pd.to_numeric(df[dependent_var], errors='coerce').fillna(0)\n",
    "\n",
    "    regressors_str = ' + '.join(regressors)\n",
    "    base_formula = f'{dependent_var} ~ {regressors_str}'\n",
    "    models = {}\n",
    "    tidy_list = []\n",
    "\n",
    "    # 1) No fixed effects (Logit)\n",
    "    try:\n",
    "        formula = base_formula + ' + is_exposed + num_tasks'\n",
    "        res_no_fe = smf.logit(formula, data=df).fit(disp=False)\n",
    "        models['no_fe'] = res_no_fe\n",
    "        tidy_list.append(build_tidy_coefs(res_no_fe, dataset_name, 'no_fe'))\n",
    "    except Exception as e:\n",
    "        print('No-FE logit model failed:', e)\n",
    "\n",
    "    # 2) Fixed effects models (each separately)\n",
    "    fe_cols = [\n",
    "        ('Major_Group_Code','MajorGroup'),\n",
    "        ('Minor_Group_Code','MinorGroup')\n",
    "    ]\n",
    "\n",
    "    for col, short in fe_cols:\n",
    "        formula = base_formula + f' + C({col}) + is_exposed + num_tasks'\n",
    "\n",
    "        # Drop problematic FE groups for THIS FE\n",
    "        df_fe = keep_var_groups(df, col, y=dependent_var, min_size=2)\n",
    "        kept = df_fe[col].nunique()\n",
    "        dropped = df[col].nunique() - kept\n",
    "\n",
    "        try:\n",
    "            res = smf.logit(formula, data=df_fe).fit(disp=False)\n",
    "            models[f'fe_{short}'] = res\n",
    "            tidy_list.append(build_tidy_coefs(res, dataset_name, f'fe_{short}'))\n",
    "        except Exception as e:\n",
    "            print(f'FE logit model with {col} failed:', e)\n",
    "\n",
    "    # Combine tidy coeffs for this dataset\n",
    "    if len(tidy_list):\n",
    "        tidy_combined = pd.concat(tidy_list, ignore_index=True)\n",
    "    else:\n",
    "        tidy_combined = pd.DataFrame(columns=['dataset','model','nobs','df_resid','term','coef','std_err','p_value'])\n",
    "\n",
    "    # Save per-dataset four-variable summary\n",
    "    out_dir = Path(f'{output_data_path}/regression_summaries_{dependent_var}')\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_path = out_dir / f'regression_{dataset_name}_fourvars_summary.csv'\n",
    "    tidy_combined.to_csv(out_path, index=False)\n",
    "    # print(f'Saved per-dataset four-variable summary to {out_path}')\n",
    "\n",
    "    return models, tidy_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "caa80b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting regressions on full merged_data\n",
      "Full dataset has 17920 rows.\n",
      "\n",
      "Starting regressions on filtered dataset (dwa_execType_varying == 1)\n",
      "Filtered dataset has 8694 rows.\n",
      "Combined four-variable CSV saved to ../data/computed_objects/execTypeVaryingDWA_anthropicIndex/regression_fourvars_allDatasets_is_ai.csv\n"
     ]
    }
   ],
   "source": [
    "# Run regression on original datasets: full and filtered (dwa_execType_varying == 1)\n",
    "print('Starting regressions on full merged_data')\n",
    "print(f'Full dataset has {merged_data.shape[0]} rows.')\n",
    "models_full, coefs_full = run_regressions_on(merged_data, 'full_merged_data', dependent_var=dependent_var, regressors=TARGET_REGS)\n",
    "\n",
    "\n",
    "print('\\nStarting regressions on filtered dataset (dwa_execType_varying == 1)')\n",
    "filtered = merged_data[merged_data['dwa_execType_varying'] == 1].reset_index(drop=True)\n",
    "print(f'Filtered dataset has {filtered.shape[0]} rows.')\n",
    "models_filtered, coefs_filtered = run_regressions_on(filtered, 'filtered_dwaExecTypeVarying', dependent_var=dependent_var, regressors=TARGET_REGS)\n",
    "\n",
    "\n",
    "combined_all = pd.concat([coefs_full, coefs_filtered], ignore_index=True)\n",
    "final_out = Path(output_data_path) / f'regression_fourvars_allDatasets_{dependent_var}.csv'\n",
    "combined_all.to_csv(final_out, index=False)\n",
    "print(f'Combined four-variable CSV saved to {final_out}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a344f341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O*NET-SOC Code</th>\n",
       "      <th>Occupation Title</th>\n",
       "      <th>Task ID</th>\n",
       "      <th>Task Title</th>\n",
       "      <th>Task Position</th>\n",
       "      <th>label</th>\n",
       "      <th>human_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>20461</td>\n",
       "      <td>Review and analyze legislation, laws, or publi...</td>\n",
       "      <td>1</td>\n",
       "      <td>Augmentation</td>\n",
       "      <td>E2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>8825</td>\n",
       "      <td>Analyze operations to evaluate performance of ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Augmentation</td>\n",
       "      <td>E2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>8824</td>\n",
       "      <td>Confer with board members, organization offici...</td>\n",
       "      <td>4</td>\n",
       "      <td>Augmentation</td>\n",
       "      <td>E0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>8826</td>\n",
       "      <td>Direct, plan, or implement policies, objective...</td>\n",
       "      <td>6</td>\n",
       "      <td>Manual</td>\n",
       "      <td>E0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>8843</td>\n",
       "      <td>Interpret and explain policies, rules, regulat...</td>\n",
       "      <td>7</td>\n",
       "      <td>Augmentation</td>\n",
       "      <td>E1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>53-7081.00</td>\n",
       "      <td>Refuse and Recyclable Material Collectors</td>\n",
       "      <td>7180</td>\n",
       "      <td>Tag garbage or recycling containers to inform ...</td>\n",
       "      <td>11</td>\n",
       "      <td>Manual</td>\n",
       "      <td>E1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>53-7081.00</td>\n",
       "      <td>Refuse and Recyclable Material Collectors</td>\n",
       "      <td>7184</td>\n",
       "      <td>Provide quotes for refuse collection contracts.</td>\n",
       "      <td>16</td>\n",
       "      <td>Manual</td>\n",
       "      <td>E2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>53-7121.00</td>\n",
       "      <td>Tank Car, Truck, and Ship Loaders</td>\n",
       "      <td>12792</td>\n",
       "      <td>Verify tank car, barge, or truck load numbers ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Manual</td>\n",
       "      <td>E2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>53-7121.00</td>\n",
       "      <td>Tank Car, Truck, and Ship Loaders</td>\n",
       "      <td>12801</td>\n",
       "      <td>Test samples for specific gravity, using hydro...</td>\n",
       "      <td>15</td>\n",
       "      <td>Manual</td>\n",
       "      <td>E0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8693</th>\n",
       "      <td>53-7121.00</td>\n",
       "      <td>Tank Car, Truck, and Ship Loaders</td>\n",
       "      <td>12796</td>\n",
       "      <td>Record operating data such as products and qua...</td>\n",
       "      <td>16</td>\n",
       "      <td>Manual</td>\n",
       "      <td>E2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8694 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     O*NET-SOC Code                           Occupation Title  Task ID  \\\n",
       "0        11-1011.00                           Chief Executives    20461   \n",
       "1        11-1011.00                           Chief Executives     8825   \n",
       "2        11-1011.00                           Chief Executives     8824   \n",
       "3        11-1011.00                           Chief Executives     8826   \n",
       "4        11-1011.00                           Chief Executives     8843   \n",
       "...             ...                                        ...      ...   \n",
       "8689     53-7081.00  Refuse and Recyclable Material Collectors     7180   \n",
       "8690     53-7081.00  Refuse and Recyclable Material Collectors     7184   \n",
       "8691     53-7121.00          Tank Car, Truck, and Ship Loaders    12792   \n",
       "8692     53-7121.00          Tank Car, Truck, and Ship Loaders    12801   \n",
       "8693     53-7121.00          Tank Car, Truck, and Ship Loaders    12796   \n",
       "\n",
       "                                             Task Title  Task Position  \\\n",
       "0     Review and analyze legislation, laws, or publi...              1   \n",
       "1     Analyze operations to evaluate performance of ...              3   \n",
       "2     Confer with board members, organization offici...              4   \n",
       "3     Direct, plan, or implement policies, objective...              6   \n",
       "4     Interpret and explain policies, rules, regulat...              7   \n",
       "...                                                 ...            ...   \n",
       "8689  Tag garbage or recycling containers to inform ...             11   \n",
       "8690    Provide quotes for refuse collection contracts.             16   \n",
       "8691  Verify tank car, barge, or truck load numbers ...              1   \n",
       "8692  Test samples for specific gravity, using hydro...             15   \n",
       "8693  Record operating data such as products and qua...             16   \n",
       "\n",
       "             label human_labels  \n",
       "0     Augmentation           E2  \n",
       "1     Augmentation           E2  \n",
       "2     Augmentation           E0  \n",
       "3           Manual           E0  \n",
       "4     Augmentation           E1  \n",
       "...            ...          ...  \n",
       "8689        Manual           E1  \n",
       "8690        Manual           E2  \n",
       "8691        Manual           E2  \n",
       "8692        Manual           E0  \n",
       "8693        Manual           E2  \n",
       "\n",
       "[8694 rows x 7 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered[['O*NET-SOC Code', 'Occupation Title', 'Task ID', 'Task Title', 'Task Position', 'label', 'human_labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911f4ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing observed coefficients (original ordering)\n",
      "Running 1000 reshuffles...\n",
      "  Completed 50/1000\n",
      "  Completed 100/1000\n",
      "  Completed 150/1000\n",
      "  Completed 200/1000\n",
      "  Completed 250/1000\n",
      "  Completed 300/1000\n",
      "  Completed 350/1000\n",
      "  Completed 400/1000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# --- logistic transformation ---\n",
    "def logistic(x):\n",
    "    return 1 / (1 + np.exp(-x)) if not np.isnan(x) else np.nan\n",
    "\n",
    "# Compute observed (non-reshuffled) coefficients\n",
    "print('Computing observed coefficients (original ordering)')\n",
    "obs_models_full, obs_coefs_full = run_regressions_on(merged_data, 'obs_full', dependent_var=dependent_var, regressors=TARGET_REGS)\n",
    "filtered_obs = merged_data[merged_data['dwa_execType_varying'] == 1].reset_index(drop=True)\n",
    "obs_models_filt, obs_coefs_filt = run_regressions_on(filtered_obs, 'obs_filtered', dependent_var=dependent_var, regressors=TARGET_REGS)\n",
    "\n",
    "# --- convert tidy results to dict of propensities instead of raw coefs ---\n",
    "def tidy_to_dict(tidy_df):\n",
    "    out = {spec: {term: np.nan for term in TARGET_REGS} for spec in SPECS}\n",
    "    for _, row in tidy_df.iterrows():\n",
    "        spec = row['model']\n",
    "        term = row['term']\n",
    "        if spec in out and term in out[spec]:\n",
    "            coef = row['coef']\n",
    "            out[spec][term] = logistic(coef)  # convert to propensity\n",
    "    return out\n",
    "\n",
    "obs_dict_full = tidy_to_dict(obs_coefs_full)\n",
    "obs_dict_filt = tidy_to_dict(obs_coefs_filt)\n",
    "\n",
    "# Prepare containers for reshuffled *propensities*\n",
    "resh_full = {spec: {t: [] for t in TARGET_REGS} for spec in SPECS}\n",
    "resh_filt = {spec: {t: [] for t in TARGET_REGS} for spec in SPECS}\n",
    "\n",
    "out_dir = Path(f\"{output_data_path}/regression_summaries_{dependent_var}\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f'Running {n_shuffles} reshuffles...')\n",
    "for i in range(n_shuffles):\n",
    "    seed = 42 + i\n",
    "    fname_full = out_dir / f'regression_shuf_full_{i}_{dependent_var}_fourvars_summary.csv'\n",
    "    fname_filt = out_dir / f'regression_shuf_filt_{i}_{dependent_var}_fourvars_summary.csv'\n",
    "\n",
    "    if fname_full.exists() and fname_filt.exists():\n",
    "        coefs_shuf_full = pd.read_csv(fname_full)\n",
    "        coefs_shuf_filt = pd.read_csv(fname_filt)\n",
    "        print(f'  Seed {i}: loaded existing results')\n",
    "    else:\n",
    "        df_shuf = merged_data.copy()\n",
    "        df_shuf['Task Position'] = df_shuf.groupby('O*NET-SOC Code')['Task Position'].transform(\n",
    "            lambda x: x.sample(frac=1, random_state=seed).values\n",
    "        )\n",
    "        df_shuf = add_neighbor_flags(df_shuf)\n",
    "        _, coefs_shuf_full = run_regressions_on(df_shuf, f'shuf_full_{i}', dependent_var=dependent_var, regressors=TARGET_REGS)\n",
    "        \n",
    "        df_shuf_filt = df_shuf[df_shuf['dwa_execType_varying'] == 1].reset_index(drop=True)\n",
    "        _, coefs_shuf_filt = run_regressions_on(df_shuf_filt, f'shuf_filt_{i}', dependent_var=dependent_var, regressors=TARGET_REGS)\n",
    "\n",
    "    # Convert to dict of propensities\n",
    "    d_full = tidy_to_dict(coefs_shuf_full) if not coefs_shuf_full.empty else tidy_to_dict(pd.DataFrame())\n",
    "    d_filt = tidy_to_dict(coefs_shuf_filt) if not coefs_shuf_filt.empty else tidy_to_dict(pd.DataFrame())\n",
    "\n",
    "    for spec in SPECS:\n",
    "        for t in TARGET_REGS:\n",
    "            resh_full[spec][t].append(d_full.get(spec, {}).get(t, np.nan))\n",
    "            resh_filt[spec][t].append(d_filt.get(spec, {}).get(t, np.nan))\n",
    "\n",
    "    if (i+1) % 50 == 0:\n",
    "        print(f'  Completed {i+1}/{n_shuffles}')\n",
    "\n",
    "print('Reshuffles complete; creating comparative plots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30477f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved full multi-row plot to ../writeup/plots/execTypeVaryingDWA/is_ai/propensity_full_is_ai.png\n",
      "Saved row plot to ../writeup/plots/execTypeVaryingDWA/is_ai/propensity_full_is_ai_no_fe.png\n",
      "Saved row plot to ../writeup/plots/execTypeVaryingDWA/is_ai/propensity_full_is_ai_fe_MajorGroup.png\n",
      "Saved row plot to ../writeup/plots/execTypeVaryingDWA/is_ai/propensity_full_is_ai_fe_MinorGroup.png\n",
      "Saved full multi-row plot to ../writeup/plots/execTypeVaryingDWA/is_ai/propensity_filtered_is_ai.png\n",
      "Saved row plot to ../writeup/plots/execTypeVaryingDWA/is_ai/propensity_filtered_is_ai_no_fe.png\n",
      "Saved row plot to ../writeup/plots/execTypeVaryingDWA/is_ai/propensity_filtered_is_ai_fe_MajorGroup.png\n",
      "Saved row plot to ../writeup/plots/execTypeVaryingDWA/is_ai/propensity_filtered_is_ai_fe_MinorGroup.png\n",
      "All done: comparative propensity histogram figures created.\n"
     ]
    }
   ],
   "source": [
    "# --- Plotting: distributions of propensities ---\n",
    "def plot_comparison_hist(resh_dict, obs_dict, title, out_name, plot_title_variable, bins=30):\n",
    "    \"\"\"Create the multi-row comparison histogram and also save each row (spec) as a separate image.\n",
    "\n",
    "    Args:\n",
    "        resh_dict: dict of reshuffled propensities per spec and term\n",
    "        obs_dict: dict of observed propensities per spec and term\n",
    "        title: title string to include in saved figures\n",
    "        out_name: filename for the full multi-row figure\n",
    "        plot_title_variable: human-readable dependent var name for titles\n",
    "        bins: histogram bins\n",
    "    \"\"\"\n",
    "    colors = [plt.cm.tab10(i % 10) for i in range(len(SPECS))]\n",
    "    fig, axes = plt.subplots(nrows=len(SPECS), ncols=len(TARGET_REGS), figsize=(6*len(TARGET_REGS), 5*len(SPECS)), sharey='col')\n",
    "\n",
    "    for r, spec in enumerate(SPECS):\n",
    "        color_row = colors[r]\n",
    "        for c, term in enumerate(TARGET_REGS):\n",
    "            ax = axes[r, c] if len(SPECS) > 1 else axes[c]\n",
    "            vals = np.array(resh_dict[spec][term], dtype=float)\n",
    "            vals_clean = vals[~np.isnan(vals)]\n",
    "\n",
    "            if len(vals_clean):\n",
    "                ax.hist(vals_clean, bins=bins, color=color_row, alpha=0.7, edgecolor='k')\n",
    "                lo, hi = np.percentile(vals_clean, [2.5, 97.5])\n",
    "                ax.axvline(lo, color=color_row, linestyle=':', alpha=0.8)\n",
    "                ax.axvline(hi, color=color_row, linestyle=':', alpha=0.8)\n",
    "                ax.axvline(np.mean(vals_clean), color=color_row, linestyle='-', alpha=0.9)\n",
    "            else:\n",
    "                ax.text(0.5, 0.5, 'no estimates', ha='center', va='center')\n",
    "\n",
    "            # observed propensity (red dashed)\n",
    "            obs_val = obs_dict.get(spec, {}).get(term, np.nan)\n",
    "            if not np.isnan(obs_val):\n",
    "                ax.axvline(obs_val, color='red', linestyle='--', linewidth=3, label='observed')\n",
    "\n",
    "            # baseline: random (0.5 probability)\n",
    "            ax.axvline(0.5, color='black', linestyle='--', linewidth=2, alpha=0.7, label='0.5 baseline')\n",
    "\n",
    "            if r == 0:\n",
    "                ax.set_title(term, fontsize=12)\n",
    "            if r == len(SPECS) - 1:\n",
    "                ax.set_xlabel('Regression Coefficient', fontsize=12)\n",
    "            if c == 0:\n",
    "                ax.set_ylabel(spec, fontsize=12)\n",
    "            ax.set_xlim(0.42, 0.78)\n",
    "\n",
    "            ax.grid(axis='y', linestyle=':', alpha=0.5)\n",
    "\n",
    "    # fig.suptitle(f'Reshuffled vs. Observed Propensity (P[ {plot_title_variable} | Neighbor AI ])\\n\\n{title}',\n",
    "    #              fontsize=16, fontweight='bold')\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "\n",
    "    # Ensure output dir exists\n",
    "    Path(output_plot_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Save full multi-row figure\n",
    "    out_dir = f'{output_plot_path}/{dependent_var}'\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    out_path = f'{out_dir}/{out_name}'\n",
    "    fig.savefig(out_path, dpi=150, bbox_inches='tight')\n",
    "    print('Saved full multi-row plot to', out_path)\n",
    "\n",
    "    # Also save each row (each spec) as its own figure while keeping the multi-row output\n",
    "    base_name = out_name.rsplit('.', 1)[0]\n",
    "    for r, spec in enumerate(SPECS):\n",
    "        # Create a single-row figure with one column per target reg\n",
    "        fig_row, axs_row = plt.subplots(nrows=1, ncols=len(TARGET_REGS), figsize=(24, 5), sharey=False)\n",
    "        # normalize axs_row to list for consistent indexing\n",
    "        if len(TARGET_REGS) == 1:\n",
    "            axs_row = [axs_row]\n",
    "        color_row = colors[r]\n",
    "        for c, term in enumerate(TARGET_REGS):\n",
    "            axr = axs_row[c]\n",
    "            vals = np.array(resh_dict[spec][term], dtype=float)\n",
    "            vals_clean = vals[~np.isnan(vals)]\n",
    "\n",
    "            if len(vals_clean):\n",
    "                axr.hist(vals_clean, bins=bins, color=color_row, alpha=0.7, edgecolor='k')\n",
    "                lo, hi = np.percentile(vals_clean, [2.5, 97.5])\n",
    "                axr.axvline(lo, color=color_row, linestyle=':', alpha=0.8)\n",
    "                axr.axvline(hi, color=color_row, linestyle=':', alpha=0.8)\n",
    "                axr.axvline(np.mean(vals_clean), color=color_row, linestyle='-', alpha=0.9)\n",
    "            else:\n",
    "                axr.text(0.5, 0.5, 'no estimates', ha='center', va='center')\n",
    "\n",
    "            obs_val = obs_dict.get(spec, {}).get(term, np.nan)\n",
    "            if not np.isnan(obs_val):\n",
    "                axr.axvline(obs_val, color='red', linestyle='--', linewidth=3, label='observed')\n",
    "\n",
    "            axr.axvline(0.5, color='black', linestyle='--', linewidth=2, alpha=0.7, label='0.5 baseline')\n",
    "            axr.set_title(term, fontsize=12)\n",
    "            if c == 0:\n",
    "                axr.set_ylabel(spec, fontsize=12)\n",
    "            axr.grid(axis='y', linestyle=':', alpha=0.5)\n",
    "            axr.set_xlim(0.42, 0.78)\n",
    "            axr.set_xlabel('Regression Coefficient', fontsize=12)\n",
    "\n",
    "        # fig_row.suptitle(f'{spec} — Reshuffled vs. Observed Propensity (P[{plot_title_variable} | Neighbor AI])\\n\\n{title}', fontsize=14)\n",
    "        fig_row.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        # Save\n",
    "        out_dir = f'{output_plot_path}/{dependent_var}'\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        out_path_row = f'{out_dir}/{base_name}_{spec}.png'\n",
    "        fig_row.savefig(out_path_row, dpi=150, bbox_inches='tight')\n",
    "        plt.close(fig_row)\n",
    "        print('Saved row plot to', out_path_row)\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "# --- Run plots ---\n",
    "Path(output_plot_path).mkdir(parents=True, exist_ok=True)\n",
    "plot_comparison_hist(resh_full, obs_dict_full, f'FULL Dataset (n={n_shuffles})', f'propensity_full_{dependent_var}.png', plot_title_variable)\n",
    "plot_comparison_hist(resh_filt, obs_dict_filt, f'FILTERED Dataset (n={n_shuffles})', f'propensity_filtered_{dependent_var}.png', plot_title_variable)\n",
    "\n",
    "print('All done: comparative propensity histogram figures created.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
