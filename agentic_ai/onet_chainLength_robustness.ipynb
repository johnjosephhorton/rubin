{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc7fc397",
   "metadata": {},
   "source": [
    "#### By: Peyman Shahidi\n",
    "#### Created: Jan 30, 2026\n",
    "#### Last Edit: Jan 30, 2026\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10366af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python\n",
    "import getpass\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "import random \n",
    "\n",
    "## formatting number to appear comma separated and with two digits after decimal: e.g, 1000 shown as 1,000.00\n",
    "pd.set_option('float_format', \"{:,.2f}\".format)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "#from matplotlib.legend import Legend\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "519e43cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder_path = \"..\"\n",
    "input_data_path = f\"{main_folder_path}/data\"\n",
    "output_data_path = f'{input_data_path}/computed_objects/aiChain_length_count_robustness'\n",
    "output_plot_path = f\"{main_folder_path}/writeup/plots/aiChain_length_count_robustness\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84e6e6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories if they don't exist\n",
    "import os\n",
    "\n",
    "for path in [output_data_path, output_plot_path]:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48ff34a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine AI chains\n",
    "def create_ai_chains_df_def1(df, group_cols):\n",
    "    # Create is_ai column\n",
    "    ai_chains_df = df.copy()\n",
    "    ai_chains_df = ai_chains_df.sort_values(by=group_cols + ['Task Position']).reset_index(drop=True)\n",
    "    ai_chains_df['is_ai'] = ai_chains_df['label'].isin(['Augmentation', 'Automation']).astype(int)\n",
    "\n",
    "    # Create next_is_ai column within occupation groups\n",
    "    ai_chains_df['next_is_ai'] = ai_chains_df.groupby(group_cols)['is_ai'].shift(-1).fillna(0).astype(int)\n",
    "\n",
    "    # Determine if task is part of an AI chain\n",
    "    ai_chains_df['ai_chain'] = 0\n",
    "    ai_chain_logic = (ai_chains_df['is_ai'] == 1) & (ai_chains_df['next_is_ai'] == 1)\n",
    "    ai_chains_df.loc[ai_chain_logic, 'ai_chain'] = 1\n",
    "\n",
    "    # Flag for switching from AI chain to non-AI task\n",
    "    ai_chains_df['ai_chain_end'] = 0\n",
    "    ai_chains_df.loc[(ai_chains_df['is_ai'] == 1) & (ai_chains_df['next_is_ai'] == 0), 'ai_chain_end'] = 1\n",
    "\n",
    "\n",
    "    # Calculate AI chain ids and lengths\n",
    "    # Approach: within each occupation, detect starts of contiguous runs of is_ai (current is_ai==1 and previous is_ai!=1),\n",
    "    # assign an incrementing chain id for those runs, then compute the length of each chain and the number of chains per occupation.\n",
    "    # previous task's is_ai (within occupation)\n",
    "    ai_chains_df['prev_is_ai'] = ai_chains_df.groupby(group_cols)['is_ai'].shift(1).fillna(0).astype(int)\n",
    "    # mark start of a new chain when current is AI and previous is not\n",
    "    ai_chains_df['start_chain'] = ((ai_chains_df['is_ai'] == 1) & (ai_chains_df['prev_is_ai'] == 0)).astype(int)\n",
    "    # cumulative sum of starts per occupation gives a chain id (0 if never started)\n",
    "    ai_chains_df['chain_id'] = ai_chains_df.groupby(group_cols)['start_chain'].cumsum()\n",
    "    # Non-AI tasks shouldn't have a chain id; set to NA for clarity\n",
    "    ai_chains_df.loc[ai_chains_df['is_ai'] == 0, 'chain_id'] = pd.NA\n",
    "\n",
    "\n",
    "    # Compute chain lengths (only for AI tasks/chain ids)\n",
    "    chain_lengths = (\n",
    "        ai_chains_df[ai_chains_df['is_ai'] == 1]\n",
    "        .groupby(group_cols + ['chain_id'])\n",
    "        .size()\n",
    "        .reset_index(name='chain_length')\n",
    "    )\n",
    "    # Attach chain lengths back to the main df\n",
    "    ai_chains_df = ai_chains_df.merge(chain_lengths, on=group_cols + ['chain_id'], how='left')\n",
    "\n",
    "    # Average Number of AI Chains per occupation\n",
    "    num_chains = (\n",
    "        chain_lengths.groupby(group_cols)['chain_id']\n",
    "        .nunique()\n",
    "        .reset_index(name='num_ai_chains')\n",
    "    )\n",
    "    ai_chains_df = ai_chains_df.merge(num_chains, on=group_cols, how='left')\n",
    "    ai_chains_df['num_ai_chains'] = ai_chains_df['num_ai_chains'].fillna(0).astype(int)\n",
    "\n",
    "    # For convenience: fill chain_length = 0 for non-AI rows\n",
    "    ai_chains_df['chain_length'] = ai_chains_df['chain_length'].fillna(0).astype(int)\n",
    "\n",
    "    # Remove irrelevant columns\n",
    "    ai_chains_df = ai_chains_df.drop(columns=['prev_is_ai','start_chain'])\n",
    "\n",
    "    # Calculate mean length of AI chains and Average Number of AI Chains across entire dataset\n",
    "    mean_chain_length = chain_lengths['chain_length'].mean()\n",
    "    num_ai_chains = ai_chains_df['num_ai_chains'].mean()\n",
    "\n",
    "    return ai_chains_df, chain_lengths, mean_chain_length, num_ai_chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6363b238",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_results = []   # list of DataFrames, concat once at end\n",
    "\n",
    "# Initialize the input file with the original data\n",
    "input_file_path_list = [f\"{input_data_path}/computed_objects/ONET_Eloundou_Anthropic_GPT/ONET_Eloundou_Anthropic_GPT.csv\"]\n",
    "\n",
    "for x in range(1, 11): # Ignore 0 as it's the repetition of the original prompts\n",
    "    input_file_path_list.append(f\"{input_data_path}/computed_objects/ONET_Eloundou_Anthropic_GPT/ONET_Eloundou_Anthropic_GPT_{x}.csv\")\n",
    "\n",
    "\n",
    "for x, input_file_path in enumerate(input_file_path_list):\n",
    "    merged_data = pd.read_csv(input_file_path)\n",
    "    merged_data = merged_data[['O*NET-SOC Code', 'Occupation Title', 'Task ID', 'Task Title',\n",
    "        'Task Position', 'Task Type', \n",
    "        'Major_Group_Code', 'Major_Group_Title', \n",
    "        'Minor_Group_Code', 'Minor_Group_Title',\n",
    "        'Broad_Occupation_Code', 'Broad_Occupation_Title',\n",
    "        'Detailed_Occupation_Code', 'Detailed_Occupation_Title',\n",
    "        'gpt4_exposure', 'human_labels', \n",
    "        'automation', 'augmentation', 'label']]\n",
    "\n",
    "\n",
    "    # AI Chain Definition 1: treat Augmentation and Automation as AI tasks\n",
    "    group_cols = ['O*NET-SOC Code', 'Occupation Title']\n",
    "\n",
    "    # Run\n",
    "    ai_chains_df, chain_lengths, mean_chain_length, num_ai_chains = create_ai_chains_df_def1(merged_data, group_cols)\n",
    "\n",
    "    # Create dataframe summarizing results\n",
    "    result_df = pd.DataFrame({\n",
    "        'prompt': [x],\n",
    "        'mean_chain_length': [mean_chain_length],\n",
    "        'avg_num_ai_chains': [num_ai_chains]\n",
    "    })\n",
    "\n",
    "    master_results.append(result_df)\n",
    "\n",
    "# Concatenate all results into a master dataframe and save\n",
    "master_df = pd.concat(master_results, ignore_index=True)\n",
    "master_df.to_csv(f\"{output_data_path}/aiChain_length_count.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3febdd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read randomized task position results for plotting\n",
    "df = pd.read_csv(f\"{input_data_path}/computed_objects/aiChain_length_count/aiChains_taskPositionReshuffle_definition1.csv\")\n",
    "df = df[1:]  # Exclude first row if it's a repetition of original run\n",
    "randomized_position_mean_chain_length = df['mean_chain_length'].mean()\n",
    "randomized_position_avg_num_ai_chains = df['num_ai_chains'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47d8c953",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = master_df.copy()\n",
    "\n",
    "# Clean + sort\n",
    "df[\"prompt\"] = pd.to_numeric(df[\"prompt\"], errors=\"coerce\")\n",
    "df[\"mean_chain_length\"] = pd.to_numeric(df[\"mean_chain_length\"], errors=\"coerce\")\n",
    "df[\"avg_num_ai_chains\"] = pd.to_numeric(df[\"avg_num_ai_chains\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"prompt\", \"mean_chain_length\", \"avg_num_ai_chains\"]).sort_values(\"prompt\")\n",
    "\n",
    "x = df[\"prompt\"].values\n",
    "y_len = df[\"mean_chain_length\"].values\n",
    "y_cnt = df[\"avg_num_ai_chains\"].values\n",
    "\n",
    "mask0 = (df[\"prompt\"] == 0)\n",
    "has0 = mask0.any()\n",
    "\n",
    "# ----------------------------\n",
    "# Plot 1: Average AI Chain Length\n",
    "# ----------------------------\n",
    "fig, ax = plt.subplots(figsize=(8, 6), constrained_layout=True)\n",
    "\n",
    "if has0:\n",
    "    ax.scatter(df.loc[mask0, \"prompt\"], df.loc[mask0, \"mean_chain_length\"],\n",
    "               color=\"red\", zorder=3, s=50, label=\"Main Prompt\")\n",
    "\n",
    "ax.scatter(x, y_len, marker='o', color=\"tab:orange\", lw=1.8, zorder=2, label=\"Robustness Prompts\")\n",
    "    \n",
    "# ✅ mean line (across prompts)\n",
    "mean_len = float(np.nanmean(y_len))\n",
    "ax.axhline(mean_len, color=\"tab:orange\", linestyle=\"--\", lw=2.0, alpha=0.9,\n",
    "           label=f\"Mean (across prompts) = {mean_len:.2f}\")\n",
    "\n",
    "# ax.set_title(\"Average AI Chain Length Robustness Check\", fontsize=16)\n",
    "ax.set_xlabel(\"GPT Prompt\", fontsize=14)\n",
    "ax.set_ylabel(\"Average AI Chain Length\", fontsize=14)\n",
    "ax.tick_params(axis='both', labelsize=14)\n",
    "\n",
    "ax.set_ylim(1.28, 1.52)\n",
    "ax.axhline(y=randomized_position_mean_chain_length, color='black', linestyle='--', lw=1.8, alpha=0.9,\n",
    "           label='Mean of Randomized Task Position Placebos')\n",
    "\n",
    "ax.legend(loc='best', fontsize=14)\n",
    "\n",
    "plt.savefig(f\"{output_plot_path}/aiChain_length_robustness.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Plot 2: Average Number of AI Chains\n",
    "# ----------------------------\n",
    "fig, ax = plt.subplots(figsize=(8, 6), constrained_layout=True)\n",
    "\n",
    "if has0:\n",
    "    ax.scatter(df.loc[mask0, \"prompt\"], df.loc[mask0, \"avg_num_ai_chains\"],\n",
    "               color=\"red\", zorder=3, s=50, label=\"Main Prompt\")\n",
    "\n",
    "ax.scatter(x, y_cnt, marker='o', color=\"tab:blue\", lw=1.8, zorder=2, label=\"Robustness Prompts\")\n",
    "    \n",
    "# ✅ mean line (across prompts)\n",
    "mean_cnt = float(np.nanmean(y_cnt))\n",
    "ax.axhline(mean_cnt, color=\"tab:blue\", linestyle=\"--\", lw=2.0, alpha=0.9,\n",
    "           label=f\"Mean (across prompts) = {mean_cnt:.2f}\")\n",
    "\n",
    "# ax.set_title(\"Average Number of AI Chains Robustness Check\", fontsize=16)\n",
    "ax.set_xlabel(\"GPT Prompt\", fontsize=14)\n",
    "ax.set_ylabel(\"Average Count of AI Chains\", fontsize=14)\n",
    "ax.tick_params(axis='both', labelsize=14)\n",
    "\n",
    "ax.set_ylim(1.98, 2.32)\n",
    "ax.axhline(y=randomized_position_avg_num_ai_chains, color='black', linestyle='--', lw=1.8, alpha=0.9,\n",
    "           label='Mean of Randomized Task Position Placebos')\n",
    "\n",
    "ax.legend(loc='best', fontsize=14)\n",
    "\n",
    "plt.savefig(f\"{output_plot_path}/aiChain_count_robustness.png\", dpi=300)\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
