{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc7fc397",
   "metadata": {},
   "source": [
    "#### By: Peyman Shahidi\n",
    "#### Created: Oct 21, 2025\n",
    "#### Last Edit: Oct 21, 2025\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10366af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python\n",
    "import getpass\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "import random \n",
    "\n",
    "## formatting number to appear comma separated and with two digits after decimal: e.g, 1000 shown as 1,000.00\n",
    "pd.set_option('float_format', \"{:,.2f}\".format)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "#from matplotlib.legend import Legend\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519e43cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder_path = \"..\"\n",
    "input_data_path = f\"{main_folder_path}/data\"\n",
    "output_data_path = f'{input_data_path}/computed_objects'\n",
    "output_plot_path = f\"{main_folder_path}/writeup/plots/taskSequence_vs_anthropicIndex\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e6e6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories if they don't exist\n",
    "import os\n",
    "\n",
    "for path in [output_data_path, output_plot_path]:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf72cf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read O*NET data\n",
    "ONET = pd.read_csv(f'{input_data_path}/computed_objects/ONET_cleaned_tasks.csv')\n",
    "\n",
    "# Drop  columns to avoid double counting\n",
    "# Note: In ~4k instances, the same task is mapped to multiple DWAs\n",
    "ONET = ONET.drop(columns=['DWA ID', 'DWA Title'])\n",
    "\n",
    "# Remove duplicate rows\n",
    "rows_before = len(ONET)\n",
    "print(f\"Number of rows before removing duplicates: {rows_before:,}\")\n",
    "ONET = ONET.drop_duplicates().reset_index(drop=True)\n",
    "rows_after = len(ONET)\n",
    "print(f\"Number of rows after removing duplicates: {rows_after:,}\")\n",
    "print(f\"Duplicates removed: {rows_before - rows_after}\")\n",
    "\n",
    "# Print length of dataset\n",
    "print(f\"Number of rows in ONET dataset: {len(ONET):,}\")\n",
    "\n",
    "ONET.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f3fb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GPTs are GPTs full label dataset\n",
    "gpts_full_labels = pd.read_csv(f'{input_data_path}/GPTs-are-GPTs-main/data/full_labelset.tsv', sep=\"\\t\")\n",
    "\n",
    "# Keep relevant columns only\n",
    "gpts_full_labels = gpts_full_labels[['O*NET-SOC Code', 'Task ID', 'Task', 'Task Type', 'Title', 'gpt4_exposure', 'human_labels']]\n",
    "\n",
    "# Convert Task ID to integer\n",
    "gpts_full_labels['Task ID'] = gpts_full_labels['Task ID'].astype(int)\n",
    "\n",
    "# Remove apostrophes for consistency\n",
    "gpts_full_labels = gpts_full_labels.applymap(lambda x: x.replace(\"'\", \"\") if isinstance(x, str) else x)\n",
    "\n",
    "# Rename columns\n",
    "gpts_full_labels = gpts_full_labels.rename(columns={\n",
    "    'Task': 'Task Title',\n",
    "    'Title': 'Occupation Title'\n",
    "})\n",
    "\n",
    "# Print length of dataset\n",
    "print(f\"Number of rows in GPTs full labels dataset: {len(gpts_full_labels):,}\")\n",
    "\n",
    "\n",
    "gpts_full_labels.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fceda80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with ONET dataset to get hierarchical codes and titles\n",
    "ONET = ONET.merge(gpts_full_labels, on=['O*NET-SOC Code', 'Occupation Title', 'Task ID', 'Task Title', 'Task Type'], how='left')\n",
    "\n",
    "# Check how many tasks were not matched\n",
    "unmatched_tasks = ONET[ONET['gpt4_exposure'].isna()]\n",
    "print(f\"Number of unmatched tasks: {len(unmatched_tasks):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1943d85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ONET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c12ea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with Anthropic exposure data\n",
    "anthropic_exposure = pd.read_csv(f'{input_data_path}/Anthropic_EconomicIndex/automation_vs_augmentation_by_task.csv')\n",
    "\n",
    "# Remove if all entries are filtered:\n",
    "anthropic_exposure = anthropic_exposure[anthropic_exposure['filtered'] != 1].reset_index(drop=True)\n",
    "\n",
    "# Create new columns:\n",
    "# Sum feedback loop and directive into Automation\n",
    "# Sum validation, iteration, and learning into Augmentation\n",
    "anthropic_exposure['automation'] = anthropic_exposure.apply(lambda row: row['feedback_loop'] + row['directive'], axis=1)\n",
    "anthropic_exposure['augmentation'] = anthropic_exposure.apply(lambda row: row['validation'] + row['task_iteration'] + row['learning'], axis=1)\n",
    "\n",
    "# Assign labels: take the max of automation, augmentation, manual and assign the corresponding label\n",
    "def assign_label(row):\n",
    "    max_value = max(row['automation'], row['augmentation'])\n",
    "    if max_value == row['automation']:\n",
    "        return 'Automation'\n",
    "    elif max_value == row['augmentation']:\n",
    "        return 'Augmentation'\n",
    "\n",
    "anthropic_exposure['label'] = anthropic_exposure.apply(assign_label, axis=1)\n",
    "\n",
    "# Filter to only keep the relevant columns\n",
    "anthropic_exposure = anthropic_exposure[['task_name', 'automation', 'augmentation', 'label']]\n",
    "anthropic_exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51666860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print number of unique tasks in ONET dataset\n",
    "print(f\"Number of unique tasks in ONET dataset: {ONET['Task Title'].nunique():,}\")\n",
    "\n",
    "# Print number of unique tasks in Anthropic exposure dataset\n",
    "print(f\"Number of unique tasks in Anthropic exposure dataset: {anthropic_exposure['task_name'].nunique():,}\")\n",
    "\n",
    "\n",
    "# Add normalized task title to ONET for merging\n",
    "ONET[\"task_normalized\"] = ONET[\"Task Title\"].str.lower().str.strip()\n",
    "\n",
    "\n",
    "# Merge ONET and Anthropic exposure data on the normalized task title\n",
    "merged_data = pd.merge(ONET, anthropic_exposure[['task_name', 'automation', 'augmentation', 'label']], left_on=\"task_normalized\", right_on=\"task_name\", how=\"left\")\n",
    "\n",
    "# Fill the NaN values of the label column in merged dataset as Manual\n",
    "merged_data['label'] = merged_data['label'].fillna('Manual')\n",
    "\n",
    "# Print distribution after filling NaN values\n",
    "print(f\"\\nDistribution of labels after filling NaN values with 'Manual':\")\n",
    "print(merged_data['label'].value_counts())\n",
    "print(f\"Total tasks: {len(merged_data):,}\")\n",
    "\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57506c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read task sequence data\n",
    "# Go through computed_objects/tasks_sequences and read all files and merge with original ONET data\n",
    "# Get list of files in the directory\n",
    "task_sequence_files = [f for f in os.listdir(f'{input_data_path}/computed_objects/tasks_sequences') if f.endswith('.csv')]\n",
    "task_sequence = pd.concat([pd.read_csv(f'{input_data_path}/computed_objects/tasks_sequences/{file}') for file in task_sequence_files], ignore_index=True)\n",
    "\n",
    "print(f\"Task sequence data shape: {task_sequence.shape}\")\n",
    "print(f\"Columns in task sequence: {list(task_sequence.columns)}\")\n",
    "\n",
    "# Merge task sequence data with merged_data\n",
    "merged_data = pd.merge(merged_data, task_sequence[['O*NET-SOC Code', 'Task ID', 'Task Position']], on=['O*NET-SOC Code', 'Task ID'], how='left')\n",
    "merged_data = merged_data[merged_data['Task Position'].notna()].reset_index(drop=True)\n",
    "merged_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321ed843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reshuffle task assignments while preserving SOC hierarchy structure\n",
    "# # Each occupation unit (O*NET-SOC Code + hierarchy levels) stays intact, but tasks are randomly reassigned\n",
    "# # COMPLETELY UNRESTRICTED: Each task assigned to random occupation, no constraints on tasks per occupation\n",
    "\n",
    "# # Create a copy of the data for reshuffling\n",
    "# reshuffled_data = merged_data.copy()\n",
    "\n",
    "# # Create SOC hierarchy levels with descriptive names from the O*NET-SOC Code\n",
    "# reshuffled_data['soc_major_group'] = reshuffled_data['O*NET-SOC Code'].str[:2]\n",
    "# reshuffled_data['soc_minor_group'] = reshuffled_data['O*NET-SOC Code'].str[:5] \n",
    "# reshuffled_data['soc_broad_occupation'] = reshuffled_data['O*NET-SOC Code'].str[:8]\n",
    "# reshuffled_data['soc_detailed_occupation'] = reshuffled_data['O*NET-SOC Code']\n",
    "\n",
    "# # Get unique occupation units (with all hierarchy levels intact)\n",
    "# occupation_units = reshuffled_data[['O*NET-SOC Code', 'Occupation Title', 'soc_major_group', \n",
    "#                                    'soc_minor_group', 'soc_broad_occupation', 'soc_detailed_occupation']].drop_duplicates()\n",
    "\n",
    "# print(f\"Number of unique occupation units: {len(occupation_units):,}\")\n",
    "\n",
    "# # Get all unique tasks (each task appears only once)\n",
    "# unique_tasks = reshuffled_data[['Task ID', 'Task Title', 'Task Type', 'gpt4_exposure', \n",
    "#                                'human_labels', 'task_normalized', 'task_name', \n",
    "#                                'automation', 'augmentation', 'label']].drop_duplicates()\n",
    "\n",
    "# print(f\"Number of unique tasks: {len(unique_tasks):,}\")\n",
    "\n",
    "# # Set random seed for reproducibility\n",
    "# np.random.seed(42)\n",
    "\n",
    "# # UNRESTRICTED ASSIGNMENT: Each task randomly assigned to any occupation unit\n",
    "# # No constraints on how many tasks per occupation\n",
    "# n_tasks = len(unique_tasks)\n",
    "# n_occupations = len(occupation_units)\n",
    "\n",
    "# # Random assignment: each task gets assigned to a completely random occupation\n",
    "# random_occupation_indices = np.random.choice(n_occupations, size=n_tasks, replace=True)\n",
    "\n",
    "# print(f\"Assigning {n_tasks:,} tasks randomly across {n_occupations:,} occupation units\")\n",
    "\n",
    "# # Create the reshuffled dataset\n",
    "# reshuffled_list = []\n",
    "\n",
    "# for task_idx in range(n_tasks):\n",
    "#     occ_idx = random_occupation_indices[task_idx]\n",
    "    \n",
    "#     # Get task information\n",
    "#     task_row = unique_tasks.iloc[task_idx].to_dict()\n",
    "    \n",
    "#     # Get occupation information  \n",
    "#     occ_row = occupation_units.iloc[occ_idx].to_dict()\n",
    "    \n",
    "#     # Combine them\n",
    "#     combined_row = {**task_row, **occ_row}\n",
    "#     reshuffled_list.append(combined_row)\n",
    "\n",
    "# # Create the reshuffled DataFrame\n",
    "# reshuffled_data = pd.DataFrame(reshuffled_list)\n",
    "\n",
    "# print(f\"Reshuffled dataset created with {len(reshuffled_data):,} rows\")\n",
    "\n",
    "# # Verify the reshuffling worked correctly\n",
    "# print(f\"\\nOriginal dataset task distribution by occupation:\")\n",
    "# original_task_counts = merged_data.groupby('O*NET-SOC Code')['Task ID'].nunique()\n",
    "# print(f\"Min tasks per occupation: {original_task_counts.min()}\")\n",
    "# print(f\"Max tasks per occupation: {original_task_counts.max()}\")\n",
    "# print(f\"Mean tasks per occupation: {original_task_counts.mean():.2f}\")\n",
    "# print(f\"Std tasks per occupation: {original_task_counts.std():.2f}\")\n",
    "\n",
    "# print(f\"\\nReshuffled dataset task distribution by occupation:\")\n",
    "# reshuffled_task_counts = reshuffled_data.groupby('O*NET-SOC Code')['Task ID'].nunique()\n",
    "# print(f\"Min tasks per occupation: {reshuffled_task_counts.min()}\")\n",
    "# print(f\"Max tasks per occupation: {reshuffled_task_counts.max()}\")\n",
    "# print(f\"Mean tasks per occupation: {reshuffled_task_counts.mean():.2f}\")\n",
    "# print(f\"Std tasks per occupation: {reshuffled_task_counts.std():.2f}\")\n",
    "\n",
    "# # Count occupations with zero tasks\n",
    "# zero_task_occupations = (reshuffled_task_counts == 0).sum()\n",
    "# print(f\"Occupations with zero tasks: {zero_task_occupations}\")\n",
    "\n",
    "# print(f\"\\nVerification:\")\n",
    "# print(f\"Number of unique occupations preserved: {reshuffled_data['O*NET-SOC Code'].nunique() == merged_data['O*NET-SOC Code'].nunique()}\")\n",
    "# print(f\"Number of unique tasks preserved: {reshuffled_data['Task ID'].nunique() == unique_tasks['Task ID'].nunique()}\")\n",
    "# print(f\"Each task appears exactly once: {len(reshuffled_data) == len(unique_tasks)}\")\n",
    "\n",
    "# # Show SOC hierarchy column names\n",
    "# print(f\"\\nSOC hierarchy columns created:\")\n",
    "# soc_columns = ['soc_major_group', 'soc_minor_group', 'soc_broad_occupation', 'soc_detailed_occupation']\n",
    "# for col in soc_columns:\n",
    "#     print(f\"  {col}: {reshuffled_data[col].nunique():,} unique values\")\n",
    "\n",
    "\n",
    "# # Set reshuffled data as the final dataset\n",
    "# merged_data = reshuffled_data.copy()\n",
    "\n",
    "# # Show sample of reshuffled data\n",
    "# print(f\"\\nSample of reshuffled data:\")\n",
    "# reshuffled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0340c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the supplemental tasks\n",
    "merged_data = merged_data[merged_data['Task Type'] != 'Supplemental'].reset_index(drop=True)\n",
    "\n",
    "# Drop rows whose Occupation Title includes 'Teachers, Postsecondary'\n",
    "merged_data = merged_data[~merged_data['Occupation Title'].str.contains('Teachers, Postsecondary')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23928b2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc875d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep data for high AI-exposure major groups\n",
    "high_ai_exposure_major_groups = ['13-0000', '15-0000', '19-0000', '21-0000', '23-0000', '25-0000', '27-0000', '41-0000', '43-0000']\n",
    "merged_data = merged_data[merged_data['Major_Group_Code'].isin(high_ai_exposure_major_groups)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c59de8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the final merged data structure and explore some sample occupations\n",
    "print(f\"Final merged data shape: {merged_data.shape}\")\n",
    "print(f\"Columns: {list(merged_data.columns)}\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(merged_data['label'].value_counts())\n",
    "\n",
    "# Find occupations with good task sequences (have multiple tasks with position data)\n",
    "occupation_task_counts = merged_data.groupby(['O*NET-SOC Code', 'Occupation Title']).size().reset_index(name='task_count')\n",
    "occupation_task_counts = occupation_task_counts.sort_values('task_count', ascending=False)\n",
    "print(f\"\\nTop 10 occupations by task count:\")\n",
    "print(occupation_task_counts.head(10))\n",
    "\n",
    "# Select a few example occupations for visualization\n",
    "example_occupations = occupation_task_counts.head(5)['O*NET-SOC Code'].tolist()\n",
    "print(f\"\\nSelected example occupations: {example_occupations}\")\n",
    "\n",
    "# Show sample data for first occupation\n",
    "sample_occ_code = example_occupations[0]\n",
    "sample_data = merged_data[merged_data['O*NET-SOC Code'] == sample_occ_code].copy()\n",
    "sample_data = sample_data.sort_values('Task Position')\n",
    "print(f\"\\nSample data for {sample_data['Occupation Title'].iloc[0]}:\")\n",
    "print(sample_data[['Task Position', 'Task Title', 'label']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa930fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.patches import Rectangle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_task_sequence(data, occ_code, title_max_length=50):\n",
    "    \"\"\"Plot task sequence for a specific occupation with color-coded rectangles\"\"\"\n",
    "\n",
    "    # Filter and sort data for the occupation\n",
    "    occ_data = data[data['O*NET-SOC Code'] == occ_code].copy()\n",
    "    occ_data = occ_data.sort_values('Task Position')\n",
    "\n",
    "    if len(occ_data) == 0 or occ_data['Task Position'].isna().all():\n",
    "        print(f\"No data with positions found for occupation {occ_code}\")\n",
    "        return None\n",
    "\n",
    "    # Color mapping\n",
    "    color_map = {\n",
    "        'Manual': 'lightgray',\n",
    "        'Augmentation': 'orange',\n",
    "        'Automation': 'green'\n",
    "    }\n",
    "\n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(16, max(6, len(occ_data) * 0.4)))\n",
    "\n",
    "    # Plot rectangles for each task\n",
    "    for i, (idx, row) in enumerate(occ_data.iterrows()):\n",
    "        y_pos = len(occ_data) - i - 1  # Start from top\n",
    "\n",
    "        # Create rectangle\n",
    "        rect = Rectangle((0, y_pos), 10, 0.8,\n",
    "                        facecolor=color_map.get(row['label'], 'lightgray'),\n",
    "                        edgecolor='black',\n",
    "                        linewidth=1)\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # Truncate task title if too long\n",
    "        task_title = str(row['Task Title'])\n",
    "        if len(task_title) > title_max_length:\n",
    "            task_title = task_title[:title_max_length] + \"...\"\n",
    "\n",
    "        # Add task position number on the left\n",
    "        ax.text(-0.5, y_pos + 0.4, f\"{int(row['Task Position'])}\",\n",
    "               ha='right', va='center', fontweight='bold', fontsize=10)\n",
    "\n",
    "        # Add task title inside rectangle\n",
    "        ax.text(0.2, y_pos + 0.4, task_title,\n",
    "               ha='left', va='center', fontsize=9, wrap=True)\n",
    "\n",
    "        # Add label on the right\n",
    "        ax.text(10.2, y_pos + 0.4, row['label'],\n",
    "               ha='left', va='center', fontweight='bold', fontsize=9,\n",
    "               color=color_map.get(row['label'], 'black'))\n",
    "\n",
    "    # Set up the plot\n",
    "    ax.set_xlim(-2, 15)\n",
    "    ax.set_ylim(-0.5, len(occ_data) - 0.1)\n",
    "\n",
    "    # Remove axes\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "\n",
    "    # Add title\n",
    "    occupation_title = occ_data['Occupation Title'].iloc[0]\n",
    "    plt.title(f\"Task Sequence for {occupation_title}\\n({occ_code})\",\n",
    "             fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "    # Add legend\n",
    "    legend_elements = [patches.Patch(color='lightgray', label='Manual'),\n",
    "                      patches.Patch(color='orange', label='Augmentation'),\n",
    "                      patches.Patch(color='green', label='Automation')]\n",
    "    ax.legend(handles=legend_elements, loc='upper right', bbox_to_anchor=(1.15, 1))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "# Create output subfolder for all occupation plots\n",
    "output_folder = os.path.join(output_plot_path, \"all_occupation_task_sequences\")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Iterate over all occupations and save plots\n",
    "occupations = merged_data['O*NET-SOC Code'].unique()\n",
    "print(f\"Found {len(occupations):,} occupations to process. Plots will be saved to: {output_folder}\")\n",
    "\n",
    "summary_rows = []\n",
    "for i, occ_code in enumerate(sorted(occupations)):\n",
    "    try:\n",
    "        occ_data = merged_data[merged_data['O*NET-SOC Code'] == occ_code].copy()\n",
    "        n_tasks = len(occ_data)\n",
    "        # Skip if no tasks or no position information\n",
    "        if n_tasks == 0 or occ_data['Task Position'].isna().all():\n",
    "            print(f\"[{i+1}/{len(occupations)}] Skipping {occ_code}: no positional task data\")\n",
    "            summary_rows.append({\n",
    "                'O*NET-SOC Code': occ_code,\n",
    "                'Occupation Title': occ_data['Occupation Title'].iloc[0] if len(occ_data) > 0 else '',\n",
    "                'n_tasks': n_tasks,\n",
    "                'manual': 0,\n",
    "                'augmentation': 0,\n",
    "                'automation': 0,\n",
    "                'filename': '',\n",
    "                'status': 'skipped_no_positions'\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        occ_data = occ_data.sort_values('Task Position')\n",
    "\n",
    "        fig = plot_task_sequence(merged_data, occ_code)\n",
    "        if fig is None:\n",
    "            print(f\"[{i+1}/{len(occupations)}] No figure produced for {occ_code}\")\n",
    "            summary_rows.append({\n",
    "                'O*NET-SOC Code': occ_code,\n",
    "                'Occupation Title': occ_data['Occupation Title'].iloc[0],\n",
    "                'n_tasks': n_tasks,\n",
    "                'manual': occ_data['label'].value_counts().get('Manual', 0),\n",
    "                'augmentation': occ_data['label'].value_counts().get('Augmentation', 0),\n",
    "                'automation': occ_data['label'].value_counts().get('Automation', 0),\n",
    "                'filename': '',\n",
    "                'status': 'no_figure'\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # Safe filename\n",
    "        occ_title = occ_data['Occupation Title'].iloc[0]\n",
    "        safe_title = ''.join(c if (c.isalnum() or c in (' ', '_', '-')) else '_' for c in occ_title).replace(' ', '_')[:120]\n",
    "        filename = os.path.join(output_folder, f\"task_sequence_{occ_code}_{safe_title}.png\")\n",
    "\n",
    "        # Save and close\n",
    "        fig.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "        counts = occ_data['label'].value_counts()\n",
    "        summary_rows.append({\n",
    "            'O*NET-SOC Code': occ_code,\n",
    "            'Occupation Title': occ_title,\n",
    "            'n_tasks': n_tasks,\n",
    "            'manual': counts.get('Manual', 0),\n",
    "            'augmentation': counts.get('Augmentation', 0),\n",
    "            'automation': counts.get('Automation', 0),\n",
    "            'filename': filename,\n",
    "            'status': 'saved'\n",
    "        })\n",
    "\n",
    "        if (i + 1) % 50 == 0:\n",
    "            print(f\"Processed {i+1}/{len(occupations)} occupations\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {occ_code}: {e}\")\n",
    "        summary_rows.append({\n",
    "            'O*NET-SOC Code': occ_code,\n",
    "            'Occupation Title': occ_data['Occupation Title'].iloc[0] if 'occ_data' in locals() and len(occ_data) > 0 else '',\n",
    "            'n_tasks': len(occ_data) if 'occ_data' in locals() else 0,\n",
    "            'manual': occ_data['label'].value_counts().get('Manual', 0) if 'occ_data' in locals() else 0,\n",
    "            'augmentation': occ_data['label'].value_counts().get('Augmentation', 0) if 'occ_data' in locals() else 0,\n",
    "            'automation': occ_data['label'].value_counts().get('Automation', 0) if 'occ_data' in locals() else 0,\n",
    "            'filename': '',\n",
    "            'status': 'error',\n",
    "            'error_msg': str(e)\n",
    "        })\n",
    "\n",
    "# # Save summary CSV\n",
    "# summary_df = pd.DataFrame(summary_rows)\n",
    "# summary_csv_path = os.path.join(output_folder, 'task_sequence_summary.csv')\n",
    "# summary_df.to_csv(summary_csv_path, index=False)\n",
    "# print(f\"Saved summary CSV with {len(summary_df)} rows to: {summary_csv_path}\")\n",
    "# print(\"Done. Open the notebook and run this cell (or execute the notebook) to generate the plots.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c61937",
   "metadata": {},
   "source": [
    "## Task Sequence Visualization Summary\n",
    "\n",
    "The visualizations above show ordered task sequences for three example occupations, with each task represented as a rectangle and color-coded based on AI exposure classification:\n",
    "\n",
    "- **Gray rectangles**: Manual tasks (not suitable for AI assistance)\n",
    "- **Orange rectangles**: Augmentation tasks (AI can assist but human involvement needed)\n",
    "- **Green rectangles**: Automation tasks (can be fully automated by AI)\n",
    "\n",
    "### Key Observations:\n",
    "\n",
    "1. **Computer Systems Engineers/Architects (15-1299.08)**:\n",
    "   - 28 total tasks with a clear sequence from 1-28\n",
    "   - Mixed pattern: Many augmentation tasks (11) scattered throughout the sequence\n",
    "   - Only 1 automation task (task 17: \"Develop application-specific software\")\n",
    "   - Early tasks tend to be more manual (communication, analysis), while technical development tasks show more AI potential\n",
    "\n",
    "2. **Business Continuity Planners (13-1199.04)**:\n",
    "   - 20 total tasks (note: missing some position numbers, indicating gaps in the sequence)\n",
    "   - Fewer augmentation opportunities (5) compared to Computer Systems Engineers\n",
    "   - No automation tasks - this occupation appears less amenable to full AI automation\n",
    "   - Augmentation tasks cluster in specific areas: regulation interpretation, design/implementation, training, and data analysis\n",
    "\n",
    "3. **Set and Exhibit Designers (27-1027.00)**:\n",
    "   - 19 total tasks but all classified as Manual\n",
    "   - This creative occupation shows very low AI exposure across all tasks\n",
    "   - Tasks are highly creative, physical, and require human judgment and collaboration\n",
    "   - Demonstrates occupations where AI has limited applicability in current form\n",
    "\n",
    "The visualizations reveal that **AI exposure patterns vary significantly by occupation type**, with technical roles showing more potential for AI augmentation and automation compared to creative or planning-focused roles."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
