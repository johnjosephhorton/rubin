{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc7fc397",
   "metadata": {},
   "source": [
    "#### By: Peyman Shahidi\n",
    "#### Created: Oct 29, 2025\n",
    "#### Last Edit: Nov 2, 2025\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "10366af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python\n",
    "import getpass\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "import random \n",
    "\n",
    "## formatting number to appear comma separated and with two digits after decimal: e.g, 1000 shown as 1,000.00\n",
    "pd.set_option('float_format', \"{:,.2f}\".format)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "#from matplotlib.legend import Legend\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "519e43cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python\n",
    "import getpass\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "import random \n",
    "\n",
    "## formatting number to appear comma separated and with two digits after decimal: e.g, 1000 shown as 1,000.00\n",
    "pd.set_option('float_format', \"{:,.2f}\".format)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "#from matplotlib.legend import Legend\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "main_folder_path = \"..\"\n",
    "input_data_path = f\"{main_folder_path}/data\"\n",
    "# Modify the output path accordingly\n",
    "output_data_path = f'{input_data_path}/computed_objects/BLS_ONET_matchedEmpShares'\n",
    "output_plot_path = f\"{main_folder_path}/writeup/plots/anthropic_AI_index/BLS_ONET_matchedEmpShares\"\n",
    "output_plot_path_by_BLS_sector = f\"{main_folder_path}/writeup/plots/anthropic_AI_index/BLS_ONET_matchedEmpShares/by_BLS_sector\"\n",
    "output_plot_path_by_ONET_level = f\"{main_folder_path}/writeup/plots/anthropic_AI_index/BLS_ONET_matchedEmpShares/by_ONET_level\"\n",
    "output_plot_path_by_weighting_scheme = f\"{main_folder_path}/writeup/plots/anthropic_AI_index/BLS_ONET_matchedEmpShares/by_weighting_scheme\"\n",
    "output_plot_path_by_dependent_var = f\"{main_folder_path}/writeup/plots/anthropic_AI_index/BLS_ONET_matchedEmpShares/by_dependent_var\"\n",
    "\n",
    "# Toggle: if True, randomly reassign occ_totalEmpShare weights in the merged master_df\n",
    "# during the merge_industry_employment_shares step. Set to False for default behavior.\n",
    "randomize_occ_weights = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a2e933d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for path in [output_data_path, output_plot_path, \n",
    "             output_plot_path_by_BLS_sector, output_plot_path_by_ONET_level, \n",
    "             output_plot_path_by_weighting_scheme, output_plot_path_by_dependent_var]:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bf72cf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before removing duplicates: 22,310\n",
      "Number of rows after removing duplicates: 17,953\n",
      "Duplicates removed: 4357\n",
      "Number of rows in ONET dataset: 17,953\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O*NET-SOC Code</th>\n",
       "      <th>Occupation Title</th>\n",
       "      <th>Task ID</th>\n",
       "      <th>Task Title</th>\n",
       "      <th>Task Type</th>\n",
       "      <th>Job Zone</th>\n",
       "      <th>Task_Time_Percentage</th>\n",
       "      <th>Hourly_Mean_Wage</th>\n",
       "      <th>Hourly_P10_Wage</th>\n",
       "      <th>Hourly_P25_Wage</th>\n",
       "      <th>...</th>\n",
       "      <th>Relevance</th>\n",
       "      <th>Base_SOC_Code</th>\n",
       "      <th>Major_Group_Code</th>\n",
       "      <th>Major_Group_Title</th>\n",
       "      <th>Minor_Group_Code</th>\n",
       "      <th>Minor_Group_Title</th>\n",
       "      <th>Broad_Occupation_Code</th>\n",
       "      <th>Broad_Occupation_Title</th>\n",
       "      <th>Detailed_Occupation_Code</th>\n",
       "      <th>Detailed_Occupation_Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>8823</td>\n",
       "      <td>Direct or coordinate an organization's financi...</td>\n",
       "      <td>Core</td>\n",
       "      <td>5</td>\n",
       "      <td>9.62</td>\n",
       "      <td>124.47</td>\n",
       "      <td>38.46</td>\n",
       "      <td>62.90</td>\n",
       "      <td>...</td>\n",
       "      <td>94.19</td>\n",
       "      <td>11-1011</td>\n",
       "      <td>11-0000</td>\n",
       "      <td>Management Occupations</td>\n",
       "      <td>11-1000</td>\n",
       "      <td>Top Executives</td>\n",
       "      <td>11-1010</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>11-1011</td>\n",
       "      <td>Chief Executives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>8824</td>\n",
       "      <td>Confer with board members, organization offici...</td>\n",
       "      <td>Core</td>\n",
       "      <td>5</td>\n",
       "      <td>9.49</td>\n",
       "      <td>124.47</td>\n",
       "      <td>38.46</td>\n",
       "      <td>62.90</td>\n",
       "      <td>...</td>\n",
       "      <td>98.79</td>\n",
       "      <td>11-1011</td>\n",
       "      <td>11-0000</td>\n",
       "      <td>Management Occupations</td>\n",
       "      <td>11-1000</td>\n",
       "      <td>Top Executives</td>\n",
       "      <td>11-1010</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>11-1011</td>\n",
       "      <td>Chief Executives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>8825</td>\n",
       "      <td>Analyze operations to evaluate performance of ...</td>\n",
       "      <td>Core</td>\n",
       "      <td>5</td>\n",
       "      <td>9.22</td>\n",
       "      <td>124.47</td>\n",
       "      <td>38.46</td>\n",
       "      <td>62.90</td>\n",
       "      <td>...</td>\n",
       "      <td>100.00</td>\n",
       "      <td>11-1011</td>\n",
       "      <td>11-0000</td>\n",
       "      <td>Management Occupations</td>\n",
       "      <td>11-1000</td>\n",
       "      <td>Top Executives</td>\n",
       "      <td>11-1010</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>11-1011</td>\n",
       "      <td>Chief Executives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>8826</td>\n",
       "      <td>Direct, plan, or implement policies, objective...</td>\n",
       "      <td>Core</td>\n",
       "      <td>5</td>\n",
       "      <td>10.26</td>\n",
       "      <td>124.47</td>\n",
       "      <td>38.46</td>\n",
       "      <td>62.90</td>\n",
       "      <td>...</td>\n",
       "      <td>95.84</td>\n",
       "      <td>11-1011</td>\n",
       "      <td>11-0000</td>\n",
       "      <td>Management Occupations</td>\n",
       "      <td>11-1000</td>\n",
       "      <td>Top Executives</td>\n",
       "      <td>11-1010</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>11-1011</td>\n",
       "      <td>Chief Executives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>8827</td>\n",
       "      <td>Prepare budgets for approval, including those ...</td>\n",
       "      <td>Core</td>\n",
       "      <td>5</td>\n",
       "      <td>1.46</td>\n",
       "      <td>124.47</td>\n",
       "      <td>38.46</td>\n",
       "      <td>62.90</td>\n",
       "      <td>...</td>\n",
       "      <td>90.47</td>\n",
       "      <td>11-1011</td>\n",
       "      <td>11-0000</td>\n",
       "      <td>Management Occupations</td>\n",
       "      <td>11-1000</td>\n",
       "      <td>Top Executives</td>\n",
       "      <td>11-1010</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>11-1011</td>\n",
       "      <td>Chief Executives</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  O*NET-SOC Code  Occupation Title  Task ID  \\\n",
       "0     11-1011.00  Chief Executives     8823   \n",
       "1     11-1011.00  Chief Executives     8824   \n",
       "2     11-1011.00  Chief Executives     8825   \n",
       "3     11-1011.00  Chief Executives     8826   \n",
       "4     11-1011.00  Chief Executives     8827   \n",
       "\n",
       "                                          Task Title Task Type  Job Zone  \\\n",
       "0  Direct or coordinate an organization's financi...      Core         5   \n",
       "1  Confer with board members, organization offici...      Core         5   \n",
       "2  Analyze operations to evaluate performance of ...      Core         5   \n",
       "3  Direct, plan, or implement policies, objective...      Core         5   \n",
       "4  Prepare budgets for approval, including those ...      Core         5   \n",
       "\n",
       "   Task_Time_Percentage  Hourly_Mean_Wage  Hourly_P10_Wage  Hourly_P25_Wage  \\\n",
       "0                  9.62            124.47            38.46            62.90   \n",
       "1                  9.49            124.47            38.46            62.90   \n",
       "2                  9.22            124.47            38.46            62.90   \n",
       "3                 10.26            124.47            38.46            62.90   \n",
       "4                  1.46            124.47            38.46            62.90   \n",
       "\n",
       "   ...  Relevance  Base_SOC_Code  Major_Group_Code       Major_Group_Title  \\\n",
       "0  ...      94.19        11-1011           11-0000  Management Occupations   \n",
       "1  ...      98.79        11-1011           11-0000  Management Occupations   \n",
       "2  ...     100.00        11-1011           11-0000  Management Occupations   \n",
       "3  ...      95.84        11-1011           11-0000  Management Occupations   \n",
       "4  ...      90.47        11-1011           11-0000  Management Occupations   \n",
       "\n",
       "   Minor_Group_Code  Minor_Group_Title  Broad_Occupation_Code  \\\n",
       "0           11-1000     Top Executives                11-1010   \n",
       "1           11-1000     Top Executives                11-1010   \n",
       "2           11-1000     Top Executives                11-1010   \n",
       "3           11-1000     Top Executives                11-1010   \n",
       "4           11-1000     Top Executives                11-1010   \n",
       "\n",
       "   Broad_Occupation_Title  Detailed_Occupation_Code  Detailed_Occupation_Title  \n",
       "0        Chief Executives                   11-1011           Chief Executives  \n",
       "1        Chief Executives                   11-1011           Chief Executives  \n",
       "2        Chief Executives                   11-1011           Chief Executives  \n",
       "3        Chief Executives                   11-1011           Chief Executives  \n",
       "4        Chief Executives                   11-1011           Chief Executives  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read O*NET data\n",
    "ONET = pd.read_csv(f'{input_data_path}/computed_objects/ONET_cleaned_tasks.csv')\n",
    "\n",
    "# Drop  columns to avoid double counting\n",
    "# Note: In ~4k instances, the same task is mapped to multiple DWAs\n",
    "ONET = ONET.drop(columns=['DWA ID', 'DWA Title'])\n",
    "\n",
    "# Remove duplicate rows\n",
    "rows_before = len(ONET)\n",
    "print(f\"Number of rows before removing duplicates: {rows_before:,}\")\n",
    "ONET = ONET.drop_duplicates().reset_index(drop=True)\n",
    "rows_after = len(ONET)\n",
    "print(f\"Number of rows after removing duplicates: {rows_after:,}\")\n",
    "print(f\"Duplicates removed: {rows_before - rows_after}\")\n",
    "\n",
    "# Print length of dataset\n",
    "print(f\"Number of rows in ONET dataset: {len(ONET):,}\")\n",
    "\n",
    "ONET.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c0f3fb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in GPTs full labels dataset: 19,265\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O*NET-SOC Code</th>\n",
       "      <th>Task ID</th>\n",
       "      <th>Task Title</th>\n",
       "      <th>Task Type</th>\n",
       "      <th>Occupation Title</th>\n",
       "      <th>gpt4_exposure</th>\n",
       "      <th>human_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>8823</td>\n",
       "      <td>Direct or coordinate an organizations financia...</td>\n",
       "      <td>Core</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>E2</td>\n",
       "      <td>E0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>8831</td>\n",
       "      <td>Appoint department heads or managers and assig...</td>\n",
       "      <td>Core</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>E0</td>\n",
       "      <td>E0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>8825</td>\n",
       "      <td>Analyze operations to evaluate performance of ...</td>\n",
       "      <td>Core</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>E2</td>\n",
       "      <td>E2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>8826</td>\n",
       "      <td>Direct, plan, or implement policies, objective...</td>\n",
       "      <td>Core</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>E2</td>\n",
       "      <td>E0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>8827</td>\n",
       "      <td>Prepare budgets for approval, including those ...</td>\n",
       "      <td>Core</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>E2</td>\n",
       "      <td>E2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  O*NET-SOC Code  Task ID                                         Task Title  \\\n",
       "0     11-1011.00     8823  Direct or coordinate an organizations financia...   \n",
       "1     11-1011.00     8831  Appoint department heads or managers and assig...   \n",
       "2     11-1011.00     8825  Analyze operations to evaluate performance of ...   \n",
       "3     11-1011.00     8826  Direct, plan, or implement policies, objective...   \n",
       "4     11-1011.00     8827  Prepare budgets for approval, including those ...   \n",
       "\n",
       "  Task Type  Occupation Title gpt4_exposure human_labels  \n",
       "0      Core  Chief Executives            E2           E0  \n",
       "1      Core  Chief Executives            E0           E0  \n",
       "2      Core  Chief Executives            E2           E2  \n",
       "3      Core  Chief Executives            E2           E0  \n",
       "4      Core  Chief Executives            E2           E2  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load GPTs are GPTs full label dataset\n",
    "gpts_full_labels = pd.read_csv(f'{input_data_path}/GPTs-are-GPTs-main/data/full_labelset.tsv', sep=\"\\t\")\n",
    "\n",
    "# Keep relevant columns only\n",
    "gpts_full_labels = gpts_full_labels[['O*NET-SOC Code', 'Task ID', 'Task', 'Task Type', 'Title', 'gpt4_exposure', 'human_labels']]\n",
    "\n",
    "# Convert Task ID to integer\n",
    "gpts_full_labels['Task ID'] = gpts_full_labels['Task ID'].astype(int)\n",
    "\n",
    "# Remove apostrophes for consistency\n",
    "gpts_full_labels = gpts_full_labels.applymap(lambda x: x.replace(\"'\", \"\") if isinstance(x, str) else x)\n",
    "\n",
    "# Rename columns\n",
    "gpts_full_labels = gpts_full_labels.rename(columns={\n",
    "    'Task': 'Task Title',\n",
    "    'Title': 'Occupation Title'\n",
    "})\n",
    "\n",
    "# Print length of dataset\n",
    "print(f\"Number of rows in GPTs full labels dataset: {len(gpts_full_labels):,}\")\n",
    "\n",
    "\n",
    "gpts_full_labels.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5fceda80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unmatched tasks: 791\n"
     ]
    }
   ],
   "source": [
    "# Merge with ONET dataset to get hierarchical codes and titles\n",
    "ONET = ONET.merge(gpts_full_labels, on=['O*NET-SOC Code', 'Occupation Title', 'Task ID', 'Task Title', 'Task Type'], how='left')\n",
    "\n",
    "# Check how many tasks were not matched\n",
    "unmatched_tasks = ONET[ONET['gpt4_exposure'].isna()]\n",
    "print(f\"Number of unmatched tasks: {len(unmatched_tasks):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2c12ea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with Anthropic exposure data\n",
    "anthropic_exposure = pd.read_csv(f'{input_data_path}/Anthropic_EconomicIndex/automation_vs_augmentation_by_task.csv')\n",
    "\n",
    "# Remove if all entries are filtered:\n",
    "anthropic_exposure = anthropic_exposure[anthropic_exposure['filtered'] != 1].reset_index(drop=True)\n",
    "\n",
    "# Create new columns:\n",
    "# Sum feedback loop and directive into Automation\n",
    "# Sum validation, iteration, and learning into Augmentation\n",
    "anthropic_exposure['automation'] = anthropic_exposure.apply(lambda row: row['feedback_loop'] + row['directive'], axis=1)\n",
    "anthropic_exposure['augmentation'] = anthropic_exposure.apply(lambda row: row['validation'] + row['task_iteration'] + row['learning'], axis=1)\n",
    "\n",
    "# Assign labels: take the max of automation, augmentation, manual and assign the corresponding label\n",
    "def assign_label(row):\n",
    "    max_value = max(row['automation'], row['augmentation'])\n",
    "    if max_value == row['automation']:\n",
    "        return 'Automation'\n",
    "    elif max_value == row['augmentation']:\n",
    "        return 'Augmentation'\n",
    "\n",
    "anthropic_exposure['label'] = anthropic_exposure.apply(assign_label, axis=1)\n",
    "\n",
    "# Filter to only keep the relevant columns\n",
    "anthropic_exposure = anthropic_exposure[['task_name', 'automation', 'augmentation', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "51666860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tasks in ONET dataset: 16,913\n",
      "Number of unique tasks in Anthropic exposure dataset: 2,298\n",
      "\n",
      "Distribution of labels after filling NaN values with 'Manual':\n",
      "label\n",
      "Manual          15605\n",
      "Augmentation     1626\n",
      "Automation        722\n",
      "Name: count, dtype: int64\n",
      "Total tasks: 17,953\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O*NET-SOC Code</th>\n",
       "      <th>Occupation Title</th>\n",
       "      <th>Task ID</th>\n",
       "      <th>Task Title</th>\n",
       "      <th>Task Type</th>\n",
       "      <th>Job Zone</th>\n",
       "      <th>Task_Time_Percentage</th>\n",
       "      <th>Hourly_Mean_Wage</th>\n",
       "      <th>Hourly_P10_Wage</th>\n",
       "      <th>Hourly_P25_Wage</th>\n",
       "      <th>...</th>\n",
       "      <th>Broad_Occupation_Title</th>\n",
       "      <th>Detailed_Occupation_Code</th>\n",
       "      <th>Detailed_Occupation_Title</th>\n",
       "      <th>gpt4_exposure</th>\n",
       "      <th>human_labels</th>\n",
       "      <th>task_normalized</th>\n",
       "      <th>task_name</th>\n",
       "      <th>automation</th>\n",
       "      <th>augmentation</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>8823</td>\n",
       "      <td>Direct or coordinate an organization's financi...</td>\n",
       "      <td>Core</td>\n",
       "      <td>5</td>\n",
       "      <td>9.62</td>\n",
       "      <td>124.47</td>\n",
       "      <td>38.46</td>\n",
       "      <td>62.90</td>\n",
       "      <td>...</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>11-1011</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>direct or coordinate an organization's financi...</td>\n",
       "      <td>direct or coordinate an organization's financi...</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.57</td>\n",
       "      <td>Augmentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>8824</td>\n",
       "      <td>Confer with board members, organization offici...</td>\n",
       "      <td>Core</td>\n",
       "      <td>5</td>\n",
       "      <td>9.49</td>\n",
       "      <td>124.47</td>\n",
       "      <td>38.46</td>\n",
       "      <td>62.90</td>\n",
       "      <td>...</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>11-1011</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>E0</td>\n",
       "      <td>E0</td>\n",
       "      <td>confer with board members, organization offici...</td>\n",
       "      <td>confer with board members, organization offici...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.61</td>\n",
       "      <td>Augmentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>8825</td>\n",
       "      <td>Analyze operations to evaluate performance of ...</td>\n",
       "      <td>Core</td>\n",
       "      <td>5</td>\n",
       "      <td>9.22</td>\n",
       "      <td>124.47</td>\n",
       "      <td>38.46</td>\n",
       "      <td>62.90</td>\n",
       "      <td>...</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>11-1011</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>E2</td>\n",
       "      <td>E2</td>\n",
       "      <td>analyze operations to evaluate performance of ...</td>\n",
       "      <td>analyze operations to evaluate performance of ...</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.66</td>\n",
       "      <td>Augmentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>8826</td>\n",
       "      <td>Direct, plan, or implement policies, objective...</td>\n",
       "      <td>Core</td>\n",
       "      <td>5</td>\n",
       "      <td>10.26</td>\n",
       "      <td>124.47</td>\n",
       "      <td>38.46</td>\n",
       "      <td>62.90</td>\n",
       "      <td>...</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>11-1011</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>E2</td>\n",
       "      <td>E0</td>\n",
       "      <td>direct, plan, or implement policies, objective...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Manual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>8827</td>\n",
       "      <td>Prepare budgets for approval, including those ...</td>\n",
       "      <td>Core</td>\n",
       "      <td>5</td>\n",
       "      <td>1.46</td>\n",
       "      <td>124.47</td>\n",
       "      <td>38.46</td>\n",
       "      <td>62.90</td>\n",
       "      <td>...</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>11-1011</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>E2</td>\n",
       "      <td>E2</td>\n",
       "      <td>prepare budgets for approval, including those ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Manual</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  O*NET-SOC Code  Occupation Title  Task ID  \\\n",
       "0     11-1011.00  Chief Executives     8823   \n",
       "1     11-1011.00  Chief Executives     8824   \n",
       "2     11-1011.00  Chief Executives     8825   \n",
       "3     11-1011.00  Chief Executives     8826   \n",
       "4     11-1011.00  Chief Executives     8827   \n",
       "\n",
       "                                          Task Title Task Type  Job Zone  \\\n",
       "0  Direct or coordinate an organization's financi...      Core         5   \n",
       "1  Confer with board members, organization offici...      Core         5   \n",
       "2  Analyze operations to evaluate performance of ...      Core         5   \n",
       "3  Direct, plan, or implement policies, objective...      Core         5   \n",
       "4  Prepare budgets for approval, including those ...      Core         5   \n",
       "\n",
       "   Task_Time_Percentage  Hourly_Mean_Wage  Hourly_P10_Wage  Hourly_P25_Wage  \\\n",
       "0                  9.62            124.47            38.46            62.90   \n",
       "1                  9.49            124.47            38.46            62.90   \n",
       "2                  9.22            124.47            38.46            62.90   \n",
       "3                 10.26            124.47            38.46            62.90   \n",
       "4                  1.46            124.47            38.46            62.90   \n",
       "\n",
       "   ...  Broad_Occupation_Title  Detailed_Occupation_Code  \\\n",
       "0  ...        Chief Executives                   11-1011   \n",
       "1  ...        Chief Executives                   11-1011   \n",
       "2  ...        Chief Executives                   11-1011   \n",
       "3  ...        Chief Executives                   11-1011   \n",
       "4  ...        Chief Executives                   11-1011   \n",
       "\n",
       "   Detailed_Occupation_Title  gpt4_exposure  human_labels  \\\n",
       "0           Chief Executives            NaN           NaN   \n",
       "1           Chief Executives             E0            E0   \n",
       "2           Chief Executives             E2            E2   \n",
       "3           Chief Executives             E2            E0   \n",
       "4           Chief Executives             E2            E2   \n",
       "\n",
       "                                     task_normalized  \\\n",
       "0  direct or coordinate an organization's financi...   \n",
       "1  confer with board members, organization offici...   \n",
       "2  analyze operations to evaluate performance of ...   \n",
       "3  direct, plan, or implement policies, objective...   \n",
       "4  prepare budgets for approval, including those ...   \n",
       "\n",
       "                                           task_name  automation  \\\n",
       "0  direct or coordinate an organization's financi...        0.35   \n",
       "1  confer with board members, organization offici...        0.25   \n",
       "2  analyze operations to evaluate performance of ...        0.31   \n",
       "3                                                NaN         NaN   \n",
       "4                                                NaN         NaN   \n",
       "\n",
       "   augmentation         label  \n",
       "0          0.57  Augmentation  \n",
       "1          0.61  Augmentation  \n",
       "2          0.66  Augmentation  \n",
       "3           NaN        Manual  \n",
       "4           NaN        Manual  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print number of unique tasks in ONET dataset\n",
    "print(f\"Number of unique tasks in ONET dataset: {ONET['Task Title'].nunique():,}\")\n",
    "\n",
    "# Print number of unique tasks in Anthropic exposure dataset\n",
    "print(f\"Number of unique tasks in Anthropic exposure dataset: {anthropic_exposure['task_name'].nunique():,}\")\n",
    "\n",
    "\n",
    "# Add normalized task title to ONET for merging\n",
    "ONET[\"task_normalized\"] = ONET[\"Task Title\"].str.lower().str.strip()\n",
    "\n",
    "\n",
    "# Merge ONET and Anthropic exposure data on the normalized task title\n",
    "merged_data = pd.merge(ONET, anthropic_exposure[['task_name', 'automation', 'augmentation', 'label']], left_on=\"task_normalized\", right_on=\"task_name\", how=\"left\")\n",
    "\n",
    "# Fill the NaN values of the label column in merged dataset as Manual\n",
    "merged_data['label'] = merged_data['label'].fillna('Manual')\n",
    "\n",
    "# Print distribution after filling NaN values\n",
    "print(f\"\\nDistribution of labels after filling NaN values with 'Manual':\")\n",
    "print(merged_data['label'].value_counts())\n",
    "print(f\"Total tasks: {len(merged_data):,}\")\n",
    "\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4814f4c2",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ba8b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_occupation_analysis(my_sector, my_onet_level,\n",
    "                               merged_data, onet_occupation_code_var, onet_occupation_title_var):\n",
    "    # Create occupation-level analysis for scatter plots\n",
    "    # Group by occupation and calculate label fractions and task counts\n",
    "    occupation_stats = []\n",
    "\n",
    "    for (soc_code, occ_title), group in merged_data.groupby([onet_occupation_code_var, onet_occupation_title_var]):\n",
    "        num_tasks = group['Task ID'].nunique()\n",
    "        # num_occupations = group[onet_occupation_code_var].nunique()\n",
    "        total_tasks = len(group)\n",
    "        \n",
    "        manual_fraction = (group['label'] == 'Manual').sum() / total_tasks\n",
    "        augmentation_fraction = (group['label'] == 'Augmentation').sum() / total_tasks  \n",
    "        automation_fraction = (group['label'] == 'Automation').sum() / total_tasks\n",
    "        ai_fraction = augmentation_fraction + automation_fraction\n",
    "        gpt4_E0_fraction = (group['gpt4_exposure'] == 'E0').sum() / total_tasks\n",
    "        gpt4_E1_fraction = (group['gpt4_exposure'] == 'E1').sum() / total_tasks\n",
    "        gpt4_E2_fraction = (group['gpt4_exposure'] == 'E2').sum() / total_tasks\n",
    "        gpt4_aiExposure_fraction = gpt4_E1_fraction + gpt4_E2_fraction\n",
    "        human_E0_fraction = (group['human_labels'] == 'E0').sum() / total_tasks\n",
    "        human_E1_fraction = (group['human_labels'] == 'E1').sum() / total_tasks\n",
    "        human_E2_fraction = (group['human_labels'] == 'E2').sum() / total_tasks\n",
    "        human_aiExposure_fraction = human_E1_fraction + human_E2_fraction\n",
    "\n",
    "        \n",
    "        occupation_stats.append({\n",
    "            f'{onet_occupation_code_var}': soc_code,\n",
    "            f'{onet_occupation_title_var}': occ_title,\n",
    "            'num_tasks': num_tasks,\n",
    "            # 'num_occupations': num_occupations,\n",
    "            'manual_fraction': manual_fraction,\n",
    "            'ai_fraction': ai_fraction,\n",
    "            'augmentation_fraction': augmentation_fraction,\n",
    "            'automation_fraction': automation_fraction,\n",
    "            'gpt4_E0_fraction': gpt4_E0_fraction,\n",
    "            'gpt4_E1_fraction': gpt4_E1_fraction,\n",
    "            'gpt4_E2_fraction': gpt4_E2_fraction,\n",
    "            'gpt4_aiExposure_fraction': gpt4_aiExposure_fraction,\n",
    "            'human_E0_fraction': human_E0_fraction,\n",
    "            'human_E1_fraction': human_E1_fraction,\n",
    "            'human_E2_fraction': human_E2_fraction,\n",
    "            'human_aiExposure_fraction': human_aiExposure_fraction\n",
    "        })\n",
    "\n",
    "    occupation_analysis = pd.DataFrame(occupation_stats)\n",
    "\n",
    "    return occupation_analysis\n",
    "\n",
    "\n",
    "\n",
    "def merge_industry_employment_shares(seed, \n",
    "                                     my_sector, my_onet_level,\n",
    "                                     dependent_var,\n",
    "                                     onet_occupation_code_var, onet_occupation_title_var,\n",
    "                                     weight_col,\n",
    "                                     occupation_analysis):\n",
    "\n",
    "    # Merge industry employment share weights for all NAICS sectors and create a master dataset\n",
    "    bls_sector_shares = pd.read_csv(f'{input_data_path}/computed_objects/BLS_ONET_empShares/bls_{my_sector}_ONET{my_onet_level}_empShares.csv')\n",
    "\n",
    "    # bls_sector_shares = bls_sector_shares[bls_sector_shares.TOT_EMP >= 50].reset_index(drop=True)\n",
    "\n",
    "    # Ensure NAICS is string for consistent merging\n",
    "    bls_sector_shares['NAICS'] = bls_sector_shares['NAICS'].astype(str)\n",
    "\n",
    "    unique_sectors = bls_sector_shares['NAICS'].unique()\n",
    "    # print(f\"Found {len(unique_sectors)} unique NAICS sectors to process\")\n",
    "\n",
    "    master_dfs = []\n",
    "    processed_sectors = []\n",
    "\n",
    "    for sector_code in unique_sectors:\n",
    "        sector_weights_df = bls_sector_shares[bls_sector_shares.NAICS == sector_code]\n",
    "\n",
    "        # Merge occupation-level analysis with this sector's weights\n",
    "        sector_occupation_analysis = occupation_analysis.merge(\n",
    "            sector_weights_df[['NAICS', 'NAICS_TITLE', 'OCC_CODE', weight_col]],\n",
    "            left_on=onet_occupation_code_var,\n",
    "            right_on='OCC_CODE',\n",
    "            how='inner'\n",
    "        )\n",
    "        # Drop the OCC_CODE column after merge\n",
    "        sector_occupation_analysis = sector_occupation_analysis.drop(columns=['OCC_CODE'])\n",
    "\n",
    "        # Append to master list\n",
    "        master_dfs.append(sector_occupation_analysis)\n",
    "        processed_sectors.append(sector_code)\n",
    "\n",
    "    # Concatenate all sector-specific records into a master dataframe\n",
    "    master_df = pd.concat(master_dfs, ignore_index=True)\n",
    "\n",
    "    # Calculate sum of weight_col\n",
    "    master_df = (\n",
    "        master_df.groupby([onet_occupation_code_var, onet_occupation_title_var, dependent_var, 'num_tasks'], as_index=False)[weight_col]\n",
    "        .sum(numeric_only=True)\n",
    "    )\n",
    "    # master_df = master_df[~master_df[onet_occupation_title_var].isin(['Fast Food and Counter Workers'])]\n",
    "    # master_df = master_df[~master_df[onet_occupation_title_var].isin(['Retail Salespersons', 'Fast Food and Counter Workers', 'General and Operations Managers'])]\n",
    "    # print(f\"Aggregated to {len(master_df):,} unique occupations (summed over selected columns).\")\n",
    "\n",
    "    # Sort by weight_col descending\n",
    "    master_df = master_df.sort_values(by=weight_col, ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # OPTIONAL: randomize (shuffle) the existing values in the selected weight column\n",
    "    # If enabled, we take the existing values in `weight_col` and randomly permute\n",
    "    # them across rows. This preserves the original values (no normalization or new\n",
    "    # values), only their assignment to rows changes. The RNG uses\n",
    "    # `randomize_weights_seed` for reproducibility when set.\n",
    "    if globals().get('randomize_occ_weights', False) and seed > 0:\n",
    "        rng = np.random.RandomState(seed)\n",
    "\n",
    "        # Extract current values (may contain NaNs). We'll permute the full array.\n",
    "        vals = master_df[weight_col].to_numpy()\n",
    "        if len(vals) > 0:\n",
    "            perm = rng.permutation(len(vals))\n",
    "            shuffled_vals = vals[perm]\n",
    "            master_df[weight_col] = shuffled_vals\n",
    "\n",
    "    # Save master dataframe to CSV\n",
    "    out_dir = f\"{output_data_path}/BLS{my_sector}_ONET{my_onet_level}/{dependent_var}/\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    master_out = f\"{out_dir}/BLS{my_sector}_ONET{my_onet_level}_taskExposureAIability_{weight_col}_{dependent_var}.csv\"\n",
    "    master_df.to_csv(master_out, index=False)\n",
    "\n",
    "\n",
    "    return master_df\n",
    "\n",
    "\n",
    "\n",
    "def plot_industry_count_distribution(my_sector, my_onet_level,\n",
    "                                     master_df, onet_occupation_code_var, onet_occupation_title_var):\n",
    "\n",
    "    # Count how many industries each occupation appears in\n",
    "    occupation_industry_counts = master_df.groupby([onet_occupation_code_var, onet_occupation_title_var])['NAICS'].nunique().reset_index()\n",
    "    occupation_industry_counts = occupation_industry_counts.rename(columns={'NAICS': 'num_industries'})\n",
    "    occupation_industry_counts = occupation_industry_counts.sort_values(by=['num_industries', onet_occupation_code_var], ascending=[False, True]).reset_index(drop=True)\n",
    "\n",
    "    # Plot histogram of number of industries per occupation\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(occupation_industry_counts['num_industries'], bins=range(1, occupation_industry_counts['num_industries'].max() + 2), align='left', color='skyblue', edgecolor='black')\n",
    "    plt.title('Distribution of Number of Industries per Occupation')\n",
    "    plt.xlabel('Number of Industries')\n",
    "    plt.ylabel('Number of Occupations')\n",
    "    plt.savefig(f'{output_plot_path}/BLS{my_sector}_ONET{my_onet_level}_countDist.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "# Regression and Plot different weighting schemes\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "import os\n",
    "\n",
    "def plot_weighted_regression_and_binned_scatter(my_sector, my_onet_level,\n",
    "                                                dependent_var, dependent_var_title, dependent_var_save_name_prefix,\n",
    "                                                master_df, weight_col,\n",
    "                                                plot_title_suffix, plot_save_name_prefix, q=20):\n",
    "\n",
    "    # ================================\n",
    "    # DATA PREP\n",
    "    # ================================\n",
    "    if 'NAICS' not in master_df.columns or master_df['NAICS'].isna().all():\n",
    "        master_df['NAICS'] = 'All_Industries'\n",
    "    df = master_df[[dependent_var, 'num_tasks', weight_col, 'NAICS']].copy()\n",
    "    df = df[df[dependent_var].notna() & df['num_tasks'].notna()].copy()\n",
    "\n",
    "    # Coerce numeric\n",
    "    df['num_tasks'] = pd.to_numeric(df['num_tasks'], errors='coerce')\n",
    "    df[dependent_var] = pd.to_numeric(df[dependent_var], errors='coerce')\n",
    "    df[weight_col] = pd.to_numeric(df[weight_col], errors='coerce')\n",
    "\n",
    "    # Drop rows with missing core vars\n",
    "    df = df.dropna(subset=['num_tasks', dependent_var, weight_col]).reset_index(drop=True)\n",
    "\n",
    "    # ================================\n",
    "    # REGRESSIONS (WLS + WLS with FE)\n",
    "    # ================================\n",
    "    model_wls = smf.wls(f'{dependent_var} ~ num_tasks', data=df, weights=df[weight_col]).fit(cov_type='HC3')\n",
    "    # print(model_wls.summary())\n",
    "\n",
    "    model_wls_fe = smf.wls(f'{dependent_var} ~ num_tasks + C(NAICS)', data=df, weights=df[weight_col]).fit(cov_type='HC3')\n",
    "    # print(model_wls_fe.summary())\n",
    "\n",
    "    # Save regression coefficient, std, and p-value for num_tasks for later inspection\n",
    "    try:\n",
    "        reg_out_dir = f\"{output_data_path}/regressions\"\n",
    "        os.makedirs(reg_out_dir, exist_ok=True)\n",
    "\n",
    "        rows = []\n",
    "        for mname, m in [('WLS', model_wls), ('WLS_FE', model_wls_fe)]:\n",
    "            if 'num_tasks' in m.params.index:\n",
    "                coef = float(m.params['num_tasks'])\n",
    "            else:\n",
    "                coef = float('nan')\n",
    "            try:\n",
    "                se = float(m.bse['num_tasks'])\n",
    "            except Exception:\n",
    "                se = float('nan')\n",
    "            try:\n",
    "                pval = float(m.pvalues['num_tasks'])\n",
    "            except Exception:\n",
    "                pval = float('nan')\n",
    "            try:\n",
    "                nobs = int(m.nobs)\n",
    "            except Exception:\n",
    "                nobs = len(df)\n",
    "\n",
    "            rows.append({\n",
    "                'BLS_sector_level': my_sector,\n",
    "                'ONET_level': my_onet_level,\n",
    "                'dependent_var': dependent_var,\n",
    "                'weight_col': weight_col,\n",
    "                'plot_prefix': plot_save_name_prefix,\n",
    "                'model': mname,\n",
    "                'coef_num_tasks': coef,\n",
    "                'std_err': se,\n",
    "                'pvalue': pval,\n",
    "                'n_obs': nobs\n",
    "            })\n",
    "\n",
    "        reg_df = pd.DataFrame(rows)\n",
    "        out_file = f\"{reg_out_dir}/reg_BLS{my_sector}_ONET{my_onet_level}_{plot_save_name_prefix}_{dependent_var}.csv\"\n",
    "        reg_df.to_csv(out_file, index=False)\n",
    "        # print(f\"Saved regression results to {out_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save regression results: {e}\")\n",
    "\n",
    "    # ================================\n",
    "    # BINNED SCATTER (weighted means within unweighted num_tasks bins)\n",
    "    # ================================\n",
    "    unique_vals = df['num_tasks'].nunique()\n",
    "    q_use = min(q, unique_vals) if unique_vals > 1 else 1\n",
    "\n",
    "    try:\n",
    "        bins = pd.qcut(df['num_tasks'], q=q_use, duplicates='drop')\n",
    "    except Exception:\n",
    "        bins = pd.cut(df['num_tasks'], bins=q_use)\n",
    "\n",
    "    def weighted_stats(g):\n",
    "        w = g[weight_col].to_numpy()\n",
    "        x = g['num_tasks'].to_numpy()\n",
    "        y = g[dependent_var].to_numpy()\n",
    "        sum_w = np.nansum(w)\n",
    "        x_wmean = np.average(x, weights=w) if sum_w > 0 else np.nan\n",
    "        y_wmean = np.average(y, weights=w) if sum_w > 0 else np.nan\n",
    "        return pd.Series({\n",
    "            'num_tasks_wmean': x_wmean,\n",
    "            f'{dependent_var}_wmean': y_wmean,\n",
    "            'sum_w': sum_w,\n",
    "            'n': len(g)\n",
    "        })\n",
    "\n",
    "    binned = df.groupby(bins, observed=True).apply(weighted_stats).reset_index(drop=True)\n",
    "\n",
    "    # # ================================\n",
    "    # # PLOT\n",
    "    # # ================================\n",
    "    # plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # # Bubble area scaling by summed weights\n",
    "    # s_min, s_max = 40, 900\n",
    "    # max_w = binned['sum_w'].max()\n",
    "    # if pd.notna(max_w) and max_w > 0:\n",
    "    #     sizes = s_min + (s_max - s_min) * (binned['sum_w'] / max_w)\n",
    "    # else:\n",
    "    #     sizes = np.full(len(binned), s_min)\n",
    "\n",
    "    # # Single color, no colorbar\n",
    "    # plt.scatter(\n",
    "    #     binned['num_tasks_wmean'], binned[f'{dependent_var}_wmean'],\n",
    "    #     s=sizes, c='steelblue', edgecolor='black', linewidth=0.8, alpha=0.9\n",
    "    # )\n",
    "\n",
    "    # plt.xlabel('Number of Tasks in Occupation')\n",
    "    # plt.ylabel(f'{dependent_var_title} in Occupation')\n",
    "    # if dependent_var == 'aiFraction':\n",
    "    #     plt.ylim(-0.02, 0.5)\n",
    "    # else:\n",
    "    #     plt.ylim(-0.02, 1.02)\n",
    "    # plt.title(f'Bin Scatter: {dependent_var_title} vs. Number of Tasks in Occupation\\n\\n({plot_title_suffix})')\n",
    "\n",
    "    # # ================================\n",
    "    # # OVERLAY WLS LINE + 95% CI\n",
    "    # # ================================\n",
    "    # x_line = np.linspace(df['num_tasks'].min(), df['num_tasks'].max(), 200)\n",
    "    # preds = model_wls.get_prediction(pd.DataFrame({'num_tasks': x_line}))\n",
    "    # pred_df = preds.summary_frame(alpha=0.05)\n",
    "\n",
    "    # slope_wls = float(model_wls.params['num_tasks'])\n",
    "    # plt.plot(x_line, pred_df['mean'], color='red', lw=2, label=f'WLS fit (slope={slope_wls:.4f})')\n",
    "    # plt.fill_between(x_line, pred_df['mean_ci_lower'], pred_df['mean_ci_upper'], color='red', alpha=0.18, label='95% CI')\n",
    "\n",
    "    # # ================================\n",
    "    # # OVERLAY FE LINE + 95% CI (average over NAICS categories)\n",
    "    # # ================================\n",
    "    # cats = pd.unique(df['NAICS'])\n",
    "    # mean_lines, low_lines, up_lines = [], [], []\n",
    "    # for g in cats:\n",
    "    #     Xg = pd.DataFrame({'num_tasks': x_line, 'NAICS': g})\n",
    "    #     if pd.api.types.is_categorical_dtype(df['NAICS']):\n",
    "    #         Xg['NAICS'] = pd.Categorical([g]*len(x_line), categories=df['NAICS'].cat.categories)\n",
    "    #     sf = model_wls_fe.get_prediction(Xg).summary_frame(alpha=0.05)\n",
    "    #     mean_lines.append(sf['mean'].to_numpy())\n",
    "    #     low_lines.append(sf['mean_ci_lower'].to_numpy())\n",
    "    #     up_lines.append(sf['mean_ci_upper'].to_numpy())\n",
    "\n",
    "    # mean_line = np.vstack(mean_lines).mean(axis=0)\n",
    "    # low_band  = np.vstack(low_lines).mean(axis=0)\n",
    "    # up_band   = np.vstack(up_lines).mean(axis=0)\n",
    "    # slope_fe = float(model_wls_fe.params['num_tasks'])\n",
    "\n",
    "    # plt.plot(x_line, mean_line, color='navy', lw=2, ls='--', label=f'FE fit (Avg over NAICS, slope={slope_fe:.4f})')\n",
    "    # plt.fill_between(x_line, low_band, up_band, color='navy', alpha=0.12)\n",
    "\n",
    "    # plt.grid(alpha=0.3)\n",
    "    # plt.legend(loc='upper right')\n",
    "\n",
    "    # ================================\n",
    "    # SAVE / SHOW\n",
    "    # ================================\n",
    "    # out_file = f\"{output_plot_path}/{plot_save_name_prefix}_BLS{my_sector}_ONET{my_onet_level}_aiFraction.png\"\n",
    "\n",
    "    # # Save in three different folders:\n",
    "    # out_file = f\"{output_plot_path_by_BLS_sector}/BLS{my_sector}_{plot_save_name_prefix}_ONET{my_onet_level}_{dependent_var_save_name_prefix}.png\"\n",
    "    # plt.savefig(out_file, bbox_inches='tight', dpi=300)\n",
    "    # out_file = f\"{output_plot_path_by_ONET_level}/ONET{my_onet_level}_{plot_save_name_prefix}_BLS{my_sector}_{dependent_var_save_name_prefix}.png\"\n",
    "    # plt.savefig(out_file, bbox_inches='tight', dpi=300)\n",
    "    # out_file = f\"{output_plot_path_by_weighting_scheme}/{plot_save_name_prefix}_BLS{my_sector}_ONET{my_onet_level}_{dependent_var_save_name_prefix}.png\"\n",
    "    # plt.savefig(out_file, bbox_inches='tight', dpi=300)\n",
    "    # out_file = f\"{output_plot_path_by_dependent_var}/{dependent_var_save_name_prefix}_{plot_save_name_prefix}_BLS{my_sector}_ONET{my_onet_level}.png\"\n",
    "    # plt.savefig(out_file, bbox_inches='tight', dpi=300)\n",
    "    # plt.close()\n",
    "\n",
    "\n",
    "\n",
    "def regress_exposure_on_AIability(my_sector, my_onet_level, \n",
    "                                  onet_occupation_code_var, onet_occupation_title_var,\n",
    "                                  weight_col):\n",
    "    # Read data\n",
    "    exposure_df = pd.read_csv(f'{output_data_path}/BLS{my_sector}_ONET{my_onet_level}/human_E1_fraction/BLS{my_sector}_ONET{my_onet_level}_taskExposureAIability_{weight_col}_human_E1_fraction.csv')\n",
    "    ai_ability_df = pd.read_csv(f'{output_data_path}/BLS{my_sector}_ONET{my_onet_level}/ai_fraction/BLS{my_sector}_ONET{my_onet_level}_taskExposureAIability_{weight_col}_ai_fraction.csv')\n",
    "\n",
    "    # Merge on occupation code and title\n",
    "    # print length before merge\n",
    "    # print(f\"Exposure data records: {len(exposure_df):,}, AI ability data records: {len(ai_ability_df):,}\")\n",
    "    merged_df = pd.merge(exposure_df, ai_ability_df,\n",
    "                             on=[onet_occupation_code_var, onet_occupation_title_var, 'num_tasks', weight_col],\n",
    "                             how='inner')\n",
    "    # print(f\"Merged exposure and AI ability data: {len(merged_df):,} records\")\n",
    "\n",
    "    # Save merged dataframe\n",
    "    merged_df.to_csv(f'{output_data_path}/BLS{my_sector}_ONET{my_onet_level}/BLS{my_sector}_ONET{my_onet_level}_exposure_vs_AIability.csv', index=False)\n",
    "\n",
    "    # Perform regression analysis\n",
    "    model = smf.wls(f'ai_fraction ~ human_E1_fraction + num_tasks', data=merged_df, weights=merged_df[weight_col]).fit(cov_type='HC3')\n",
    "    # print(model.summary())\n",
    "\n",
    "    # Save regression results\n",
    "    try:\n",
    "        reg_out_dir = f\"{output_data_path}/regression_BLS{my_sector}_ONET{my_onet_level}\"\n",
    "        os.makedirs(reg_out_dir, exist_ok=True)\n",
    "\n",
    "        rows = []\n",
    "        coef = float(model.params['human_E1_fraction']) if 'human_E1_fraction' in model.params.index else float('nan')\n",
    "        try:\n",
    "            se = float(model.bse['human_E1_fraction'])\n",
    "        except Exception:\n",
    "            se = float('nan')\n",
    "        try:\n",
    "            pval = float(model.pvalues['human_E1_fraction'])\n",
    "        except Exception:\n",
    "            pval = float('nan')\n",
    "        try:\n",
    "            nobs = int(model.nobs)\n",
    "        except Exception:\n",
    "            nobs = len(merged_df)\n",
    "\n",
    "        rows.append({\n",
    "            'BLS_sector_level': my_sector,\n",
    "            'ONET_level': my_onet_level,\n",
    "            'weight_col': weight_col,\n",
    "            'model': 'WLS_exposure_on_AIability',\n",
    "            'coef_human_E1_fraction': coef,\n",
    "            'std_err': se,\n",
    "            'pvalue': pval,\n",
    "            'n_obs': nobs\n",
    "        })\n",
    "        reg_df = pd.DataFrame(rows)\n",
    "        out_file = f\"{reg_out_dir}/reg_BLS{my_sector}_ONET{my_onet_level}_exposure_on_AIability_{weight_col}.csv\"\n",
    "        reg_df.to_csv(out_file, index=False)\n",
    "        # print(f\"Saved regression results to {out_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save regression results: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "180e3beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "my_sector, my_onet_level = ['sector', 'detailed']\n",
    "dependent_var_list = ['ai_fraction', 'human_E1_fraction']\n",
    "onet_occupation_code_var, onet_occupation_title_var = ['Detailed_Occupation_Code', 'Detailed_Occupation_Title']\n",
    "weight_col = 'occ_totalEmpShare'\n",
    "occupation_analysis = create_occupation_analysis(my_sector, my_onet_level, merged_data, onet_occupation_code_var, onet_occupation_title_var)\n",
    "\n",
    "weight_cols = ['occ_totalEmpShare',         # Weight each occupation by occupation's share of total employment (ignoring sector shares)\n",
    "               'sectorEmpShare',            # Weight each occupation by its sector's share of total employment\n",
    "               'occ_sectorEmpShare']        # Weight each occupation by its share of employment within its sector and weight sectors equally  \n",
    "\n",
    "# Merge industry employment share weights for all NAICS sectors and create a master dataset\n",
    "bls_sector_shares = pd.read_csv(f'{input_data_path}/computed_objects/BLS_ONET_empShares/bls_{my_sector}_ONET{my_onet_level}_empShares.csv')\n",
    "\n",
    "# Ensure NAICS is string for consistent merging\n",
    "bls_sector_shares['NAICS'] = bls_sector_shares['NAICS'].astype(str)\n",
    "\n",
    "\n",
    "# occupation_analysis_desired_columns = [onet_occupation_code_var, onet_occupation_title_var, 'num_tasks']\n",
    "# output_df = occupation_analysis[occupation_analysis_desired_columns].copy()\n",
    "output_df = occupation_analysis.copy()\n",
    "\n",
    "if 'occ_totalEmpShare' in weight_cols:\n",
    "    bls_occ_totalEmpShares = bls_sector_shares[['OCC_CODE', 'TOT_EMP']].groupby('OCC_CODE').sum().reset_index()\n",
    "\n",
    "    # Convert to % and change variable name\n",
    "    bls_occ_totalEmpShares['TOT_EMP'] = bls_occ_totalEmpShares['TOT_EMP'] / bls_occ_totalEmpShares['TOT_EMP'].sum()\n",
    "    bls_occ_totalEmpShares = bls_occ_totalEmpShares.rename(columns={'TOT_EMP': 'occ_totalEmpShare'})\n",
    "\n",
    "    # Add weight column to output_df\n",
    "    output_df = output_df.merge(bls_occ_totalEmpShares, left_on=onet_occupation_code_var, right_on=['OCC_CODE'], how='left')\n",
    "\n",
    "if 'sectorEmpShare' in weight_cols:\n",
    "    sector_weights_df = bls_sector_shares[['NAICS', 'NAICS_TITLE', 'TOT_EMP']].groupby(['NAICS', 'NAICS_TITLE']).sum('TOT_EMP')\n",
    "\n",
    "    # Convert to % and change variable name\n",
    "    sector_weights_df['TOT_EMP'] = sector_weights_df['TOT_EMP'] / sector_weights_df['TOT_EMP'].sum()\n",
    "    sector_weights_df = sector_weights_df.rename(columns={'TOT_EMP': 'sectorEmpShare'})\n",
    "\n",
    "    # Merge back sector weights to bls dataset to get sector-by-sector occupation data with sector weights\n",
    "    bls_sector_weights_df = bls_sector_shares[['NAICS', 'NAICS_TITLE', 'OCC_CODE', 'OCC_TITLE']].merge(sector_weights_df, on='NAICS', how='left')\n",
    "\n",
    "    \n",
    "    # Aggregate sector weights across occupations\n",
    "    bls_sector_weights_occupation_df = bls_sector_weights_df.groupby('OCC_CODE').sum('sectorEmpShare')\n",
    "\n",
    "    # Add weight column to output_df\n",
    "    output_df = output_df.merge(bls_sector_weights_occupation_df, left_on=onet_occupation_code_var, right_on=['OCC_CODE'], how='left')\n",
    "\n",
    "if 'occ_sectorEmpShare' in weight_cols:\n",
    "    within_sector_weights_df = bls_sector_shares[['NAICS', 'NAICS_TITLE', 'OCC_CODE', 'OCC_TITLE', 'TOT_EMP']].copy()\n",
    "    within_sector_weights_df['occ_sectorEmpShare'] = within_sector_weights_df['TOT_EMP'] / within_sector_weights_df.groupby(['NAICS', 'NAICS_TITLE'])['TOT_EMP'].transform('sum')\n",
    "\n",
    "    # Calculate sum over all sectors\n",
    "    within_sector_weights = within_sector_weights_df[['OCC_CODE', 'OCC_TITLE', 'occ_sectorEmpShare']].groupby(['OCC_CODE', 'OCC_TITLE']).sum()\n",
    "\n",
    "    # Add weight column to output_df\n",
    "    output_df = output_df.merge(within_sector_weights, left_on=onet_occupation_code_var, right_on=['OCC_CODE'], how='left')\n",
    "\n",
    "\n",
    "# Drop the 'OCC_CODE' column\n",
    "output_df = output_df.drop(columns='OCC_CODE')\n",
    "\n",
    "# Save master dataframe to CSV\n",
    "output_df.to_csv(f'{output_data_path}/BLS{my_sector}_ONET{my_onet_level}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da0340c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drop the supplemental tasks\n",
    "# merged_data = merged_data[merged_data['Task Type'] != 'Supplemental'].reset_index(drop=True)\n",
    "\n",
    "# # Drop rows whose Occupation Title includes 'Teachers, Postsecondary'\n",
    "# merged_data = merged_data[~merged_data['Occupation Title'].str.contains('Teachers, Postsecondary')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58762f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Detailed_Occupation_Code</th>\n",
       "      <th>Detailed_Occupation_Title</th>\n",
       "      <th>ai_fraction</th>\n",
       "      <th>num_tasks</th>\n",
       "      <th>occ_totalEmpShare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41-2031</td>\n",
       "      <td>Retail Salespersons</td>\n",
       "      <td>0.17</td>\n",
       "      <td>24</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35-3023</td>\n",
       "      <td>Fast Food and Counter Workers</td>\n",
       "      <td>0.04</td>\n",
       "      <td>47</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11-1021</td>\n",
       "      <td>General and Operations Managers</td>\n",
       "      <td>0.06</td>\n",
       "      <td>17</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41-2011</td>\n",
       "      <td>Cashiers</td>\n",
       "      <td>0.14</td>\n",
       "      <td>29</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29-1141</td>\n",
       "      <td>Registered Nurses</td>\n",
       "      <td>0.09</td>\n",
       "      <td>137</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Detailed_Occupation_Code        Detailed_Occupation_Title  ai_fraction  \\\n",
       "0                  41-2031              Retail Salespersons         0.17   \n",
       "1                  35-3023    Fast Food and Counter Workers         0.04   \n",
       "2                  11-1021  General and Operations Managers         0.06   \n",
       "3                  41-2011                         Cashiers         0.14   \n",
       "4                  29-1141                Registered Nurses         0.09   \n",
       "\n",
       "   num_tasks  occ_totalEmpShare  \n",
       "0         24               0.00  \n",
       "1         47               0.00  \n",
       "2         17               0.00  \n",
       "3         29               0.00  \n",
       "4        137               0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Detailed_Occupation_Code</th>\n",
       "      <th>Detailed_Occupation_Title</th>\n",
       "      <th>human_E1_fraction</th>\n",
       "      <th>num_tasks</th>\n",
       "      <th>occ_totalEmpShare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41-2031</td>\n",
       "      <td>Retail Salespersons</td>\n",
       "      <td>0.29</td>\n",
       "      <td>24</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35-3023</td>\n",
       "      <td>Fast Food and Counter Workers</td>\n",
       "      <td>0.06</td>\n",
       "      <td>47</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11-1021</td>\n",
       "      <td>General and Operations Managers</td>\n",
       "      <td>0.12</td>\n",
       "      <td>17</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41-2011</td>\n",
       "      <td>Cashiers</td>\n",
       "      <td>0.14</td>\n",
       "      <td>29</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29-1141</td>\n",
       "      <td>Registered Nurses</td>\n",
       "      <td>0.12</td>\n",
       "      <td>137</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Detailed_Occupation_Code        Detailed_Occupation_Title  \\\n",
       "0                  41-2031              Retail Salespersons   \n",
       "1                  35-3023    Fast Food and Counter Workers   \n",
       "2                  11-1021  General and Operations Managers   \n",
       "3                  41-2011                         Cashiers   \n",
       "4                  29-1141                Registered Nurses   \n",
       "\n",
       "   human_E1_fraction  num_tasks  occ_totalEmpShare  \n",
       "0               0.29         24               0.00  \n",
       "1               0.06         47               0.00  \n",
       "2               0.12         17               0.00  \n",
       "3               0.14         29               0.00  \n",
       "4               0.12        137               0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Detailed_Occupation_Code</th>\n",
       "      <th>Detailed_Occupation_Title</th>\n",
       "      <th>ai_fraction</th>\n",
       "      <th>num_tasks</th>\n",
       "      <th>sectorEmpShare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11-1011</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>0.27</td>\n",
       "      <td>49</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13-1141</td>\n",
       "      <td>Compensation, Benefits, and Job Analysis Speci...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>24</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15-1232</td>\n",
       "      <td>Computer User Support Specialists</td>\n",
       "      <td>0.44</td>\n",
       "      <td>16</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43-3061</td>\n",
       "      <td>Procurement Clerks</td>\n",
       "      <td>0.05</td>\n",
       "      <td>19</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43-4051</td>\n",
       "      <td>Customer Service Representatives</td>\n",
       "      <td>0.20</td>\n",
       "      <td>15</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Detailed_Occupation_Code                          Detailed_Occupation_Title  \\\n",
       "0                  11-1011                                   Chief Executives   \n",
       "1                  13-1141  Compensation, Benefits, and Job Analysis Speci...   \n",
       "2                  15-1232                  Computer User Support Specialists   \n",
       "3                  43-3061                                 Procurement Clerks   \n",
       "4                  43-4051                   Customer Service Representatives   \n",
       "\n",
       "   ai_fraction  num_tasks  sectorEmpShare  \n",
       "0         0.27         49            0.18  \n",
       "1         0.17         24            0.18  \n",
       "2         0.44         16            0.18  \n",
       "3         0.05         19            0.18  \n",
       "4         0.20         15            0.18  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Detailed_Occupation_Code</th>\n",
       "      <th>Detailed_Occupation_Title</th>\n",
       "      <th>human_E1_fraction</th>\n",
       "      <th>num_tasks</th>\n",
       "      <th>sectorEmpShare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11-1011</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>0.12</td>\n",
       "      <td>49</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13-1141</td>\n",
       "      <td>Compensation, Benefits, and Job Analysis Speci...</td>\n",
       "      <td>0.29</td>\n",
       "      <td>24</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15-1232</td>\n",
       "      <td>Computer User Support Specialists</td>\n",
       "      <td>0.44</td>\n",
       "      <td>16</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43-3061</td>\n",
       "      <td>Procurement Clerks</td>\n",
       "      <td>0.26</td>\n",
       "      <td>19</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43-4051</td>\n",
       "      <td>Customer Service Representatives</td>\n",
       "      <td>0.40</td>\n",
       "      <td>15</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Detailed_Occupation_Code                          Detailed_Occupation_Title  \\\n",
       "0                  11-1011                                   Chief Executives   \n",
       "1                  13-1141  Compensation, Benefits, and Job Analysis Speci...   \n",
       "2                  15-1232                  Computer User Support Specialists   \n",
       "3                  43-3061                                 Procurement Clerks   \n",
       "4                  43-4051                   Customer Service Representatives   \n",
       "\n",
       "   human_E1_fraction  num_tasks  sectorEmpShare  \n",
       "0               0.12         49            0.18  \n",
       "1               0.29         24            0.18  \n",
       "2               0.44         16            0.18  \n",
       "3               0.26         19            0.18  \n",
       "4               0.40         15            0.18  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Detailed_Occupation_Code</th>\n",
       "      <th>Detailed_Occupation_Title</th>\n",
       "      <th>ai_fraction</th>\n",
       "      <th>num_tasks</th>\n",
       "      <th>occ_sectorEmpShare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11-1021</td>\n",
       "      <td>General and Operations Managers</td>\n",
       "      <td>0.06</td>\n",
       "      <td>17</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45-2092</td>\n",
       "      <td>Farmworkers and Laborers, Crop, Nursery, and G...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>29</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43-4051</td>\n",
       "      <td>Customer Service Representatives</td>\n",
       "      <td>0.20</td>\n",
       "      <td>15</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53-7062</td>\n",
       "      <td>Laborers and Freight, Stock, and Material Move...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>39</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43-9061</td>\n",
       "      <td>Office Clerks, General</td>\n",
       "      <td>0.38</td>\n",
       "      <td>21</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Detailed_Occupation_Code                          Detailed_Occupation_Title  \\\n",
       "0                  11-1021                    General and Operations Managers   \n",
       "1                  45-2092  Farmworkers and Laborers, Crop, Nursery, and G...   \n",
       "2                  43-4051                   Customer Service Representatives   \n",
       "3                  53-7062  Laborers and Freight, Stock, and Material Move...   \n",
       "4                  43-9061                             Office Clerks, General   \n",
       "\n",
       "   ai_fraction  num_tasks  occ_sectorEmpShare  \n",
       "0         0.06         17                0.57  \n",
       "1         0.07         29                0.47  \n",
       "2         0.20         15                0.44  \n",
       "3         0.00         39                0.42  \n",
       "4         0.38         21                0.37  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Detailed_Occupation_Code</th>\n",
       "      <th>Detailed_Occupation_Title</th>\n",
       "      <th>human_E1_fraction</th>\n",
       "      <th>num_tasks</th>\n",
       "      <th>occ_sectorEmpShare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11-1021</td>\n",
       "      <td>General and Operations Managers</td>\n",
       "      <td>0.12</td>\n",
       "      <td>17</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45-2092</td>\n",
       "      <td>Farmworkers and Laborers, Crop, Nursery, and G...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43-4051</td>\n",
       "      <td>Customer Service Representatives</td>\n",
       "      <td>0.40</td>\n",
       "      <td>15</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53-7062</td>\n",
       "      <td>Laborers and Freight, Stock, and Material Move...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>39</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43-9061</td>\n",
       "      <td>Office Clerks, General</td>\n",
       "      <td>0.24</td>\n",
       "      <td>21</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Detailed_Occupation_Code                          Detailed_Occupation_Title  \\\n",
       "0                  11-1021                    General and Operations Managers   \n",
       "1                  45-2092  Farmworkers and Laborers, Crop, Nursery, and G...   \n",
       "2                  43-4051                   Customer Service Representatives   \n",
       "3                  53-7062  Laborers and Freight, Stock, and Material Move...   \n",
       "4                  43-9061                             Office Clerks, General   \n",
       "\n",
       "   human_E1_fraction  num_tasks  occ_sectorEmpShare  \n",
       "0               0.12         17                0.57  \n",
       "1               0.00         29                0.47  \n",
       "2               0.40         15                0.44  \n",
       "3               0.00         39                0.42  \n",
       "4               0.24         21                0.37  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Detailed_Occupation_Code</th>\n",
       "      <th>Detailed_Occupation_Title</th>\n",
       "      <th>ai_fraction</th>\n",
       "      <th>num_tasks</th>\n",
       "      <th>occ_totalEmpShare</th>\n",
       "      <th>sectorEmpShare</th>\n",
       "      <th>occ_sectorEmpShare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41-2031</td>\n",
       "      <td>Retail Salespersons</td>\n",
       "      <td>0.17</td>\n",
       "      <td>24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35-3023</td>\n",
       "      <td>Fast Food and Counter Workers</td>\n",
       "      <td>0.04</td>\n",
       "      <td>47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11-1021</td>\n",
       "      <td>General and Operations Managers</td>\n",
       "      <td>0.06</td>\n",
       "      <td>17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41-2011</td>\n",
       "      <td>Cashiers</td>\n",
       "      <td>0.14</td>\n",
       "      <td>29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29-1141</td>\n",
       "      <td>Registered Nurses</td>\n",
       "      <td>0.09</td>\n",
       "      <td>137</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>49-9045</td>\n",
       "      <td>Refractory Materials Repairers, Except Brickma...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>51-7031</td>\n",
       "      <td>Model Makers, Wood</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>13-1074</td>\n",
       "      <td>Farm Labor Contractors</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>51-2061</td>\n",
       "      <td>Timing Device Assemblers and Adjusters</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>51-7032</td>\n",
       "      <td>Patternmakers, Wood</td>\n",
       "      <td>0.10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>738 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Detailed_Occupation_Code  \\\n",
       "0                    41-2031   \n",
       "1                    35-3023   \n",
       "2                    11-1021   \n",
       "3                    41-2011   \n",
       "4                    29-1141   \n",
       "..                       ...   \n",
       "733                  49-9045   \n",
       "734                  51-7031   \n",
       "735                  13-1074   \n",
       "736                  51-2061   \n",
       "737                  51-7032   \n",
       "\n",
       "                             Detailed_Occupation_Title  ai_fraction  \\\n",
       "0                                  Retail Salespersons         0.17   \n",
       "1                        Fast Food and Counter Workers         0.04   \n",
       "2                      General and Operations Managers         0.06   \n",
       "3                                             Cashiers         0.14   \n",
       "4                                    Registered Nurses         0.09   \n",
       "..                                                 ...          ...   \n",
       "733  Refractory Materials Repairers, Except Brickma...         0.00   \n",
       "734                                 Model Makers, Wood         0.00   \n",
       "735                             Farm Labor Contractors         0.00   \n",
       "736             Timing Device Assemblers and Adjusters         0.00   \n",
       "737                                Patternmakers, Wood         0.10   \n",
       "\n",
       "     num_tasks  occ_totalEmpShare  sectorEmpShare  occ_sectorEmpShare  \n",
       "0           24               0.00            0.18                0.28  \n",
       "1           47               0.00            0.17                0.28  \n",
       "2           17               0.00            0.18                0.57  \n",
       "3           29               0.00            0.18                0.25  \n",
       "4          137               0.00            0.17                0.18  \n",
       "..         ...                ...             ...                 ...  \n",
       "733         16               0.00            0.02                0.00  \n",
       "734         14               0.00            0.04                0.00  \n",
       "735          8               0.00            0.00                0.00  \n",
       "736         17               0.00            0.02                0.00  \n",
       "737         20               0.00            0.02                0.00  \n",
       "\n",
       "[738 rows x 7 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bls_sector_levels = ['sector']#, '3-digit', '4-digit', '5-digit', '6-digit']\n",
    "\n",
    "onet_levels = ['major', 'minor', 'broad', 'detailed']\n",
    "onet_occupation_code_vars = ['Major_Group_Code', 'Minor_Group_Code', 'Broad_Occupation_Code', 'Detailed_Occupation_Code']\n",
    "onet_occupation_title_vars = ['Major_Group_Title', 'Minor_Group_Title', 'Broad_Occupation_Title', 'Detailed_Occupation_Title']\n",
    "\n",
    "weight_cols = ['occ_totalEmpShare',         # Weight each occupation by occupation's share of total employment (ignoring sector shares)\n",
    "               'sectorEmpShare',            # Weight each occupation by its sector's share of total employment\n",
    "               'occ_sectorEmpShare']        # Weight each occupation by its share of employment within its sector and weight sectors equally  \n",
    "plot_title_suffix_list = ['Weighted by Occupation Share of Total Employment',\n",
    "                          'Weighted by Sector Share of Total Employment',\n",
    "                          'Weighted by Occupation Employment Share of Sector']\n",
    "plot_save_name_prefix_list = ['occupationEmpShareWeights',\n",
    "                              'sectorEmpShareWeights',\n",
    "                              'occupationEmpShareWithinSectorWeights']\n",
    "\n",
    "dependent_var_list = ['ai_fraction', 'human_E1_fraction']#, 'human_aiExposure_fraction']#, 'gpt4_E1_fraction']\n",
    "dependent_var_title_list = ['Fraction of AI Tasks (Anthropic)', r'Fraction of Human $\\alpha$ Exposure (Eloundou et al.)']#, r'Fraction of Human \\gamma AI Exposure (Eloundou et al.)']#, r'Fraction of GPT-4 $\\alpha$ Exposure (Eloundou et al.)']\n",
    "dependent_var_save_name_prefix_list = ['aiFraction', 'humanAiExposureFraction']#, 'humanAiExposureFraction']#, 'gpt4AiExposureFraction']\n",
    "\n",
    "\n",
    "master_df_all_weights = pd.DataFrame()\n",
    "# Run the analysis for each BLS sector level and ONET occupation level\n",
    "for my_sector in bls_sector_levels:\n",
    "    for my_onet_level, onet_occupation_code_var, onet_occupation_title_var in zip(onet_levels, onet_occupation_code_vars, onet_occupation_title_vars):\n",
    "        if my_onet_level != 'detailed':\n",
    "                    continue\n",
    "        \n",
    "        # Get occupation data\n",
    "        occupation_analysis = create_occupation_analysis(my_sector, my_onet_level,\n",
    "                                                         merged_data, onet_occupation_code_var, onet_occupation_title_var)\n",
    "\n",
    "        # Regression and Plot different weighting schemes\n",
    "        for weight_col, plot_title_suffix, plot_save_name_prefix in zip(weight_cols, plot_title_suffix_list, plot_save_name_prefix_list):\n",
    "            # if (weight_col == 'ONE') or (weight_col == 'occ_sectorEmpShare'):\n",
    "            #     continue\n",
    "\n",
    "            for dependent_var, dependent_var_title, dependent_var_save_name_prefix in zip(dependent_var_list, dependent_var_title_list, dependent_var_save_name_prefix_list):\n",
    "                # Get master dataframe with industry employment shares merged to occupation analysis data\n",
    "                master_df = merge_industry_employment_shares(0,\n",
    "                                                            my_sector,\n",
    "                                                            my_onet_level, \n",
    "                                                            dependent_var,\n",
    "                                                            onet_occupation_code_var, onet_occupation_title_var,\n",
    "                                                            weight_col,\n",
    "                                                            occupation_analysis)\n",
    "\n",
    "                # # Plot industry occupation count\n",
    "                # plot_industry_count_distribution(my_sector, my_onet_level, \n",
    "                #                                 master_df, onet_occupation_code_var, onet_occupation_title_var)            \n",
    "\n",
    "                master_df_all_weights = pd.concat([master_df_all_weights, master_df], ignore_index=True)\n",
    "bls_sector_levels = ['sector']#, '3-digit', '4-digit', '5-digit', '6-digit']\n",
    "\n",
    "onet_levels = ['major', 'minor', 'broad', 'detailed']\n",
    "onet_occupation_code_vars = ['Major_Group_Code', 'Minor_Group_Code', 'Broad_Occupation_Code', 'Detailed_Occupation_Code']\n",
    "onet_occupation_title_vars = ['Major_Group_Title', 'Minor_Group_Title', 'Broad_Occupation_Title', 'Detailed_Occupation_Title']\n",
    "\n",
    "weight_cols = ['occ_totalEmpShare',         # Weight each occupation by occupation's share of total employment (ignoring sector shares)\n",
    "               'sectorEmpShare',            # Weight each occupation by its sector's share of total employment\n",
    "               'occ_sectorEmpShare']        # Weight each occupation by its share of employment within its sector and weight sectors equally  \n",
    "plot_title_suffix_list = ['Weighted by Occupation Share of Total Employment',\n",
    "                          'Weighted by Sector Share of Total Employment',\n",
    "                          'Weighted by Occupation Employment Share of Sector']\n",
    "plot_save_name_prefix_list = ['occupationEmpShareWeights',\n",
    "                              'sectorEmpShareWeights',\n",
    "                              'occupationEmpShareWithinSectorWeights']\n",
    "\n",
    "dependent_var_list = ['ai_fraction', 'human_E1_fraction']#, 'human_aiExposure_fraction']#, 'gpt4_E1_fraction']\n",
    "dependent_var_title_list = ['Fraction of AI Tasks (Anthropic)', r'Fraction of Human $\\alpha$ Exposure (Eloundou et al.)']#, r'Fraction of Human \\gamma AI Exposure (Eloundou et al.)']#, r'Fraction of GPT-4 $\\alpha$ Exposure (Eloundou et al.)']\n",
    "dependent_var_save_name_prefix_list = ['aiFraction', 'humanAiExposureFraction']#, 'humanAiExposureFraction']#, 'gpt4AiExposureFraction']\n",
    "\n",
    "weight_cols_numericCounter_list = [i for i in range(1, len(weight_cols) + 1)]\n",
    "\n",
    "master_df_all_weights = pd.DataFrame()\n",
    "# Run the analysis for each BLS sector level and ONET occupation level\n",
    "for my_sector in bls_sector_levels:\n",
    "    for my_onet_level, onet_occupation_code_var, onet_occupation_title_var in zip(onet_levels, onet_occupation_code_vars, onet_occupation_title_vars):\n",
    "        if my_onet_level != 'detailed':\n",
    "                    continue\n",
    "        \n",
    "        # Get occupation data\n",
    "        occupation_analysis = create_occupation_analysis(my_sector, my_onet_level,\n",
    "                                                         merged_data, onet_occupation_code_var, onet_occupation_title_var)\n",
    "\n",
    "        # Regression and Plot different weighting schemes\n",
    "        for weight_col, plot_title_suffix, plot_save_name_prefix, counter in zip(weight_cols, plot_title_suffix_list, plot_save_name_prefix_list, weight_cols_numericCounter_list):\n",
    "\n",
    "            for dependent_var, dependent_var_title, dependent_var_save_name_prefix in zip(dependent_var_list, dependent_var_title_list, dependent_var_save_name_prefix_list):\n",
    "                # Get master dataframe with industry employment shares merged to occupation analysis data\n",
    "                master_df = merge_industry_employment_shares(0,\n",
    "                                                            my_sector,\n",
    "                                                            my_onet_level, \n",
    "                                                            dependent_var,\n",
    "                                                            onet_occupation_code_var, onet_occupation_title_var,\n",
    "                                                            weight_col,\n",
    "                                                            occupation_analysis)\n",
    "                display(master_df.head())\n",
    "                \n",
    "                if len(master_df_all_weights) == 0:\n",
    "                    master_df_all_weights = master_df.copy()\n",
    "\n",
    "            if counter > 1:\n",
    "                master_df_all_weights = master_df_all_weights.merge(master_df[[onet_occupation_code_var, onet_occupation_title_var, weight_col]],\n",
    "                                                                    on=[onet_occupation_code_var, onet_occupation_title_var],\n",
    "                                                                    how='inner') \n",
    "\n",
    "                # # Plot industry occupation count\n",
    "                # plot_industry_count_distribution(my_sector, my_onet_level, \n",
    "                #                                 master_df, onet_occupation_code_var, onet_occupation_title_var)            \n",
    "\n",
    "\n",
    "master_df_all_weights\n",
    "# # Run the analysis for each BLS sector level and ONET occupation level\n",
    "# for my_sector in bls_sector_levels:\n",
    "#     for my_onet_level, onet_occupation_code_var, onet_occupation_title_var in zip(onet_levels, onet_occupation_code_vars, onet_occupation_title_vars):\n",
    "#         if my_onet_level != 'detailed':\n",
    "#                     continue\n",
    "        \n",
    "#         # Get occupation data\n",
    "#         occupation_analysis = create_occupation_analysis(my_sector, my_onet_level,\n",
    "#                                                          merged_data, onet_occupation_code_var, onet_occupation_title_var)\n",
    "\n",
    "#         # Regression and Plot different weighting schemes\n",
    "#         for weight_col, plot_title_suffix, plot_save_name_prefix in zip(weight_cols, plot_title_suffix_list, plot_save_name_prefix_list):\n",
    "#             # if (weight_col == 'ONE') or (weight_col == 'occ_sectorEmpShare'):\n",
    "#             #     continue\n",
    "\n",
    "#             for dependent_var, dependent_var_title, dependent_var_save_name_prefix in zip(dependent_var_list, dependent_var_title_list, dependent_var_save_name_prefix_list):\n",
    "#                 # Get master dataframe with industry employment shares merged to occupation analysis data\n",
    "#                 master_df = merge_industry_employment_shares(0,\n",
    "#                                                             my_sector,\n",
    "#                                                             my_onet_level, \n",
    "#                                                             dependent_var,\n",
    "#                                                             onet_occupation_code_var, onet_occupation_title_var,\n",
    "#                                                             weight_col,\n",
    "#                                                             occupation_analysis)\n",
    "\n",
    "#                 # # Plot industry occupation count\n",
    "#                 # plot_industry_count_distribution(my_sector, my_onet_level, \n",
    "#                 #                                 master_df, onet_occupation_code_var, onet_occupation_title_var)\n",
    "\n",
    "#                 plot_weighted_regression_and_binned_scatter(my_sector, my_onet_level, \n",
    "#                                                             dependent_var, dependent_var_title, dependent_var_save_name_prefix,\n",
    "#                                                             master_df, weight_col, \n",
    "#                                                             plot_title_suffix, plot_save_name_prefix)\n",
    "                \n",
    "#             regress_exposure_on_AIability(my_sector, my_onet_level,\n",
    "#                                             onet_occupation_code_var, onet_occupation_title_var,\n",
    "#                                             weight_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e795d8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bls_sector_levels = ['sector']#, '3-digit', '4-digit', '5-digit', '6-digit']\n",
    "\n",
    "onet_levels = ['major', 'minor', 'broad', 'detailed']\n",
    "onet_occupation_code_vars = ['Major_Group_Code', 'Minor_Group_Code', 'Broad_Occupation_Code', 'Detailed_Occupation_Code']\n",
    "onet_occupation_title_vars = ['Major_Group_Title', 'Minor_Group_Title', 'Broad_Occupation_Title', 'Detailed_Occupation_Title']\n",
    "\n",
    "weight_cols = ['occ_totalEmpShare',         # Weight each occupation by occupation's share of total employment (ignoring sector shares)\n",
    "               'sectorEmpShare',            # Weight each occupation by its sector's share of total employment\n",
    "               'occ_sectorEmpShare']        # Weight each occupation by its share of employment within its sector and weight sectors equally  \n",
    "plot_title_suffix_list = ['Weighted by Occupation Share of Total Employment',\n",
    "                          'Weighted by Sector Share of Total Employment',\n",
    "                          'Weighted by Occupation Employment Share of Sector']\n",
    "plot_save_name_prefix_list = ['occupationEmpShareWeights',\n",
    "                              'sectorEmpShareWeights',\n",
    "                              'occupationEmpShareWithinSectorWeights']\n",
    "\n",
    "dependent_var_list = ['ai_fraction', 'human_E1_fraction']#, 'human_aiExposure_fraction']#, 'gpt4_E1_fraction']\n",
    "dependent_var_title_list = ['Fraction of AI Tasks (Anthropic)', r'Fraction of Human $\\alpha$ Exposure (Eloundou et al.)']#, r'Fraction of Human \\gamma AI Exposure (Eloundou et al.)']#, r'Fraction of GPT-4 $\\alpha$ Exposure (Eloundou et al.)']\n",
    "dependent_var_save_name_prefix_list = ['aiFraction', 'humanAiExposureFraction']#, 'humanAiExposureFraction']#, 'gpt4AiExposureFraction']\n",
    "\n",
    "# Run the analysis for each BLS sector level and ONET occupation level\n",
    "for my_sector in bls_sector_levels:\n",
    "    for my_onet_level, onet_occupation_code_var, onet_occupation_title_var in zip(onet_levels, onet_occupation_code_vars, onet_occupation_title_vars):\n",
    "        if my_onet_level != 'detailed':\n",
    "                    continue\n",
    "        \n",
    "        # Get occupation data\n",
    "        occupation_analysis = create_occupation_analysis(my_sector, my_onet_level,\n",
    "                                                         merged_data, onet_occupation_code_var, onet_occupation_title_var)\n",
    "\n",
    "        # Regression and Plot different weighting schemes\n",
    "        for weight_col, plot_title_suffix, plot_save_name_prefix in zip(weight_cols, plot_title_suffix_list, plot_save_name_prefix_list):\n",
    "            # if (weight_col == 'ONE') or (weight_col == 'occ_sectorEmpShare'):\n",
    "            #     continue\n",
    "\n",
    "            for dependent_var, dependent_var_title, dependent_var_save_name_prefix in zip(dependent_var_list, dependent_var_title_list, dependent_var_save_name_prefix_list):\n",
    "                # Get master dataframe with industry employment shares merged to occupation analysis data\n",
    "                master_df = merge_industry_employment_shares(0,\n",
    "                                                            my_sector,\n",
    "                                                            my_onet_level, \n",
    "                                                            dependent_var,\n",
    "                                                            onet_occupation_code_var, onet_occupation_title_var,\n",
    "                                                            weight_col,\n",
    "                                                            occupation_analysis)\n",
    "\n",
    "                # # Plot industry occupation count\n",
    "                # plot_industry_count_distribution(my_sector, my_onet_level, \n",
    "                #                                 master_df, onet_occupation_code_var, onet_occupation_title_var)\n",
    "\n",
    "                plot_weighted_regression_and_binned_scatter(my_sector, my_onet_level, \n",
    "                                                            dependent_var, dependent_var_title, dependent_var_save_name_prefix,\n",
    "                                                            master_df, weight_col, \n",
    "                                                            plot_title_suffix, plot_save_name_prefix)\n",
    "                \n",
    "            regress_exposure_on_AIability(my_sector, my_onet_level,\n",
    "                                            onet_occupation_code_var, onet_occupation_title_var,\n",
    "                                            weight_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e7bd0878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined 6 regression files into ../data/computed_objects/BLS_ONET_matchedEmpShares/regressions/master_regressions.csv\n",
      "Combined 3 regression files into ../data/computed_objects/BLS_ONET_matchedEmpShares/regression_BLSsector_ONETdetailed/master_regressions.csv\n"
     ]
    }
   ],
   "source": [
    "# After the loops: combine all per-iteration regression outputs into a master file\n",
    "import os, glob\n",
    "paths_list = ['regressions', f'regression_BLS{my_sector}_ONET{my_onet_level}']\n",
    "for path in paths_list:\n",
    "    reg_out_dir = f'{output_data_path}/{path}'\n",
    "    os.makedirs(reg_out_dir, exist_ok=True)\n",
    "    reg_files = glob.glob(os.path.join(reg_out_dir, 'reg_BLS*.csv'))\n",
    "\n",
    "    combined = pd.concat([pd.read_csv(f) for f in reg_files], ignore_index=True)\n",
    "    combined = combined.sort_values(by=['model', 'BLS_sector_level', 'ONET_level', 'weight_col'], ascending=True).reset_index(drop=True)\n",
    "\n",
    "    combined = combined[(combined['model'] == 'WLS') | (combined['model'] == 'WLS_exposure_on_AIability')].reset_index(drop=True)\n",
    "    combined = combined.drop(columns=['model'])\n",
    "\n",
    "    try:\n",
    "        # Drop unimportant entries\n",
    "        combined = combined.drop(columns=['plot_prefix'])\n",
    "        combined = combined[combined['ONET_level'] != 'major']\n",
    "        # combined = combined[(combined['weight_col'] != 'ONE') & (combined['weight_col'] != 'occ_sectorEmpShare')].reset_index(drop=True)\n",
    "\n",
    "        # Sort order of entries\n",
    "        # Create mapping dicts\n",
    "        dependent_var_map = {'ai_fraction': 0, 'gpt4_E1_fraction': 2, 'human_E1_fraction': 1}\n",
    "        bls_map = {v: i for i, v in enumerate(bls_sector_levels)}\n",
    "        onet_map = {v: i for i, v in enumerate(onet_levels)}\n",
    "        weight_map = {v: i for i, v in enumerate(weight_cols)}\n",
    "\n",
    "        # Sort by all three with different mappings\n",
    "        combined = combined.sort_values(\n",
    "            by=[\"weight_col\", \"dependent_var\", \"BLS_sector_level\", \"ONET_level\"],\n",
    "            key=lambda col: (\n",
    "                col.map(dependent_var_map) if col.name == \"dependent_var\" else\n",
    "                col.map(weight_map) if col.name == \"weight_col\" else\n",
    "                col.map(bls_map) if col.name == \"BLS_sector_level\" else\n",
    "                col.map(onet_map)\n",
    "            )\n",
    "        ).reset_index(drop=True)\n",
    "\n",
    "        master_file = os.path.join(reg_out_dir, 'master_regressions.csv')\n",
    "        combined.to_csv(master_file, index=False)\n",
    "        print(f\"Combined {len(reg_files)} regression files into {master_file}\")\n",
    "    except Exception as e:\n",
    "        master_file = os.path.join(reg_out_dir, 'master_regressions.csv')\n",
    "        combined.to_csv(master_file, index=False)\n",
    "        print(f\"Combined {len(reg_files)} regression files into {master_file}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0404f0b",
   "metadata": {},
   "source": [
    "## Placebo Test: Reshuffle Task-Occupation Assignment and Repeat the Same Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b8854f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshuffle mode: preserve_unit_counts=True\n",
      "Running full observed (original) pipeline and saving outputs under seed_shuffles/seed_0 ...\n",
      "Saved observed master_regressions under seed_0 -> ../data/computed_objects/BLS_ONET_matchedEmpShares/seed_shuffles/seed_0/regressions/master_regressions.csv (9 rows)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seeds: 100%|██████████| 1000/1000 [00:07<00:00, 128.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found observed master file: ../data/computed_objects/BLS_ONET_matchedEmpShares/seed_shuffles/seed_0/regressions/master_regressions.csv (9 rows)\n",
      "Using coef column 'coef_num_tasks' and keys ['BLS_sector_level', 'ONET_level', 'dependent_var', 'weight_col'] to identify regressions.\n"
     ]
    }
   ],
   "source": [
    "# ---- Begin: 100-seed reshuffle + analysis ----\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# List of unit columns exactly as you specified\n",
    "unit_cols = [\n",
    "    \"O*NET-SOC Code\",\n",
    "    \"Occupation Title\",\n",
    "    \"Base_SOC_Code\",\n",
    "    \"Major_Group_Code\",\n",
    "    \"Major_Group_Title\",\n",
    "    \"Minor_Group_Code\",\n",
    "    \"Minor_Group_Title\",\n",
    "    \"Broad_Occupation_Code\",\n",
    "    \"Broad_Occupation_Title\",\n",
    "    \"Detailed_Occupation_Code\",\n",
    "    \"Detailed_Occupation_Title\"\n",
    "]\n",
    "\n",
    "def reshuffle_tasks_preserve_unit_counts(merged_df, seed, unit_cols):\n",
    "    \"\"\"\n",
    "    Shuffle task records across units while preserving each unit's number of tasks.\n",
    "    - unit_cols: list of columns that define a unit (will remain as unit identity).\n",
    "    - All other columns (including 'Task ID' and 'Task Title' and other task properties)\n",
    "      are considered task properties and move with the task to a new unit.\n",
    "    Returns a new reshuffled DataFrame with same columns and same number of rows.\n",
    "    \"\"\"\n",
    "    # Defensive copy\n",
    "    df = merged_df.copy()\n",
    "\n",
    "    # Determine task/property columns = all columns except unit columns\n",
    "    task_columns = [c for c in df.columns if c not in unit_cols]\n",
    "\n",
    "    # Compute unit-level counts (preserve order)\n",
    "    unit_counts = df.groupby(unit_cols, sort=False).size().reset_index(name='n_tasks')\n",
    "\n",
    "    # Extract the task pool (task properties only)\n",
    "    task_pool = df[task_columns].sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "    assigned_blocks = []\n",
    "    cursor = 0\n",
    "    for _, row in unit_counts.iterrows():\n",
    "        n = int(row['n_tasks'])\n",
    "        # slice of tasks to assign to this unit\n",
    "        tasks_slice = task_pool.iloc[cursor:cursor + n].copy().reset_index(drop=True)\n",
    "        cursor += n\n",
    "\n",
    "        # create a block with unit columns repeated for each assigned task\n",
    "        unit_block = pd.DataFrame([row[unit_cols].to_dict()] * n)\n",
    "        block = pd.concat([unit_block.reset_index(drop=True), tasks_slice.reset_index(drop=True)], axis=1)\n",
    "        assigned_blocks.append(block)\n",
    "\n",
    "    reshuffled = pd.concat(assigned_blocks, ignore_index=True)\n",
    "\n",
    "    # Keep original column order\n",
    "    reshuffled = reshuffled[df.columns]\n",
    "    return reshuffled\n",
    "\n",
    "\n",
    "def reshuffle_tasks_random_assignments(merged_df, seed, unit_cols):\n",
    "    \"\"\"\n",
    "    Randomly reassign tasks to units (occupations) without preserving the\n",
    "    original number of tasks per unit. This draws unit identities at random\n",
    "    (with replacement) for each task, so unit counts will vary across the\n",
    "    reshuffle.\n",
    "\n",
    "    - merged_df: DataFrame with task rows and unit-identifying columns in unit_cols\n",
    "    - seed: integer random seed\n",
    "    - unit_cols: list of columns that define a unit\n",
    "\n",
    "    Returns a DataFrame with the same columns as merged_df but unit columns\n",
    "    reassigned randomly.\n",
    "    \"\"\"\n",
    "    df = merged_df.copy()\n",
    "    rng = np.random.RandomState(seed)\n",
    "\n",
    "    # Build list of unique unit identity rows (dicts)\n",
    "    unit_id_rows = df[unit_cols].drop_duplicates().to_dict(orient='records')\n",
    "    n_units = len(unit_id_rows)\n",
    "    if n_units == 0:\n",
    "        # nothing to do\n",
    "        return df\n",
    "\n",
    "    # For each task row, sample a unit index (with replacement) so counts can vary\n",
    "    sampled_idxs = rng.randint(0, n_units, size=len(df))\n",
    "    sampled_units = [unit_id_rows[i] for i in sampled_idxs]\n",
    "    sampled_df = pd.DataFrame(sampled_units)\n",
    "\n",
    "    # Overwrite the unit columns in the copy\n",
    "    for col in unit_cols:\n",
    "        if col in sampled_df.columns:\n",
    "            df[col] = sampled_df[col].values\n",
    "\n",
    "    # Keep original column order\n",
    "    df = df[merged_df.columns]\n",
    "    return df\n",
    "\n",
    "# Where to save per-seed outputs (will create seed-specific subfolders under this)\n",
    "base_output_dir = output_data_path  # uses your notebook's variable by default\n",
    "seed_root = os.path.join(base_output_dir, \"seed_shuffles\")\n",
    "os.makedirs(seed_root, exist_ok=True)\n",
    "\n",
    "# Option: preserve the number of tasks per unit (occupation) or not.\n",
    "# Set to True to preserve counts (original behavior). Set to False to allow\n",
    "# arbitrary reassignment of tasks to units (unit counts will change).\n",
    "preserve_unit_counts = True  # <-- change this to False to use non-preserving reshuffle\n",
    "print(f\"Reshuffle mode: preserve_unit_counts={preserve_unit_counts}\")\n",
    "\n",
    "# ------------------ Run the full pipeline on the ORIGINAL (observed) dataset first and save under seed_0 ------------------\n",
    "print(\"Running full observed (original) pipeline and saving outputs under seed_shuffles/seed_0 ...\")\n",
    "seed0_output = os.path.join(seed_root, 'seed_0')\n",
    "os.makedirs(seed0_output, exist_ok=True)\n",
    "_saved_output_data_path = globals().get('output_data_path', None)\n",
    "globals()['output_data_path'] = seed0_output\n",
    "\n",
    "# Run the same loops used elsewhere in the notebook to produce observed regressions and plots\n",
    "for my_sector in bls_sector_levels:\n",
    "    for my_onet_level, onet_occupation_code_var, onet_occupation_title_var in zip(onet_levels, onet_occupation_code_vars, onet_occupation_title_vars):\n",
    "        if my_onet_level != 'detailed':\n",
    "            continue\n",
    "\n",
    "        occupation_analysis = create_occupation_analysis(my_sector, my_onet_level, merged_data, onet_occupation_code_var, onet_occupation_title_var)\n",
    "\n",
    "        for weight_col, plot_title_suffix, plot_save_name_prefix in zip(weight_cols, plot_title_suffix_list, plot_save_name_prefix_list):\n",
    "            for dependent_var, dependent_var_title, dependent_var_save_name_prefix in zip(dependent_var_list, dependent_var_title_list, dependent_var_save_name_prefix_list):\n",
    "                master_df = merge_industry_employment_shares(0, my_sector, my_onet_level, dependent_var, onet_occupation_code_var, onet_occupation_title_var, weight_col, occupation_analysis)\n",
    "                plot_weighted_regression_and_binned_scatter(my_sector, my_onet_level, dependent_var, dependent_var_title, dependent_var_save_name_prefix, master_df, weight_col, plot_title_suffix, plot_save_name_prefix)\n",
    "\n",
    "        # run exposure vs AIability regression per weight_col (once per sector/onet level)\n",
    "        for weight_col in weight_cols:\n",
    "            regress_exposure_on_AIability(my_sector, my_onet_level, onet_occupation_code_var, onet_occupation_title_var, weight_col)\n",
    "\n",
    "# Combine observed regression outputs generated under seed_0 into a master_regressions.csv inside seed_0/regressions\n",
    "reg_files_seed0 = glob.glob(os.path.join(seed0_output, '**', 'reg_BLS*.csv'), recursive=True)\n",
    "if len(reg_files_seed0) > 0:\n",
    "    combined_obs = pd.concat([pd.read_csv(f) for f in reg_files_seed0], ignore_index=True)\n",
    "    combined_obs = combined_obs.sort_values(by=['model', 'BLS_sector_level', 'ONET_level', 'weight_col'], ascending=True).reset_index(drop=True)\n",
    "    combined_obs = combined_obs[(combined_obs['model'] == 'WLS') | (combined_obs['model'] == 'WLS_exposure_on_AIability')].reset_index(drop=True)\n",
    "    if 'plot_prefix' in combined_obs.columns:\n",
    "        combined_obs = combined_obs.drop(columns=['plot_prefix'])\n",
    "    out_dir_obs = os.path.join(seed0_output, 'regressions')\n",
    "    os.makedirs(out_dir_obs, exist_ok=True)\n",
    "    master_file_obs = os.path.join(out_dir_obs, 'master_regressions.csv')\n",
    "    combined_obs.to_csv(master_file_obs, index=False)\n",
    "    print(f\"Saved observed master_regressions under seed_0 -> {master_file_obs} ({len(combined_obs)} rows)\")\n",
    "else:\n",
    "    print(\"Warning: No reg_BLS*.csv files found under seed_0 outputs to combine for the observed run.\")\n",
    "\n",
    "# restore original output_data_path if it existed (seed loop will override it per-seed later)\n",
    "if _saved_output_data_path is None:\n",
    "    globals().pop('output_data_path', None)\n",
    "else:\n",
    "    globals()['output_data_path'] = _saved_output_data_path\n",
    "# ------------------ End observed-to-seed0 pipeline ------------------\n",
    "\n",
    "# Now run reshuffles starting from seed 1\n",
    "n_seeds = 1000\n",
    "np.random.seed(42)  # for reproducibility of seed list\n",
    "seeds = list(range(1, n_seeds + 1))\n",
    "\n",
    "# Keep track of per-seed master_regressions file paths\n",
    "seed_master_files = []\n",
    "\n",
    "# Run the pipeline for each seed\n",
    "for seed in tqdm(seeds, desc=\"Seeds\"):\n",
    "    try:\n",
    "        reshuffled = merged_data.copy()\n",
    "        # # 1) Build reshuffled merged_data for this seed\n",
    "        # if preserve_unit_counts:\n",
    "        #     reshuffled = reshuffle_tasks_preserve_unit_counts(merged_data, seed=seed, unit_cols=unit_cols)\n",
    "        # else:\n",
    "        #     reshuffled = reshuffle_tasks_random_assignments(merged_data, seed=seed, unit_cols=unit_cols)\n",
    "\n",
    "        # 2) Temporarily redirect outputs to seed-specific folder so each seed's regressions don't collide\n",
    "        seed_output_data_path = os.path.join(seed_root, f\"seed_{seed}\")\n",
    "        if not os.path.exists(seed_output_data_path):\n",
    "            os.makedirs(seed_output_data_path, exist_ok=True)\n",
    "        else:\n",
    "            continue  # skip already-done seeds\n",
    "\n",
    "        # Save and restore original output_data_path after seed run\n",
    "        orig_output_data_path = globals().get('output_data_path', None)\n",
    "        globals()['output_data_path'] = seed_output_data_path\n",
    "\n",
    "        # 3) Run the same analysis you do in the notebook, but on `reshuffled`\n",
    "        #    We replicate the part of your main loop that creates occupation_analysis and then merges and runs regressions/plots.\n",
    "        #    Keep to the same ONET level(s) and sector levels you use in the notebook.\n",
    "        #    We'll follow the same loops you have. Adjust if you want fewer runs.\n",
    "        for my_sector in bls_sector_levels:\n",
    "            for my_onet_level, onet_occupation_code_var, onet_occupation_title_var in zip(onet_levels, onet_occupation_code_vars, onet_occupation_title_vars):\n",
    "                if my_onet_level != 'detailed':\n",
    "                    continue\n",
    "\n",
    "                # Use reshuffled for occupation analysis\n",
    "                occupation_analysis = create_occupation_analysis(my_sector, my_onet_level,\n",
    "                                                                 reshuffled, onet_occupation_code_var, onet_occupation_title_var)\n",
    "\n",
    "                for weight_col, plot_title_suffix, plot_save_name_prefix in zip(weight_cols, plot_title_suffix_list, plot_save_name_prefix_list):\n",
    "                    for dependent_var, dependent_var_title, dependent_var_save_name_prefix in zip(dependent_var_list, dependent_var_title_list, dependent_var_save_name_prefix_list):\n",
    "                        master_df = merge_industry_employment_shares(seed,\n",
    "                                                                     my_sector,\n",
    "                                                                    my_onet_level,\n",
    "                                                                    dependent_var,\n",
    "                                                                    onet_occupation_code_var, onet_occupation_title_var,\n",
    "                                                                    weight_col,\n",
    "                                                                    occupation_analysis)\n",
    "\n",
    "                        plot_weighted_regression_and_binned_scatter(my_sector, my_onet_level,\n",
    "                                                                   dependent_var, dependent_var_title, dependent_var_save_name_prefix,\n",
    "                                                                   master_df, weight_col,\n",
    "                                                                   plot_title_suffix, plot_save_name_prefix)\n",
    "                    # run exposure vs AIability regression per weight_col\n",
    "                    regress_exposure_on_AIability(my_sector, my_onet_level,\n",
    "                                                  onet_occupation_code_var, onet_occupation_title_var,\n",
    "                                                  weight_col)\n",
    "\n",
    "        # 4) After finishing seed runs, run the same combining code you have that creates master_regressions.csv\n",
    "        #    (Your notebook's combining code expects variables my_onet_level & my_sector from the last loop; to be safe, we'll recompute and call it similarly)\n",
    "        # We'll create combined master_regressions within the seed folder:\n",
    "        # reuse your combining logic but pointing at this seed's output folder\n",
    "        try:\n",
    "            # try to find all reg files under this seed output folder\n",
    "            reg_files = glob.glob(os.path.join(seed_output_data_path, '**', 'reg_BLS*.csv'), recursive=True)\n",
    "            if len(reg_files) == 0:\n",
    "                print(f\"[seed {seed}] No reg files found under {seed_output_data_path}; skipping combine.\")\n",
    "            else:\n",
    "                combined = pd.concat([pd.read_csv(f) for f in reg_files], ignore_index=True)\n",
    "                # Apply the same cleaning/sorting you do in the notebook\n",
    "                combined = combined.sort_values(by=['model', 'BLS_sector_level', 'ONET_level', 'weight_col'], ascending=True).reset_index(drop=True)\n",
    "                combined = combined[(combined['model'] == 'WLS') | (combined['model'] == 'WLS_exposure_on_AIability')].reset_index(drop=True)\n",
    "                # drop model and unneeded cols if present\n",
    "                if 'plot_prefix' in combined.columns:\n",
    "                    combined = combined.drop(columns=['plot_prefix'])\n",
    "                combined = combined[combined['ONET_level'] != 'major'] if 'ONET_level' in combined.columns else combined\n",
    "\n",
    "                out_dir = os.path.join(seed_output_data_path, 'regressions')\n",
    "                os.makedirs(out_dir, exist_ok=True)\n",
    "                master_file = os.path.join(out_dir, 'master_regressions.csv')\n",
    "                combined.to_csv(master_file, index=False)\n",
    "                seed_master_files.append(master_file)\n",
    "                if seed % 50 == 0:\n",
    "                    print(f\"[seed {seed}] Combined regressions -> {master_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[seed {seed}] Failed to combine regression files: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[seed {seed}] ERROR during seed processing: {e}\")\n",
    "    # finally:\n",
    "    #     # restore original output_data_path global\n",
    "    #     if orig_output_data_path is None:\n",
    "    #         globals().pop('output_data_path', None)\n",
    "    #     else:\n",
    "    #         globals()['output_data_path'] = orig_output_data_path\n",
    "\n",
    "# ---- Collect coefficients across seeds and plot histograms (one plot per regression id) ----\n",
    "\n",
    "# Prefer the seed_0 observed master file if it exists, otherwise look for any observed master not in seed_shuffles\n",
    "seed0_master = os.path.join(seed_root, 'seed_0', 'regressions', 'master_regressions.csv')\n",
    "if os.path.exists(seed0_master):\n",
    "    observed_master_file = seed0_master\n",
    "else:\n",
    "    observed_master_candidates = glob.glob(os.path.join(base_output_dir, '**', 'master_regressions.csv'), recursive=True)\n",
    "    # prefer one that is not in the seed_shuffles folder\n",
    "    observed_master_candidates = [p for p in observed_master_candidates if 'seed_shuffles' not in p]\n",
    "    observed_master_file = observed_master_candidates[0] if len(observed_master_candidates) > 0 else None\n",
    "\n",
    "if observed_master_file is None:\n",
    "    print(\"WARNING: Could not find an observed master_regressions.csv. Observed value will not be plotted.\")\n",
    "else:\n",
    "    observed_df = pd.read_csv(observed_master_file)\n",
    "    print(f\"Found observed master file: {observed_master_file} ({len(observed_df)} rows)\")\n",
    "\n",
    "# Load per-seed master files into a single DataFrame with 'seed' column\n",
    "seed_dfs = []\n",
    "for seed in seeds:\n",
    "    f = os.path.join(seed_root, f\"seed_{seed}\", \"regressions\", \"master_regressions.csv\")\n",
    "    if os.path.exists(f):\n",
    "        try:\n",
    "            d = pd.read_csv(f)\n",
    "            d['seed'] = seed\n",
    "            seed_dfs.append(d)\n",
    "        except Exception as e:\n",
    "            print(f\"[seed {seed}] failed to read {f}: {e}\")\n",
    "    else:\n",
    "        # don't spam if many missing - print only occasionally\n",
    "        print(f\"[seed {seed}] master_regressions.csv not found at expected path {f}\")\n",
    "\n",
    "if len(seed_dfs) == 0:\n",
    "    raise RuntimeError(\"No per-seed master_regressions found; aborting histogram plotting. Check that the seed runs produced regressions.\")\n",
    "\n",
    "all_seeds_df = pd.concat(seed_dfs, ignore_index=True)\n",
    "\n",
    "# Identify coefficient column (try the commonly used names first)\n",
    "# look in the per-seed combined DataFrame first, then observed if needed\n",
    "coef_col = None\n",
    "candidates = []\n",
    "if 'coef_num_tasks' in all_seeds_df.columns:\n",
    "    candidates.append('coef_num_tasks')\n",
    "if 'coef_human_E1_fraction' in all_seeds_df.columns:\n",
    "    candidates.append('coef_human_E1_fraction')\n",
    "if len(candidates) == 0:\n",
    "    candidates = [c for c in all_seeds_df.columns if str(c).startswith('coef')]\n",
    "if len(candidates) == 0 and 'observed_df' in locals():\n",
    "    # try observed file as a last resort\n",
    "    candidates = [c for c in observed_df.columns if str(c).startswith('coef')]\n",
    "if len(candidates) == 0:\n",
    "    raise RuntimeError(\"Could not find a coefficient column in per-seed master_regressions or observed master. Look for 'coef_num_tasks' or other 'coef_*' columns.\")\n",
    "coef_col = candidates[0]\n",
    "\n",
    "# Determine keys that uniquely identify a regression entry (use string names)\n",
    "candidate_keys = ['BLS_sector_level', 'ONET_level', 'dependent_var', 'weight_col']\n",
    "# prefer keys present in the per-seed dataframe\n",
    "key_cols = [c for c in candidate_keys if c in all_seeds_df.columns]\n",
    "# if observed exists and provides a better set of keys, prefer intersection that is present in both\n",
    "if 'observed_df' in locals():\n",
    "    obs_keys = [c for c in candidate_keys if c in observed_df.columns]\n",
    "    if len(obs_keys) > 0:\n",
    "        inter = [c for c in candidate_keys if c in obs_keys and c in all_seeds_df.columns]\n",
    "        if len(inter) > 0:\n",
    "            key_cols = inter\n",
    "# final fallback: keep any sensible keys present in all_seeds_df\n",
    "if len(key_cols) == 0:\n",
    "    key_cols = [c for c in ['dependent_var', 'weight_col'] if c in all_seeds_df.columns]\n",
    "\n",
    "print(f\"Using coef column '{coef_col}' and keys {key_cols} to identify regressions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "643c079e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved histogram for BLS_sector_level-sector__ONET_level-detailed__dependent_var-human_E1_fraction__weight_col-occ_sectorEmpShare -> ../data/computed_objects/BLS_ONET_matchedEmpShares/shuffle_histograms/hist_BLS_sector_level-sector__ONET_level-detailed__dependent_var-human_E1_fraction__weight_col-occ_sectorEmpShare.png\n",
      "Saved histogram for BLS_sector_level-sector__ONET_level-detailed__dependent_var-ai_fraction__weight_col-occ_sectorEmpShare -> ../data/computed_objects/BLS_ONET_matchedEmpShares/shuffle_histograms/hist_BLS_sector_level-sector__ONET_level-detailed__dependent_var-ai_fraction__weight_col-occ_sectorEmpShare.png\n",
      "Saved histogram for BLS_sector_level-sector__ONET_level-detailed__dependent_var-ai_fraction__weight_col-occ_totalEmpShare -> ../data/computed_objects/BLS_ONET_matchedEmpShares/shuffle_histograms/hist_BLS_sector_level-sector__ONET_level-detailed__dependent_var-ai_fraction__weight_col-occ_totalEmpShare.png\n",
      "Saved histogram for BLS_sector_level-sector__ONET_level-detailed__dependent_var-human_E1_fraction__weight_col-occ_totalEmpShare -> ../data/computed_objects/BLS_ONET_matchedEmpShares/shuffle_histograms/hist_BLS_sector_level-sector__ONET_level-detailed__dependent_var-human_E1_fraction__weight_col-occ_totalEmpShare.png\n",
      "Saved histogram for BLS_sector_level-sector__ONET_level-detailed__dependent_var-human_E1_fraction__weight_col-sectorEmpShare -> ../data/computed_objects/BLS_ONET_matchedEmpShares/shuffle_histograms/hist_BLS_sector_level-sector__ONET_level-detailed__dependent_var-human_E1_fraction__weight_col-sectorEmpShare.png\n",
      "Saved histogram for BLS_sector_level-sector__ONET_level-detailed__dependent_var-ai_fraction__weight_col-sectorEmpShare -> ../data/computed_objects/BLS_ONET_matchedEmpShares/shuffle_histograms/hist_BLS_sector_level-sector__ONET_level-detailed__dependent_var-ai_fraction__weight_col-sectorEmpShare.png\n",
      "Skipping BLS_sector_level-sector__ONET_level-detailed__dependent_var-nan__weight_col-occ_sectorEmpShare: no coef values found across seeds.\n",
      "Skipping BLS_sector_level-sector__ONET_level-detailed__dependent_var-nan__weight_col-occ_totalEmpShare: no coef values found across seeds.\n",
      "Skipping BLS_sector_level-sector__ONET_level-detailed__dependent_var-nan__weight_col-sectorEmpShare: no coef values found across seeds.\n",
      "Done: created 6 histogram(s). Per-seed master_regressions (if produced) were stored under:\n",
      "  ../data/computed_objects/BLS_ONET_matchedEmpShares/seed_shuffles\n",
      "Histograms saved under:\n",
      "  ../data/computed_objects/BLS_ONET_matchedEmpShares/shuffle_histograms\n"
     ]
    }
   ],
   "source": [
    "# Prepare output dir for combined histograms\n",
    "hist_out_dir = os.path.join(base_output_dir, \"shuffle_histograms\")\n",
    "os.makedirs(hist_out_dir, exist_ok=True)\n",
    "\n",
    "# Prefer regressions present in observed master if available, otherwise use union across seeds\n",
    "if len(key_cols) == 0:\n",
    "    # No clear keys available: fall back to plotting one histogram aggregating all seed coefficients\n",
    "    unique_keys_df = pd.DataFrame([{}])\n",
    "else:\n",
    "    if 'observed_df' in locals():\n",
    "        # Use observed regressions if possible (safer to plot what was actually run)\n",
    "        obs_keys_present = [c for c in key_cols if c in observed_df.columns]\n",
    "        if len(obs_keys_present) == len(key_cols):\n",
    "            unique_keys_df = observed_df[key_cols].drop_duplicates().reset_index(drop=True)\n",
    "        else:\n",
    "            # observed missing some key columns: fall back to union across seeds\n",
    "            unique_keys_df = all_seeds_df[key_cols].drop_duplicates().reset_index(drop=True)\n",
    "    else:\n",
    "        unique_keys_df = all_seeds_df[key_cols].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "plots_created = 0\n",
    "for idx, key_row in unique_keys_df.iterrows():\n",
    "    # build boolean mask across all seeds; if no key_cols, this stays all True\n",
    "    mask = np.ones(len(all_seeds_df), dtype=bool)\n",
    "    label_parts = []\n",
    "    for col in key_cols:\n",
    "        # key_row may be an empty dict when key_cols == []\n",
    "        val = key_row[col]\n",
    "        mask &= (all_seeds_df[col] == val)\n",
    "        label_parts.append(f\"{val}\")\n",
    "\n",
    "    if len(key_cols) == 0:\n",
    "        regression_id = \"all_regressions\"\n",
    "    else:\n",
    "        regression_id = \"__\".join([f\"{col}-{str(key_row[col])}\" for col in key_cols])\n",
    "\n",
    "    coef_vals = all_seeds_df.loc[mask, coef_col].dropna().astype(float).values\n",
    "\n",
    "    if coef_vals.size == 0:\n",
    "        print(f\"Skipping {regression_id}: no coef values found across seeds.\")\n",
    "        continue\n",
    "\n",
    "    # Plot single histogram that aggregates coefficients from all seeds for this regression\n",
    "    plt.figure(figsize=(9, 5))\n",
    "    plt.hist(coef_vals, bins=min(30, max(5, int(len(coef_vals) / 2))), color='orange', edgecolor='k', alpha=0.9)\n",
    "    plt.xlabel(coef_col)\n",
    "    plt.ylabel('Count')\n",
    "    title = f\"{len(coef_vals)} Reshuffles: {' | '.join(label_parts) if len(label_parts)>0 else 'all'}\\n\\n(Randomized Weights, Fixed Task Assignment)\"\n",
    "    plt.title(title)\n",
    "\n",
    "    # If observed data exists, overlay the observed coefficient as a dashed red line\n",
    "    if 'observed_df' in locals():\n",
    "        # if we have key_cols, try to match observed rows; otherwise use any observed coef available\n",
    "        if len(key_cols) > 0:\n",
    "            mask_obs = np.ones(len(observed_df), dtype=bool)\n",
    "            for col in key_cols:\n",
    "                if col in observed_df.columns:\n",
    "                    mask_obs &= (observed_df[col] == key_row[col])\n",
    "                else:\n",
    "                    # cannot match on this key in observed; set mask_obs all False to skip\n",
    "                    mask_obs &= False\n",
    "            obs_series = observed_df.loc[mask_obs, coef_col].dropna().astype(float) if mask_obs.any() else pd.Series(dtype=float)\n",
    "        else:\n",
    "            obs_series = observed_df[coef_col].dropna().astype(float) if coef_col in observed_df.columns else pd.Series(dtype=float)\n",
    "\n",
    "        if len(obs_series) > 0:\n",
    "            obs_val = float(obs_series.iloc[0])\n",
    "            plt.axvline(obs_val, color='red', linestyle='--', lw=2, label='Observed')\n",
    "            plt.axvline(0, color='black', linestyle='--', lw=1.5)\n",
    "            # annotate percentile: how many seeds are below the observed value\n",
    "            percentile = (coef_vals < obs_val).mean() * 100.0\n",
    "            plt.legend(loc = 'upper right', title=f'Observed (pct below: {percentile:.1f}% )')\n",
    "            plt.xlim(-0.004, 0.004)\n",
    "\n",
    "    out_file = os.path.join(hist_out_dir, f\"hist_{regression_id}.png\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_file, dpi=300)\n",
    "    plt.close()\n",
    "    plots_created += 1\n",
    "    print(f\"Saved histogram for {regression_id} -> {out_file}\")\n",
    "\n",
    "print(f\"Done: created {plots_created} histogram(s). Per-seed master_regressions (if produced) were stored under:\\n  {seed_root}\")\n",
    "print(f\"Histograms saved under:\\n  {hist_out_dir}\")\n",
    "\n",
    "# ---- End cell ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b47f486",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
