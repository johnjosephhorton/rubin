{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc7fc397",
   "metadata": {},
   "source": [
    "#### By: Peyman Shahidi\n",
    "#### Created: Oct 10, 2025\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10366af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python\n",
    "import getpass\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "import random \n",
    "\n",
    "## formatting number to appear comma separated and with two digits after decimal: e.g, 1000 shown as 1,000.00\n",
    "pd.set_option('float_format', \"{:,.2f}\".format)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "#from matplotlib.legend import Legend\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "519e43cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder_path = \"..\"\n",
    "input_data_path = f\"{main_folder_path}/data\"\n",
    "output_data_path = f'{input_data_path}/computed_objects'\n",
    "output_plot_path = f\"{main_folder_path}/writeup/plots\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84e6e6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories if they don't exist\n",
    "import os\n",
    "\n",
    "for path in [output_data_path, output_plot_path]:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be56448",
   "metadata": {},
   "source": [
    "### O*NET Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "857f1b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all datasets\n",
    "task_ratings_df = pd.read_csv(f'{input_data_path}/db_27_3_text/Task Ratings.txt', sep='\\t')\n",
    "task_categories_df = pd.read_csv(f'{input_data_path}/db_27_3_text/Task Categories.txt', sep='\\t')\n",
    "tasks_to_dwas_df = pd.read_csv(f'{input_data_path}/db_27_3_text/Tasks to DWAs.txt', sep='\\t')\n",
    "dwa_reference_df = pd.read_csv(f'{input_data_path}/db_27_3_text/DWA Reference.txt', sep='\\t')\n",
    "job_zones_df = pd.read_csv(f'{input_data_path}/db_27_3_text/Job Zones.txt', sep='\\t')\n",
    "task_statements_df = pd.read_csv(f'{input_data_path}/db_27_3_text/Task Statements.txt', sep='\\t')\n",
    "occupation_data_df = pd.read_csv(f'{input_data_path}/db_27_3_text/Occupation Data.txt', sep='\\t')\n",
    "soc_structure_df = pd.read_csv(f'{input_data_path}/SOC_Structure.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4c8ebdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge and transform O*NET task data\n",
    "ONET = task_ratings_df.merge(task_categories_df, on=['Scale ID', 'Category'], how='left')\n",
    "\n",
    "# Process Category Description\n",
    "ONET['Category Description'] = ONET['Category Description'].apply(lambda x: f'FT_{x}' if pd.notna(x) else x)\n",
    "ONET['Category Description'] = ONET['Category Description'].fillna(ONET['Scale ID'])\n",
    "ONET['Category Description'] = ONET['Category Description'].replace({'IM': 'Importance', 'RT': 'Relevance'})\n",
    "\n",
    "# Reshape from long to wide format\n",
    "ONET = ONET.pivot_table(\n",
    "    index=['O*NET-SOC Code', 'Task ID'],\n",
    "    columns='Category Description',\n",
    "    values='Data Value',\n",
    "    aggfunc='first'\n",
    ").reset_index()\n",
    "ONET.columns.name = None\n",
    "\n",
    "# Merge additional data\n",
    "ONET = ONET.merge(occupation_data_df[['O*NET-SOC Code', 'Title']], on='O*NET-SOC Code', how='left')\n",
    "ONET.rename(columns={'Title': 'Occupation Title'}, inplace=True)\n",
    "\n",
    "ONET = ONET.merge(task_statements_df[['O*NET-SOC Code', 'Task ID', 'Task', 'Task Type']], on=['O*NET-SOC Code', 'Task ID'], how='left')\n",
    "ONET.rename(columns={'Task': 'Task Title'}, inplace=True)\n",
    "\n",
    "ONET = ONET.merge(tasks_to_dwas_df[['O*NET-SOC Code', 'Task ID', 'DWA ID']], on=['O*NET-SOC Code', 'Task ID'], how='left')\n",
    "ONET = ONET.merge(dwa_reference_df[['DWA ID', 'DWA Title']], on='DWA ID', how='left')\n",
    "ONET = ONET.merge(job_zones_df[['O*NET-SOC Code', 'Job Zone']], on='O*NET-SOC Code', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d947ef",
   "metadata": {},
   "source": [
    "### Filter Occupations Containing \"All Other\" and \"Teachers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71645324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before removing 'All Other': 22,310\n",
      "Number of rows after removing 'All Other': 22,310\n"
     ]
    }
   ],
   "source": [
    "# Remove rows where occupation title contains \"All Other\"\n",
    "print(f\"Number of rows before removing 'All Other': {ONET.shape[0]:,}\")\n",
    "ONET = ONET[~ONET[\"Occupation Title\"].str.contains(\"All Other\", case=False, na=False)]\n",
    "print(f\"Number of rows after removing 'All Other': {ONET.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a28e5059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Filter and remove \"Teachers\"-related occupations\n",
    "# contains_teacher = ONET[ONET['Occupation Title'].str.contains('Teachers', case=False, na=False)]\n",
    "\n",
    "# unique_teacher_occupations = contains_teacher['Occupation Title'].nunique()\n",
    "# print(f'Number of unique occupations containing the word \"Teachers\": {unique_teacher_occupations}')\n",
    "\n",
    "# # Remove rows that contain \"Teacher\" (case-insensitive)\n",
    "# ONET = ONET[~ONET['Occupation Title'].str.contains('Teachers', case=False, na=False)].reset_index(drop=True)\n",
    "# print(f\"Rows after removing Teachers: {len(ONET):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae99494",
   "metadata": {},
   "source": [
    "### SOC Industry Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c842646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SOC Code-to-Label mapping\n",
    "code_label_rows = []\n",
    "for idx, row in soc_structure_df.iterrows():\n",
    "    if pd.notna(row['Major Group']):\n",
    "        code = row['Major Group']\n",
    "    elif pd.notna(row['Minor Group']):\n",
    "        code = row['Minor Group']\n",
    "    elif pd.notna(row['Broad Occupation']):\n",
    "        code = row['Broad Occupation']\n",
    "    elif pd.notna(row['Detailed Occupation']):\n",
    "        code = row['Detailed Occupation']\n",
    "    elif pd.notna(row['Detailed O*NET-SOC']):\n",
    "        code = row['Detailed O*NET-SOC']\n",
    "    else:\n",
    "        continue\n",
    "    code_label_rows.append({'Code': code, 'Label': row['SOC or O*NET-SOC 2019 Title']})\n",
    "\n",
    "soc_code_label = pd.DataFrame(code_label_rows)\n",
    "soc_code_label.to_csv(f'{output_data_path}/SOC_Code_Label_Mapping.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c480f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create industry codes at different hierarchy levels\n",
    "ONET['SOC_Code_7digit'] = ONET['O*NET-SOC Code'].str.split('.').str[0]\n",
    "\n",
    "industry_levels = {\n",
    "    2: 'Major_Group',\n",
    "    5: 'Minor_Group', \n",
    "    6: 'Broad_Occupation',\n",
    "    7: 'Detailed_Occupation'\n",
    "}\n",
    "\n",
    "for num_digits, level_name in industry_levels.items():\n",
    "    if num_digits == 2:\n",
    "        ONET[f'{level_name}_Code'] = ONET['SOC_Code_7digit'].str[:2] + '-0000'\n",
    "    elif num_digits == 5:\n",
    "        ONET[f'{level_name}_Code'] = ONET['SOC_Code_7digit'].str[:5] + '00'\n",
    "    elif num_digits == 6:\n",
    "        ONET[f'{level_name}_Code'] = ONET['SOC_Code_7digit'].str[:6] + '0'\n",
    "    else:\n",
    "        ONET[f'{level_name}_Code'] = ONET['SOC_Code_7digit']\n",
    "\n",
    "# Drop SOC_Code_7digit from columns\n",
    "ONET = ONET.drop(columns=['SOC_Code_7digit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3e69f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hierarchical Task Counts Summary:\n",
      "  Total rows: 2,179\n",
      "\n",
      "Breakdown by aggregation level:\n",
      "  Major Group: 22\n",
      "  Minor Group: 95\n",
      "  Broad Occupation: 430\n",
      "  Detailed Occupation: 759\n",
      "  Occupation: 873\n"
     ]
    }
   ],
   "source": [
    "# Add title labels for each industry level\n",
    "for num_digits, level_name in industry_levels.items():\n",
    "    code_col = f'{level_name}_Code'\n",
    "    label_col = f'{level_name}_Title'\n",
    "    ONET = ONET.merge(\n",
    "        soc_code_label.rename(columns={'Code': code_col, 'Label': label_col}),\n",
    "        on=code_col,\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "\n",
    "# Aggregate unique task and DWA counts at each hierarchical level\n",
    "def aggregate_by_level(df, code_col, title_col, level_name):\n",
    "    \"\"\"\n",
    "    Aggregate unique task and DWA counts for a given hierarchical level.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame to aggregate\n",
    "    - code_col: Column name for the code/ID\n",
    "    - title_col: Column name for the title/description\n",
    "    - level_name: Name of the hierarchical level (e.g., 'Major Group')\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with columns: Level, Code, Title, num_unique_tasks, num_unique_dwas\n",
    "    \"\"\"\n",
    "    agg = (\n",
    "        df.groupby([code_col, title_col])\n",
    "        .agg(\n",
    "            num_unique_tasks=('Task ID', 'nunique'),\n",
    "            num_unique_dwas=('DWA ID', 'nunique') if 'DWA ID' in df.columns else ('Task ID', lambda x: 0)\n",
    "        )\n",
    "        .reset_index()\n",
    "        .rename(columns={code_col: 'Code', title_col: 'Title'})\n",
    "    )\n",
    "    agg['Level'] = level_name\n",
    "    return agg[['Level', 'Code', 'Title', 'num_unique_tasks', 'num_unique_dwas']]\n",
    "\n",
    "\n",
    "# Create aggregations for each hierarchical level\n",
    "major_group_agg = aggregate_by_level(ONET, 'Major_Group_Code', 'Major_Group_Title', 'Major Group')\n",
    "minor_group_agg = aggregate_by_level(ONET, 'Minor_Group_Code', 'Minor_Group_Title', 'Minor Group')\n",
    "broad_occ_agg = aggregate_by_level(ONET, 'Broad_Occupation_Code', 'Broad_Occupation_Title', 'Broad Occupation')\n",
    "detailed_occ_agg = aggregate_by_level(ONET, 'Detailed_Occupation_Code', 'Detailed_Occupation_Title', 'Detailed Occupation')\n",
    "occupation_agg = aggregate_by_level(ONET, 'O*NET-SOC Code', 'Occupation Title', 'Occupation')\n",
    "\n",
    "# Combine all levels into one dataset\n",
    "hierarchical_task_counts = pd.concat([\n",
    "    major_group_agg,\n",
    "    minor_group_agg,\n",
    "    broad_occ_agg,\n",
    "    detailed_occ_agg,\n",
    "    occupation_agg\n",
    "], ignore_index=True)\n",
    "\n",
    "# Save the combined dataset\n",
    "hierarchical_task_counts.to_csv(f'{output_data_path}/hierarchical_task_counts.csv', index=False)\n",
    "\n",
    "print(f\"\\nHierarchical Task Counts Summary:\")\n",
    "print(f\"  Total rows: {len(hierarchical_task_counts):,}\")\n",
    "print(f\"\\nBreakdown by aggregation level:\")\n",
    "for level in ['Major Group', 'Minor Group', 'Broad Occupation', 'Detailed Occupation', 'Occupation']:\n",
    "    count = len(hierarchical_task_counts[hierarchical_task_counts['Level'] == level])\n",
    "    print(f\"  {level}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdacd3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows (with DWA ID & Title): 0\n",
      "Number of duplicate rows (without DWA ID & Title): 4357\n",
      "Number of tasks matched to multiple DWAs: 3780\n",
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates with DWA ID and DWA Title\n",
    "dup_cols_full = ['O*NET-SOC Code', 'Task ID', 'Task Type', 'DWA ID', 'DWA Title']\n",
    "num_duplicates_full = ONET.duplicated(subset=dup_cols_full).sum()\n",
    "print(f\"Number of duplicate rows (with DWA ID & Title): {num_duplicates_full}\")\n",
    "\n",
    "# Check for duplicates without DWA ID and DWA Title\n",
    "dup_cols_task = ['O*NET-SOC Code', 'Task ID', 'Task Type']\n",
    "num_duplicates_task = ONET.duplicated(subset=dup_cols_task).sum()\n",
    "print(f\"Number of duplicate rows (without DWA ID & Title): {num_duplicates_task}\")\n",
    "\n",
    "# Show how many tasks are matched to multiple DWAs\n",
    "task_counts = ONET.groupby(dup_cols_task)['DWA ID'].nunique()\n",
    "multi_dwa_tasks = (task_counts > 1).sum()\n",
    "print(f\"Number of tasks matched to multiple DWAs: {multi_dwa_tasks}\")\n",
    "\n",
    "# Remove duplicates (keep first occurrence)\n",
    "num_duplicates = ONET.duplicated(subset=dup_cols_full).sum()\n",
    "ONET = ONET.drop_duplicates(subset=dup_cols_full).reset_index(drop=True)\n",
    "print(f\"Number of duplicate rows: {num_duplicates}\")\n",
    "\n",
    "# Reorder columns before saving\n",
    "first_cols = ['O*NET-SOC Code', 'Occupation Title', 'Task ID', 'Task Title', 'Task Type', 'DWA ID', 'DWA Title', 'Job Zone']\n",
    "last_cols = ['Major_Group_Code', 'Major_Group_Title', 'Minor_Group_Code', 'Minor_Group_Title', \n",
    "             'Broad_Occupation_Code', 'Broad_Occupation_Title', 'Detailed_Occupation_Code', 'Detailed_Occupation_Title']\n",
    "middle_cols = [col for col in ONET.columns if col not in first_cols + last_cols]\n",
    "ONET = ONET[first_cols + middle_cols + last_cols]\n",
    "\n",
    "# Save final dataset\n",
    "ONET.to_csv(f'{output_data_path}/ONET_cleaned_tasks.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "386a86a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DWA repetition dataset across hierarchical levels\n",
    "dwa_repetition_data = []\n",
    "\n",
    "# Filter out rows where DWA ID is null\n",
    "onet_with_dwa = ONET[ONET['DWA ID'].notna()]\n",
    "\n",
    "for dwa_id in onet_with_dwa['DWA ID'].unique():\n",
    "    dwa_data = onet_with_dwa[onet_with_dwa['DWA ID'] == dwa_id]\n",
    "    dwa_title = dwa_data['DWA Title'].iloc[0]\n",
    "    \n",
    "    dwa_repetition_data.append({\n",
    "        'DWA ID': dwa_id,\n",
    "        'DWA Title': dwa_title,\n",
    "        'num_occupations': dwa_data['O*NET-SOC Code'].nunique(),\n",
    "        'num_detailed_occupations': dwa_data['Detailed_Occupation_Code'].nunique(),\n",
    "        'num_broad_occupations': dwa_data['Broad_Occupation_Code'].nunique(),\n",
    "        'num_minor_groups': dwa_data['Minor_Group_Code'].nunique(),\n",
    "        'num_major_groups': dwa_data['Major_Group_Code'].nunique()\n",
    "    })\n",
    "\n",
    "dwa_repetition_df = pd.DataFrame(dwa_repetition_data)\n",
    "dwa_repetition_df.to_csv(f'{output_data_path}/dwa_repetition_by_hierarchy.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd3c14b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create task repetition dataset across hierarchical levels\n",
    "# task_repetition_data = []\n",
    "\n",
    "# for task_id in ONET['Task ID'].unique():\n",
    "#     task_data = ONET[ONET['Task ID'] == task_id]\n",
    "    \n",
    "#     # Get task title (should be consistent for same task ID)\n",
    "#     task_title = task_data['Task Title'].iloc[0]\n",
    "    \n",
    "#     # Count occurrences at each hierarchical level\n",
    "#     task_repetition_data.append({\n",
    "#         'Task ID': task_id,\n",
    "#         'Task Title': task_title,\n",
    "#         'num_occupations': task_data['O*NET-SOC Code'].nunique(),\n",
    "#         'num_detailed_occupations': task_data['Detailed_Occupation_Code'].nunique(),\n",
    "#         'num_broad_occupations': task_data['Broad_Occupation_Code'].nunique(),\n",
    "#         'num_minor_groups': task_data['Minor_Group_Code'].nunique(),\n",
    "#         'num_major_groups': task_data['Major_Group_Code'].nunique()\n",
    "#     })\n",
    "\n",
    "# task_repetition_df = pd.DataFrame(task_repetition_data)\n",
    "\n",
    "# # Save task repetition dataset\n",
    "# task_repetition_df.to_csv(f'{output_data_path}/task_repetition_by_hierarchy.csv', index=False)\n",
    "\n",
    "# print(\"Task Repetition Analysis:\")\n",
    "# print(f\"  Total unique tasks: {len(task_repetition_df):,}\")\n",
    "# print(f\"\\nTasks appearing in multiple occupations:\")\n",
    "# print(f\"  Tasks in 2+ occupations: {(task_repetition_df['num_occupations'] >= 2).sum():,}\")\n",
    "# print(f\"  Tasks in 5+ occupations: {(task_repetition_df['num_occupations'] >= 5).sum():,}\")\n",
    "# print(f\"  Tasks in 10+ occupations: {(task_repetition_df['num_occupations'] >= 10).sum():,}\")\n",
    "# print(f\"\\nMax repetition across levels:\")\n",
    "# print(f\"  Max occupations per task: {task_repetition_df['num_occupations'].max()}\")\n",
    "# print(f\"  Max detailed occupations per task: {task_repetition_df['num_detailed_occupations'].max()}\")\n",
    "# print(f\"  Max broad occupations per task: {task_repetition_df['num_broad_occupations'].max()}\")\n",
    "# print(f\"  Max minor groups per task: {task_repetition_df['num_minor_groups'].max()}\")\n",
    "# print(f\"  Max major groups per task: {task_repetition_df['num_major_groups'].max()}\")\n",
    "# print(f\"\\nSaved to: {output_data_path}/task_repetition_by_hierarchy.csv\")\n",
    "\n",
    "# task_repetition_df.head(10)\n",
    "\n",
    "# # Tasks are unique! ==> All 1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cec7206c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (22310, 25)\n",
      "Total rows: 22,310\n",
      "\n",
      "Columns with NaN values:\n",
      "==================================================\n",
      "Minor_Group_Title: 4,231 (18.96%)\n",
      "DWA ID: 425 (1.90%)\n",
      "DWA Title: 425 (1.90%)\n",
      "Broad_Occupation_Title: 215 (0.96%)\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: NaN values\n",
    "nan_counts = ONET.isna().sum()\n",
    "nan_summary = nan_counts[nan_counts > 0].sort_values(ascending=False)\n",
    "\n",
    "print(f\"Dataset shape: {ONET.shape}\")\n",
    "print(f\"Total rows: {len(ONET):,}\\n\")\n",
    "\n",
    "if len(nan_summary) > 0:\n",
    "    print(\"Columns with NaN values:\")\n",
    "    print(\"=\" * 50)\n",
    "    for col, count in nan_summary.items():\n",
    "        percentage = (count / len(ONET)) * 100\n",
    "        print(f\"{col}: {count:,} ({percentage:.2f}%)\")\n",
    "else:\n",
    "    print(\"✓ No NaN values found in any column!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
