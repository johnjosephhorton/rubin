{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc7fc397",
   "metadata": {},
   "source": [
    "#### By: Peyman Shahidi\n",
    "#### Created: Nov 7, 2025\n",
    "#### Last Edit: Nov 10, 2025\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10366af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python\n",
    "import getpass\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "import random \n",
    "\n",
    "## formatting number to appear comma separated and with two digits after decimal: e.g, 1000 shown as 1,000.00\n",
    "pd.set_option('float_format', \"{:,.2f}\".format)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "#from matplotlib.legend import Legend\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "519e43cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder_path = \"..\"\n",
    "input_data_path = f\"{main_folder_path}/data\"\n",
    "output_data_path = f'{input_data_path}/computed_objects/contiguityMeasure'\n",
    "output_plot_path = f\"{main_folder_path}/writeup/plots/contiguityMeasure\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84e6e6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories if they don't exist\n",
    "import os\n",
    "\n",
    "for path in [output_data_path, output_plot_path]:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb2fcce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-sided window length (number of steps to look left/right)\n",
    "window_length = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ce9cd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_occupation_analysis(df, onet_occupation_code_var, onet_occupation_title_var):\n",
    "    # Create occupation-level analysis for scatter plots\n",
    "    # Group by occupation and calculate label fractions and task counts\n",
    "    occupation_stats = []\n",
    "\n",
    "    for (soc_code, occ_title), group in df.groupby([onet_occupation_code_var, onet_occupation_title_var]):\n",
    "        num_tasks = group['Task ID'].nunique()\n",
    "        # num_occupations = group[onet_occupation_code_var].nunique()\n",
    "        total_tasks = len(group)\n",
    "        \n",
    "        manual_fraction = (group['label'] == 'Manual').sum() / total_tasks\n",
    "        augmentation_fraction = (group['label'] == 'Augmentation').sum() / total_tasks  \n",
    "        automation_fraction = (group['label'] == 'Automation').sum() / total_tasks\n",
    "        ai_fraction = augmentation_fraction + automation_fraction\n",
    "        gpt4_E0_fraction = (group['gpt4_exposure'] == 'E0').sum() / total_tasks\n",
    "        gpt4_E1_fraction = (group['gpt4_exposure'] == 'E1').sum() / total_tasks\n",
    "        gpt4_E2_fraction = (group['gpt4_exposure'] == 'E2').sum() / total_tasks\n",
    "        gpt4_aiExposure_fraction = gpt4_E1_fraction + gpt4_E2_fraction\n",
    "        human_E0_fraction = (group['human_labels'] == 'E0').sum() / total_tasks\n",
    "        human_E1_fraction = (group['human_labels'] == 'E1').sum() / total_tasks\n",
    "        human_E2_fraction = (group['human_labels'] == 'E2').sum() / total_tasks\n",
    "        human_aiExposure_fraction = human_E1_fraction + human_E2_fraction\n",
    "\n",
    "        \n",
    "        occupation_stats.append({\n",
    "            f'{onet_occupation_code_var}': soc_code,\n",
    "            f'{onet_occupation_title_var}': occ_title,\n",
    "            'num_tasks': num_tasks,\n",
    "            # 'num_occupations': num_occupations,\n",
    "            'manual_fraction': manual_fraction,\n",
    "            'ai_fraction': ai_fraction,\n",
    "            'augmentation_fraction': augmentation_fraction,\n",
    "            'automation_fraction': automation_fraction,\n",
    "            'gpt4_E0_fraction': gpt4_E0_fraction,\n",
    "            'gpt4_E1_fraction': gpt4_E1_fraction,\n",
    "            'gpt4_E2_fraction': gpt4_E2_fraction,\n",
    "            'gpt4_aiExposure_fraction': gpt4_aiExposure_fraction,\n",
    "            'human_E0_fraction': human_E0_fraction,\n",
    "            'human_E1_fraction': human_E1_fraction,\n",
    "            'human_E2_fraction': human_E2_fraction,\n",
    "            'human_aiExposure_fraction': human_aiExposure_fraction\n",
    "        })\n",
    "\n",
    "    occupation_analysis = pd.DataFrame(occupation_stats)\n",
    "\n",
    "    return occupation_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2038cb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the merged data\n",
    "merged_data = pd.read_csv(f\"{input_data_path}/computed_objects/ONET_Eloundou_Anthropic_GPT/ONET_Eloundou_Anthropic_GPT.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da0340c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drop the supplemental tasks\n",
    "# merged_data = merged_data[merged_data['Task Type'] != 'Supplemental'].reset_index(drop=True)\n",
    "\n",
    "# # Drop rows whose Occupation Title includes 'Teachers, Postsecondary'\n",
    "# merged_data = merged_data[~merged_data['Occupation Title'].str.contains('Teachers, Postsecondary')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617af65e",
   "metadata": {},
   "source": [
    "## Calculate Contiguity Measure defined as an indicator for whether +_ X tasks next to a task are AI Exposed (measured via E1 AI exposure measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6363b238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O*NET-SOC Code</th>\n",
       "      <th>Occupation Title</th>\n",
       "      <th>Task Position</th>\n",
       "      <th>Task ID</th>\n",
       "      <th>human_labels</th>\n",
       "      <th>share_exposed_in_window</th>\n",
       "      <th>label</th>\n",
       "      <th>is_ai</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1959</th>\n",
       "      <td>15-1251.00</td>\n",
       "      <td>Computer Programmers</td>\n",
       "      <td>2</td>\n",
       "      <td>1277</td>\n",
       "      <td>E2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Manual</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>15-1251.00</td>\n",
       "      <td>Computer Programmers</td>\n",
       "      <td>3</td>\n",
       "      <td>1276</td>\n",
       "      <td>E2</td>\n",
       "      <td>0.33</td>\n",
       "      <td>Automation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <td>15-1251.00</td>\n",
       "      <td>Computer Programmers</td>\n",
       "      <td>4</td>\n",
       "      <td>1273</td>\n",
       "      <td>E1</td>\n",
       "      <td>0.67</td>\n",
       "      <td>Augmentation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>15-1251.00</td>\n",
       "      <td>Computer Programmers</td>\n",
       "      <td>5</td>\n",
       "      <td>1270</td>\n",
       "      <td>E1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Automation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963</th>\n",
       "      <td>15-1251.00</td>\n",
       "      <td>Computer Programmers</td>\n",
       "      <td>6</td>\n",
       "      <td>21049</td>\n",
       "      <td>E1</td>\n",
       "      <td>0.67</td>\n",
       "      <td>Manual</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>15-1251.00</td>\n",
       "      <td>Computer Programmers</td>\n",
       "      <td>7</td>\n",
       "      <td>1269</td>\n",
       "      <td>E2</td>\n",
       "      <td>0.67</td>\n",
       "      <td>Augmentation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>15-1251.00</td>\n",
       "      <td>Computer Programmers</td>\n",
       "      <td>8</td>\n",
       "      <td>1268</td>\n",
       "      <td>E1</td>\n",
       "      <td>0.33</td>\n",
       "      <td>Manual</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>15-1251.00</td>\n",
       "      <td>Computer Programmers</td>\n",
       "      <td>9</td>\n",
       "      <td>1275</td>\n",
       "      <td>E0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>Augmentation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>15-1251.00</td>\n",
       "      <td>Computer Programmers</td>\n",
       "      <td>10</td>\n",
       "      <td>1267</td>\n",
       "      <td>E1</td>\n",
       "      <td>0.33</td>\n",
       "      <td>Automation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <td>15-1251.00</td>\n",
       "      <td>Computer Programmers</td>\n",
       "      <td>11</td>\n",
       "      <td>1272</td>\n",
       "      <td>E2</td>\n",
       "      <td>0.33</td>\n",
       "      <td>Automation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969</th>\n",
       "      <td>15-1251.00</td>\n",
       "      <td>Computer Programmers</td>\n",
       "      <td>12</td>\n",
       "      <td>1278</td>\n",
       "      <td>E2</td>\n",
       "      <td>0.33</td>\n",
       "      <td>Augmentation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>15-1251.00</td>\n",
       "      <td>Computer Programmers</td>\n",
       "      <td>13</td>\n",
       "      <td>1274</td>\n",
       "      <td>E1</td>\n",
       "      <td>0.67</td>\n",
       "      <td>Manual</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>15-1251.00</td>\n",
       "      <td>Computer Programmers</td>\n",
       "      <td>14</td>\n",
       "      <td>21050</td>\n",
       "      <td>E1</td>\n",
       "      <td>0.67</td>\n",
       "      <td>Manual</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>15-1251.00</td>\n",
       "      <td>Computer Programmers</td>\n",
       "      <td>15</td>\n",
       "      <td>1279</td>\n",
       "      <td>E2</td>\n",
       "      <td>0.67</td>\n",
       "      <td>Manual</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>15-1251.00</td>\n",
       "      <td>Computer Programmers</td>\n",
       "      <td>16</td>\n",
       "      <td>1281</td>\n",
       "      <td>E1</td>\n",
       "      <td>0.33</td>\n",
       "      <td>Manual</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     O*NET-SOC Code      Occupation Title  Task Position  Task ID  \\\n",
       "1959     15-1251.00  Computer Programmers              2     1277   \n",
       "1960     15-1251.00  Computer Programmers              3     1276   \n",
       "1961     15-1251.00  Computer Programmers              4     1273   \n",
       "1962     15-1251.00  Computer Programmers              5     1270   \n",
       "1963     15-1251.00  Computer Programmers              6    21049   \n",
       "1964     15-1251.00  Computer Programmers              7     1269   \n",
       "1965     15-1251.00  Computer Programmers              8     1268   \n",
       "1966     15-1251.00  Computer Programmers              9     1275   \n",
       "1967     15-1251.00  Computer Programmers             10     1267   \n",
       "1968     15-1251.00  Computer Programmers             11     1272   \n",
       "1969     15-1251.00  Computer Programmers             12     1278   \n",
       "1970     15-1251.00  Computer Programmers             13     1274   \n",
       "1971     15-1251.00  Computer Programmers             14    21050   \n",
       "1972     15-1251.00  Computer Programmers             15     1279   \n",
       "1973     15-1251.00  Computer Programmers             16     1281   \n",
       "\n",
       "     human_labels  share_exposed_in_window         label  is_ai  \n",
       "1959           E2                     0.00        Manual      0  \n",
       "1960           E2                     0.33    Automation      1  \n",
       "1961           E1                     0.67  Augmentation      1  \n",
       "1962           E1                     1.00    Automation      1  \n",
       "1963           E1                     0.67        Manual      0  \n",
       "1964           E2                     0.67  Augmentation      1  \n",
       "1965           E1                     0.33        Manual      0  \n",
       "1966           E0                     0.67  Augmentation      1  \n",
       "1967           E1                     0.33    Automation      1  \n",
       "1968           E2                     0.33    Automation      1  \n",
       "1969           E2                     0.33  Augmentation      1  \n",
       "1970           E1                     0.67        Manual      0  \n",
       "1971           E1                     0.67        Manual      0  \n",
       "1972           E2                     0.67        Manual      0  \n",
       "1973           E1                     0.33        Manual      0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate fragmentation index\n",
    "# For the sake of this exercise we treat all AI tasks as a single category\n",
    "\n",
    "# Create is_exposed column\n",
    "cm_df = merged_data[['O*NET-SOC Code', 'Occupation Title', 'Task Position', 'Task ID', 'human_labels']].copy()\n",
    "cm_df['human_labels'] = cm_df['human_labels'].fillna('E0')\n",
    "cm_df['is_exposed'] = cm_df['human_labels'].isin(['E1']).astype(int)\n",
    "\n",
    "# Ensure order within each occupation group (adjust if your ordering col is different)\n",
    "group_cols = ['O*NET-SOC Code', 'Occupation Title']\n",
    "order_cols = group_cols + (['Task Position'] if 'Task Position' in cm_df.columns else [])\n",
    "cm_df = cm_df.sort_values(order_cols)\n",
    "\n",
    "g = cm_df.groupby(group_cols, sort=False)\n",
    "\n",
    "# --- Build all shifted exposure columns systematically ---\n",
    "shifts = {}\n",
    "for i in range(1, window_length + 1):\n",
    "    shifts[f'previous_is_exposed_{i}'] = g['is_exposed'].shift(i).fillna(0).astype('int8')\n",
    "    shifts[f'next_is_exposed_{i}']     = g['is_exposed'].shift(-i).fillna(0).astype('int8')\n",
    "\n",
    "cm_df = cm_df.assign(**shifts)\n",
    "\n",
    "# Helpers to reduce across an arbitrary list of Series\n",
    "def max_reduce(series_list, default=0):\n",
    "    if not series_list:\n",
    "        return pd.Series(default, index=cm_df.index, dtype='int8')\n",
    "    out = series_list[0].copy()\n",
    "    for s in series_list[1:]:\n",
    "        out = np.maximum(out, s)\n",
    "    return out.astype('int8')\n",
    "\n",
    "def min_reduce(series_list, default=1):\n",
    "    if not series_list:\n",
    "        return pd.Series(default, index=cm_df.index, dtype='int8')\n",
    "    out = series_list[0].copy()\n",
    "    for s in series_list[1:]:\n",
    "        out = np.minimum(out, s)\n",
    "    return out.astype('int8')\n",
    "\n",
    "prev_cols = [cm_df[f'previous_is_exposed_{i}'] for i in range(1, window_length + 1)]\n",
    "next_cols = [cm_df[f'next_is_exposed_{i}']     for i in range(1, window_length + 1)]\n",
    "\n",
    "# 1) STRICT contiguity: entire block of size (2*W+1) is exposed\n",
    "strict_block = min_reduce([cm_df['is_exposed']] + prev_cols + next_cols, default=1)\n",
    "cm_df['is_contiguous_strict'] = strict_block  # 1 iff every neighbor within the window is exposed\n",
    "\n",
    "# 2) ANY-ON-BOTH-SIDES contiguity: at least one exposed on the left AND one on the right (within window)\n",
    "left_any  = max_reduce(prev_cols, default=0)\n",
    "right_any = max_reduce(next_cols, default=0)\n",
    "cm_df['is_contiguous_any_sides'] = (cm_df['is_exposed'].values & left_any.values & right_any.values).astype('int8')\n",
    "\n",
    "# 3) Useful summaries: counts/shares in the window (incl. self)\n",
    "neighbors_sum = sum(prev_cols + next_cols) if window_length > 0 else 0\n",
    "cm_df['num_exposed_in_window']   = (neighbors_sum + cm_df['is_exposed']).astype('int16')\n",
    "cm_df['share_exposed_in_window'] = cm_df['num_exposed_in_window'] / (2*window_length + 1)\n",
    "\n",
    "# 4) Optional: length of the contiguous exposed block that includes the focal task\n",
    "def exposed_block_len(s):\n",
    "    grp = (s != s.shift()).cumsum()\n",
    "    seg_size = s.groupby(grp).transform('size')\n",
    "    return np.where(s.eq(1), seg_size, 0).astype('int16')\n",
    "\n",
    "cm_df['exposed_block_len'] = g['is_exposed'].transform(exposed_block_len)\n",
    "\n",
    "# A single flag choosing one of the options:\n",
    "cm_df['is_contiguous'] = cm_df['is_contiguous_strict']\n",
    "\n",
    "# Sort within groups by Task Position (ascending)\n",
    "cm_df = cm_df.sort_values(['O*NET-SOC Code', 'Occupation Title', 'Task Position']).reset_index(drop=True)\n",
    "\n",
    "# Index within group (0-based) and group sizes\n",
    "g = cm_df.groupby(['O*NET-SOC Code', 'Occupation Title'], sort=False)\n",
    "cm_df['_i'] = g.cumcount()\n",
    "cm_df['_n'] = g['Task Position'].transform('size')\n",
    "\n",
    "# Keep only interior rows: window_length ... n-1-window_length\n",
    "keep = (cm_df['_i'] >= window_length) & (cm_df['_i'] < cm_df['_n'] - window_length)\n",
    "cm_df = cm_df.loc[keep].drop(columns=['_i','_n']).reset_index(drop=True)\n",
    "\n",
    "# Keep only relevant columns\n",
    "cm_df = cm_df[['O*NET-SOC Code', 'Occupation Title', 'Task Position', 'Task ID', 'human_labels', 'share_exposed_in_window']]\n",
    "\n",
    "\n",
    "# Create is_ai column\n",
    "ai_df = merged_data[['O*NET-SOC Code', 'Occupation Title', 'Task ID', 'label']].copy()\n",
    "ai_df['is_ai'] = ai_df['label'].isin(['Automation', 'Augmentation']).astype(int)\n",
    "\n",
    "# Merge with cm_df \n",
    "cm_df = cm_df.merge(ai_df, on=['O*NET-SOC Code', 'Occupation Title', 'Task ID'], how='left')\n",
    "\n",
    "# Save contiguity measure data\n",
    "cm_df.to_csv(f\"{output_data_path}/contiguityMeasure.csv\", index=False)\n",
    "cm_df[cm_df['O*NET-SOC Code']=='15-1251.00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af48adff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add back SOC levels for fixed effects in regressions\n",
    "my_onet_level = 'detailed'\n",
    "onet_occupation_code_var = 'Detailed_Occupation_Code'\n",
    "onet_occupation_title_var = 'Detailed_Occupation_Title'\n",
    "\n",
    "# Read OG occupation analysis with SOC mappings\n",
    "ONET = pd.read_csv(f\"{input_data_path}/computed_objects/ONET_cleaned_tasks.csv\")\n",
    "\n",
    "# Keep only the relevant \n",
    "SOC_mappings = ONET[['O*NET-SOC Code', 'Occupation Title',\n",
    "                     'Major_Group_Code', 'Major_Group_Title',\n",
    "                     'Minor_Group_Code', 'Minor_Group_Title',\n",
    "                     'Broad_Occupation_Code', 'Broad_Occupation_Title',\n",
    "                     'Detailed_Occupation_Code', 'Detailed_Occupation_Title']].copy()\n",
    "SOC_mappings = SOC_mappings.drop_duplicates(subset=['O*NET-SOC Code', onet_occupation_code_var])\n",
    "\n",
    "# Merge SOC levels with the occupation analysis\n",
    "cm_df = cm_df.merge(SOC_mappings, on=['O*NET-SOC Code', 'Occupation Title'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01cf10da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.370499\n",
      "         Iterations 6\n",
      "\n",
      "\n",
      "=== Model A — selected coefficients ===\n",
      "                         coef   se     t    p  ci_low  ci_high\n",
      "share_exposed_in_window  1.94 0.11 17.83 0.00    1.73     2.15\n",
      "\n",
      "\n",
      "=== Model B — selected coefficients ===\n",
      "                         coef   se    t    p  ci_low  ci_high\n",
      "share_exposed_in_window  0.81 0.14 5.81 0.00    0.53     1.08\n",
      "\n",
      "\n",
      "=== Model C — selected coefficients ===\n",
      "                         coef   se    t    p  ci_low  ci_high\n",
      "share_exposed_in_window  0.68 0.16 4.23 0.00    0.37     1.00\n",
      "\n",
      "\n",
      "=== Model A with minor_df — selected coefficients ===\n",
      "                         coef   se    t    p  ci_low  ci_high\n",
      "share_exposed_in_window  1.84 0.22 8.28 0.00    1.41     2.28\n",
      "\n",
      "\n",
      "=== Model B with minor_df — selected coefficients ===\n",
      "                         coef   se    t    p  ci_low  ci_high\n",
      "share_exposed_in_window  0.81 0.17 4.90 0.00    0.49     1.13\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Helper: compact table for selected vars\n",
    "def coef_table(res, vars_):\n",
    "    ci = res.conf_int().rename(columns={0: 'ci_low', 1: 'ci_high'})\n",
    "    out = (pd.DataFrame({'coef': res.params, 'se': res.bse,\n",
    "                         't': res.tvalues, 'p': res.pvalues})\n",
    "           .join(ci)\n",
    "           .loc[vars_])\n",
    "    return out\n",
    "\n",
    "vars_of_interest = ['share_exposed_in_window']\n",
    "\n",
    "# --- Model A: no FE ---\n",
    "mod_a = smf.logit(\n",
    "    formula=f'is_ai ~ share_exposed_in_window',\n",
    "    data=cm_df\n",
    ").fit(cov_type=\"cluster\",\n",
    "    cov_kwds={\n",
    "        \"groups\": cm_df['O*NET-SOC Code'],\n",
    "        \"use_correction\": True,\n",
    "        \"df_correction\": True\n",
    "    })\n",
    "print(\"\\n\\n=== Model A — selected coefficients ===\")\n",
    "print(coef_table(mod_a, vars_of_interest))\n",
    "\n",
    "\n",
    "# For fixed effects, some major and minor groups have no variation in is_ai and thus lead to singular matrices\n",
    "# Remove those from the analysis\n",
    "def sanitize_for_fe_logit(df, fe, y, xcols, min_obs=3):\n",
    "    d = df.dropna(subset=[fe, y] + xcols).copy()\n",
    "\n",
    "    # 1) enough observations per FE\n",
    "    cnt = d.groupby(fe).size()\n",
    "    good = cnt[cnt >= min_obs].index\n",
    "    d = d[d[fe].isin(good)]\n",
    "\n",
    "    # 2) outcome must vary within FE (avoid complete separation by intercept)\n",
    "    yvar = d.groupby(fe)[y].nunique()\n",
    "    good = yvar[yvar > 1].index\n",
    "    d = d[d[fe].isin(good)]\n",
    "\n",
    "    # 3) regressors must vary within FE\n",
    "    for x in xcols:\n",
    "        xv = d.groupby(fe)[x].var()\n",
    "        good = xv[xv > 0].index\n",
    "        d = d[d[fe].isin(good)]\n",
    "\n",
    "    return d\n",
    "\n",
    "# —— Major FE ——\n",
    "df_major = sanitize_for_fe_logit(cm_df, 'Major_Group_Code', 'is_ai', ['share_exposed_in_window'])\n",
    "\n",
    "mod_b = smf.logit(\n",
    "    'is_ai ~ share_exposed_in_window + C(Major_Group_Code)',\n",
    "    data=df_major\n",
    ").fit(method='lbfgs', maxiter=200, disp=0,\n",
    "     cov_type='cluster',\n",
    "     cov_kwds={'groups': df_major['Major_Group_Code'],\n",
    "               'use_correction': True, 'df_correction': True})\n",
    "print(\"\\n\\n=== Model B — selected coefficients ===\")\n",
    "print(coef_table(mod_b, vars_of_interest))\n",
    "\n",
    "# —— Minor FE ——\n",
    "df_minor = sanitize_for_fe_logit(cm_df, 'Minor_Group_Code', 'is_ai', ['share_exposed_in_window'])\n",
    "\n",
    "# Try standard MLE first\n",
    "mod_c = smf.logit(\n",
    "        'is_ai ~ share_exposed_in_window + C(Minor_Group_Code)',\n",
    "        data=df_minor\n",
    "    ).fit(method='lbfgs', maxiter=300, disp=0,\n",
    "         cov_type='cluster',\n",
    "         cov_kwds={'groups': df_minor['Minor_Group_Code'],\n",
    "                   'use_correction': True, 'df_correction': True})\n",
    "print(\"\\n\\n=== Model C — selected coefficients ===\")\n",
    "print(coef_table(mod_c, vars_of_interest))\n",
    "\n",
    "\n",
    "# Now run models A and B using the minor_df for sanity check:\n",
    "mod_d = smf.logit(\n",
    "        'is_ai ~ share_exposed_in_window',\n",
    "        data=df_minor\n",
    "    ).fit(method='lbfgs', maxiter=300, disp=0,\n",
    "         cov_type='cluster',\n",
    "         cov_kwds={'groups': df_minor['Minor_Group_Code'],\n",
    "                   'use_correction': True, 'df_correction': True})\n",
    "print(\"\\n\\n=== Model A with minor_df — selected coefficients ===\")\n",
    "print(coef_table(mod_d, vars_of_interest))\n",
    "\n",
    "mod_e = smf.logit(\n",
    "        'is_ai ~ share_exposed_in_window + C(Major_Group_Code)',\n",
    "        data=df_minor\n",
    "    ).fit(method='lbfgs', maxiter=300, disp=0,\n",
    "         cov_type='cluster',\n",
    "         cov_kwds={'groups': df_minor['Minor_Group_Code'],\n",
    "                   'use_correction': True, 'df_correction': True})\n",
    "print(\"\\n\\n=== Model B with minor_df — selected coefficients ===\")\n",
    "print(coef_table(mod_e, vars_of_interest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ad39c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshuffle regression results file already exists at ../data/computed_objects/contiguityMeasure/reshuffle_regression_results_win1.csv\n",
      "Skipping reshuffle analysis to avoid overwriting existing results.\n",
      "If you want to rerun the analysis, please delete the existing file first.\n"
     ]
    }
   ],
   "source": [
    "# Batch-run regressions over many reshuffled datasets and save coefficients\n",
    "import os\n",
    "results = []\n",
    "\n",
    "# Reuse the same contiguity calculation as above but as a function\n",
    "def compute_cm_df(merged, window_length):\n",
    "    cm_df = merged[['O*NET-SOC Code', 'Occupation Title', 'Task Position', 'Task ID', 'human_labels']].copy()\n",
    "    cm_df['human_labels'] = cm_df['human_labels'].fillna('E0')\n",
    "    cm_df['is_exposed'] = cm_df['human_labels'].isin(['E1']).astype(int)\n",
    "    group_cols = ['O*NET-SOC Code', 'Occupation Title']\n",
    "    order_cols = group_cols + (['Task Position'] if 'Task Position' in cm_df.columns else [])\n",
    "    cm_df = cm_df.sort_values(order_cols)\n",
    "\n",
    "    g = cm_df.groupby(group_cols, sort=False)\n",
    "    shifts = {}\n",
    "    for i in range(1, window_length + 1):\n",
    "        shifts[f'previous_is_exposed_{i}'] = g['is_exposed'].shift(i).fillna(0).astype('int8')\n",
    "        shifts[f'next_is_exposed_{i}']     = g['is_exposed'].shift(-i).fillna(0).astype('int8')\n",
    "    cm_df = cm_df.assign(**shifts)\n",
    "\n",
    "    def max_reduce(series_list, default=0):\n",
    "        if not series_list:\n",
    "            return pd.Series(default, index=cm_df.index, dtype='int8')\n",
    "        out = series_list[0].copy()\n",
    "        for s in series_list[1:]:\n",
    "            out = np.maximum(out, s)\n",
    "        return out.astype('int8')\n",
    "\n",
    "    def min_reduce(series_list, default=1):\n",
    "        if not series_list:\n",
    "            return pd.Series(default, index=cm_df.index, dtype='int8')\n",
    "        out = series_list[0].copy()\n",
    "        for s in series_list[1:]:\n",
    "            out = np.minimum(out, s)\n",
    "        return out.astype('int8')\n",
    "\n",
    "    prev_cols = [cm_df[f'previous_is_exposed_{i}'] for i in range(1, window_length + 1)]\n",
    "    next_cols = [cm_df[f'next_is_exposed_{i}']     for i in range(1, window_length + 1)]\n",
    "\n",
    "    strict_block = min_reduce([cm_df['is_exposed']] + prev_cols + next_cols, default=1)\n",
    "    cm_df['is_contiguous_strict'] = strict_block\n",
    "    left_any  = max_reduce(prev_cols, default=0)\n",
    "    right_any = max_reduce(next_cols, default=0)\n",
    "    cm_df['is_contiguous_any_sides'] = (cm_df['is_exposed'].values & left_any.values & right_any.values).astype('int8')\n",
    "\n",
    "    neighbors_sum = sum(prev_cols + next_cols) if window_length > 0 else 0\n",
    "    cm_df['num_exposed_in_window']   = (neighbors_sum + cm_df['is_exposed']).astype('int16')\n",
    "    cm_df['share_exposed_in_window'] = cm_df['num_exposed_in_window'] / (2*window_length + 1)\n",
    "\n",
    "    def exposed_block_len(s):\n",
    "        grp = (s != s.shift()).cumsum()\n",
    "        seg_size = s.groupby(grp).transform('size')\n",
    "        return np.where(s.eq(1), seg_size, 0).astype('int16')\n",
    "\n",
    "    cm_df['exposed_block_len'] = g['is_exposed'].transform(exposed_block_len)\n",
    "    cm_df['is_contiguous'] = cm_df['is_contiguous_strict']\n",
    "\n",
    "    cm_df = cm_df.sort_values(['O*NET-SOC Code', 'Occupation Title', 'Task Position']).reset_index(drop=True)\n",
    "    g = cm_df.groupby(['O*NET-SOC Code', 'Occupation Title'], sort=False)\n",
    "    cm_df['_i'] = g.cumcount()\n",
    "    cm_df['_n'] = g['Task Position'].transform('size')\n",
    "    keep = (cm_df['_i'] >= window_length) & (cm_df['_i'] < cm_df['_n'] - window_length)\n",
    "    cm_df = cm_df.loc[keep].drop(columns=['_i','_n']).reset_index(drop=True)\n",
    "\n",
    "    cm_df = cm_df[['O*NET-SOC Code', 'Occupation Title', 'Task Position', 'Task ID', 'human_labels', 'share_exposed_in_window']]\n",
    "    ai_df = merged[['O*NET-SOC Code', 'Occupation Title', 'Task ID', 'label']].copy()\n",
    "    ai_df['is_ai'] = ai_df['label'].isin(['Automation', 'Augmentation']).astype(int)\n",
    "    cm_df = cm_df.merge(ai_df, on=['O*NET-SOC Code', 'Occupation Title', 'Task ID'], how='left')\n",
    "    if 'SOC_mappings' in globals():\n",
    "        cm_df = cm_df.merge(SOC_mappings, on=['O*NET-SOC Code', 'Occupation Title'], how='left')\n",
    "    return cm_df\n",
    "\n",
    "# Fit models and extract coefficients (robust to errors)\n",
    "def fit_models_and_extract(cm_df):\n",
    "    out = {}\n",
    "    # Model A: no FE (cluster by O*NET-SOC Code)\n",
    "    try:\n",
    "        m = smf.logit(formula='is_ai ~ share_exposed_in_window', data=cm_df).fit(\n",
    "            disp=0,\n",
    "            cov_type='cluster',\n",
    "            cov_kwds={\n",
    "                'groups': cm_df['O*NET-SOC Code'],\n",
    "                'use_correction': True,\n",
    "                'df_correction': True\n",
    "            }\n",
    "        )\n",
    "        out['mod_a_coef'] = m.params.get('share_exposed_in_window', np.nan)\n",
    "        out['mod_a_se'] = m.bse.get('share_exposed_in_window', np.nan)\n",
    "        out['mod_a_p'] = m.pvalues.get('share_exposed_in_window', np.nan)\n",
    "    except Exception as e:\n",
    "        out['mod_a_error'] = str(e)\n",
    "        out['mod_a_coef'] = np.nan; out['mod_a_se'] = np.nan; out['mod_a_p'] = np.nan\n",
    "\n",
    "    # Model B: Major FE\n",
    "    try:\n",
    "        df_major = sanitize_for_fe_logit(cm_df, 'Major_Group_Code', 'is_ai', ['share_exposed_in_window'])\n",
    "        m2 = smf.logit('is_ai ~ share_exposed_in_window + C(Major_Group_Code)', data=df_major).fit(\n",
    "            method='lbfgs', maxiter=200, disp=0,\n",
    "            cov_type='cluster',\n",
    "            cov_kwds={'groups': df_major['Major_Group_Code'], 'use_correction': True, 'df_correction': True}\n",
    "        )\n",
    "        out['mod_b_coef'] = m2.params.get('share_exposed_in_window', np.nan)\n",
    "        out['mod_b_se'] = m2.bse.get('share_exposed_in_window', np.nan)\n",
    "        out['mod_b_p'] = m2.pvalues.get('share_exposed_in_window', np.nan)\n",
    "    except Exception as e:\n",
    "        out['mod_b_error'] = str(e)\n",
    "        out['mod_b_coef'] = np.nan; out['mod_b_se'] = np.nan; out['mod_b_p'] = np.nan\n",
    "\n",
    "    # Model C: Minor FE\n",
    "    try:\n",
    "        df_minor = sanitize_for_fe_logit(cm_df, 'Minor_Group_Code', 'is_ai', ['share_exposed_in_window'])\n",
    "        m3 = smf.logit('is_ai ~ share_exposed_in_window + C(Minor_Group_Code)', data=df_minor).fit(\n",
    "            method='lbfgs', maxiter=300, disp=0,\n",
    "            cov_type='cluster',\n",
    "            cov_kwds={'groups': df_minor['Minor_Group_Code'], 'use_correction': True, 'df_correction': True}\n",
    "        )\n",
    "        out['mod_c_coef'] = m3.params.get('share_exposed_in_window', np.nan)\n",
    "        out['mod_c_se'] = m3.bse.get('share_exposed_in_window', np.nan)\n",
    "        out['mod_c_p'] = m3.pvalues.get('share_exposed_in_window', np.nan)\n",
    "    except Exception as e:\n",
    "        out['mod_c_error'] = str(e)\n",
    "        out['mod_c_coef'] = np.nan; out['mod_c_se'] = np.nan; out['mod_c_p'] = np.nan\n",
    "\n",
    "    # Model D: no FE but on df_minor (sanity check)\n",
    "    try:\n",
    "        # ensure df_minor is available (recompute if previous failed)\n",
    "        if 'df_minor' not in locals():\n",
    "            df_minor = sanitize_for_fe_logit(cm_df, 'Minor_Group_Code', 'is_ai', ['share_exposed_in_window'])\n",
    "        m4 = smf.logit('is_ai ~ share_exposed_in_window', data=df_minor).fit(\n",
    "            method='lbfgs', maxiter=300, disp=0,\n",
    "            cov_type='cluster',\n",
    "            cov_kwds={'groups': df_minor['Minor_Group_Code'], 'use_correction': True, 'df_correction': True}\n",
    "        )\n",
    "        out['mod_d_coef'] = m4.params.get('share_exposed_in_window', np.nan)\n",
    "        out['mod_d_se'] = m4.bse.get('share_exposed_in_window', np.nan)\n",
    "        out['mod_d_p'] = m4.pvalues.get('share_exposed_in_window', np.nan)\n",
    "    except Exception as e:\n",
    "        out['mod_d_error'] = str(e)\n",
    "        out['mod_d_coef'] = np.nan; out['mod_d_se'] = np.nan; out['mod_d_p'] = np.nan\n",
    "\n",
    "    # Model E: Major FE but fitted on df_minor (as in earlier mod_e)\n",
    "    try:\n",
    "        if 'df_minor' not in locals():\n",
    "            df_minor = sanitize_for_fe_logit(cm_df, 'Minor_Group_Code', 'is_ai', ['share_exposed_in_window'])\n",
    "        m5 = smf.logit('is_ai ~ share_exposed_in_window + C(Major_Group_Code)', data=df_minor).fit(\n",
    "            method='lbfgs', maxiter=300, disp=0,\n",
    "            cov_type='cluster',\n",
    "            cov_kwds={'groups': df_minor['Minor_Group_Code'], 'use_correction': True, 'df_correction': True}\n",
    "        )\n",
    "        out['mod_e_coef'] = m5.params.get('share_exposed_in_window', np.nan)\n",
    "        out['mod_e_se'] = m5.bse.get('share_exposed_in_window', np.nan)\n",
    "        out['mod_e_p'] = m5.pvalues.get('share_exposed_in_window', np.nan)\n",
    "    except Exception as e:\n",
    "        out['mod_e_error'] = str(e)\n",
    "        out['mod_e_coef'] = np.nan; out['mod_e_se'] = np.nan; out['mod_e_p'] = np.nan\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "# Run the reshuffle analysis if the output file does not already exist\n",
    "out_file = f\"{output_data_path}/reshuffle_regression_results_win{window_length}.csv\"\n",
    "if os.path.exists(out_file):\n",
    "    print('Reshuffle regression results file already exists at', out_file)\n",
    "    print('Skipping reshuffle analysis to avoid overwriting existing results.')\n",
    "    print('If you want to rerun the analysis, please delete the existing file first.')\n",
    "\n",
    "else:\n",
    "    # 1) Add the observed/original dataset results (merged_data exists earlier in the notebook)\n",
    "    try:\n",
    "        cm_obs = compute_cm_df(merged_data, window_length)\n",
    "        row_obs = {'seed': 'observed'}\n",
    "        row_obs.update(fit_models_and_extract(cm_obs))\n",
    "        results.append(row_obs)\n",
    "    except Exception as e:\n",
    "        print('Failed to compute observed dataset results:', e)\n",
    "\n",
    "    # 2) Loop over reshuffled files (attempt up to 1000) and collect results\n",
    "    n_rep = 1000\n",
    "    base_dir = f\"{input_data_path}/computed_objects/ONET_Eloundou_Anthropic_GPT/taskReshuffled_preserveCounts\"\n",
    "    for seed in range(n_rep):\n",
    "        if seed % 50 == 0:\n",
    "            print(f'Iteration {seed+1} of {n_rep}')\n",
    "        \n",
    "        fpath = os.path.join(base_dir, f'ONET_Eloundou_Anthropic_GPT_iter{seed+1}.csv')\n",
    "        if not os.path.exists(fpath):\n",
    "            # Skip missing files (prints so user knows)\n",
    "            if seed < 5:\n",
    "                print(f'Missing {fpath} (skipping)')\n",
    "            continue\n",
    "        try:\n",
    "            resh = pd.read_csv(fpath)\n",
    "            cm = compute_cm_df(resh, window_length)\n",
    "            row = {'seed': int(seed)}\n",
    "            row.update(fit_models_and_extract(cm))\n",
    "            results.append(row)\n",
    "        except Exception as e:\n",
    "            print(f'Failed seed {seed}: {e}')\n",
    "\n",
    "    # Save results to CSV for later plotting/comparison\n",
    "    res_df = pd.DataFrame(results)\n",
    "    out_file = f\"{output_data_path}/reshuffle_regression_results_win{window_length}.csv\"\n",
    "    res_df.to_csv(out_file, index=False)\n",
    "    print('Wrote regression results to', out_file)\n",
    "    res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cda4da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved plot to ../writeup/plots/contiguityMeasure/win1\n",
      "Saved plot to ../writeup/plots/contiguityMeasure/win1\n",
      "Saved plot to ../writeup/plots/contiguityMeasure/win1\n",
      "Saved plot to ../writeup/plots/contiguityMeasure/win1\n",
      "Saved plot to ../writeup/plots/contiguityMeasure/win1\n"
     ]
    }
   ],
   "source": [
    "# Plot histogram of reshuffled coefficients and highlight observed value\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define models and their explanations\n",
    "models = ['mod_a_coef', 'mod_b_coef', 'mod_c_coef', 'mod_d_coef', 'mod_e_coef']\n",
    "model_explanation = ['No FE', 'Major FE', 'Minor FE', 'No FE (minor df)', 'Major FE (minor df)']\n",
    "plot_colors = ['steelblue', 'orange', 'green', 'steelblue', 'orange']\n",
    "\n",
    "# Loop over models to create histograms\n",
    "for model, explanation, plot_color in zip(models, model_explanation, plot_colors):\n",
    "    plot_df = pd.read_csv(f\"{output_data_path}/reshuffle_regression_results_win{window_length}.csv\")\n",
    "    # Separate reshuffled (exclude 'observed')\n",
    "    reshuffled = plot_df[plot_df['seed'] != 'observed'] if 'seed' in plot_df.columns else plot_df\n",
    "    resh_vals = pd.to_numeric(reshuffled[model], errors='coerce').dropna()\n",
    "    obs_row = plot_df[plot_df['seed'] == 'observed'] if 'seed' in plot_df.columns else pd.DataFrame()\n",
    "    obs_val = float(obs_row[model].iloc[0])\n",
    "\n",
    "    pct = (resh_vals <= obs_val).mean() * 100\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.hist(resh_vals, bins=50, color=plot_color, edgecolor='black')\n",
    "    plt.axvline(obs_val, color='red', linestyle='--', linewidth=2, label=f'Observed (pctl={pct:.1f}%)')\n",
    "    plt.xlabel('Regression Coefficient')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title(f'Histogram of Reshuffled Task Assignments - {explanation} Regression (n={len(resh_vals)})\\n\\nWindow Length = {window_length*2 +1}, Dependent Var: is_ai')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    # save plot\n",
    "    save_path = f\"{output_plot_path}/win{window_length}\"\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    plt.savefig(f'{save_path}/hist_win{window_length}_{model}.png', dpi=300)\n",
    "    print('Saved plot to', save_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b0c18e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
