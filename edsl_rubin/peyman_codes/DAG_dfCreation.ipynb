{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('libraries.py') as f:\n",
    "    code = f.read()\n",
    "exec(code)\n",
    "\n",
    "with open('functions.py') as f:\n",
    "    code = f.read()\n",
    "exec(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine user\n",
    "user = getpass.getuser()\n",
    "if user == 'peymansh':\n",
    "    main_folder_path = '/Users/peymansh/Dropbox (MIT)/Research/AI and Occupations/ai-exposure'\n",
    "    data_path = f'{main_folder_path}/output'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick occupation and initialize variables\n",
    "occupation = 'travelAgents'\n",
    "#occupation = 'insuranceUnderwriters'\n",
    "\n",
    "GPT_input_occupation, plot_title_occupation, occupation_code, occupation_folder = pick_occupation(occupation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "onet = pd.read_csv(f'{data_path}/data/onet_occupations_yearly.csv')\n",
    "onet = onet.sort_values(by=['year', 'occ_code', 'occ_title', 'task_id'])\n",
    "onet = onet[onet['year'] == 2023].reset_index(drop=True)\n",
    "\n",
    "# Get list of tasks\n",
    "my_df = onet[(onet.occ_code == f'{occupation_code}') & (onet.year == 2023)]\n",
    "tasks = my_df['task'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "# Manual DAG df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read manual adjacency matrix\n",
    "manual_AM = pd.read_csv(f'{occupation_folder}/{occupation}_AM.csv', index_col=0)\n",
    "manual_AM = add_sink_node(manual_AM, occupation)\n",
    "\n",
    "# Initialize lists to store the source and target nodes\n",
    "sources = []\n",
    "targets = []\n",
    "\n",
    "# Iterate over the adjacency matrix to find ones and populate the lists\n",
    "for row_label, row in manual_AM.iterrows():\n",
    "    for col_label, value in row.items():\n",
    "        if value == 1:\n",
    "            sources.append(row_label)\n",
    "            targets.append(col_label)\n",
    "\n",
    "# Create data frame\n",
    "manual_DAG_df = pd.DataFrame({'source': sources, 'target': targets})\n",
    "\n",
    "# Save output\n",
    "manual_DAG_df.to_csv(f'{occupation_folder}/{occupation}_manual_DAG_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "# GPT DAG df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Step Method: Directly ask for pairwise comparison w/o giving the \"either\" option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f24bd2cb2bb44d618db9046df78a88a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare pair of tasks\n",
    "def task_relationships(occupation, tasks):\n",
    "    if '\"Sink\"' in tasks:\n",
    "        tasks.remove('\"Sink\"')\n",
    "\n",
    "    scenarios = [Scenario({\"occupation\": occupation, \"task_A\": task_A, \"task_B\": task_B}) \n",
    "        for task_A, task_B in combinations(tasks, 2)]\n",
    "\n",
    "    q = QuestionMultipleChoice(\n",
    "        question_name = \"ordering\",\n",
    "        question_text = dedent(\"\"\"\\\n",
    "            Consider {{ occupation }}. \n",
    "            And consider these two tasks: \n",
    "            A) {{ task_A }} \n",
    "            B) {{ task_B }}\n",
    "            What is the relationship between these tasks?\n",
    "            \"\"\"),\n",
    "        question_options = [\n",
    "            \"A would be done first\", \n",
    "            \"B would be done first\",\n",
    "            \"Not part of the same task sequence\"]\n",
    "    )\n",
    "    results = q.by(m4).by(scenarios).run(progress_bar = True)\n",
    "    return results\n",
    "\n",
    "results = task_relationships(GPT_input_occupation, tasks)\n",
    "#results.select(\"task_A\", \"task_B\", \"ordering\", \"comment.ordering_comment\").print()\n",
    "pairwise_relationships_wo_raw = results.select(\"task_A\", \"task_B\", \"ordering\", \"comment.ordering_comment\").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap columns and subset only those that are part of the same task sequence \n",
    "pairwise_relationships_wo = pairwise_relationships_wo_raw.copy()\n",
    "mask = pairwise_relationships_wo['answer.ordering'] == 'B would be done first'\n",
    "pairwise_relationships_wo.loc[mask, ['scenario.task_A', 'scenario.task_B']] = pairwise_relationships_wo.loc[mask, ['scenario.task_B', 'scenario.task_A']].values\n",
    "pairwise_relationships_wo.loc[mask, 'answer.ordering'] = 'A would be done first'\n",
    "pairwise_relationships_wo = pairwise_relationships_wo[pairwise_relationships_wo['answer.ordering']=='A would be done first']\n",
    "pairwise_relationships_wo = pairwise_relationships_wo[['scenario.task_A', 'scenario.task_B', 'comment.ordering_comment']]\n",
    "\n",
    "# Change column names\n",
    "pairwise_relationships_wo = pairwise_relationships_wo.rename(columns={'scenario.task_A': 'source', \n",
    "                                                                      'scenario.task_B': 'target', \n",
    "                                                                      'comment.ordering_comment': 'comment'})\n",
    "\n",
    "# Save output\n",
    "pairwise_relationships_wo.to_csv(f'{occupation_folder}/{occupation}_oneStepGPT_DAG_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two Steps Method: Give option of \"either\" and then filter symmetric edges\n",
    "### Step 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "039e342796ef4bb88ee17e424254881c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare pair of tasks\n",
    "def task_relationships(occupation, tasks):\n",
    "    if '\"Sink\"' in tasks:\n",
    "        tasks.remove('\"Sink\"')\n",
    "\n",
    "    scenarios = [Scenario({\"occupation\": occupation, \"task_A\": task_A, \"task_B\": task_B}) \n",
    "        for task_A, task_B in combinations(tasks, 2)]\n",
    "\n",
    "    q = QuestionMultipleChoice(\n",
    "        question_name = \"ordering\",\n",
    "        question_text = dedent(\"\"\"\\\n",
    "            Consider {{ occupation }}. \n",
    "            And consider these two tasks: \n",
    "            A) {{ task_A }} \n",
    "            B) {{ task_B }}\n",
    "            What is the relationship between these tasks?\n",
    "            \"\"\"),\n",
    "        question_options = [\n",
    "            \"A would be done first\", \n",
    "            \"B would be done first\",\n",
    "            \"Could be done in either order, but still part of the same sequence\",\n",
    "            \"Not part of the same task sequence\"]\n",
    "    )\n",
    "    results = q.by(m4).by(scenarios).run(progress_bar = True)\n",
    "    return results\n",
    "\n",
    "results = task_relationships(GPT_input_occupation, tasks)\n",
    "#results.select(\"task_A\", \"task_B\", \"ordering\", \"comment.ordering_comment\").print()\n",
    "pairwise_relationships_w_raw = results.select(\"task_A\", \"task_B\", \"ordering\", \"comment.ordering_comment\").to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7edabda1b7314429805dfb30806ad4e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# subset symmetric edges\n",
    "both_edges = pairwise_relationships_w_raw[pairwise_relationships_w_raw['answer.ordering'] == 'Could be done in either order, but still part of the same sequence']\n",
    "task_A_list = both_edges['scenario.task_A'].tolist()\n",
    "task_B_list = both_edges['scenario.task_B'].tolist()\n",
    "\n",
    "\n",
    "# Decide which one of symmetric edges to keep\n",
    "def pick_oneOf_symmetricEdges(occupation, task_A_list, task_B_list):\n",
    "    scenarios = [Scenario({\"occupation\": occupation, \"task_A\": task_A, \"task_B\": task_B}) \n",
    "        for task_A, task_B in zip(task_A_list, task_B_list)]\n",
    "\n",
    "    q = QuestionMultipleChoice(\n",
    "        question_name = \"ordering\",\n",
    "        question_text = dedent(\"\"\"\\\n",
    "            Consider {{ occupation }}. \n",
    "            And consider these two tasks: \n",
    "            A) {{ task_A }} \n",
    "            B) {{ task_B }}\n",
    "            What is the relationship between these tasks?\n",
    "            \"\"\"),\n",
    "        question_options = [\n",
    "            \"A would be done first\", \n",
    "            \"B would be done first\",]\n",
    "    )\n",
    "    results = q.by(m4).by(scenarios).run(progress_bar = True)\n",
    "    return results\n",
    "\n",
    "results = pick_oneOf_symmetricEdges(GPT_input_occupation, task_A_list, task_B_list)\n",
    "#results.select(\"task_A\", \"task_B\", \"ordering\", \"comment.ordering_comment\").print()\n",
    "which_symmetric_edge = results.select(\"task_A\", \"task_B\", \"ordering\", \"comment.ordering_comment\").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets\n",
    "pairwise_relationships_w = pairwise_relationships_w_raw[pairwise_relationships_w_raw['answer.ordering'].isin(['A would be done first', 'B would be done first'])]\n",
    "pairwise_relationships_w = pd.concat([pairwise_relationships_w, which_symmetric_edge], ignore_index=True)\n",
    "\n",
    "# Swap columns\n",
    "mask = pairwise_relationships_w['answer.ordering'] == 'B would be done first'\n",
    "pairwise_relationships_w.loc[mask, ['scenario.task_A', 'scenario.task_B']] = pairwise_relationships_w.loc[mask, ['scenario.task_B', 'scenario.task_A']].values\n",
    "pairwise_relationships_w.loc[mask, 'answer.ordering'] = 'A would be done first'\n",
    "pairwise_relationships_w = pairwise_relationships_w[pairwise_relationships_w['answer.ordering']=='A would be done first']\n",
    "pairwise_relationships_w = pairwise_relationships_w[['scenario.task_A', 'scenario.task_B', 'comment.ordering_comment']]\n",
    "\n",
    "# Change column names\n",
    "pairwise_relationships_w = pairwise_relationships_w.rename(columns={'scenario.task_A': 'source', \n",
    "                                                                    'scenario.task_B': 'target', \n",
    "                                                                    'comment.ordering_comment': 'comment'})\n",
    "\n",
    "# Save output\n",
    "pairwise_relationships_w.to_csv(f'{occupation_folder}/{occupation}_twoStepGPT_DAG_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "# GPT First Last Task Method df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use One Step Method: Directly ask for pairwise comparison w/o giving the \"either\" option\n",
    "### Next determine first and last task/tasks to be done in the sequence and ask GPT to produce DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast # for converting outputs to a list\n",
    "\n",
    "def first_last_tasks(occupation, tasks):\n",
    "    # Remove \"Sink\" node if it exists\n",
    "    if '\"Sink\"' in tasks:\n",
    "        tasks.remove('\"Sink\"')\n",
    "\n",
    "    scenarios = [Scenario({\"occupation\": GPT_input_occupation, \"tasks\": tasks})]\n",
    "\n",
    "    # First task\n",
    "    q1 = QuestionCheckBox(\n",
    "        question_name = \"firstTask\",\n",
    "        question_text = dedent(\"\"\"\\\n",
    "            Consider {{ occupation }}.\n",
    "            The tasks below are part of the job of a {{ occupation }}: {{ tasks }}.\n",
    "            Among the following, which task or set of tasks would be done before all other tasks in order to compelete the job?\n",
    "            \"\"\"),\n",
    "        question_options = tasks,\n",
    "        min_selections = 1,\n",
    "        max_selections = 3\n",
    "    )\n",
    "    results1 = q1.by(m4).by(scenarios).run().to_pandas()\n",
    "    first_task = results1['answer.firstTask'][0]\n",
    "    first_task = ast.literal_eval(first_task) # convert from string resembling list format to actual list\n",
    "\n",
    "\n",
    "    # Last task\n",
    "    q2 = QuestionCheckBox(\n",
    "        question_name = \"lastTask\",\n",
    "        question_text = dedent(\"\"\"\\\n",
    "            Consider {{ occupation }}. \n",
    "            The tasks below are part of the job of {{ occupation }}: {{ tasks }}.\n",
    "            Among the following, which task or set of tasks would be done after all other tasks are completed?\n",
    "            \"\"\"),\n",
    "        question_options = tasks,\n",
    "        min_selections = 1,\n",
    "        max_selections = 3\n",
    "    )\n",
    "    results2 = q2.by(m4).by(scenarios).run().to_pandas()\n",
    "    last_task = results2['answer.lastTask'][0]\n",
    "    last_task = ast.literal_eval(last_task) # convert from string resembling list format to actual list\n",
    "    \n",
    "    return first_task, last_task\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First task(s): ['Examine documents to determine degree of risk from factors such as applicant health, financial standing and value, and condition of property.', 'Write to field representatives, medical personnel, or others to obtain further information, quote rates, or explain company underwriting policies.', 'Review company records to determine amount of insurance in force on single risk or group of closely related risks.']\n",
      "Last task(s): ['Decline excessive risks.', 'Authorize reinsurance of policy when risk is high.'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "first_task, last_task = first_last_tasks(GPT_input_occupation, tasks)\n",
    "print(\"First task(s):\", first_task)\n",
    "print(\"Last task(s):\", last_task, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f49477a8ff4d4f1c9caa7172fc7f6b18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare pair of tasks\n",
    "def task_relationships_firstLast_included(occupation, tasks, first_task, last_task):\n",
    "    if '\"Sink\"' in tasks:\n",
    "        tasks.remove('\"Sink\"')\n",
    "\n",
    "    # Modify the first task and last task to appear as a single string\n",
    "    first_task = \" And \".join(first_task)\n",
    "    last_task = \" And \".join(last_task)\n",
    "\n",
    "    scenarios = [Scenario({\"occupation\": occupation, \n",
    "                           \"task_A\": task_A, \"task_B\": task_B,\n",
    "                           \"first_task\": first_task, \"last_task\": last_task}) \n",
    "                           for task_A, task_B in combinations(tasks, 2)]\n",
    "\n",
    "    q = QuestionMultipleChoice(\n",
    "        question_name = \"ordering\",\n",
    "        question_text = dedent(\"\"\"\\\n",
    "            Consider {{ occupation }}.\n",
    "            The first task (or set of tasks) to be completed for the job is: {{ first_task }}\n",
    "            The last task (or set of tasks) to be completed for the job is: {{ last_task }}. \n",
    "            Now consider these two tasks: \n",
    "            A) {{ task_A }} \n",
    "            B) {{ task_B }}\n",
    "            What is the relationship between these tasks?\n",
    "            \"\"\"),\n",
    "        question_options = [\n",
    "            \"A would be done first\", \n",
    "            \"B would be done first\",\n",
    "            \"Not part of the same task sequence\"]\n",
    "    )\n",
    "    results = q.by(m4).by(scenarios).run(progress_bar = True)\n",
    "    return results\n",
    "\n",
    "results = task_relationships_firstLast_included(GPT_input_occupation, tasks, first_task, last_task)\n",
    "#results.select(\"task_A\", \"task_B\", \"ordering\", \"comment.ordering_comment\").print()\n",
    "GPT_firstLast_df_raw = results.select(\"task_A\", \"task_B\", \"ordering\", \"comment.ordering_comment\").to_pandas()\n",
    "\n",
    "# Swap columns and subset only those that are part of the same task sequence \n",
    "GPT_firstLast_df = GPT_firstLast_df_raw.copy()\n",
    "mask = GPT_firstLast_df['answer.ordering'] == 'B would be done first'\n",
    "GPT_firstLast_df.loc[mask, ['scenario.task_A', 'scenario.task_B']] = GPT_firstLast_df.loc[mask, ['scenario.task_B', 'scenario.task_A']].values\n",
    "GPT_firstLast_df.loc[mask, 'answer.ordering'] = 'A would be done first'\n",
    "GPT_firstLast_df = GPT_firstLast_df[GPT_firstLast_df['answer.ordering']=='A would be done first']\n",
    "GPT_firstLast_df = GPT_firstLast_df[['scenario.task_A', 'scenario.task_B', 'comment.ordering_comment']]\n",
    "\n",
    "# Change column names\n",
    "GPT_firstLast_df = GPT_firstLast_df.rename(columns={'scenario.task_A': 'source', \n",
    "                                                    'scenario.task_B': 'target', \n",
    "                                                    'comment.ordering_comment': 'comment'})\n",
    "\n",
    "# Save output\n",
    "GPT_firstLast_df.to_csv(f'{occupation_folder}/{occupation}_firstLastTaskGPT_DAG_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "# GPT Triangles/Conditioning Method df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach: Use First Last method in creating original GPT DAG. Next use the \"Triangles\" or \"Conditioning\" method for narrowing down set of edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "### Step 1:\n",
    "\n",
    "#### Find all \"triangles\", defined as cases with:\n",
    "##### A --> B --> C\n",
    "##### A --> C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read output of one step GPT DAG\n",
    "GPT_AM_df = pd.read_csv(f'{occupation_folder}/{occupation}_firstLastTaskGPT_DAG_df.csv')\n",
    "\n",
    "# Convert GPT AM data frame to adjacency matrix\n",
    "GPT_AM = pd.DataFrame(0, index=tasks, columns=tasks)\n",
    "for index, row in GPT_AM_df.iterrows():\n",
    "    GPT_AM.at[row['source'], row['target']] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of triangles: [[1, 2, 0], [1, 2, 3], [1, 2, 5], [1, 3, 0], [1, 3, 5]]\n",
      "Count of triangles: 30\n"
     ]
    }
   ],
   "source": [
    "def find_triangles(matrix):\n",
    "    # Ensure matrix is a numpy array\n",
    "    if not isinstance(matrix, np.ndarray):\n",
    "        matrix = matrix.to_numpy()\n",
    "    \n",
    "    # get length of matrix\n",
    "    n = matrix.shape[0]\n",
    "\n",
    "    # create list containing integers from 0 to n-1 for indexing\n",
    "    numbers = list(range(n))\n",
    "\n",
    "    # Find triangles\n",
    "    triangles = []\n",
    "    for x, y, z in itertools.permutations(numbers, 3):\n",
    "        # get indices of destination nodes for outgoing edges of x\n",
    "        out_edges_destination_x = np.where(matrix[x] == 1)[0]\n",
    "        out_edges_destination_x = list(out_edges_destination_x)\n",
    "\n",
    "        # check if x has outgoing edge to both y and z\n",
    "        # if yes, check if y has outgoing edge to z\n",
    "        if y in out_edges_destination_x and z in out_edges_destination_x:\n",
    "            out_edges_destination_y = np.where(matrix[y] == 1)[0]\n",
    "            out_edges_destination_y = list(out_edges_destination_y)\n",
    "            \n",
    "            # check if y has outgoing edge to z\n",
    "            # if yes, we have a triangle\n",
    "            if z in out_edges_destination_y:\n",
    "                triangles.append([x, y, z])\n",
    "    \n",
    "    return triangles\n",
    "\n",
    "# Find triangles\n",
    "GPT_AM_triangles_list = find_triangles(GPT_AM)\n",
    "print(f'Examples of triangles: {GPT_AM_triangles_list[:5]}')\n",
    "print(f'Count of triangles: {len(GPT_AM_triangles_list)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: \n",
    "#### Ask GPT whether conditional on having B --> C we need A --> C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feb3af2bb0cf4e1fa43647135f072e2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def triangle_check(occupation, tasks, triangles_list):\n",
    "    triangles = np.array(triangles_list)\n",
    "    task_A_list = triangles[:, 0]\n",
    "    task_B_list = triangles[:, 1]\n",
    "    task_C_list = triangles[:, 2]\n",
    "    scenarios = [Scenario({\"occupation\": occupation, \"task_A\": tasks[task_A], \"task_B\": tasks[task_B], \"task_C\": tasks[task_C]}) \n",
    "        for task_A, task_B, task_C in zip(task_A_list, task_B_list, task_C_list)]\n",
    "\n",
    "    q = QuestionMultipleChoice(\n",
    "        question_name = \"ordering\",\n",
    "        question_text = dedent(\"\"\"\\\n",
    "            Consider {{ occupation }}. \n",
    "            And consider these three tasks: \n",
    "            A) {{ task_A }} \n",
    "            B) {{ task_B }}\n",
    "            C) {{ task_C }} \n",
    "            What are the prerequisites of doing task C?\n",
    "            \"\"\"),\n",
    "        question_options = [\n",
    "            \"C can be done after A without having to do B\",\n",
    "            \"C can only be done after B\",\n",
    "            \"These are not part of the same task sequence\"]\n",
    "    )\n",
    "    results = q.by(m4).by(scenarios).run(progress_bar = True)\n",
    "    return results\n",
    "\n",
    "results = triangle_check(GPT_input_occupation, tasks, GPT_AM_triangles_list)\n",
    "#results.select(\"task_A\", \"task_B\", \"task_C\", \"ordering\", \"comment.ordering_comment\").print()\n",
    "GPT_trianglesCheck_output = results.select(\"task_A\", \"task_B\", \"task_C\", \"ordering\", \"comment.ordering_comment\").to_pandas()\n",
    "GPT_trianglesCheck_output = GPT_trianglesCheck_output.sort_values(by=['scenario.task_A', 'scenario.task_C', 'scenario.task_B']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In cases where A --> C is shared among multiple triangles, only delete when all triangles say delete (lowers computation load for later cleanings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_trianglesCheck_output = results.select(\"task_A\", \"task_B\", \"task_C\", \"ordering\", \"comment.ordering_comment\").to_pandas()\n",
    "GPT_trianglesCheck_output = GPT_trianglesCheck_output.sort_values(by=['scenario.task_A', 'scenario.task_C', 'scenario.task_B'])\n",
    "\n",
    "# Step 1: Find the count of triangles for each A --> C pair\n",
    "GPT_trianglesCheck_output['AC_pair_triangles_count'] = GPT_trianglesCheck_output.groupby(['scenario.task_A', 'scenario.task_C'])['scenario.task_A'].transform('count')\n",
    "\n",
    "\n",
    "# Step 2: Find if all triangles say delete\n",
    "aux_df = GPT_trianglesCheck_output.groupby(['scenario.task_A', 'scenario.task_C'])['answer.ordering'].apply(lambda x: (x == 'C can only be done after B').all()).reset_index()\n",
    "\n",
    "# Rename the resulting columns for better readability\n",
    "aux_df.columns = ['scenario.task_A', 'scenario.task_C', 'delete_AC_pair']\n",
    "aux_df = aux_df[aux_df['delete_AC_pair']==True]\n",
    "edges_to_remove = aux_df[['scenario.task_A', 'scenario.task_C']].copy()\n",
    "\n",
    "\n",
    "# Step 3: Delete the rows where all triangles say delete\n",
    "modified_GPT_trianglesCheck_output = pd.merge(GPT_trianglesCheck_output, aux_df, how='left', \n",
    "                              on=['scenario.task_A', 'scenario.task_C'], \n",
    "                              indicator=True)\n",
    "modified_GPT_trianglesCheck_output = modified_GPT_trianglesCheck_output[modified_GPT_trianglesCheck_output['_merge'] == 'left_only'].drop(columns=['_merge', 'AC_pair_triangles_count', 'delete_AC_pair'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct a variable saying how many times each node appears in triangles.\n",
    "### Purpose: find quanrangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario.task_A</th>\n",
       "      <th>scenario.task_B</th>\n",
       "      <th>scenario.task_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Evaluate possibility of losses due to catastrophe or excessive insurance.</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    scenario.task_A  \\\n",
       "Evaluate possibility of losses due to catastrop...                2   \n",
       "\n",
       "                                                    scenario.task_B  \\\n",
       "Evaluate possibility of losses due to catastrop...                6   \n",
       "\n",
       "                                                    scenario.task_C  \n",
       "Evaluate possibility of losses due to catastrop...                3  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize an empty DataFrame with unique values as columns and original columns as rows\n",
    "aux_df = pd.DataFrame(0, index=['scenario.task_A', 'scenario.task_B', 'scenario.task_C'], columns=tasks)\n",
    "\n",
    "# Fill the new DataFrame with counts\n",
    "for col in modified_GPT_trianglesCheck_output[['scenario.task_A', 'scenario.task_B', 'scenario.task_C']].columns:\n",
    "    value_counts = modified_GPT_trianglesCheck_output[col].value_counts()\n",
    "    aux_df.loc[col, value_counts.index] = value_counts.values\n",
    "aux_df = aux_df.T\n",
    "\n",
    "# Keep tasks which are sometimes node A of a triangle and sometimes node B of a triangle\n",
    "aux_df = aux_df[(aux_df > 0).all(axis=1)]\n",
    "\n",
    "# get list of pivotal tasks\n",
    "pivotal_tasks = aux_df.index.tolist()\n",
    "aux_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_AC_DC = QuestionMultipleChoice(\n",
    "    question_name = \"AC_DC\",\n",
    "    question_text = dedent(\"\"\"\\\n",
    "        Consider {{ occupation }} as an occupation.\n",
    "        And consider these tasks: {{ tasks }}.           \n",
    "        As part of the steps leading up to completion of this job '{{ task_B }}' is done after '{{ task_A }}' but before '{{ task_C }}'.\n",
    "        Furthermore, '{{ task_A }}' is done after '{{ task_D }}' but before '{{ task_C }}'.\n",
    "        Given this structure, determine if A and D below are direct prerequisites of doing C?\n",
    "        A) {{ task_A }}\n",
    "        B) {{ task_B }}\n",
    "        C) {{ task_C }}\n",
    "        D) {{ task_D }}\n",
    "        \"\"\"),\n",
    "    question_options = [\n",
    "    \"C can be done after B only after both A and D have been done earlier\", # drop AC, drop DC\n",
    "    \"C can be done after A only after having done D first, but without having to do B\", # keep AC, drop DC\n",
    "    \"C can be done immediately after D without having to do A or B, but it cannot be done after A without having done D or B first\", # drop AC, keep DC\n",
    "    \"C can be done immediately after D without having to do A or B, and it can also be done after A without having done D or B\", # keep AC, keep DC\n",
    "    \"These are not part of the same task sequence\"\n",
    "    ]        \n",
    ")\n",
    "#results_AC_DC = q_AC_DC.by(m4).by(scenarios).run()\n",
    "#results_AC_DC.print()\n",
    "\n",
    "##### Note:\n",
    "##### must check these questions options. not sure if they work properly or our travel agents example is not a exhausting all possibilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the list of tuples and subset the DataFrame\n",
    "identifier = 1\n",
    "quadrangles_tasks = []\n",
    "quadrangles_df = pd.DataFrame()\n",
    "for A, B, C, D in itertools.permutations(tasks, 4):\n",
    "    # Initialize an empty list to collect the indices of desired rows\n",
    "    quadrangle_indices = []\n",
    "\n",
    "    # Find rows where triangle nodes are A, B, C\n",
    "    condition1 = (modified_GPT_trianglesCheck_output['scenario.task_A'] == A) & (modified_GPT_trianglesCheck_output['scenario.task_B'] == B) & (modified_GPT_trianglesCheck_output['scenario.task_C'] == C)\n",
    "    rows1 = modified_GPT_trianglesCheck_output[condition1]\n",
    "    \n",
    "    # Find rows where triangle nodes are D, A, C\n",
    "    condition2 = (modified_GPT_trianglesCheck_output['scenario.task_A'] == D) & (modified_GPT_trianglesCheck_output['scenario.task_B'] == A) & (modified_GPT_trianglesCheck_output['scenario.task_C'] == C)\n",
    "    rows2 = modified_GPT_trianglesCheck_output[condition2]\n",
    "    \n",
    "    # If both conditions are met, add the indices to the list\n",
    "    if not rows1.empty and not rows2.empty:\n",
    "        #print(f'Quadrangle {identifier}: A={A[:10]}, B={B[:10]}, C={C[:10]}, D={D[:10]}')\n",
    "        quadrangles_tasks.append((A, B, C, D))\n",
    "\n",
    "        # quadrangle_indices.extend(rows1.index)\n",
    "        # quadrangle_indices.extend(rows2.index)\n",
    "\n",
    "        # # Create a new DataFrame using the collected indices\n",
    "        # aux_df = modified_GPT_trianglesCheck_output[['scenario.task_A', 'scenario.task_B', 'scenario.task_C']].loc[quadrangle_indices].drop_duplicates()\n",
    "        # aux_df['identifier'] = identifier\n",
    "        # quadrangles_df = pd.concat([quadrangles_df, aux_df])\n",
    "        # identifier += 1\n",
    "    \n",
    "\n",
    "scenarios = [Scenario({\"occupation\": GPT_input_occupation, \"tasks\": tasks,\n",
    "                \"task_A\": A, \"task_B\": B, \"task_C\": C, \"task_D\": D})\n",
    "                for A, B, C, D in quadrangles_tasks]\n",
    "results_AC_DC = q_AC_DC.by(m4).by(scenarios).run()\n",
    "#results_AC_DC.select(['answer.AC_DC', 'scenario.task_A', 'scenario.task_B', 'scenario.task_C', 'scenario.task_D', 'comment.AC_DC_comment']).print()\n",
    "quadrangles_df = results_AC_DC.select(['answer.AC_DC', 'scenario.task_A', 'scenario.task_B', 'scenario.task_C', 'scenario.task_D', 'comment.AC_DC_comment']).to_pandas()\n",
    "\n",
    "# quadrangles_df = quadrangles_df.reset_index(drop=True)\n",
    "# quadrangles_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decide whether to keep or drop AC and DC\n",
    "quadrangles_df['keep_AC'] = quadrangles_df['answer.AC_DC'].apply(lambda x: x in ['C can be done after A only after having done D first, but without having to do B', \n",
    "                                                                                   'C can be done immediately after D without having to do A or B, and it can also be done after A without having done D or B'])\n",
    "quadrangles_df['keep_DC'] = quadrangles_df['answer.AC_DC'].apply(lambda x: x in ['C can be done immediately after D without having to do A or B, but it cannot be done after A without having done D or B first', \n",
    "                                                                                   'C can be done immediately after D without having to do A or B, and it can also be done after A without having done D or B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(input_list):\n",
    "    seen = set()\n",
    "    unique_list = []\n",
    "    for item in input_list:\n",
    "        if item not in seen:\n",
    "            unique_list.append(item)\n",
    "            seen.add(item)\n",
    "    return unique_list\n",
    "\n",
    "# Get list of unique edges involved in quadrangles\n",
    "pairs_AC = list(zip(quadrangles_df[\"scenario.task_A\"], quadrangles_df[\"scenario.task_C\"]))\n",
    "pairs_DC = list(zip(quadrangles_df[\"scenario.task_D\"], quadrangles_df[\"scenario.task_C\"]))\n",
    "all_pairs = pairs_AC + pairs_DC\n",
    "ACDC_edges_list = remove_duplicates(all_pairs)\n",
    "\n",
    "\n",
    "# Get list of edges to keep\n",
    "aux_df = quadrangles_df[quadrangles_df['keep_AC']==True]\n",
    "pairs_AC_toKeep = list(zip(aux_df[\"scenario.task_A\"], aux_df[\"scenario.task_C\"]))\n",
    "aux_df = quadrangles_df[quadrangles_df['keep_DC']==True]\n",
    "pairs_DC_toKeep = list(zip(aux_df[\"scenario.task_D\"], aux_df[\"scenario.task_C\"]))\n",
    "all_pairs_toKeep = pairs_AC_toKeep + pairs_DC_toKeep\n",
    "ACDC_edges_toKeep_list = remove_duplicates(all_pairs_toKeep)\n",
    "\n",
    "\n",
    "# Get list of edges to drop\n",
    "ACDC_edges_toDrop_list = [item for item in ACDC_edges_list if item not in ACDC_edges_toKeep_list]\n",
    "\n",
    "\n",
    "# Create a new DataFrame with the edges to drop\n",
    "ACDC_edges_to_remove = pd.DataFrame(ACDC_edges_toDrop_list, columns=[\"scenario.task_A\", \"scenario.task_C\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove redundant edges\n",
    "edges_to_remove = pd.concat([edges_to_remove, ACDC_edges_to_remove], ignore_index=True)\n",
    "\n",
    "modified_GPT_AM_df = GPT_AM_df.copy()\n",
    "modified_GPT_AM_df = pd.merge(modified_GPT_AM_df, edges_to_remove, how='left', \n",
    "                              left_on=['source', 'target'], right_on=['scenario.task_A', 'scenario.task_C'], \n",
    "                              indicator=True)\n",
    "modified_GPT_AM_df = modified_GPT_AM_df[modified_GPT_AM_df['_merge'] == 'left_only'].drop(columns=['_merge', 'scenario.task_A', 'scenario.task_C'])\n",
    "modified_GPT_AM_df = modified_GPT_AM_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue w/ deciding on edges\n",
    "Suppose we have the following structure:\n",
    "A --> B, B --> C\n",
    "A --> D, D --> C\n",
    "\n",
    "In the A --> B --> C, GPT says drop A --> C but in the A --> D --> C it says keep A --> C. We will keep it for now but I don't know its implications. Think about it later. Shared triangle source and targets (A and C tasks) are common in insurance underwriters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get edges to be removed in triangle cases\n",
    "# edges_to_remove = GPT_trianglesCheck_output[GPT_trianglesCheck_output['answer.ordering'] == \"C can only be done after B\"]\n",
    "# edges_to_remove = edges_to_remove[['scenario.task_A', 'scenario.task_C']]\n",
    "\n",
    "# # Remove redundant edges\n",
    "# modified_GPT_AM_df = GPT_AM_df.copy()\n",
    "# modified_GPT_AM_df = pd.merge(modified_GPT_AM_df, edges_to_remove, how='left', \n",
    "#                               left_on=['source', 'target'], right_on=['scenario.task_A', 'scenario.task_C'], \n",
    "#                               indicator=True)\n",
    "# modified_GPT_AM_df = modified_GPT_AM_df[modified_GPT_AM_df['_merge'] == 'left_only'].drop(columns=['_merge', 'scenario.task_A', 'scenario.task_C'])\n",
    "# modified_GPT_AM_df = modified_GPT_AM_df.reset_index(drop=True)\n",
    "# modified_GPT_AM_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get edges which survived the triangle check\n",
    "# survived_edges = GPT_trianglesCheck_output[GPT_trianglesCheck_output['answer.ordering'] == \"C can be done after A without having to do B\"]\n",
    "# survived_edges['pair_count'] = survived_edges.groupby(['scenario.task_A', 'scenario.task_C'])['scenario.task_A'].transform('count')\n",
    "# survived_edges = survived_edges[['scenario.task_A', 'scenario.task_C', 'comment.ordering_comment']]\n",
    "\n",
    "# # Merge back comments of survived edges\n",
    "# modified_GPT_AM_df = pd.merge(modified_GPT_AM_df, survived_edges, how='left', \n",
    "#                               left_on=['source', 'target'], right_on=['scenario.task_A', 'scenario.task_C'], \n",
    "#                               indicator=True)\n",
    "# modified_GPT_AM_df = modified_GPT_AM_df.rename(columns={'comment.ordering_comment': 'comment_triangles'})\n",
    "# modified_GPT_AM_df['comment_triangles'] = modified_GPT_AM_df['comment_triangles'].fillna('')\n",
    "# modified_GPT_AM_df\n",
    "\n",
    "# # Add triangle comments to the original comments\n",
    "# modified_GPT_AM_df['comment'] =  modified_GPT_AM_df['comment'] + ' \\n GPT comment in Triangle test iteration:\\n ' + modified_GPT_AM_df['comment_triangles']\n",
    "# modified_GPT_AM_df = modified_GPT_AM_df.drop(columns=['_merge', 'scenario.task_A', 'scenario.task_C', 'comment_triangles'])\n",
    "# modified_GPT_AM_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save output\n",
    "modified_GPT_AM_df.to_csv(f'{occupation_folder}/{occupation}_trianglesGPT_DAG_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
