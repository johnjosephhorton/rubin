{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('libraries.py') as f:\n",
    "    code = f.read()\n",
    "exec(code)\n",
    "\n",
    "with open('functions.py') as f:\n",
    "    code = f.read()\n",
    "exec(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine user\n",
    "user = getpass.getuser()\n",
    "if user == 'peymansh':\n",
    "    main_folder_path = '/Users/peymansh/Dropbox (MIT)/Research/AI and Occupations/ai-exposure'\n",
    "    data_path = f'{main_folder_path}/output'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick occupation and initialize variables\n",
    "occupation = 'travelAgents'\n",
    "occupation = 'insuranceUnderwriters'\n",
    "\n",
    "GPT_input_occupation, plot_title_occupation, occupation_code, occupation_folder = pick_occupation(occupation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "onet = pd.read_csv(f'{data_path}/data/onet_occupations_yearly.csv')\n",
    "onet = onet.sort_values(by=['year', 'occ_code', 'occ_title', 'task_id'])\n",
    "onet = onet[onet['year'] == 2023].reset_index(drop=True)\n",
    "\n",
    "# Get list of tasks\n",
    "my_df = onet[(onet.occ_code == f'{occupation_code}') & (onet.year == 2023)]\n",
    "tasks = my_df['task'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "# 1) Manual DAG df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read manual adjacency matrix\n",
    "manual_AM = pd.read_csv(f'{occupation_folder}/{occupation}_AM.csv', index_col=0)\n",
    "#manual_AM = add_sink_node(manual_AM, occupation)\n",
    "\n",
    "# Initialize lists to store the source and target nodes\n",
    "sources = []\n",
    "targets = []\n",
    "\n",
    "# Iterate over the adjacency matrix to find ones and populate the lists\n",
    "for row_label, row in manual_AM.iterrows():\n",
    "    for col_label, value in row.items():\n",
    "        if value == 1:\n",
    "            sources.append(row_label)\n",
    "            targets.append(col_label)\n",
    "\n",
    "# Create data frame\n",
    "manual_DAG_df = pd.DataFrame({'source': sources, 'target': targets})\n",
    "\n",
    "# Remove \"Sink\" node for now\n",
    "manual_DAG_df = manual_DAG_df[~manual_DAG_df.isin(['\"Sink\"']).any(axis=1)]\n",
    "\n",
    "# Save output\n",
    "manual_DAG_df.to_csv(f'{occupation_folder}/{occupation}_manual_DAG_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "# 2) GPT DAG df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) One Step Method: Directly ask for pairwise comparison w/o giving the \"either\" option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edb4f8538ef64e9f83868d1c692eb924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare pair of tasks\n",
    "def task_relationships(occupation, tasks):\n",
    "    if '\"Sink\"' in tasks:\n",
    "        tasks.remove('\"Sink\"')\n",
    "\n",
    "    scenarios = [Scenario({\"occupation\": occupation, \"task_A\": task_A, \"task_B\": task_B}) \n",
    "        for task_A, task_B in combinations(tasks, 2)]\n",
    "\n",
    "    q = QuestionMultipleChoice(\n",
    "        question_name = \"ordering\",\n",
    "        question_text = dedent(\"\"\"\\\n",
    "            Consider {{ occupation }}. \n",
    "            And consider these two tasks: \n",
    "            A) {{ task_A }} \n",
    "            B) {{ task_B }}\n",
    "            What is the relationship between these tasks?\n",
    "            \"\"\"),\n",
    "        question_options = [\n",
    "            \"A would be done first\", \n",
    "            \"B would be done first\",\n",
    "            \"Not part of the same task sequence\"]\n",
    "    )\n",
    "    results = q.by(m4).by(scenarios).run(progress_bar = True)\n",
    "    return results\n",
    "\n",
    "results = task_relationships(GPT_input_occupation, tasks)\n",
    "#results.select(\"task_A\", \"task_B\", \"ordering\", \"comment.ordering_comment\").print()\n",
    "pairwise_relationships_wo_raw = results.select(\"task_A\", \"task_B\", \"ordering\", \"comment.ordering_comment\").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap columns and subset only those that are part of the same task sequence \n",
    "pairwise_relationships_wo = pairwise_relationships_wo_raw.copy()\n",
    "mask = pairwise_relationships_wo['answer.ordering'] == 'B would be done first'\n",
    "pairwise_relationships_wo.loc[mask, ['scenario.task_A', 'scenario.task_B']] = pairwise_relationships_wo.loc[mask, ['scenario.task_B', 'scenario.task_A']].values\n",
    "pairwise_relationships_wo.loc[mask, 'answer.ordering'] = 'A would be done first'\n",
    "pairwise_relationships_wo = pairwise_relationships_wo[pairwise_relationships_wo['answer.ordering']=='A would be done first']\n",
    "pairwise_relationships_wo = pairwise_relationships_wo[['scenario.task_A', 'scenario.task_B', 'comment.ordering_comment']]\n",
    "\n",
    "# Change column names\n",
    "pairwise_relationships_wo = pairwise_relationships_wo.rename(columns={'scenario.task_A': 'source', \n",
    "                                                                      'scenario.task_B': 'target', \n",
    "                                                                      'comment.ordering_comment': 'comment'})\n",
    "\n",
    "# Save output\n",
    "pairwise_relationships_wo.to_csv(f'{occupation_folder}/{occupation}_oneStepGPT_DAG_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Two Steps Method: Give option of \"either\" and then filter symmetric edges\n",
    "### Step 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff22abd8500492aa446f09bbc02d07e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare pair of tasks\n",
    "def task_relationships(occupation, tasks):\n",
    "    if '\"Sink\"' in tasks:\n",
    "        tasks.remove('\"Sink\"')\n",
    "\n",
    "    scenarios = [Scenario({\"occupation\": occupation, \"task_A\": task_A, \"task_B\": task_B}) \n",
    "        for task_A, task_B in combinations(tasks, 2)]\n",
    "\n",
    "    q = QuestionMultipleChoice(\n",
    "        question_name = \"ordering\",\n",
    "        question_text = dedent(\"\"\"\\\n",
    "            Consider {{ occupation }}. \n",
    "            And consider these two tasks: \n",
    "            A) {{ task_A }} \n",
    "            B) {{ task_B }}\n",
    "            What is the relationship between these tasks?\n",
    "            \"\"\"),\n",
    "        question_options = [\n",
    "            \"A would be done first\", \n",
    "            \"B would be done first\",\n",
    "            \"Could be done in either order, but still part of the same sequence\",\n",
    "            \"Not part of the same task sequence\"]\n",
    "    )\n",
    "    results = q.by(m4).by(scenarios).run(progress_bar = True)\n",
    "    return results\n",
    "\n",
    "results = task_relationships(GPT_input_occupation, tasks)\n",
    "#results.select(\"task_A\", \"task_B\", \"ordering\", \"comment.ordering_comment\").print()\n",
    "pairwise_relationships_w_raw = results.select(\"task_A\", \"task_B\", \"ordering\", \"comment.ordering_comment\").to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a5dbc4193794015a7263452a2859fce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# subset symmetric edges\n",
    "both_edges = pairwise_relationships_w_raw[pairwise_relationships_w_raw['answer.ordering'] == 'Could be done in either order, but still part of the same sequence']\n",
    "task_A_list = both_edges['scenario.task_A'].tolist()\n",
    "task_B_list = both_edges['scenario.task_B'].tolist()\n",
    "\n",
    "\n",
    "# Decide which one of symmetric edges to keep\n",
    "def pick_oneOf_symmetricEdges(occupation, task_A_list, task_B_list):\n",
    "    scenarios = [Scenario({\"occupation\": occupation, \"task_A\": task_A, \"task_B\": task_B}) \n",
    "        for task_A, task_B in zip(task_A_list, task_B_list)]\n",
    "\n",
    "    q = QuestionMultipleChoice(\n",
    "        question_name = \"ordering\",\n",
    "        question_text = dedent(\"\"\"\\\n",
    "            Consider {{ occupation }}. \n",
    "            And consider these two tasks: \n",
    "            A) {{ task_A }} \n",
    "            B) {{ task_B }}\n",
    "            What is the relationship between these tasks?\n",
    "            \"\"\"),\n",
    "        question_options = [\n",
    "            \"A would be done first\", \n",
    "            \"B would be done first\",]\n",
    "    )\n",
    "    results = q.by(m4).by(scenarios).run(progress_bar = True)\n",
    "    return results\n",
    "\n",
    "results = pick_oneOf_symmetricEdges(GPT_input_occupation, task_A_list, task_B_list)\n",
    "#results.select(\"task_A\", \"task_B\", \"ordering\", \"comment.ordering_comment\").print()\n",
    "which_symmetric_edge = results.select(\"task_A\", \"task_B\", \"ordering\", \"comment.ordering_comment\").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets\n",
    "pairwise_relationships_w = pairwise_relationships_w_raw[pairwise_relationships_w_raw['answer.ordering'].isin(['A would be done first', 'B would be done first'])]\n",
    "pairwise_relationships_w = pd.concat([pairwise_relationships_w, which_symmetric_edge], ignore_index=True)\n",
    "\n",
    "# Swap columns\n",
    "mask = pairwise_relationships_w['answer.ordering'] == 'B would be done first'\n",
    "pairwise_relationships_w.loc[mask, ['scenario.task_A', 'scenario.task_B']] = pairwise_relationships_w.loc[mask, ['scenario.task_B', 'scenario.task_A']].values\n",
    "pairwise_relationships_w.loc[mask, 'answer.ordering'] = 'A would be done first'\n",
    "pairwise_relationships_w = pairwise_relationships_w[pairwise_relationships_w['answer.ordering']=='A would be done first']\n",
    "pairwise_relationships_w = pairwise_relationships_w[['scenario.task_A', 'scenario.task_B', 'comment.ordering_comment']]\n",
    "\n",
    "# Change column names\n",
    "pairwise_relationships_w = pairwise_relationships_w.rename(columns={'scenario.task_A': 'source', \n",
    "                                                                    'scenario.task_B': 'target', \n",
    "                                                                    'comment.ordering_comment': 'comment'})\n",
    "\n",
    "# Save output\n",
    "pairwise_relationships_w.to_csv(f'{occupation_folder}/{occupation}_twoStepGPT_DAG_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "# 3) GPT First Last Task Method df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use One Step Method: Directly ask for pairwise comparison w/o giving the \"either\" option\n",
    "### Next determine first and last task/tasks to be done in the sequence and ask GPT to produce DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_last_tasks(occupation, tasks):\n",
    "    # Remove \"Sink\" node if it exists\n",
    "    if '\"Sink\"' in tasks:\n",
    "        tasks.remove('\"Sink\"')\n",
    "\n",
    "    scenarios = [Scenario({\"occupation\": GPT_input_occupation, \"tasks\": tasks})]\n",
    "\n",
    "    # First task\n",
    "    q1 = QuestionCheckBox(\n",
    "        question_name = \"firstTask\",\n",
    "        question_text = dedent(\"\"\"\\\n",
    "            Consider {{ occupation }}.\n",
    "            The tasks below are part of the job of a {{ occupation }}: {{ tasks }}.\n",
    "            Among the following, which task or set of tasks would be done before all other tasks in order to compelete the job?\n",
    "            \"\"\"),\n",
    "        question_options = tasks,\n",
    "        min_selections = 1,\n",
    "        max_selections = 3\n",
    "    )\n",
    "    results1 = q1.by(m4).by(scenarios).run().to_pandas()\n",
    "    first_task = results1['answer.firstTask'][0]\n",
    "    first_task = ast.literal_eval(first_task) # convert from string resembling list format to actual list\n",
    "\n",
    "\n",
    "    # Last task\n",
    "    q2 = QuestionCheckBox(\n",
    "        question_name = \"lastTask\",\n",
    "        question_text = dedent(\"\"\"\\\n",
    "            Consider {{ occupation }}. \n",
    "            The tasks below are part of the job of {{ occupation }}: {{ tasks }}.\n",
    "            Among the following, which task or set of tasks would be done after all other tasks are completed?\n",
    "            \"\"\"),\n",
    "        question_options = tasks,\n",
    "        min_selections = 1,\n",
    "        max_selections = 3\n",
    "    )\n",
    "    results2 = q2.by(m4).by(scenarios).run().to_pandas()\n",
    "    last_task = results2['answer.lastTask'][0]\n",
    "    last_task = ast.literal_eval(last_task) # convert from string resembling list format to actual list\n",
    "    \n",
    "    return first_task, last_task\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First task(s): ['Examine documents to determine degree of risk from factors such as applicant health, financial standing and value, and condition of property.']\n",
      "Last task(s): ['Decline excessive risks.', 'Authorize reinsurance of policy when risk is high.'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "first_task, last_task = first_last_tasks(GPT_input_occupation, tasks)\n",
    "print(\"First task(s):\", first_task)\n",
    "print(\"Last task(s):\", last_task, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f5887ad2e9148eab43bba6497b5cc38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare pair of tasks\n",
    "def task_relationships_firstLast_included(occupation, tasks, first_task, last_task):\n",
    "    if '\"Sink\"' in tasks:\n",
    "        tasks.remove('\"Sink\"')\n",
    "\n",
    "    # Modify the first task and last task to appear as a single string\n",
    "    first_task = \" And \".join(first_task)\n",
    "    last_task = \" And \".join(last_task)\n",
    "\n",
    "    scenarios = [Scenario({\"occupation\": occupation, \n",
    "                           \"task_A\": task_A, \"task_B\": task_B,\n",
    "                           \"first_task\": first_task, \"last_task\": last_task}) \n",
    "                           for task_A, task_B in combinations(tasks, 2)]\n",
    "\n",
    "    q = QuestionMultipleChoice(\n",
    "        question_name = \"ordering\",\n",
    "        question_text = dedent(\"\"\"\\\n",
    "            Consider {{ occupation }}.\n",
    "            The first task (or set of tasks) to be completed for the job is: {{ first_task }}\n",
    "            The last task (or set of tasks) to be completed for the job is: {{ last_task }}. \n",
    "            Now consider these two tasks: \n",
    "            A) {{ task_A }} \n",
    "            B) {{ task_B }}\n",
    "            What is the relationship between these tasks?\n",
    "            \"\"\"),\n",
    "        question_options = [\n",
    "            \"A would be done first\", \n",
    "            \"B would be done first\",\n",
    "            \"Not part of the same task sequence\"]\n",
    "    )\n",
    "    results = q.by(m4).by(scenarios).run(progress_bar = True)\n",
    "    return results\n",
    "\n",
    "results = task_relationships_firstLast_included(GPT_input_occupation, tasks, first_task, last_task)\n",
    "#results.select(\"task_A\", \"task_B\", \"ordering\", \"comment.ordering_comment\").print()\n",
    "GPT_firstLast_df_raw = results.select(\"task_A\", \"task_B\", \"ordering\", \"comment.ordering_comment\").to_pandas()\n",
    "\n",
    "# Swap columns and subset only those that are part of the same task sequence \n",
    "GPT_firstLast_df = GPT_firstLast_df_raw.copy()\n",
    "mask = GPT_firstLast_df['answer.ordering'] == 'B would be done first'\n",
    "GPT_firstLast_df.loc[mask, ['scenario.task_A', 'scenario.task_B']] = GPT_firstLast_df.loc[mask, ['scenario.task_B', 'scenario.task_A']].values\n",
    "GPT_firstLast_df.loc[mask, 'answer.ordering'] = 'A would be done first'\n",
    "GPT_firstLast_df = GPT_firstLast_df[GPT_firstLast_df['answer.ordering']=='A would be done first']\n",
    "GPT_firstLast_df = GPT_firstLast_df[['scenario.task_A', 'scenario.task_B', 'comment.ordering_comment']]\n",
    "\n",
    "# Change column names\n",
    "GPT_firstLast_df = GPT_firstLast_df.rename(columns={'scenario.task_A': 'source', \n",
    "                                                    'scenario.task_B': 'target', \n",
    "                                                    'comment.ordering_comment': 'comment'})\n",
    "\n",
    "# Save output\n",
    "GPT_firstLast_df.to_csv(f'{occupation_folder}/{occupation}_firstLastTaskGPT_DAG_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "# 4) GPT Triangles/Conditioned Method df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach: Use First Last method in creating original GPT DAG. Next use the \"Triangles\" or \"Conditioning\" method for narrowing down set of edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "### Step 1:\n",
    "\n",
    "#### Find all \"triangles\", defined as cases with:\n",
    "##### A --> B --> C\n",
    "##### A --> C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read output of one step GPT DAG\n",
    "GPT_AM_df = pd.read_csv(f'{occupation_folder}/{occupation}_firstLastTaskGPT_DAG_df.csv')\n",
    "\n",
    "# Convert GPT AM data frame to adjacency matrix\n",
    "GPT_AM = pd.DataFrame(0, index=tasks, columns=tasks)\n",
    "for index, row in GPT_AM_df.iterrows():\n",
    "    GPT_AM.at[row['source'], row['target']] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of triangles: [[1, 3, 0], [1, 3, 5], [1, 4, 0], [1, 4, 3], [1, 4, 5]]\n",
      "Count of triangles: 29\n"
     ]
    }
   ],
   "source": [
    "def find_triangles(matrix):\n",
    "    # Ensure matrix is a numpy array\n",
    "    if not isinstance(matrix, np.ndarray):\n",
    "        matrix = matrix.to_numpy()\n",
    "    \n",
    "    # get length of matrix\n",
    "    n = matrix.shape[0]\n",
    "\n",
    "    # create list containing integers from 0 to n-1 for indexing\n",
    "    numbers = list(range(n))\n",
    "\n",
    "    # Find triangles\n",
    "    triangles = []\n",
    "    for x, y, z in itertools.permutations(numbers, 3):\n",
    "        # get indices of destination nodes for outgoing edges of x\n",
    "        out_edges_destination_x = np.where(matrix[x] == 1)[0]\n",
    "        out_edges_destination_x = list(out_edges_destination_x)\n",
    "\n",
    "        # check if x has outgoing edge to both y and z\n",
    "        # if yes, check if y has outgoing edge to z\n",
    "        if y in out_edges_destination_x and z in out_edges_destination_x:\n",
    "            out_edges_destination_y = np.where(matrix[y] == 1)[0]\n",
    "            out_edges_destination_y = list(out_edges_destination_y)\n",
    "            \n",
    "            # check if y has outgoing edge to z\n",
    "            # if yes, we have a triangle\n",
    "            if z in out_edges_destination_y:\n",
    "                triangles.append([x, y, z])\n",
    "    \n",
    "    return triangles\n",
    "\n",
    "# Find triangles\n",
    "GPT_AM_triangles_list = find_triangles(GPT_AM)\n",
    "print(f'Examples of triangles: {GPT_AM_triangles_list[:5]}')\n",
    "print(f'Count of triangles: {len(GPT_AM_triangles_list)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: \n",
    "#### Ask GPT whether conditional on having B --> C we need A --> C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ebc0f2e3dd84584b44ec9d72d419528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def triangle_check(occupation, tasks, triangles_list):\n",
    "    triangles = np.array(triangles_list)\n",
    "    task_A_list = triangles[:, 0]\n",
    "    task_B_list = triangles[:, 1]\n",
    "    task_C_list = triangles[:, 2]\n",
    "    scenarios = [Scenario({\"occupation\": occupation, \"task_A\": tasks[task_A], \"task_B\": tasks[task_B], \"task_C\": tasks[task_C]}) \n",
    "        for task_A, task_B, task_C in zip(task_A_list, task_B_list, task_C_list)]\n",
    "\n",
    "    q = QuestionMultipleChoice(\n",
    "        question_name = \"ordering\",\n",
    "        question_text = dedent(\"\"\"\\\n",
    "            Consider {{ occupation }}. \n",
    "            And consider these three tasks: \n",
    "            A) {{ task_A }} \n",
    "            B) {{ task_B }}\n",
    "            C) {{ task_C }} \n",
    "            What are the prerequisites of doing task C?\n",
    "            \"\"\"),\n",
    "        question_options = [\n",
    "            \"C can be done after A without having to do B\",\n",
    "            \"C can only be done after B\",\n",
    "            \"These are not part of the same task sequence\"]\n",
    "    )\n",
    "    results = q.by(m4).by(scenarios).run(progress_bar = True)\n",
    "    return results\n",
    "\n",
    "results = triangle_check(GPT_input_occupation, tasks, GPT_AM_triangles_list)\n",
    "#results.select(\"task_A\", \"task_B\", \"task_C\", \"ordering\", \"comment.ordering_comment\").print()\n",
    "GPT_trianglesCheck_output = results.select(\"task_A\", \"task_B\", \"task_C\", \"ordering\", \"comment.ordering_comment\").to_pandas()\n",
    "GPT_trianglesCheck_output = GPT_trianglesCheck_output.sort_values(by=['scenario.task_A', 'scenario.task_C', 'scenario.task_B']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In cases where A --> C is shared among multiple triangles, only delete when all triangles say delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_trianglesCheck_output = results.select(\"task_A\", \"task_B\", \"task_C\", \"ordering\", \"comment.ordering_comment\").to_pandas()\n",
    "GPT_trianglesCheck_output = GPT_trianglesCheck_output.sort_values(by=['scenario.task_A', 'scenario.task_C', 'scenario.task_B'])\n",
    "\n",
    "# Step 1: Find the count of triangles for each A --> C pair\n",
    "GPT_trianglesCheck_output['AC_pair_triangles_count'] = GPT_trianglesCheck_output.groupby(['scenario.task_A', 'scenario.task_C'])['scenario.task_A'].transform('count')\n",
    "\n",
    "\n",
    "# Step 2: Find if all triangles say delete\n",
    "aux_df = GPT_trianglesCheck_output.groupby(['scenario.task_A', 'scenario.task_C'])['answer.ordering'].apply(lambda x: (x == 'C can only be done after B').mean()*100).reset_index()\n",
    "aux_df.columns = ['scenario.task_A', 'scenario.task_C', 'fraction_triangles_say_delete']\n",
    "edges_to_remove = aux_df[aux_df['fraction_triangles_say_delete']==100]\n",
    "\n",
    "\n",
    "# Step 3: Delete the rows where all triangles say delete\n",
    "modified_GPT_trianglesCheck = pd.merge(GPT_trianglesCheck_output, edges_to_remove, how='left', \n",
    "                              on=['scenario.task_A', 'scenario.task_C'], \n",
    "                              indicator=True)\n",
    "modified_GPT_trianglesCheck = modified_GPT_trianglesCheck[modified_GPT_trianglesCheck['_merge'] == 'left_only'].drop(columns=['_merge', 'AC_pair_triangles_count', 'fraction_triangles_say_delete'])\n",
    "modified_GPT_trianglesCheck = modified_GPT_trianglesCheck.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a variable saying how many times each node appears as which node in a triangle\n",
    "##### Purpose: find quanrangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes stats as nodes A, B, C of a triangle:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario.task_A</th>\n",
       "      <th>scenario.task_B</th>\n",
       "      <th>scenario.task_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decline excessive risks.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Write to field representatives, medical personnel, or others to obtain further information, quote rates, or explain company underwriting policies.</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Evaluate possibility of losses due to catastrophe or excessive insurance.</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decrease value of policy when risk is substandard and specify applicable endorsements or apply rating to ensure safe, profitable distribution of risks, using reference materials.</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Review company records to determine amount of insurance in force on single risk or group of closely related risks.</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Authorize reinsurance of policy when risk is high.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Examine documents to determine degree of risk from factors such as applicant health, financial standing and value, and condition of property.</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    scenario.task_A  \\\n",
       "Decline excessive risks.                                          0   \n",
       "Write to field representatives, medical personn...                0   \n",
       "Evaluate possibility of losses due to catastrop...                5   \n",
       "Decrease value of policy when risk is substanda...                0   \n",
       "Review company records to determine amount of i...                2   \n",
       "Authorize reinsurance of policy when risk is high.                0   \n",
       "Examine documents to determine degree of risk f...               13   \n",
       "\n",
       "                                                    scenario.task_B  \\\n",
       "Decline excessive risks.                                          0   \n",
       "Write to field representatives, medical personn...                7   \n",
       "Evaluate possibility of losses due to catastrop...                5   \n",
       "Decrease value of policy when risk is substanda...                5   \n",
       "Review company records to determine amount of i...                3   \n",
       "Authorize reinsurance of policy when risk is high.                0   \n",
       "Examine documents to determine degree of risk f...                0   \n",
       "\n",
       "                                                    scenario.task_C  \n",
       "Decline excessive risks.                                          8  \n",
       "Write to field representatives, medical personn...                1  \n",
       "Evaluate possibility of losses due to catastrop...                0  \n",
       "Decrease value of policy when risk is substanda...                4  \n",
       "Review company records to determine amount of i...                1  \n",
       "Authorize reinsurance of policy when risk is high.                6  \n",
       "Examine documents to determine degree of risk f...                0  "
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize an empty DataFrame with unique values as columns and original columns as rows\n",
    "aux_df = pd.DataFrame(0, index=['scenario.task_A', 'scenario.task_B', 'scenario.task_C'], columns=tasks)\n",
    "\n",
    "# Fill the new DataFrame with counts\n",
    "for col in modified_GPT_trianglesCheck[['scenario.task_A', 'scenario.task_B', 'scenario.task_C']].columns:\n",
    "    value_counts = modified_GPT_trianglesCheck[col].value_counts()\n",
    "    aux_df.loc[col, value_counts.index] = value_counts.values\n",
    "aux_df = aux_df.T\n",
    "\n",
    "# Keep tasks which are sometimes node A of a triangle and sometimes node B of a triangle\n",
    "#aux_df = aux_df[(aux_df > 0).all(axis=1)]\n",
    "print('Nodes stats as nodes A, B, C of a triangle:')\n",
    "aux_df\n",
    "\n",
    "# get list of pivotal tasks\n",
    "#pivotal_tasks = aux_df.index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In cases where \n",
    "A --> B --> C and D --> A --> C \n",
    "##### the situation is different from when \n",
    "A --> B --> C and A --> D --> C\n",
    "##### In such cases, edges A --> C and D --> C must be considered simultaneously as triangles are not totally \"independent\". \n",
    "#### So we look for \"quadrangles\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_AC_DC = QuestionMultipleChoice(\n",
    "    question_name = \"AC_DC\",\n",
    "    question_text = dedent(\"\"\"\\\n",
    "        Consider {{ occupation }} as an occupation.\n",
    "        And consider these tasks: {{ tasks }}.           \n",
    "        As part of the steps leading up to completion of this job '{{ task_B }}' is done after '{{ task_A }}' but before '{{ task_C }}'.\n",
    "        Furthermore, '{{ task_A }}' is done after '{{ task_D }}' but before '{{ task_C }}'.\n",
    "        Given this structure, determine if A and D below are direct prerequisites of doing C?\n",
    "        A) {{ task_A }}\n",
    "        B) {{ task_B }}\n",
    "        C) {{ task_C }}\n",
    "        D) {{ task_D }}\n",
    "        \"\"\"),\n",
    "    question_options = [\n",
    "    \"C can be done after B only after both A and D have been done earlier\", # drop AC, drop DC\n",
    "    \"C can be done after A only after having done D first, but without having to do B\", # keep AC, drop DC\n",
    "    \"C can be done immediately after D without having to do A or B, but it cannot be done after A without having done D or B first\", # drop AC, keep DC\n",
    "    \"C can be done immediately after D without having to do A or B, and it can also be done after A without having done D or B\", # keep AC, keep DC\n",
    "    \"These are not part of the same task sequence\"\n",
    "    ]        \n",
    ")\n",
    "##### Note:\n",
    "##### must check these questions options. not sure if they work properly or our travel agents example is not a exhausting all possibilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the list of tuples and subset the DataFrame\n",
    "quadrangles_tasks = []\n",
    "for A, B, C, D in itertools.permutations(tasks, 4):\n",
    "    # Initialize an empty list to collect the indices of desired rows\n",
    "    quadrangle_indices = []\n",
    "\n",
    "    # Find rows where triangle nodes are A, B, C\n",
    "    condition1 = (modified_GPT_trianglesCheck['scenario.task_A'] == A) & (modified_GPT_trianglesCheck['scenario.task_B'] == B) & (modified_GPT_trianglesCheck['scenario.task_C'] == C)\n",
    "    rows1 = modified_GPT_trianglesCheck[condition1]\n",
    "    \n",
    "    # Find rows where triangle nodes are D, A, C\n",
    "    condition2 = (modified_GPT_trianglesCheck['scenario.task_A'] == D) & (modified_GPT_trianglesCheck['scenario.task_B'] == A) & (modified_GPT_trianglesCheck['scenario.task_C'] == C)\n",
    "    rows2 = modified_GPT_trianglesCheck[condition2]\n",
    "    \n",
    "    # If both conditions are met, add the indices to the list\n",
    "    if not rows1.empty and not rows2.empty:\n",
    "        quadrangles_tasks.append((A, B, C, D))    \n",
    "\n",
    "scenarios = [Scenario({\"occupation\": GPT_input_occupation, \"tasks\": tasks,\n",
    "                \"task_A\": A, \"task_B\": B, \"task_C\": C, \"task_D\": D})\n",
    "                for A, B, C, D in quadrangles_tasks]\n",
    "results_AC_DC = q_AC_DC.by(m4).by(scenarios).run()\n",
    "#results_AC_DC.select(['answer.AC_DC', 'scenario.task_A', 'scenario.task_B', 'scenario.task_C', 'scenario.task_D', 'comment.AC_DC_comment']).print()\n",
    "quadrangles_df = results_AC_DC.select(['answer.AC_DC', 'scenario.task_A', 'scenario.task_B', 'scenario.task_C', 'scenario.task_D', 'comment.AC_DC_comment']).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer.AC_DC</th>\n",
       "      <th>comment.AC_DC_comment</th>\n",
       "      <th>scenario.task_A</th>\n",
       "      <th>scenario.task_B</th>\n",
       "      <th>scenario.task_C</th>\n",
       "      <th>scenario.task_D</th>\n",
       "      <th>keep_AC</th>\n",
       "      <th>keep_DC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C can be done after A only after having done D...</td>\n",
       "      <td>C (Decline excessive risks) can be done after ...</td>\n",
       "      <td>Evaluate possibility of losses due to catastro...</td>\n",
       "      <td>Write to field representatives, medical person...</td>\n",
       "      <td>Decline excessive risks.</td>\n",
       "      <td>Review company records to determine amount of ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C can be done after A only after having done D...</td>\n",
       "      <td>According to the given structure, 'Decline exc...</td>\n",
       "      <td>Evaluate possibility of losses due to catastro...</td>\n",
       "      <td>Write to field representatives, medical person...</td>\n",
       "      <td>Decline excessive risks.</td>\n",
       "      <td>Examine documents to determine degree of risk ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C can be done after A only after having done D...</td>\n",
       "      <td>C (Decrease value of policy when risk is subst...</td>\n",
       "      <td>Evaluate possibility of losses due to catastro...</td>\n",
       "      <td>Write to field representatives, medical person...</td>\n",
       "      <td>Decrease value of policy when risk is substand...</td>\n",
       "      <td>Examine documents to determine degree of risk ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C can be done after A only after having done D...</td>\n",
       "      <td>C (Authorize reinsurance of policy when risk i...</td>\n",
       "      <td>Evaluate possibility of losses due to catastro...</td>\n",
       "      <td>Write to field representatives, medical person...</td>\n",
       "      <td>Authorize reinsurance of policy when risk is h...</td>\n",
       "      <td>Examine documents to determine degree of risk ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C can be done after A only after having done D...</td>\n",
       "      <td>C (Decline excessive risks) can be done after ...</td>\n",
       "      <td>Evaluate possibility of losses due to catastro...</td>\n",
       "      <td>Decrease value of policy when risk is substand...</td>\n",
       "      <td>Decline excessive risks.</td>\n",
       "      <td>Review company records to determine amount of ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C can be done after A only after having done D...</td>\n",
       "      <td>Based on the given structure, 'Decline excessi...</td>\n",
       "      <td>Evaluate possibility of losses due to catastro...</td>\n",
       "      <td>Decrease value of policy when risk is substand...</td>\n",
       "      <td>Decline excessive risks.</td>\n",
       "      <td>Examine documents to determine degree of risk ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C can be done after B only after both A and D ...</td>\n",
       "      <td>C (Authorize reinsurance of policy when risk i...</td>\n",
       "      <td>Evaluate possibility of losses due to catastro...</td>\n",
       "      <td>Decrease value of policy when risk is substand...</td>\n",
       "      <td>Authorize reinsurance of policy when risk is h...</td>\n",
       "      <td>Examine documents to determine degree of risk ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C can be done after B only after both A and D ...</td>\n",
       "      <td>C (Decline excessive risks) can be done after ...</td>\n",
       "      <td>Review company records to determine amount of ...</td>\n",
       "      <td>Evaluate possibility of losses due to catastro...</td>\n",
       "      <td>Decline excessive risks.</td>\n",
       "      <td>Examine documents to determine degree of risk ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C can be done after B only after both A and D ...</td>\n",
       "      <td>C (Decline excessive risks) can only be done a...</td>\n",
       "      <td>Review company records to determine amount of ...</td>\n",
       "      <td>Decrease value of policy when risk is substand...</td>\n",
       "      <td>Decline excessive risks.</td>\n",
       "      <td>Examine documents to determine degree of risk ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        answer.AC_DC  \\\n",
       "0  C can be done after A only after having done D...   \n",
       "1  C can be done after A only after having done D...   \n",
       "2  C can be done after A only after having done D...   \n",
       "3  C can be done after A only after having done D...   \n",
       "4  C can be done after A only after having done D...   \n",
       "5  C can be done after A only after having done D...   \n",
       "6  C can be done after B only after both A and D ...   \n",
       "7  C can be done after B only after both A and D ...   \n",
       "8  C can be done after B only after both A and D ...   \n",
       "\n",
       "                               comment.AC_DC_comment  \\\n",
       "0  C (Decline excessive risks) can be done after ...   \n",
       "1  According to the given structure, 'Decline exc...   \n",
       "2  C (Decrease value of policy when risk is subst...   \n",
       "3  C (Authorize reinsurance of policy when risk i...   \n",
       "4  C (Decline excessive risks) can be done after ...   \n",
       "5  Based on the given structure, 'Decline excessi...   \n",
       "6  C (Authorize reinsurance of policy when risk i...   \n",
       "7  C (Decline excessive risks) can be done after ...   \n",
       "8  C (Decline excessive risks) can only be done a...   \n",
       "\n",
       "                                     scenario.task_A  \\\n",
       "0  Evaluate possibility of losses due to catastro...   \n",
       "1  Evaluate possibility of losses due to catastro...   \n",
       "2  Evaluate possibility of losses due to catastro...   \n",
       "3  Evaluate possibility of losses due to catastro...   \n",
       "4  Evaluate possibility of losses due to catastro...   \n",
       "5  Evaluate possibility of losses due to catastro...   \n",
       "6  Evaluate possibility of losses due to catastro...   \n",
       "7  Review company records to determine amount of ...   \n",
       "8  Review company records to determine amount of ...   \n",
       "\n",
       "                                     scenario.task_B  \\\n",
       "0  Write to field representatives, medical person...   \n",
       "1  Write to field representatives, medical person...   \n",
       "2  Write to field representatives, medical person...   \n",
       "3  Write to field representatives, medical person...   \n",
       "4  Decrease value of policy when risk is substand...   \n",
       "5  Decrease value of policy when risk is substand...   \n",
       "6  Decrease value of policy when risk is substand...   \n",
       "7  Evaluate possibility of losses due to catastro...   \n",
       "8  Decrease value of policy when risk is substand...   \n",
       "\n",
       "                                     scenario.task_C  \\\n",
       "0                           Decline excessive risks.   \n",
       "1                           Decline excessive risks.   \n",
       "2  Decrease value of policy when risk is substand...   \n",
       "3  Authorize reinsurance of policy when risk is h...   \n",
       "4                           Decline excessive risks.   \n",
       "5                           Decline excessive risks.   \n",
       "6  Authorize reinsurance of policy when risk is h...   \n",
       "7                           Decline excessive risks.   \n",
       "8                           Decline excessive risks.   \n",
       "\n",
       "                                     scenario.task_D  keep_AC  keep_DC  \n",
       "0  Review company records to determine amount of ...     True    False  \n",
       "1  Examine documents to determine degree of risk ...     True    False  \n",
       "2  Examine documents to determine degree of risk ...     True    False  \n",
       "3  Examine documents to determine degree of risk ...     True    False  \n",
       "4  Review company records to determine amount of ...     True    False  \n",
       "5  Examine documents to determine degree of risk ...     True    False  \n",
       "6  Examine documents to determine degree of risk ...    False    False  \n",
       "7  Examine documents to determine degree of risk ...    False    False  \n",
       "8  Examine documents to determine degree of risk ...    False    False  "
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decide whether to keep or drop AC and DC\n",
    "quadrangles_df['keep_AC'] = quadrangles_df['answer.AC_DC'].apply(lambda x: x in ['C can be done after A only after having done D first, but without having to do B', \n",
    "                                                                                   'C can be done immediately after D without having to do A or B, and it can also be done after A without having done D or B'])\n",
    "quadrangles_df['keep_DC'] = quadrangles_df['answer.AC_DC'].apply(lambda x: x in ['C can be done immediately after D without having to do A or B, but it cannot be done after A without having done D or B first', \n",
    "                                                                                   'C can be done immediately after D without having to do A or B, and it can also be done after A without having done D or B'])\n",
    "quadrangles_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop extra AC and DC edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(input_list):\n",
    "    seen = set()\n",
    "    unique_list = []\n",
    "    for item in input_list:\n",
    "        if item not in seen:\n",
    "            unique_list.append(item)\n",
    "            seen.add(item)\n",
    "    return unique_list\n",
    "\n",
    "# Step 1: Get list of unique edges found in all quadrangles\n",
    "pairs_AC = list(zip(quadrangles_df[\"scenario.task_A\"], quadrangles_df[\"scenario.task_C\"]))\n",
    "pairs_DC = list(zip(quadrangles_df[\"scenario.task_D\"], quadrangles_df[\"scenario.task_C\"]))\n",
    "all_pairs = pairs_AC + pairs_DC\n",
    "ACDC_edges_list = remove_duplicates(all_pairs)\n",
    "\n",
    "\n",
    "# Step 2: Get list of edges to keep\n",
    "aux_df = quadrangles_df[quadrangles_df['keep_AC']==True]\n",
    "pairs_AC_toKeep = list(zip(aux_df[\"scenario.task_A\"], aux_df[\"scenario.task_C\"]))\n",
    "aux_df = quadrangles_df[quadrangles_df['keep_DC']==True]\n",
    "pairs_DC_toKeep = list(zip(aux_df[\"scenario.task_D\"], aux_df[\"scenario.task_C\"]))\n",
    "all_pairs_toKeep = pairs_AC_toKeep + pairs_DC_toKeep\n",
    "ACDC_edges_toKeep_list = remove_duplicates(all_pairs_toKeep)\n",
    "\n",
    "\n",
    "# Step 3: Get list of edges to drop\n",
    "ACDC_edges_toDrop_list = [item for item in ACDC_edges_list if item not in ACDC_edges_toKeep_list]\n",
    "\n",
    "\n",
    "# Create a DataFrame of edges to be dropped from this analysis and earlier analyses\n",
    "ACDC_edges_to_remove = pd.DataFrame(ACDC_edges_toDrop_list, columns=[\"scenario.task_A\", \"scenario.task_C\"])\n",
    "edges_to_remove = pd.concat([edges_to_remove, ACDC_edges_to_remove], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove redundant edges\n",
    "modified_GPT_AM_df = GPT_AM_df.copy()\n",
    "modified_GPT_AM_df = pd.merge(modified_GPT_AM_df, edges_to_remove, how='left', \n",
    "                              left_on=['source', 'target'], right_on=['scenario.task_A', 'scenario.task_C'], \n",
    "                              indicator=True)\n",
    "modified_GPT_AM_df = modified_GPT_AM_df[modified_GPT_AM_df['_merge'] == 'left_only'].drop(columns=['_merge', 'scenario.task_A', 'scenario.task_C'])\n",
    "modified_GPT_AM_df = modified_GPT_AM_df.reset_index(drop=True)\n",
    "\n",
    "# Save output\n",
    "modified_GPT_AM_df.to_csv(f'{occupation_folder}/{occupation}_conditionedGPT_DAG_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "# 5) GPT Task Partitioning Method df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start w/ breaking down the DAG into multiple minimally-connected subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb80186cbc414cbb89883a118abc285b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare pair of tasks\n",
    "def partition_tasks(occupation, tasks):\n",
    "    if '\"Sink\"' in tasks:\n",
    "        tasks.remove('\"Sink\"')\n",
    "\n",
    "    scenarios = [Scenario({\"occupation\": occupation, \"tasks\": tasks})]\n",
    "\n",
    "    q = QuestionFreeText(\n",
    "        question_name = \"partition\",\n",
    "        question_text = dedent(\"\"\"\\\n",
    "            Consider {{ occupation }}. \n",
    "            And consider these tasks: {{ tasks }}.\n",
    "            Can these tasks be partitioned into separate, minimally connected groups of tasks?\n",
    "            If so, give the number of groups and list tasks in each group. \n",
    "            Avoid using \\n in the answer, and list groups in the following format: Group x: ['task1', 'task2', 'task3'].\n",
    "            \"\"\")\n",
    "    )\n",
    "    results = q.by(m4).by(scenarios).run(progress_bar = True)\n",
    "    return results\n",
    "\n",
    "results = partition_tasks(GPT_input_occupation, tasks)\n",
    "#results.print()\n",
    "partition_tasks_output_str = results.select(\"answer.partition\").to_pandas().iloc[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group tasks into smaller partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: \"['Decline excessive risks.', 'Evaluate possibility of losses due to catastrophe or excessive insurance.', 'Decrease value of policy when risk is substandard and specify applicable endorsements or apply rating to ensure safe, profitable distribution of risks, using reference materials.', 'Authorize reinsurance of policy when risk is high.']\",\n",
       " 2: \"['Write to field representatives, medical personnel, or others to obtain further information, quote rates, or explain company underwriting policies.', 'Review company records to determine amount of insurance in force on single risk or group of closely related risks.', 'Examine documents to determine degree of risk from factors such as applicant health, financial standing and value, and condition of property.']\"}"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find all \"Group x\" occurrences in LLM output\n",
    "groups = re.findall(r'Group \\d+', partition_tasks_output_str)\n",
    "\n",
    "# Split the text at each \"Group x\"\n",
    "parts = re.split(r'(Group \\d+:)', partition_tasks_output_str)\n",
    "\n",
    "# Initialize a dictionary to hold the group texts\n",
    "partitions_dict = {}\n",
    "\n",
    "# Iterate through the parts and store the texts in the dictionary\n",
    "for i in range(1, len(parts), 2):\n",
    "    group_name = parts[i].strip(': ')\n",
    "    group_number = int(re.search(r'\\d+', group_name).group())\n",
    "    group_text = parts[i+1].strip().rstrip('.,')\n",
    "    \n",
    "    # Convert the string representation of the list to an actual list\n",
    "    partitions_dict[group_number] = group_text\n",
    "\n",
    "# Output the dictionary\n",
    "partitions_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine relation of partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5afde2e7f27f4680b37558ec5eca6bda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare pair of tasks\n",
    "def partition_relationships(occupation, partitions_dict):\n",
    "    scenarios = [Scenario({\"occupation\": occupation, \"partition_A\": A, \"partition_B\": B}) \n",
    "        for A, B in itertools.combinations(partitions_dict.values(), 2)]\n",
    "\n",
    "    q = QuestionMultipleChoice(\n",
    "        question_name = \"ordering\",\n",
    "        question_text = dedent(\"\"\"\\\n",
    "            Consider {{ occupation }}. \n",
    "            And consider these two partitions of tasks: \n",
    "            A) {{ partition_A }} \n",
    "            B) {{ partition_B }}\n",
    "            What is the relationship between these groups of tasks?\n",
    "            \"\"\"),\n",
    "        question_options = [\n",
    "            \"Tasks of partition A would be done first\", \n",
    "            \"Tasks of partition B would be done first\",\n",
    "            \"Could be done in either order, but still part of the same sequence\",\n",
    "            \"Not part of the same task sequence\"]\n",
    "    )\n",
    "    results = q.by(m4).by(scenarios).run(progress_bar = True)\n",
    "    return results\n",
    "\n",
    "results = partition_relationships(GPT_input_occupation, partitions_dict)\n",
    "#results.print()\n",
    "partitions_ordering_df = results.select(\"partition_A\", \"partition_B\", \"ordering\", \"ordering_comment\").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap columns so that all partitions in first column are done earlier\n",
    "mask = partitions_ordering_df['answer.ordering'] == 'Tasks of partition B would be done first'\n",
    "partitions_ordering_df.loc[mask, ['scenario.partition_A', 'scenario.partition_B']] = partitions_ordering_df.loc[mask, ['scenario.partition_B', 'scenario.partition_A']].values\n",
    "partitions_ordering_df.loc[mask, 'answer.ordering'] = 'Tasks of partition A would be done first'\n",
    "partitions_ordering_df = partitions_ordering_df[partitions_ordering_df['answer.ordering']=='Tasks of partition A would be done first']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer.ordering</th>\n",
       "      <th>comment.ordering_comment</th>\n",
       "      <th>scenario.partition_A</th>\n",
       "      <th>scenario.partition_B</th>\n",
       "      <th>partition_A_groupNum</th>\n",
       "      <th>partition_B_groupNum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tasks of partition A would be done first</td>\n",
       "      <td>Tasks of partition B involve gathering and rev...</td>\n",
       "      <td>['Write to field representatives, medical pers...</td>\n",
       "      <td>['Decline excessive risks.', 'Evaluate possibi...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            answer.ordering  \\\n",
       "0  Tasks of partition A would be done first   \n",
       "\n",
       "                            comment.ordering_comment  \\\n",
       "0  Tasks of partition B involve gathering and rev...   \n",
       "\n",
       "                                scenario.partition_A  \\\n",
       "0  ['Write to field representatives, medical pers...   \n",
       "\n",
       "                                scenario.partition_B  partition_A_groupNum  \\\n",
       "0  ['Decline excessive risks.', 'Evaluate possibi...                     2   \n",
       "\n",
       "   partition_B_groupNum  \n",
       "0                     1  "
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add group numbers to data frame\n",
    "aux_dict = {v: k for k, v in partitions_dict.items()}\n",
    "partitions_ordering_df['partition_A_groupNum'] = partitions_ordering_df['scenario.partition_A'].map(aux_dict)\n",
    "partitions_ordering_df['partition_B_groupNum'] = partitions_ordering_df['scenario.partition_B'].map(aux_dict)\n",
    "partitions_ordering_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f24de04caa3b4a73bd9ee947aab891ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f8ff418f39a45d3b2e6340d2ac13376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare pair of tasks within each partition\n",
    "def task_relationships_within_partition(occupation, tasks):\n",
    "    if '\"Sink\"' in tasks:\n",
    "        tasks.remove('\"Sink\"')\n",
    "\n",
    "    scenarios = [Scenario({\"occupation\": occupation, \"task_A\": task_A, \"task_B\": task_B}) \n",
    "        for task_A, task_B in combinations(tasks, 2)]\n",
    "\n",
    "    q = QuestionMultipleChoice(\n",
    "        question_name = \"ordering\",\n",
    "        question_text = dedent(\"\"\"\\\n",
    "            Consider {{ occupation }}. \n",
    "            And consider these two tasks: \n",
    "            A) {{ task_A }} \n",
    "            B) {{ task_B }}\n",
    "            What is the relationship between these tasks?\n",
    "            \"\"\"),\n",
    "        question_options = [\n",
    "            \"A would be done first\", \n",
    "            \"B would be done first\",\n",
    "            \"Not part of the same task sequence\"]\n",
    "    )\n",
    "    results = q.by(m4).by(scenarios).run(progress_bar = True)\n",
    "    return results\n",
    "\n",
    "\n",
    "# Function to handle apastrophes and commas in the list string\n",
    "def clean_list_string(s):\n",
    "    # Escape the apostrophe in specific problematic cases\n",
    "    s = re.sub(r\"(?<!\\\\)'s costs\", r\"\\\\'s costs\", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "task_relationships_within_partition_df = pd.DataFrame()\n",
    "for key, value in partitions_dict.items():\n",
    "    # Get list of tasks in the partition\n",
    "    my_partition_tasks = clean_list_string(value)\n",
    "    my_partition_tasks = ast.literal_eval(my_partition_tasks)\n",
    "    if len(my_partition_tasks) < 2:\n",
    "        continue\n",
    "\n",
    "    # Run the function\n",
    "    results = task_relationships_within_partition(GPT_input_occupation, my_partition_tasks)\n",
    "    aux_df = results.select(\"task_A\", \"task_B\", \"ordering\", \"comment.ordering_comment\").to_pandas()\n",
    "    aux_df['partition'] = key\n",
    "\n",
    "    # Add to data frame\n",
    "    task_relationships_within_partition_df = pd.concat([task_relationships_within_partition_df, aux_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebc1bfd74b5645a0a468adaf290f28dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare pair of tasks within each partition\n",
    "def task_relationships_between_partitions(occupation, tasks_partition1, tasks_partition2):\n",
    "    if '\"Sink\"' in tasks_partition1:\n",
    "        tasks_partition1.remove('\"Sink\"')\n",
    "    if '\"Sink\"' in tasks_partition2:\n",
    "        tasks_partition2.remove('\"Sink\"')\n",
    "    \n",
    "\n",
    "    scenarios = [Scenario({\"occupation\": occupation, \n",
    "                           \"tasks_partition1\": tasks_partition1, \"tasks_partition2\": tasks_partition2,\n",
    "                           \"task_A\": task_A, \"task_B\": task_B}) \n",
    "        for task_A, task_B in itertools.product(tasks_partition1, tasks_partition2)]\n",
    "\n",
    "    q = QuestionMultipleChoice(\n",
    "        question_name = \"ordering\",\n",
    "        question_text = dedent(\"\"\"\\\n",
    "            Consider {{ occupation }}. \n",
    "            And consider these two partitions of tasks; partition 1: {{ tasks_partition1 }} and partition 2: {{ tasks_partition2 }}.\n",
    "            We know that tasks in partition 1 would be done before tasks in partition 2.\n",
    "            Now consider these two tasks:\n",
    "            A) {{ task_A }} \n",
    "            B) {{ task_B }}\n",
    "            Knowing that task A is from partition 1 and task B is from partition 2, what is the relationship between these tasks?\n",
    "            \"\"\"),\n",
    "        question_options = [\n",
    "            \"A must be done in order to do B\", \n",
    "            \"A is not required for doing B\",\n",
    "            ]\n",
    "    )\n",
    "    results = q.by(m4).by(scenarios).run(progress_bar = True)\n",
    "    return results\n",
    "\n",
    "\n",
    "task_relationships_between_partitions_df = pd.DataFrame()\n",
    "for (key1, value1), (key2, value2) in itertools.combinations(partitions_dict.items(), 2):\n",
    "    # determine which partition is done first\n",
    "    if len(partitions_ordering_df[(partitions_ordering_df['partition_A_groupNum'] == key1) & (partitions_ordering_df['partition_B_groupNum'] == key2)]) > 0:\n",
    "        first_partition = key1\n",
    "        second_partition = key2\n",
    "    elif len(partitions_ordering_df[(partitions_ordering_df['partition_A_groupNum'] == key2) & (partitions_ordering_df['partition_B_groupNum'] == key1)]) > 0:\n",
    "        first_partition = key2\n",
    "        second_partition = key1\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    # Get list of tasks in the partition\n",
    "    tasks_partition1 = ast.literal_eval(clean_list_string(value1))\n",
    "    tasks_partition2 = ast.literal_eval(clean_list_string(value2))\n",
    "    \n",
    "    # Run the function\n",
    "    results = task_relationships_between_partitions(GPT_input_occupation, tasks_partition1, tasks_partition2)\n",
    "    aux_df = results.select(\"task_A\", \"task_B\", \"ordering\", \"comment.ordering_comment\").to_pandas()\n",
    "    \n",
    "    # Add to data frame\n",
    "    task_relationships_between_partitions_df = pd.concat([task_relationships_between_partitions_df, aux_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get edges from within and between partitions data frames\n",
    "between_edges = task_relationships_between_partitions_df[task_relationships_between_partitions_df['answer.ordering'] == 'A must be done in order to do B']\n",
    "between_edges = between_edges[['scenario.task_A', 'scenario.task_B', 'comment.ordering_comment']]\n",
    "within_edges = task_relationships_within_partition_df[['scenario.task_A', 'scenario.task_B', 'comment.ordering_comment']]\n",
    "\n",
    "# Combine edges from within and between partitions\n",
    "partitions_DAG_df = pd.concat([within_edges, between_edges], ignore_index=True)\n",
    "\n",
    "# Change column names\n",
    "partitions_DAG_df = partitions_DAG_df.rename(columns={'scenario.task_A': 'source', \n",
    "                                                    'scenario.task_B': 'target', \n",
    "                                                    'comment.ordering_comment': 'comment'})\n",
    "\n",
    "# Save output\n",
    "partitions_DAG_df.to_csv(f'{occupation_folder}/{occupation}_partitionedGPT_DAG_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
