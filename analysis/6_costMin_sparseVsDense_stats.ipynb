{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b861f4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('libraries.py') as f:\n",
    "    code = f.read()\n",
    "exec(code)\n",
    "\n",
    "with open('functions.py') as f:\n",
    "    code = f.read()\n",
    "exec(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e0c01952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['caffeinate']>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Run caffeinate in the background to prevent sleep\n",
    "subprocess.Popen(['caffeinate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "280bdd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine user\n",
    "user = getpass.getuser()\n",
    "if user == 'peymanshahidi':\n",
    "    main_folder_path = '/Users/peymanshahidi/Dropbox (MIT)/Research/AI and Occupations/ai-exposure'\n",
    "    data_path = f'{main_folder_path}/output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e7013ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tasks(onet_data_path,\n",
    "              occupation_code):\n",
    "\n",
    "    # Load the data\n",
    "    onet = pd.read_csv(onet_data_path)\n",
    "    onet = onet.sort_values(by=['year', 'occ_code', 'occ_title', 'task_id'])\n",
    "    onet = onet[onet['year'] == 2023].reset_index(drop=True)\n",
    "\n",
    "    # Get list of tasks\n",
    "    my_df = onet[(onet.occ_code == f'{occupation_code}') & (onet.year == 2023)]\n",
    "    tasks = my_df['task'].unique().tolist()\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5278ed9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate all path lengths from a node to the target node using DFS\n",
    "def dfs_count_paths(adj_matrix, current_node, target_node, path_length, path_lengths, visited):\n",
    "    if current_node == target_node:\n",
    "        path_lengths.append(path_length)\n",
    "        return\n",
    "\n",
    "    visited[current_node] = True\n",
    "    for neighbor in range(len(adj_matrix)):\n",
    "        if adj_matrix[current_node][neighbor] == 1 and not visited[neighbor]:\n",
    "            dfs_count_paths(adj_matrix, neighbor, target_node, path_length + 1, path_lengths, visited)\n",
    "    visited[current_node] = False\n",
    "\n",
    "# Function to calculate all path lengths from all nodes to the target node\n",
    "def calculate_all_path_lengths_to_target(adj_matrix):\n",
    "    # Number of nodes in the DAG\n",
    "    n = len(adj_matrix)\n",
    "    target_node = n - 1  # Index of the Target node\n",
    "\n",
    "    all_path_lengths = []\n",
    "\n",
    "    for start_node in range(n):\n",
    "        if start_node != target_node:\n",
    "            path_lengths = []\n",
    "            visited = [False] * n\n",
    "            dfs_count_paths(adj_matrix, start_node, target_node, 0, path_lengths, visited)\n",
    "            all_path_lengths.extend(path_lengths)\n",
    "\n",
    "    return all_path_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e8ef102e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparsity_calculator(adjacency_matrix):\n",
    "    # Number of nodes in the DAG\n",
    "    n = adjacency_matrix.shape[0]\n",
    "\n",
    "    # Calculate the number of edges\n",
    "    number_of_edges = np.sum(adjacency_matrix)\n",
    "\n",
    "    # Calculate the maximum possible number of edges in a directed graph\n",
    "    max_possible_edges = n * (n - 1)\n",
    "\n",
    "    # Calculate sparsity\n",
    "    sparsity = 1 - (number_of_edges / max_possible_edges)\n",
    "\n",
    "    return sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "34f9f6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_neighbors(adjacency_matrix):\n",
    "    # Get the number of nodes (n) from the shape of the adjacency matrix\n",
    "    n = adjacency_matrix.shape[0]\n",
    "    \n",
    "    # Initialize an empty dictionary to store the neighbors for each node\n",
    "    neighbors = {i: [] for i in range(n)}\n",
    "    \n",
    "    # Loop through each entry in the adjacency matrix\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            # If there's an edge from i to j or from j to i, add j to the neighbors of i\n",
    "            if adjacency_matrix[i, j] == 1 or adjacency_matrix[j, i] == 1:\n",
    "                if j not in neighbors[i]:  # Avoid duplicate neighbors\n",
    "                    neighbors[i].append(j)\n",
    "                if i not in neighbors[j]:  # Ensure symmetry in the undirected version\n",
    "                    neighbors[j].append(i)\n",
    "    \n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6ef4cc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inactive_node_neighbor_subset_combinations(inactive_neighbors_valid_subsets_dict):\n",
    "    # Step 1: Extract unique lists from the dictionary values\n",
    "    all_lists = [list(set(item)) for sublist in inactive_neighbors_valid_subsets_dict.values() for item in sublist]\n",
    "    print(f'Number of lists extracted: {len(all_lists)}')\n",
    "\n",
    "    # Step 2: Create all combinations and directly add unique elements\n",
    "    output_set = set()\n",
    "    \n",
    "    # Instead of recomputing length and duplicates, work with unique sets directly\n",
    "    all_combinations = []\n",
    "    \n",
    "    for r in range(1, len(all_lists) + 1):\n",
    "        for combo in itertools.combinations(all_lists, r):\n",
    "            # Convert each combination to a flattened tuple of sorted unique elements\n",
    "            flattened_combo = tuple(sorted(set(itertools.chain(*combo))))\n",
    "            output_set.add(flattened_combo)  # Add to set to ensure uniqueness\n",
    "    \n",
    "    # Convert the set back to sorted list of lists and return the result\n",
    "    output_list = [list(combo) for combo in output_set]\n",
    "    \n",
    "    return sorted(output_list, key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3b1312ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_connected(matrix):\n",
    "    # Number of nodes in the matrix\n",
    "    num_nodes = matrix.shape[0]\n",
    "    \n",
    "    # Visited array to keep track of visited nodes\n",
    "    visited = np.zeros(num_nodes, dtype=bool)\n",
    "    \n",
    "    # Helper function to perform DFS\n",
    "    def dfs(node):\n",
    "        visited[node] = True\n",
    "        # Visit all the neighbors of the current node\n",
    "        for neighbor in range(num_nodes):\n",
    "            if matrix[node, neighbor] == 1 and not visited[neighbor]:\n",
    "                dfs(neighbor)\n",
    "            elif matrix[neighbor, node] == 1 and not visited[neighbor]:\n",
    "                dfs(neighbor)\n",
    "    \n",
    "    # Start DFS from the first node (node 0)\n",
    "    dfs(0)\n",
    "    \n",
    "    # If all nodes are visited, the matrix is connected\n",
    "    return np.all(visited)\n",
    "\n",
    "\n",
    "def validate_partition_using_connectedness(adjacency_matrix, tasks_list):\n",
    "    # Return valid if Singleton\n",
    "    if len(tasks_list) == 1:\n",
    "        return True\n",
    "    # Check if partition forms connected graph\n",
    "    else:\n",
    "        # Subset original adjacency matrix\n",
    "        subset_matrix = adjacency_matrix[np.ix_(tasks_list, tasks_list)]\n",
    "\n",
    "        # check if subset matrix is a connected graph\n",
    "        subset_matrix_connected = is_connected(subset_matrix)\n",
    "\n",
    "        # return true if connected and false otherwise\n",
    "        return subset_matrix_connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f8c7a950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_partition_boundary(adjacency_matrix, partition):\n",
    "    # create a matrix whose columns are nodes not in the partition and whose rows are nodes in the partition\n",
    "    # (subset adjacency matrix to outgoing edges of partition nodes --i.e., rows-- and incoming edges of non-partition nodes --i.e., columns.)\n",
    "    reduced_matrix = np.delete(adjacency_matrix, partition, axis=1) \n",
    "    reduced_matrix = reduced_matrix[partition, :]\n",
    "\n",
    "    # find nodes in partition w/ an edge to non-partition nodes\n",
    "    partition_boundary_tasks = [i for i in partition if np.any(reduced_matrix[partition.index(i), :])]\n",
    "\n",
    "    return partition_boundary_tasks\n",
    "\n",
    "\n",
    "def compute_plan_cost(adjacency_matrix,\n",
    "                      execution_plan, \n",
    "                      human_labor_dict,\n",
    "                      machine_labor_dict, machine_management_dict, \n",
    "                      management_difficulty_dict, completion_difficulty_dict,\n",
    "                      AI_quality = 1e-8,\n",
    "                      human_labor_wage = 100,\n",
    "                      machine_management_wage = 100000,\n",
    "                      machine_automation_wage = 1000):\n",
    "    # initialize costs\n",
    "    human_tasks_list = []\n",
    "    managed_tasks_list = []\n",
    "    automated_tasks_list = []\n",
    "\n",
    "    total_cost = 0\n",
    "    for partition in execution_plan:\n",
    "        #print(f'Cost calculation partition: {partition}')\n",
    "        if len(partition) == 1:\n",
    "            human_labor_cost = sum(human_labor_dict[key] for key in partition)\n",
    "            \n",
    "            machine_management_cost = sum(machine_management_dict[key] for key in partition)\n",
    "            management_difficulty = sum(management_difficulty_dict[key] for key in partition)\n",
    "            management_cost = machine_management_cost * (AI_quality ** (-1 * management_difficulty))\n",
    "            \n",
    "            if human_labor_cost < management_cost:\n",
    "                total_cost += human_labor_cost * human_labor_wage\n",
    "                human_tasks_list.append(partition)\n",
    "            if human_labor_cost >= management_cost:\n",
    "                total_cost += management_cost * machine_management_wage\n",
    "                managed_tasks_list.append(partition)\n",
    "        else:\n",
    "            # determine which tasks are automated and which tasks are managed\n",
    "            managed_tasks = get_partition_boundary(adjacency_matrix, partition)\n",
    "            automated_tasks = [task for task in partition if task not in managed_tasks]\n",
    "            managed_tasks_list.append(managed_tasks)\n",
    "            automated_tasks_list.append(automated_tasks)\n",
    "\n",
    "            # calculate management cost of partition\n",
    "            machine_management_cost = sum(machine_management_dict[key] for key in managed_tasks)\n",
    "            management_difficulty = sum(management_difficulty_dict[key] for key in managed_tasks)\n",
    "            management_cost = machine_management_cost * (AI_quality ** (-1 * management_difficulty))\n",
    "            total_cost += management_cost * machine_management_wage\n",
    "\n",
    "            # calculate labor cost of partition\n",
    "            machine_automation_cost = sum(machine_labor_dict[key] for key in automated_tasks)\n",
    "            completion_difficulty = sum(completion_difficulty_dict[key] for key in automated_tasks)\n",
    "            machine_cost = machine_automation_cost * (AI_quality ** (-1 * completion_difficulty))\n",
    "            total_cost += machine_cost * machine_automation_wage\n",
    "\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bc3c7f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plan_to_active_dict(execution_plan, n):\n",
    "    # Initialize a dictionary with n keys, all set to False\n",
    "    init_dict = {i: False for i in range(n)}\n",
    "\n",
    "    # Iterate through each sublist and each item in the list of lists\n",
    "    for sublist in execution_plan:\n",
    "        for item in sublist:\n",
    "            # Keep only digits in the item\n",
    "            key = ''.join(filter(str.isdigit, str(item)))\n",
    "            if key.isdigit():  # Check if key is a valid digit\n",
    "                key = int(key)\n",
    "                if key in init_dict:  # Ensure key is within dictionary range\n",
    "                    init_dict[key] = True\n",
    "    return init_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9e30f196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_execution_plan_sorter(execution_plan):\n",
    "    # sort execution plan:\n",
    "    # 1. sort each partition in ascending order\n",
    "    # 2. sort partitions in ascending order\n",
    "    output = sorted([sorted(inner) for inner in execution_plan], key=len)\n",
    "    print(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fb93ca47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_min_cost_vars(adjacency_matrix,\n",
    "                         current_min_cost_plan, current_min_cost,\n",
    "                         current_plan,\n",
    "                         human_labor_dict, machine_labor_dict, machine_management_dict, \n",
    "                         management_difficulty_dict, completion_difficulty_dict,\n",
    "                         AI_quality):\n",
    "    \n",
    "    # calculate cost of current plan\n",
    "    current_plan_cost = compute_plan_cost(adjacency_matrix, current_plan, \n",
    "                                            human_labor_dict, machine_labor_dict, machine_management_dict, \n",
    "                                            management_difficulty_dict, completion_difficulty_dict,\n",
    "                                            AI_quality)\n",
    "                    \n",
    "    # if current_plan has lower cost than current_min_cost, update current_min_cost and current_min_cost_plan\n",
    "    if current_plan_cost < current_min_cost:\n",
    "\n",
    "        ######################################################## \n",
    "        # if costs are the same break tie in favor of more automation?\n",
    "        ########################################################\n",
    "\n",
    "        current_min_cost_plan = current_plan\n",
    "        current_min_cost = current_plan_cost\n",
    "        # print('--------------------------------------')\n",
    "        # print('*minimum-cost execution plan updated*')\n",
    "        # print(f'new min cost plan: {current_min_cost_plan}')\n",
    "        # print(f'new min cost: {current_min_cost}')\n",
    "\n",
    "    return current_min_cost_plan, current_min_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b3a0e75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def get_min_cost_plan(adjacency_matrix, \n",
    "                      human_labor_dict, machine_labor_dict, machine_management_dict, \n",
    "                      management_difficulty_dict, completion_difficulty_dict,\n",
    "                      AI_quality = 1e-8):\n",
    "\n",
    "    def compute_min_cost_recursive(adjacency_matrix, \n",
    "                                   neighbors_dict, active_dict, memory_dict, \n",
    "                                   current_node, current_plan,\n",
    "                                   current_min_cost_plan, current_min_cost,\n",
    "                                   AI_quality):\n",
    "        \n",
    "        ############################################################################################################################\n",
    "        def extended_plan_cost_check_and_append(adjacency_matrix, \n",
    "                                                human_labor_dict, machine_labor_dict, machine_management_dict, \n",
    "                                                management_difficulty_dict, completion_difficulty_dict,\n",
    "                                                current_plan, extended_plan,\n",
    "                                                current_node, active_nodes_list_excluding_current_node, active_nodes_tuple,\n",
    "                                                neighbors_dict, active_dict, memory_dict,\n",
    "                                                neighbor,\n",
    "                                                current_min_cost_plan, current_min_cost,\n",
    "                                                execution_plans_list,\n",
    "                                                AI_quality):\n",
    "            # check if need to pursue this plan\n",
    "            extended_plan_cost = compute_plan_cost(adjacency_matrix, current_plan, \n",
    "                                                    human_labor_dict, machine_labor_dict, machine_management_dict, \n",
    "                                                    management_difficulty_dict, completion_difficulty_dict,\n",
    "                                                    AI_quality)\n",
    "            if extended_plan_cost < current_min_cost:\n",
    "                # get acitve_dict for extended_plan\n",
    "                active_dict = plan_to_active_dict(extended_plan, n)\n",
    "\n",
    "                # calculate min cost and min cost plan for extended plan\n",
    "                current_min_cost_plan , current_min_cost, execution_plan = compute_min_cost_recursive(adjacency_matrix, \n",
    "                                                                                                    neighbors_dict, active_dict, memory_dict, \n",
    "                                                                                                    [neighbor], extended_plan,\n",
    "                                                                                                    current_min_cost_plan, current_min_cost,\n",
    "                                                                                                    AI_quality)\n",
    "                # sparse execution plan to update memory dict\n",
    "                for plan in execution_plan:\n",
    "                    exhausted_tasks = [item for sublist in plan for item in sublist]\n",
    "                    if len(exhausted_tasks) != n:\n",
    "                        continue\n",
    "\n",
    "                    current_node_index = next(i for i, sublist in enumerate(plan) if current_node[0] in sublist)\n",
    "                    extension = plan[current_node_index:]\n",
    "                    extension[0] = [item for item in extension[0] if item not in active_nodes_list_excluding_current_node]\n",
    "\n",
    "                    # update memory dict\n",
    "                    memory_dict[(active_nodes_tuple, tuple(current_node))].append(extension)\n",
    "\n",
    "                    # append plan to execution_plans_list\n",
    "                    execution_plans_list.append(plan)\n",
    "\n",
    "            return current_min_cost_plan, current_min_cost, execution_plans_list\n",
    "        ############################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "        # \"obvious\" stopping rules: \n",
    "        # 1) if current_min_cost_plan says automate all tasks then cannot do better than this\n",
    "        if len(current_min_cost_plan) == 1:\n",
    "            return current_min_cost_plan, current_min_cost, [current_plan]\n",
    "        \n",
    "        # 2) if current_plan has higher cost than current_min_cost then break (becomes important for neighbors of [0])\n",
    "        current_plan_cost = compute_plan_cost(adjacency_matrix, current_plan, \n",
    "                                              human_labor_dict, machine_labor_dict, machine_management_dict, \n",
    "                                              management_difficulty_dict, completion_difficulty_dict,\n",
    "                                              AI_quality)\n",
    "        if current_min_cost < current_plan_cost:\n",
    "            return current_min_cost_plan, current_min_cost, [current_plan]\n",
    "        \n",
    "        \n",
    "        # get active nodes list\n",
    "        active_nodes_list = [key for key, value in active_dict.items() if value == True]\n",
    "        active_nodes_list_excluding_current_node = [item for item in active_nodes_list if item not in current_node]\n",
    "        active_nodes_tuple = tuple(active_nodes_list_excluding_current_node)\n",
    "\n",
    "        # get inactive neighbors of current_plan nodes\n",
    "        current_plan_nodes = [item for sublist in current_plan for item in sublist]\n",
    "        neighbors_list = list(dict.fromkeys([value for key in current_plan_nodes if key in neighbors_dict for value in neighbors_dict[key]]))\n",
    "\n",
    "        inactive_neighbors_list = [neighbor for neighbor in neighbors_list if active_dict[neighbor] == False]\n",
    "\n",
    "\n",
    "        # if continuution of plan already calculated return it from memory\n",
    "        try:\n",
    "            if len(memory_dict[(active_nodes_tuple, tuple(current_node))]) > 0:\n",
    "\n",
    "                if len(inactive_neighbors_list) == 0:\n",
    "                    # if current_node is a last node, return current plan\n",
    "                    if memory_dict[(active_nodes_tuple, tuple(current_node))][0] == []:\n",
    "                        current_min_cost_plan, current_min_cost = update_min_cost_vars(adjacency_matrix,\n",
    "                                                                                       current_min_cost_plan, current_min_cost,\n",
    "                                                                                       current_plan,\n",
    "                                                                                       human_labor_dict, machine_labor_dict, machine_management_dict, \n",
    "                                                                                       management_difficulty_dict, completion_difficulty_dict,\n",
    "                                                                                       AI_quality)\n",
    "                        return current_min_cost_plan, current_min_cost, [current_plan]\n",
    "                    else:\n",
    "                        # generate all possible execution plans given extensions of current node\n",
    "                        execution_plans_list = []\n",
    "                        for extension in memory_dict[(active_nodes_tuple, tuple(current_node))]:\n",
    "                            # to generate execution plan:\n",
    "                            # 1) remove current node from last partition of current plan\n",
    "                            # 2) extend modified last partition of current plan with first partition of current extension\n",
    "                            # 3) add remaining partitions of current extension to the modified current plan\n",
    "                            modified_current_plan_last_partition = copy.deepcopy(current_plan[-1])\n",
    "                            modified_current_plan_last_partition.remove(current_node[0])\n",
    "                            extension_first_partition = copy.deepcopy(extension[0])\n",
    "                            modified_current_plan_last_partition += extension_first_partition\n",
    "\n",
    "                            # create execution plan\n",
    "                            execution_plan = current_plan[:-1] + [modified_current_plan_last_partition] + extension[1:]\n",
    "                            execution_plans_list.append(execution_plan)\n",
    "\n",
    "                            current_min_cost_plan, current_min_cost = update_min_cost_vars(adjacency_matrix,\n",
    "                                                                                           current_min_cost_plan, current_min_cost,\n",
    "                                                                                           execution_plan,\n",
    "                                                                                           human_labor_dict, machine_labor_dict, machine_management_dict, \n",
    "                                                                                           management_difficulty_dict, completion_difficulty_dict,\n",
    "                                                                                           AI_quality)\n",
    "\n",
    "                        return current_min_cost_plan, current_min_cost, execution_plans_list\n",
    "                    \n",
    "                else:\n",
    "                    # print(f'execution_plans_list: {execution_plans_list}')\n",
    "                    # print(f'current_plan: {current_plan}')\n",
    "\n",
    "                    execution_plans_list = []\n",
    "                    for neighbor in inactive_neighbors_list:\n",
    "                        # print(f'inactive neighbor [{neighbor}] of current plan {current_plan} **********************************************')\n",
    "\n",
    "\n",
    "                        #################################################################################################################################\n",
    "                        #################################################################################################################################\n",
    "                        \n",
    "                        # extend current_plan to include inactive neighbor\n",
    "                        # v1: add inactive neighbor as singletion partition to current_plan\n",
    "                        extended_plan = copy.deepcopy(current_plan)\n",
    "                        extended_plan += [[neighbor]]\n",
    "                        # extended_plan = [sorted(sublist) for sublist in extended_plan]\n",
    "\n",
    "\n",
    "            \n",
    "                        current_min_cost_plan, current_min_cost, execution_plans_list = extended_plan_cost_check_and_append(adjacency_matrix, \n",
    "                                                                                                                            human_labor_dict, machine_labor_dict, machine_management_dict, \n",
    "                                                                                                                            management_difficulty_dict, completion_difficulty_dict,\n",
    "                                                                                                                            current_plan, extended_plan,\n",
    "                                                                                                                            current_node, active_nodes_list_excluding_current_node, active_nodes_tuple,\n",
    "                                                                                                                            neighbors_dict, active_dict, memory_dict,\n",
    "                                                                                                                            neighbor,\n",
    "                                                                                                                            current_min_cost_plan, current_min_cost,\n",
    "                                                                                                                            execution_plans_list,\n",
    "                                                                                                                            AI_quality)\n",
    "\n",
    "                            \n",
    "                        # v2: extend last partition in current_plan by adding inactive neighbor to it\n",
    "                        extended_plan = copy.deepcopy(current_plan)\n",
    "                        extended_plan[-1].append(neighbor)\n",
    "                        # extended_plan = [sorted(sublist) for sublist in extended_plan]\n",
    "\n",
    "                        # check validity of extended_plan\n",
    "                        # (v2) extentions may not form a \"valid\" partition; if extension not valid skip \n",
    "                        if not validate_partition_using_connectedness(adjacency_matrix, extended_plan[-1]):\n",
    "                            aaa = 1\n",
    "                        else:\n",
    "                            current_min_cost_plan, current_min_cost, execution_plans_list = extended_plan_cost_check_and_append(adjacency_matrix, \n",
    "                                                                                                                                human_labor_dict, machine_labor_dict, machine_management_dict, \n",
    "                                                                                                                                management_difficulty_dict, completion_difficulty_dict,\n",
    "                                                                                                                                current_plan, extended_plan,\n",
    "                                                                                                                                current_node, active_nodes_list_excluding_current_node, active_nodes_tuple,\n",
    "                                                                                                                                neighbors_dict, active_dict, memory_dict,\n",
    "                                                                                                                                neighbor,\n",
    "                                                                                                                                current_min_cost_plan, current_min_cost,\n",
    "                                                                                                                                execution_plans_list,\n",
    "                                                                                                                                AI_quality)\n",
    "\n",
    "                    # hacky way of fixing no continuuation plan for current node:\n",
    "                    if len(memory_dict[(active_nodes_tuple, tuple(current_node))]) == 0:\n",
    "                        memory_dict[(active_nodes_tuple, tuple(current_node))] = [[]]\n",
    "                    \n",
    "                    return current_min_cost_plan , current_min_cost, execution_plans_list\n",
    "                    #################################################################################################################################\n",
    "                    #################################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "        # if partition not in memory, get valid subsets of partition\n",
    "        except KeyError:\n",
    "            # initialize memory dict key for current node\n",
    "            memory_dict[(active_nodes_tuple, tuple(current_node))] = []\n",
    "\n",
    "            if len(inactive_neighbors_list) == 0:\n",
    "                # populate memory dict with current extension of inactive nodes\n",
    "                extension = copy.deepcopy(current_plan[-1])\n",
    "                extension.remove(current_node[0])\n",
    "                inactive_extension = [item for item in extension if item not in active_nodes_list]\n",
    "                memory_dict[(active_nodes_tuple, tuple(current_node))].append(inactive_extension)\n",
    "\n",
    "                # update min cost vars\n",
    "                current_min_cost_plan, current_min_cost = update_min_cost_vars(adjacency_matrix,\n",
    "                                                                               current_min_cost_plan, current_min_cost,\n",
    "                                                                               current_plan,\n",
    "                                                                               human_labor_dict, machine_labor_dict, machine_management_dict, \n",
    "                                                                               management_difficulty_dict, completion_difficulty_dict,\n",
    "                                                                               AI_quality)\n",
    "                \n",
    "                return current_min_cost_plan, current_min_cost, [current_plan]\n",
    "            \n",
    "            \n",
    "            execution_plans_list = []\n",
    "            for neighbor in inactive_neighbors_list:\n",
    "\n",
    "                # extend current_plan to include inactive neighbor\n",
    "                # v1: add inactive neighbor as singletion partition to current_plan\n",
    "                extended_plan = copy.deepcopy(current_plan)\n",
    "                extended_plan += [[neighbor]]\n",
    "                # extended_plan = [sorted(sublist) for sublist in extended_plan]\n",
    "\n",
    "\n",
    "    \n",
    "                current_min_cost_plan, current_min_cost, execution_plans_list = extended_plan_cost_check_and_append(adjacency_matrix, \n",
    "                                                                                                                    human_labor_dict, machine_labor_dict, machine_management_dict, \n",
    "                                                                                                                    management_difficulty_dict, completion_difficulty_dict,\n",
    "                                                                                                                    current_plan, extended_plan,\n",
    "                                                                                                                    current_node, active_nodes_list_excluding_current_node, active_nodes_tuple,\n",
    "                                                                                                                    neighbors_dict, active_dict, memory_dict,\n",
    "                                                                                                                    neighbor,\n",
    "                                                                                                                    current_min_cost_plan, current_min_cost,\n",
    "                                                                                                                    execution_plans_list,\n",
    "                                                                                                                    AI_quality)\n",
    "\n",
    "                    \n",
    "                # v2: extend last partition in current_plan by adding inactive neighbor to it\n",
    "                extended_plan = copy.deepcopy(current_plan)\n",
    "                extended_plan[-1].append(neighbor)\n",
    "                # extended_plan = [sorted(sublist) for sublist in extended_plan]\n",
    "\n",
    "                # check validity of extended_plan\n",
    "                # (v2) extentions may not form a \"valid\" partition; if extension not valid skip \n",
    "                if not validate_partition_using_connectedness(adjacency_matrix, extended_plan[-1]):\n",
    "                    aaa = 1\n",
    "                else:\n",
    "                    current_min_cost_plan, current_min_cost, execution_plans_list = extended_plan_cost_check_and_append(adjacency_matrix, \n",
    "                                                                                                                        human_labor_dict, machine_labor_dict, machine_management_dict, \n",
    "                                                                                                                        management_difficulty_dict, completion_difficulty_dict,\n",
    "                                                                                                                        current_plan, extended_plan,\n",
    "                                                                                                                        current_node, active_nodes_list_excluding_current_node, active_nodes_tuple,\n",
    "                                                                                                                        neighbors_dict, active_dict, memory_dict,\n",
    "                                                                                                                        neighbor,\n",
    "                                                                                                                        current_min_cost_plan, current_min_cost,\n",
    "                                                                                                                        execution_plans_list,\n",
    "                                                                                                                        AI_quality)\n",
    "\n",
    "            # hacky way of fixing no continuuation plan for current node:\n",
    "            if len(memory_dict[(active_nodes_tuple, tuple(current_node))]) == 0:\n",
    "                memory_dict[(active_nodes_tuple, tuple(current_node))] = [[]]\n",
    "\n",
    "            return current_min_cost_plan , current_min_cost, execution_plans_list\n",
    "    \n",
    "    # subset adjacency matrix to exclude Target node\n",
    "    non_target_adjacency_matrix = adjacency_matrix[:-1,:-1].copy()\n",
    "    \n",
    "    # get neighbors of nodes\n",
    "    neighbors_dict = find_neighbors(non_target_adjacency_matrix)\n",
    "    \n",
    "    # get number of non-Target nodes\n",
    "    n = non_target_adjacency_matrix.shape[0]\n",
    "\n",
    "    # create active dictionary\n",
    "    active_dict = plan_to_active_dict([[0]], n)\n",
    "    \n",
    "    # initialize dict for valid subsets of nodes (and also partitions) to act as memory\n",
    "    memory_dict = {}\n",
    "\n",
    "    # initialize values and run function\n",
    "    current_min_cost_plan = []\n",
    "    current_min_cost = float('inf')\n",
    "    min_cost_plan, min_cost, _ = compute_min_cost_recursive(adjacency_matrix, \n",
    "                                                         neighbors_dict, active_dict, memory_dict, \n",
    "                                                         [0], [[0]],\n",
    "                                                         current_min_cost_plan, current_min_cost,\n",
    "                                                         AI_quality)\n",
    "    \n",
    "    return min_cost_plan, min_cost, memory_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea5fdb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad13251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8225ab90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689455ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "606d7f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DAG_costMin(input_path, alpha, num_tasks_current):\n",
    "    # read DAG\n",
    "    dag_df = pd.read_csv(input_path)\n",
    "\n",
    "    # remove edges if comment column labeled with \"TriangleRemovedFlag\" (edge is there for plotting purposes and is not part of the actual DAG)\n",
    "    if 'comment' in dag_df.columns:\n",
    "        dag_df = dag_df[~dag_df['comment'].str.endswith('TriangleRemovedFlag')]\n",
    "\n",
    "\n",
    "\n",
    "    # get task stats\n",
    "    tasks_stats = pd.read_csv(f'{occupation_folder}/{occupation}_taskStats.csv')\n",
    "\n",
    "\n",
    "\n",
    "    # extract list of tasks and create a dictionary for indexing tasks\n",
    "    tasks_list = tasks_stats['task'].unique()\n",
    "    tasks_dict = {i: node for i, node in enumerate(tasks_list, start=0)}\n",
    "\n",
    "    # create numpy array of adjacency matrix\n",
    "    adjacency_matrix = np.zeros((len(tasks_list), len(tasks_list)), dtype=int)\n",
    "    aux_dict = {value: key for key, value in tasks_dict.items()}\n",
    "    for _, row in dag_df.iterrows():\n",
    "        source_index = aux_dict[row['source']]\n",
    "        target_index = aux_dict[row['target']]\n",
    "        adjacency_matrix[source_index, target_index] = 1\n",
    "\n",
    "\n",
    "\n",
    "    # add task_dict key and reset index\n",
    "    aux_dict = {value: key for key, value in tasks_dict.items()}\n",
    "    tasks_stats['dict_index'] = tasks_stats.apply(lambda row: aux_dict[row.task], axis=1)\n",
    "    tasks_stats = tasks_stats.sort_values(by='dict_index')\n",
    "    tasks_stats = tasks_stats.set_index('dict_index', drop=False)\n",
    "    tasks_stats.index.name = None\n",
    "\n",
    "\n",
    "    ############################################################################################################\n",
    "    # generate DAG stats\n",
    "    num_nodes = num_tasks_current # number of non-Target nodes in the DAG\n",
    "    total_degree = len(dag_df) # total degree of the DAG\n",
    "    average_degree = total_degree / num_nodes # average degree per node\n",
    "\n",
    "    # path lengths to Target node\n",
    "    all_paths_to_target_lens = calculate_all_path_lengths_to_target(adjacency_matrix)\n",
    "    sum_paths_len_to_target = sum(all_paths_to_target_lens) # sum of path lengths to target node\n",
    "    max_path_len_to_target = max(all_paths_to_target_lens) # max path length to target node\n",
    "    avg_path_len_to_target = sum_paths_len_to_target / len(all_paths_to_target_lens) # avg path length to target node\n",
    "\n",
    "    # sparsity\n",
    "    sparsity = sparsity_calculator(adjacency_matrix) # sparsity of the DAG (1 - (number of edges / max possible edges))\n",
    "\n",
    "    # store DAG stats\n",
    "    DAG_stats = [num_nodes, total_degree, average_degree, \n",
    "                sum_paths_len_to_target, max_path_len_to_target, avg_path_len_to_target, \n",
    "                sparsity]\n",
    "    ############################################################################################################\n",
    "\n",
    "\n",
    "    # create dictionaries for human cost, management cost, and difficulty\n",
    "    human_labor_dict = dict(zip(tasks_stats['dict_index'], tasks_stats['human_cost']))\n",
    "    machine_labor_dict = dict(zip(tasks_stats['dict_index'], tasks_stats['machine_cost']))\n",
    "    machine_management_dict = dict(zip(tasks_stats['dict_index'], tasks_stats['management_cost']))\n",
    "    management_difficulty_dict = dict(zip(tasks_stats['dict_index'], tasks_stats['management_difficulty']))\n",
    "    completion_difficulty_dict = dict(zip(tasks_stats['dict_index'], tasks_stats['completion_difficulty']))\n",
    "\n",
    "\n",
    "\n",
    "    min_cost_plan, min_cost, memory_dict = get_min_cost_plan(adjacency_matrix, \n",
    "                                                            human_labor_dict, machine_labor_dict, machine_management_dict, \n",
    "                                                            management_difficulty_dict, completion_difficulty_dict,\n",
    "                                                            AI_quality = alpha)\n",
    "\n",
    "    # get number of execution plans covered (# of plans associated with the first node in memory_dict)\n",
    "    num_execution_plans_covered = len(memory_dict[list(memory_dict.keys())[0]])\n",
    "\n",
    "    return min_cost_plan, min_cost, num_execution_plans_covered, DAG_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58cb624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# set alpha as AI quality metric\n",
    "epsilon = 1e-8\n",
    "alpha_list = [epsilon, 0.5, 1-epsilon, 1e5]\n",
    "\n",
    "# set ONET data path\n",
    "onet_data_path = f'{data_path}/data/onet_occupations_yearly.csv'\n",
    "\n",
    "# list of occupations to create DAGs for\n",
    "occupation_list = ['pileDriverOperators', 'dredgeOperators', 'gradersAndSortersForAgriculturalProducts',\n",
    "                   'insuranceUnderwriters', 'insuranceAppraisersForAutoDamage', 'floorSandersAndFinishers', \n",
    "                   'reinforcingIronAndRebarWorkers', 'travelAgents', 'dataEntryKeyer', \n",
    "                   'athletesAndSportsCompetitors', 'audiovisualEquipmentInstallerAndRepairers', 'hearingAidSpecialists', \n",
    "                   'personalCareAides', \n",
    "                   'proofreadersAndCopyMarkers', 'chiropractors', \n",
    "                   'shippingReceivingAndInventoryClerks', 'cooksShortOrder', 'orthodontists',\n",
    "                   'subwayAndStreetcarOperators', 'packersAndPackagersHand', 'hoistAndWinchOperators', \n",
    "                   'forgingMachineSettersOperatorsAndTenders', 'avionicsTechnicians', 'dishwashers', \n",
    "                   'dispatchersExceptPoliceFireAndAmbulance', 'familyMedicinePhysicians', 'MachineFeedersAndOffbearers'\n",
    "                   ]\n",
    "\n",
    "occupation_list = ['proofreadersAndCopyMarkers', 'chiropractors', \n",
    "                   'shippingReceivingAndInventoryClerks', 'cooksShortOrder', 'orthodontists',\n",
    "                   'subwayAndStreetcarOperators', 'packersAndPackagersHand', 'hoistAndWinchOperators', \n",
    "                   'forgingMachineSettersOperatorsAndTenders', 'avionicsTechnicians', 'dishwashers', \n",
    "                   'dispatchersExceptPoliceFireAndAmbulance', 'familyMedicinePhysicians', 'MachineFeedersAndOffbearers'\n",
    "                   ]\n",
    "\n",
    "\n",
    "# output stats dataframe path\n",
    "stats_df_output_path = f'{main_folder_path}/sparseVsDense_DAGs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ecaf1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------- Running: proofreadersAndCopyMarkers ----------------------\n",
      "Number of non-Target tasks: 11\n",
      "\n",
      "-------Running: proofreadersAndCopyMarkers - Naive DAG - 1e-08-------\n",
      "\n",
      "proofreadersAndCopyMarkers Naive DAG (alpha = 1e-08) runtime: 2792.60 seconds\n",
      "\n",
      "-------Running: proofreadersAndCopyMarkers - Naive DAG - 0.5-------\n",
      "\n",
      "proofreadersAndCopyMarkers Naive DAG (alpha = 0.5) runtime: 1731.61 seconds\n",
      "\n",
      "-------Running: proofreadersAndCopyMarkers - Naive DAG - 0.99999999-------\n",
      "\n",
      "proofreadersAndCopyMarkers Naive DAG (alpha = 0.99999999) runtime: 3.69 seconds\n",
      "\n",
      "-------Running: proofreadersAndCopyMarkers - Naive DAG - 100000.0-------\n",
      "\n",
      "proofreadersAndCopyMarkers Naive DAG (alpha = 100000.0) runtime: 2.05 seconds\n",
      "\n",
      "-------Running: proofreadersAndCopyMarkers - Conditioned Naive DAG - 1e-08-------\n",
      "\n",
      "proofreadersAndCopyMarkers Conditioned Naive DAG (alpha = 1e-08) runtime: 642.25 seconds\n",
      "\n",
      "-------Running: proofreadersAndCopyMarkers - Conditioned Naive DAG - 0.5-------\n",
      "\n",
      "proofreadersAndCopyMarkers Conditioned Naive DAG (alpha = 0.5) runtime: 78.41 seconds\n",
      "\n",
      "-------Running: proofreadersAndCopyMarkers - Conditioned Naive DAG - 0.99999999-------\n",
      "\n",
      "proofreadersAndCopyMarkers Conditioned Naive DAG (alpha = 0.99999999) runtime: 1.91 seconds\n",
      "\n",
      "-------Running: proofreadersAndCopyMarkers - Conditioned Naive DAG - 100000.0-------\n",
      "\n",
      "proofreadersAndCopyMarkers Conditioned Naive DAG (alpha = 100000.0) runtime: 0.11 seconds\n",
      "\n",
      "-------Running: proofreadersAndCopyMarkers - First-Last Task DAG - 1e-08-------\n",
      "\n",
      "proofreadersAndCopyMarkers First-Last Task DAG (alpha = 1e-08) runtime: 1340.99 seconds\n",
      "\n",
      "-------Running: proofreadersAndCopyMarkers - First-Last Task DAG - 0.5-------\n",
      "\n",
      "proofreadersAndCopyMarkers First-Last Task DAG (alpha = 0.5) runtime: 967.08 seconds\n",
      "\n",
      "-------Running: proofreadersAndCopyMarkers - First-Last Task DAG - 0.99999999-------\n",
      "\n",
      "proofreadersAndCopyMarkers First-Last Task DAG (alpha = 0.99999999) runtime: 31995.82 seconds\n",
      "\n",
      "-------Running: proofreadersAndCopyMarkers - First-Last Task DAG - 100000.0-------\n",
      "\n",
      "proofreadersAndCopyMarkers First-Last Task DAG (alpha = 100000.0) runtime: 0.26 seconds\n",
      "\n",
      "-------Running: proofreadersAndCopyMarkers - Conditioned First-Last Task DAG - 1e-08-------\n",
      "\n",
      "proofreadersAndCopyMarkers Conditioned First-Last Task DAG (alpha = 1e-08) runtime: 286.26 seconds\n",
      "\n",
      "-------Running: proofreadersAndCopyMarkers - Conditioned First-Last Task DAG - 0.5-------\n",
      "\n",
      "proofreadersAndCopyMarkers Conditioned First-Last Task DAG (alpha = 0.5) runtime: 832.45 seconds\n",
      "\n",
      "-------Running: proofreadersAndCopyMarkers - Conditioned First-Last Task DAG - 0.99999999-------\n",
      "\n",
      "proofreadersAndCopyMarkers Conditioned First-Last Task DAG (alpha = 0.99999999) runtime: 17736.61 seconds\n",
      "\n",
      "-------Running: proofreadersAndCopyMarkers - Conditioned First-Last Task DAG - 100000.0-------\n",
      "\n",
      "proofreadersAndCopyMarkers Conditioned First-Last Task DAG (alpha = 100000.0) runtime: 0.53 seconds\n",
      "\n",
      "-------Running: proofreadersAndCopyMarkers - Partitioned DAG - 1e-08-------\n",
      "\n",
      "proofreadersAndCopyMarkers Partitioned DAG (alpha = 1e-08) runtime: 2523.62 seconds\n",
      "\n",
      "-------Running: proofreadersAndCopyMarkers - Partitioned DAG - 0.5-------\n",
      "\n",
      "proofreadersAndCopyMarkers Partitioned DAG (alpha = 0.5) runtime: 3503.42 seconds\n",
      "\n",
      "-------Running: proofreadersAndCopyMarkers - Partitioned DAG - 0.99999999-------\n",
      "\n",
      "proofreadersAndCopyMarkers Partitioned DAG (alpha = 0.99999999) runtime: 8.42 seconds\n",
      "\n",
      "-------Running: proofreadersAndCopyMarkers - Partitioned DAG - 100000.0-------\n",
      "\n",
      "proofreadersAndCopyMarkers Partitioned DAG (alpha = 100000.0) runtime: 216.54 seconds\n",
      "\n",
      "-------Running: proofreadersAndCopyMarkers - Conditioned Partitioned DAG - 1e-08-------\n"
     ]
    }
   ],
   "source": [
    "# initialize a dataframe\n",
    "col_names = ['occupation', 'DAG_type', 'alpha', 'num_tasks', 'DAG_sparsity', 'num_execution_plans_covered',\n",
    "        'total_degree', 'average_degree', 'sum_paths_len_to_target', 'max_path_len_to_target', 'avg_path_len_to_target',\n",
    "        'min_cost', 'min_cost_plan', 'exec_time_sec', 'exec_time_min']\n",
    "nrows = len(occupation_list) * len(alpha_list) * 7\n",
    "stats_df = pd.DataFrame(index=range(nrows), columns=col_names)\n",
    "\n",
    "my_index = 0\n",
    "for occupation in occupation_list:\n",
    "    print(f'\\n---------------------- Running: {occupation} ----------------------')\n",
    "    occupation_start_time = time.time()\n",
    "\n",
    "    # generate occupation-specific strings\n",
    "    GPT_input_occupation, plot_title_occupation, occupation_code, occupation_folder = pick_occupation(occupation)\n",
    "\n",
    "\n",
    "    # Get occupation tasks to create all possible partitions\n",
    "    tasks = get_tasks(onet_data_path, occupation_code)\n",
    "    num_tasks_current = len(tasks)\n",
    "    print(f'Number of non-Target tasks: {num_tasks_current}')\n",
    "\n",
    "    # Manual DAG\n",
    "    M_input_path = f'{occupation_folder}/{occupation}_M_DAG_df.csv'\n",
    "\n",
    "    # Naive DAG\n",
    "    N_input_path = f'{occupation_folder}/{occupation}_N_GPT_DAG_df.csv'\n",
    "\n",
    "    # Conditioned Naive DAG\n",
    "    CN_input_path = f'{occupation_folder}/{occupation}_CN_GPT_DAG_df.csv'\n",
    "\n",
    "    # First Last Task DAG\n",
    "    FLT_input_path = f'{occupation_folder}/{occupation}_FLT_GPT_DAG_df.csv'\n",
    "\n",
    "    # Conditioned First Last Task DAG\n",
    "    CFLT_input_path = f'{occupation_folder}/{occupation}_CFLT_GPT_DAG_df.csv'\n",
    "\n",
    "    # Partitioned DAG\n",
    "    P_input_path = f'{occupation_folder}/{occupation}_P_GPT_DAG_df.csv'\n",
    "\n",
    "    # Conditioned Partitioned DAG\n",
    "    CP_input_path = f'{occupation_folder}/{occupation}_CP_GPT_DAG_df.csv'\n",
    "    \n",
    "\n",
    "    # create list of all DAGs\n",
    "    if occupation in ['travelAgents', 'insuranceUnderwriters', 'pileDriverOperators']:\n",
    "        DAG_indicator_list = ['Manual DAG', 'Naive DAG', 'Conditioned Naive DAG', 'First-Last Task DAG', 'Conditioned First-Last Task DAG', 'Partitioned DAG', 'Conditioned Partitioned DAG']\n",
    "        input_paths_list = [M_input_path, N_input_path, CN_input_path, FLT_input_path, CFLT_input_path, P_input_path, CP_input_path]\n",
    "    else:\n",
    "        DAG_indicator_list = ['Naive DAG', 'Conditioned Naive DAG', 'First-Last Task DAG', 'Conditioned First-Last Task DAG', 'Partitioned DAG', 'Conditioned Partitioned DAG']\n",
    "        input_paths_list = [N_input_path, CN_input_path, FLT_input_path, CFLT_input_path, P_input_path, CP_input_path]\n",
    "\n",
    "\n",
    "    for DAG_indicator, input_path in zip(DAG_indicator_list, input_paths_list):\n",
    "        for alpha in alpha_list:\n",
    "\n",
    "            print(f'\\n-------Running: {occupation} - {DAG_indicator} - {alpha}-------')\n",
    "            \n",
    "            DAG_start_time = time.time()\n",
    "            min_cost_plan, min_cost, num_execution_plans_covered, DAG_stats = DAG_costMin(input_path, alpha, num_tasks_current)\n",
    "            DAG_end_time = time.time()\n",
    "            \n",
    "\n",
    "            DAG_execution_time = DAG_end_time - DAG_start_time\n",
    "            print(f\"\\n{occupation} {DAG_indicator} (alpha = {alpha}) runtime: {DAG_execution_time:.2f} seconds\")\n",
    "            \n",
    "            # unpack stats\n",
    "            num_nodes, total_degree, average_degree, sum_paths_len_to_target, max_path_len_to_target, avg_path_len_to_target, sparsity = DAG_stats\n",
    "\n",
    "            # assign values to dataset\n",
    "            stats_df.at[my_index, 'occupation'] = occupation\n",
    "            stats_df.at[my_index, 'DAG_type'] = DAG_indicator\n",
    "            stats_df.at[my_index, 'alpha'] = alpha\n",
    "            stats_df.at[my_index, 'num_tasks'] = num_nodes\n",
    "            stats_df.at[my_index, 'DAG_sparsity'] = sparsity\n",
    "            stats_df.at[my_index, 'num_execution_plans_covered'] = num_execution_plans_covered\n",
    "            stats_df.at[my_index, 'total_degree'] = total_degree\n",
    "            stats_df.at[my_index, 'average_degree'] = average_degree\n",
    "            stats_df.at[my_index, 'sum_paths_len_to_target'] = sum_paths_len_to_target\n",
    "            stats_df.at[my_index, 'max_path_len_to_target'] = max_path_len_to_target\n",
    "            stats_df.at[my_index, 'avg_path_len_to_target'] = avg_path_len_to_target\n",
    "            stats_df.at[my_index, 'min_cost'] = min_cost\n",
    "            stats_df.at[my_index, 'min_cost_plan'] = min_cost_plan\n",
    "            stats_df.at[my_index, 'exec_time_sec'] = DAG_execution_time\n",
    "            stats_df.at[my_index, 'exec_time_min'] = DAG_execution_time/60\n",
    "            my_index += 1\n",
    "            \n",
    "            stats_df.to_csv(f'{stats_df_output_path}/costMin_stats.csv', index=False)\n",
    "\n",
    "    runtime_since_start = (time.time() - start_time)/60\n",
    "    print(f\"\\nruntime since start: {runtime_since_start:.2f} minutes\\n\")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = (end_time - start_time)/60\n",
    "print(f\"\\n\\nTotal Runtime: {execution_time:.2f} minutes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
