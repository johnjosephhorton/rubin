{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b861f4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('libraries.py') as f:\n",
    "    code = f.read()\n",
    "exec(code)\n",
    "\n",
    "with open('functions.py') as f:\n",
    "    code = f.read()\n",
    "exec(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "280bdd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine user\n",
    "user = getpass.getuser()\n",
    "if user == 'peymansh':\n",
    "    main_folder_path = '/Users/peymansh/Dropbox (MIT)/Research/AI and Occupations/ai-exposure'\n",
    "    data_path = f'{main_folder_path}/output'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b7085e",
   "metadata": {},
   "source": [
    "### Generate all possible partition schemes for the set of tasks (ignoring structre of the DAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4a503b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def partitions(set_):\n",
    "    if not set_:\n",
    "        yield []\n",
    "        return\n",
    "    for i in range(1, len(set_) + 1):\n",
    "        for part in combinations(set_, i):\n",
    "            remaining = set(set_) - set(part)\n",
    "            if not remaining:\n",
    "                yield [list(part)]\n",
    "            else:\n",
    "                for b in partitions(list(remaining)):\n",
    "                    yield [list(part)] + b\n",
    "\n",
    "def generate_unique_partitions(numbers):\n",
    "    all_partitions = set()\n",
    "    for partition in partitions(numbers):\n",
    "        # Create a frozenset of frozensets to make each partition hashable and order-independent\n",
    "        partition_set = frozenset(frozenset(part) for part in partition)\n",
    "        all_partitions.add(partition_set)\n",
    "    \n",
    "    # Convert the frozensets back to lists for the final output\n",
    "    unique_partitions = [list(map(list, partition)) for partition in all_partitions]\n",
    "\n",
    "    # Sort elements\n",
    "    unique_partitions = sorted([sorted(x) for x in unique_partitions], key=len)\n",
    "    return unique_partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2081384b",
   "metadata": {},
   "source": [
    "### Check if partition scheme is \"valid\" (i.e., if its non-singleton partitions are a connected graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14339429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_connected(matrix):\n",
    "    # Number of nodes in the matrix\n",
    "    num_nodes = matrix.shape[0]\n",
    "    \n",
    "    # Visited array to keep track of visited nodes\n",
    "    visited = np.zeros(num_nodes, dtype=bool)\n",
    "    \n",
    "    # Helper function to perform DFS\n",
    "    def dfs(node):\n",
    "        visited[node] = True\n",
    "        # Visit all the neighbors of the current node\n",
    "        for neighbor in range(num_nodes):\n",
    "            if matrix[node, neighbor] == 1 and not visited[neighbor]:\n",
    "                dfs(neighbor)\n",
    "            elif matrix[neighbor, node] == 1 and not visited[neighbor]:\n",
    "                dfs(neighbor)\n",
    "    \n",
    "    # Start DFS from the first node (node 0)\n",
    "    dfs(0)\n",
    "    \n",
    "    # If all nodes are visited, the matrix is connected\n",
    "    return np.all(visited)\n",
    "\n",
    "\n",
    "def validate_partition_using_connectedness(adjacency_matrix, tasks_list):\n",
    "    # Return valid if Singleton\n",
    "    if len(tasks_list) == 1:\n",
    "        return True\n",
    "    # Check if partition forms connected graph\n",
    "    else:\n",
    "        # Subset original adjacency matrix\n",
    "        subset_matrix = adjacency_matrix[np.ix_(tasks_list, tasks_list)]\n",
    "\n",
    "        # check if subset matrix is a connected graph\n",
    "        subset_matrix_connected = is_connected(subset_matrix)\n",
    "\n",
    "        # return true if connected and false otherwise\n",
    "        return subset_matrix_connected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61692d1b",
   "metadata": {},
   "source": [
    "### Compute costs of all \"valid\" execution plans\n",
    "#### New check for validity: automated cost of tasks in non-singleton partition must be less than human costs doing partition tasks separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3b358c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_partition_boundary(adjacency_matrix, partition):\n",
    "    # create a matrix whose columns are nodes not in the partition and whose rows are nodes in the partition\n",
    "    # (subset adjacency matrix to outgoing edges of partition nodes --i.e., rows-- and incoming edges of non-partition nodes --i.e., columns.)\n",
    "    reduced_matrix = np.delete(adjacency_matrix, partition, axis=1) \n",
    "    reduced_matrix = reduced_matrix[partition, :]\n",
    "\n",
    "    # find nodes in partition w/ an edge to non-partition nodes\n",
    "    partition_boundary_tasks = [i for i in partition if np.any(reduced_matrix[partition.index(i), :])]\n",
    "\n",
    "    return partition_boundary_tasks\n",
    "\n",
    "\n",
    "def compute_partition_cost(adjacency_matrix, M_dict, A_dict, D_dict, AI_quality, partition):\n",
    "    # initialize partition done manually as False \n",
    "    # (only if partition is singleton and manual cost <= automated cost partition is done manually)\n",
    "    partition_done_manually = False\n",
    "    \n",
    "    # calculate automation cost of doing partition\n",
    "    # first, get partition boundary tasks if partition contains more than one task\n",
    "    if len(partition) > 1:\n",
    "        partition_boundary_tasks = get_partition_boundary(adjacency_matrix, partition)\n",
    "        \n",
    "        \n",
    "    # if partition boundary has zero length partition is invalid\n",
    "        if len(partition_boundary_tasks) == 0:\n",
    "            partition_cost = 100000000 # (value doesn't matter)\n",
    "            partition_done_manually = False\n",
    "            partition_is_valid = False\n",
    "            return partition_cost, partition_done_manually, partition_is_valid\n",
    "\n",
    "\n",
    "    # if partition is a singleton pick minimum of manual and machine cost\n",
    "    if len(partition) == 1:\n",
    "        partition_is_valid = True\n",
    "\n",
    "        # calculate manual cost\n",
    "        manual_cost = sum(M_dict[key] for key in partition)\n",
    "\n",
    "        # calculate machine cost\n",
    "        AI_cost = sum(A_dict[key] for key in partition)\n",
    "        difficulty = sum(D_dict[key] for key in partition)\n",
    "        automation_cost = AI_cost * (AI_quality ** (-1 * difficulty))\n",
    "        \n",
    "        # pick the minimum of the two\n",
    "        if manual_cost < automation_cost:\n",
    "            partition_cost = manual_cost\n",
    "            partition_done_manually = True \n",
    "        else:\n",
    "            partition_cost = automation_cost\n",
    "    \n",
    "\n",
    "    # if partition not a singleton calculate automation cost and return if partition passes a sanity check\n",
    "    if len(partition) > 1:\n",
    "\n",
    "        # calculate manual cost\n",
    "        manual_cost = sum(M_dict[key] for key in partition)\n",
    "\n",
    "\n",
    "        # calculate machine cost\n",
    "        # first get boundary tasks in partition\n",
    "        partition_boundary_tasks = get_partition_boundary(adjacency_matrix, partition)\n",
    "\n",
    "        # if partition has no boundary tasks partition is invalid\n",
    "        if len(partition_boundary_tasks) == 0:\n",
    "            partition_cost = 100000000 # (value doesn't matter)\n",
    "            partition_is_valid = False\n",
    "            return partition_cost, partition_done_manually, partition_is_valid \n",
    "        \n",
    "        # if partition has at least one boundary task calculate automation cost using boundary tasks for calculating machine costs and partition tasks for difficulty\n",
    "        if len(partition_boundary_tasks) > 0:\n",
    "            AI_cost = sum(A_dict[key] for key in partition_boundary_tasks)\n",
    "            difficulty = sum(D_dict[key] for key in partition)\n",
    "            automation_cost = AI_cost * (AI_quality ** (-1 * difficulty))\n",
    "\n",
    "        # sanity check partition validity: if manual cost < automation cost partition is invalid (should not have been formed)\n",
    "        if manual_cost < automation_cost:\n",
    "            partition_cost = 100000000 # (value doesn't matter)\n",
    "            partition_is_valid = False\n",
    "        else:\n",
    "            partition_cost = automation_cost\n",
    "            partition_is_valid = True\n",
    "    \n",
    "    return partition_cost, partition_done_manually, partition_is_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "694fca2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Random Thought: maybe better to sort valid_partitions on descending partition order to avoid recalculating single node partitions everytime? \n",
    "# tho the downside is that we have to first do the heavy calculations first...\n",
    "\n",
    "\n",
    "def execute_plans(adjacency_matrix, valid_partitions, M_dict, A_dict, D_dict, alpha):\n",
    "    execution_plan = []\n",
    "    execution_plan_manual_tasks = []\n",
    "    execution_cost = []\n",
    "    counter = 0\n",
    "    for partition_scheme in valid_partitions:\n",
    "        # initialize partition scheme cost\n",
    "        # and partitions that are done manually\n",
    "        partition_scheme_cost = 0\n",
    "        manual_partitions = []\n",
    "        \n",
    "        for partition in partition_scheme:\n",
    "            # calculate partition cost \n",
    "            partition_cost, partition_done_manually, partition_is_valid = compute_partition_cost(adjacency_matrix, M_dict, A_dict, D_dict, alpha, partition)\n",
    "        \n",
    "            # if (automated) partition is invalid ignore partition scheme\n",
    "            # and stop calculating costs of further partitions\n",
    "            if not partition_is_valid:\n",
    "                break\n",
    "\n",
    "            if partition_done_manually:\n",
    "                manual_partitions.append(partition)\n",
    "\n",
    "            # if (automated) partition passes sanity check\n",
    "            # add this partition's cost to partition scheme cost\n",
    "            partition_scheme_cost += partition_cost\n",
    "        \n",
    "        # if stopped because an (automated) partition wasn't valid\n",
    "        # ignore current partition scheme and continue\n",
    "        if not partition_is_valid:\n",
    "            continue\n",
    "        \n",
    "        # if partition scheme makes sense append costs\n",
    "        execution_plan.append(partition_scheme)\n",
    "        execution_plan_manual_tasks.append(manual_partitions)\n",
    "        execution_cost.append(partition_scheme_cost)\n",
    "\n",
    "        # if counter % (np.floor(len(valid_partitions)/3)) == 0:\n",
    "        #     print(partition_scheme)\n",
    "        #     print(partition_scheme_cost)\n",
    "        #     print('\\n')\n",
    "        # counter += 1\n",
    "\n",
    "    return execution_plan, execution_plan_manual_tasks, execution_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e122fa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DAG_costMin(input_path, output_path, n=1000):\n",
    "    # set alpha as AI quality metric\n",
    "    # n = 1000\n",
    "    epsilon = 1e-8\n",
    "    alpha_list = np.linspace(epsilon, 1-epsilon, n).tolist()\n",
    "\n",
    "    # read DAG\n",
    "    dag_df = pd.read_csv(input_path)\n",
    "\n",
    "    # remove edges if comment column labeled with \"TriangleRemovedFlag\" (edge is there for plotting purposes and is not part of the actual DAG)\n",
    "    if 'comment' in dag_df.columns:\n",
    "        dag_df = dag_df[~dag_df['comment'].str.endswith('TriangleRemovedFlag')]\n",
    "\n",
    "    # get task stats\n",
    "    tasks_stats = pd.read_csv(f'{occupation_folder}/{occupation}_taskStats.csv')\n",
    "    tasks_stats\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # extract list of tasks and create a dictionary for indexing tasks\n",
    "    tasks_list = tasks_stats['task'].unique()\n",
    "    print(f'Number of occupation tasks: {len(tasks_list)}')\n",
    "    tasks_dict = {i: node for i, node in enumerate(tasks_list, start=0)}\n",
    "\n",
    "    # create numpy array of adjacency matrix\n",
    "    adjacency_matrix = np.zeros((len(tasks_list), len(tasks_list)), dtype=int)\n",
    "\n",
    "    # Populate the adjacency matrix\n",
    "    aux_dict = {value: key for key, value in tasks_dict.items()}\n",
    "    for _, row in dag_df.iterrows():\n",
    "        source_index = aux_dict[row['source']]\n",
    "        target_index = aux_dict[row['target']]\n",
    "        adjacency_matrix[source_index, target_index] = 1\n",
    "\n",
    "    \n",
    "    # Define a break-even difficulty for base AI quality (alpha)\n",
    "    # Above break-even difficulty threshold task is done manually\n",
    "    # As AI quality (alpha) goes up break-even difficulty goes up\n",
    "    for index, alpha in enumerate(alpha_list):\n",
    "        if index % np.floor(n/4) == np.floor(n/4) - 1:\n",
    "            pretty_label = str(np.round(alpha,2)*100).split('.')[0]\n",
    "            #tasks_stats[f'be_difficulty_{pretty_label}'] = np.log(tasks_stats['machine_cost'] / tasks_stats['human_cost']) / np.log(alpha)\n",
    "\n",
    "\n",
    "    # add task_dict key and reset index\n",
    "    aux_dict = {value: key for key, value in tasks_dict.items()}\n",
    "    tasks_stats['dict_index'] = tasks_stats.apply(lambda row: aux_dict[row.task], axis=1)\n",
    "    tasks_stats = tasks_stats.sort_values(by='dict_index')\n",
    "    tasks_stats = tasks_stats.set_index('dict_index', drop=False)\n",
    "    tasks_stats.index.name = None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # create dictionaries for human cost, machine cost, and difficulty\n",
    "    M_dict = dict(zip(tasks_stats['dict_index'], tasks_stats['human_cost']))\n",
    "    A_dict = dict(zip(tasks_stats['dict_index'], tasks_stats['machine_cost']))\n",
    "    D_dict = dict(zip(tasks_stats['dict_index'], tasks_stats['difficulty']))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Generate list of numbers for tasks in occupation\n",
    "    tasks_list_numbers = list(range(len(tasks_list)))\n",
    "\n",
    "    # Generate all possible partitioning schemes\n",
    "    all_partitions = generate_unique_partitions(tasks_list_numbers)\n",
    "\n",
    "    # Get valid partitioning schemes\n",
    "    valid_partitions = []\n",
    "    for partition_scheme in all_partitions:\n",
    "\n",
    "        # Set valid partitions count to 0\n",
    "        valid_partition_count = 0\n",
    "        for partition in partition_scheme:\n",
    "            valid_partition = validate_partition_using_connectedness(adjacency_matrix, partition)\n",
    "            if valid_partition:\n",
    "                valid_partition_count += 1\n",
    "        \n",
    "        # If number of valid partitions within a partition scheme is equal to \n",
    "        # number of partitions in partition scheme then partition scheme is valid\n",
    "        if valid_partition_count == len(partition_scheme):\n",
    "            valid_partitions.append(partition_scheme)\n",
    "\n",
    "    # Print stats\n",
    "    print(f'Number of all possible partitioning schemes: {len(all_partitions)}')\n",
    "    print(f'Number of valid partitioning schemes given DAG: {len(valid_partitions)}')\n",
    "\n",
    "    # # print some partitions\n",
    "    # print('Examples:')\n",
    "    # for partition in valid_partitions[10:15]:\n",
    "    #     print(partition)\n",
    "    # print('\\n')\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    random.seed(1)\n",
    "    execution_plan, execution_plan_manual_tasks, execution_cost = execute_plans(adjacency_matrix, valid_partitions, M_dict, A_dict, D_dict, alpha)\n",
    "    print(f'Number of valid execution plans: {len(execution_plan)}')\n",
    "\n",
    "    # # print some valid execution plans\n",
    "    # print('Examples:')\n",
    "    # for plan in execution_plan[10:15]:\n",
    "    #     print(plan)\n",
    "    # print('\\n')\n",
    "    \n",
    "    \n",
    "\n",
    "    random.seed(1)\n",
    "    minimum_cost_list = []\n",
    "    number_of_optimal_schemes_list = []\n",
    "    optimal_execution_plan_list = []\n",
    "    optimal_plan_manualTasks_list = []\n",
    "    optimal_plan_manualTasks_count_list = []\n",
    "    multiple_plans = False\n",
    "    for counter, alpha in enumerate(alpha_list):\n",
    "        # if counter % 100 == 0:\n",
    "        #     print(f'-- Running {counter}th alpha --')\n",
    "\n",
    "        # get list of execution plans and costs for this alpha\n",
    "        execution_plan, execution_plan_manual_tasks, execution_cost = execute_plans(adjacency_matrix, valid_partitions, M_dict, A_dict, D_dict, alpha)\n",
    "\n",
    "        # choose minimum\n",
    "        minimum_cost = min(execution_cost)\n",
    "        minimum_cost_index = [index for index, value in enumerate(execution_cost) if value == minimum_cost]\n",
    "\n",
    "        # in rare cases there are more than one optimal plan\n",
    "        if len(minimum_cost_index) > 1:\n",
    "            multiple_plans = True\n",
    "            optimal_execution_scheme = [execution_plan[index] for index in minimum_cost_index]\n",
    "            optimal_execution_manual_tasks = [execution_plan_manual_tasks[index] for index in minimum_cost_index]\n",
    "            # print(alpha)\n",
    "            # print(optimal_execution_scheme)\n",
    "            # print(optimal_execution_manual_tasks)\n",
    "            # print(f'(Multiple Execution Plans for alpha={alpha})')\n",
    "        else:\n",
    "            optimal_execution_scheme = execution_plan[minimum_cost_index[0]]\n",
    "            optimal_execution_manual_tasks = execution_plan_manual_tasks[minimum_cost_index[0]]\n",
    "\n",
    "        # append lists\n",
    "        minimum_cost_list.append(minimum_cost)\n",
    "        number_of_optimal_schemes_list.append(len(minimum_cost_index))\n",
    "        optimal_execution_plan_list.append(optimal_execution_scheme)\n",
    "        optimal_plan_manualTasks_list.append(optimal_execution_manual_tasks)\n",
    "        optimal_plan_manualTasks_count_list.append(len(optimal_execution_manual_tasks))\n",
    "\n",
    "    if multiple_plans:\n",
    "        print(f'(Multiple Execution Plans for some Alpha)')\n",
    "\n",
    "    # save outputs\n",
    "    output_df = pd.DataFrame({\n",
    "        'alpha': alpha_list,\n",
    "        'optimal_schemes_count': number_of_optimal_schemes_list,\n",
    "        'cost': minimum_cost_list,\n",
    "        'optimal_scheme': optimal_execution_plan_list,\n",
    "        'optimal_scheme_manual_tasks': optimal_plan_manualTasks_list,\n",
    "        'manual_tasks_count': optimal_plan_manualTasks_count_list\n",
    "    })\n",
    "    output_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538ec907",
   "metadata": {},
   "source": [
    "## Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5db2b3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#suffix = 'MAX_' # for when partition cost used MAX of machine costs in partition (somewhat like a least common multiple)\n",
    "suffix = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ee7f28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "occupation_list = ['travelAgents', 'insuranceUnderwriters', 'pileDriverOperators', \n",
    "                   'dredgeOperators', 'gradersAndSorters', 'reinforcingIron',\n",
    "                   'insuranceAppraisers', 'floorSanders', 'dataEntryKeyer',\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3a99b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------Running: travelAgents - Manual DAG-------\n",
      "Number of occupation tasks: 8\n",
      "Number of all possible partitioning schemes: 4140\n",
      "Number of valid partitioning schemes given DAG: 192\n",
      "Number of valid execution plans: 160\n",
      "(Multiple Execution Plans for some Alpha)\n",
      "\n",
      "travelAgents Manual DAG runtime: 7.99 seconds\n",
      "\n",
      "-------Running: travelAgents - First-Last Task DAG-------\n",
      "Number of occupation tasks: 8\n",
      "Number of all possible partitioning schemes: 4140\n",
      "Number of valid partitioning schemes given DAG: 1754\n",
      "Number of valid execution plans: 1603\n",
      "(Multiple Execution Plans for some Alpha)\n",
      "\n",
      "travelAgents First-Last Task DAG runtime: 66.95 seconds\n",
      "\n",
      "-------Running: travelAgents - Conditioned First-Last Task DAG-------\n",
      "Number of occupation tasks: 8\n",
      "Number of all possible partitioning schemes: 4140\n",
      "Number of valid partitioning schemes given DAG: 874\n",
      "Number of valid execution plans: 763\n",
      "\n",
      "travelAgents Conditioned First-Last Task DAG runtime: 32.85 seconds\n",
      "\n",
      "-------Running: travelAgents - Partitioned DAG-------\n",
      "Number of occupation tasks: 8\n",
      "Number of all possible partitioning schemes: 4140\n",
      "Number of valid partitioning schemes given DAG: 2758\n",
      "Number of valid execution plans: 2748\n",
      "(Multiple Execution Plans for some Alpha)\n",
      "\n",
      "travelAgents Partitioned DAG runtime: 113.61 seconds\n",
      "\n",
      "-------Running: travelAgents - Conditioned Partitioned DAG-------\n",
      "Number of occupation tasks: 8\n",
      "Number of all possible partitioning schemes: 4140\n",
      "Number of valid partitioning schemes given DAG: 300\n",
      "Number of valid execution plans: 231\n",
      "\n",
      "travelAgents Conditioned Partitioned DAG runtime: 11.75 seconds\n",
      "\n",
      "\n",
      "*************travelAgents runtime: 3.89 minutes*************\n",
      "\n",
      "\n",
      "-------Running: insuranceUnderwriters - Manual DAG-------\n",
      "Number of occupation tasks: 7\n",
      "Number of all possible partitioning schemes: 877\n",
      "Number of valid partitioning schemes given DAG: 192\n",
      "Number of valid execution plans: 180\n",
      "(Multiple Execution Plans for some Alpha)\n",
      "\n",
      "insuranceUnderwriters Manual DAG runtime: 6.49 seconds\n",
      "\n",
      "-------Running: insuranceUnderwriters - First-Last Task DAG-------\n",
      "Number of occupation tasks: 7\n",
      "Number of all possible partitioning schemes: 877\n",
      "Number of valid partitioning schemes given DAG: 735\n",
      "Number of valid execution plans: 671\n",
      "(Multiple Execution Plans for some Alpha)\n",
      "\n",
      "insuranceUnderwriters First-Last Task DAG runtime: 24.49 seconds\n",
      "\n",
      "-------Running: insuranceUnderwriters - Conditioned First-Last Task DAG-------\n",
      "Number of occupation tasks: 7\n",
      "Number of all possible partitioning schemes: 877\n",
      "Number of valid partitioning schemes given DAG: 433\n",
      "Number of valid execution plans: 378\n",
      "\n",
      "insuranceUnderwriters Conditioned First-Last Task DAG runtime: 14.01 seconds\n",
      "\n",
      "-------Running: insuranceUnderwriters - Partitioned DAG-------\n",
      "Number of occupation tasks: 7\n",
      "Number of all possible partitioning schemes: 877\n",
      "Number of valid partitioning schemes given DAG: 718\n",
      "Number of valid execution plans: 676\n",
      "(Multiple Execution Plans for some Alpha)\n",
      "\n",
      "insuranceUnderwriters Partitioned DAG runtime: 24.06 seconds\n",
      "\n",
      "-------Running: insuranceUnderwriters - Conditioned Partitioned DAG-------\n",
      "Number of occupation tasks: 7\n",
      "Number of all possible partitioning schemes: 877\n",
      "Number of valid partitioning schemes given DAG: 299\n",
      "Number of valid execution plans: 271\n",
      "\n",
      "insuranceUnderwriters Conditioned Partitioned DAG runtime: 10.22 seconds\n",
      "\n",
      "\n",
      "*************insuranceUnderwriters runtime: 1.32 minutes*************\n",
      "\n",
      "\n",
      "-------Running: pileDriverOperators - First-Last Task DAG-------\n",
      "Number of occupation tasks: 5\n",
      "Number of all possible partitioning schemes: 52\n",
      "Number of valid partitioning schemes given DAG: 30\n",
      "Number of valid execution plans: 23\n",
      "\n",
      "pileDriverOperators First-Last Task DAG runtime: 0.74 seconds\n",
      "\n",
      "-------Running: pileDriverOperators - Conditioned First-Last Task DAG-------\n",
      "Number of occupation tasks: 5\n",
      "Number of all possible partitioning schemes: 52\n",
      "Number of valid partitioning schemes given DAG: 16\n",
      "Number of valid execution plans: 9\n",
      "\n",
      "pileDriverOperators Conditioned First-Last Task DAG runtime: 0.38 seconds\n",
      "\n",
      "-------Running: pileDriverOperators - Partitioned DAG-------\n",
      "Number of occupation tasks: 5\n",
      "Number of all possible partitioning schemes: 52\n",
      "Number of valid partitioning schemes given DAG: 52\n",
      "Number of valid execution plans: 46\n",
      "\n",
      "pileDriverOperators Partitioned DAG runtime: 1.38 seconds\n",
      "\n",
      "-------Running: pileDriverOperators - Conditioned Partitioned DAG-------\n",
      "Number of occupation tasks: 5\n",
      "Number of all possible partitioning schemes: 52\n",
      "Number of valid partitioning schemes given DAG: 25\n",
      "Number of valid execution plans: 19\n",
      "\n",
      "pileDriverOperators Conditioned Partitioned DAG runtime: 0.62 seconds\n",
      "\n",
      "\n",
      "*************pileDriverOperators runtime: 0.05 minutes*************\n",
      "\n",
      "\n",
      "-------Running: dredgeOperators - First-Last Task DAG-------\n",
      "Number of occupation tasks: 6\n",
      "Number of all possible partitioning schemes: 203\n",
      "Number of valid partitioning schemes given DAG: 40\n",
      "Number of valid execution plans: 35\n",
      "\n",
      "dredgeOperators First-Last Task DAG runtime: 1.08 seconds\n",
      "\n",
      "-------Running: dredgeOperators - Conditioned First-Last Task DAG-------\n",
      "Number of occupation tasks: 6\n",
      "Number of all possible partitioning schemes: 203\n",
      "Number of valid partitioning schemes given DAG: 32\n",
      "Number of valid execution plans: 27\n",
      "\n",
      "dredgeOperators Conditioned First-Last Task DAG runtime: 0.85 seconds\n",
      "\n",
      "-------Running: dredgeOperators - Partitioned DAG-------\n",
      "Number of occupation tasks: 6\n",
      "Number of all possible partitioning schemes: 203\n",
      "Number of valid partitioning schemes given DAG: 47\n",
      "Number of valid execution plans: 43\n",
      "\n",
      "dredgeOperators Partitioned DAG runtime: 1.28 seconds\n",
      "\n",
      "-------Running: dredgeOperators - Conditioned Partitioned DAG-------\n",
      "Number of occupation tasks: 6\n",
      "Number of all possible partitioning schemes: 203\n",
      "Number of valid partitioning schemes given DAG: 16\n",
      "Number of valid execution plans: 12\n",
      "\n",
      "dredgeOperators Conditioned Partitioned DAG runtime: 0.40 seconds\n",
      "\n",
      "\n",
      "*************dredgeOperators runtime: 0.06 minutes*************\n",
      "\n",
      "\n",
      "-------Running: gradersAndSorters - First-Last Task DAG-------\n",
      "Number of occupation tasks: 6\n",
      "Number of all possible partitioning schemes: 203\n",
      "Number of valid partitioning schemes given DAG: 126\n",
      "Number of valid execution plans: 108\n",
      "\n",
      "gradersAndSorters First-Last Task DAG runtime: 3.47 seconds\n",
      "\n",
      "-------Running: gradersAndSorters - Conditioned First-Last Task DAG-------\n",
      "Number of occupation tasks: 6\n",
      "Number of all possible partitioning schemes: 203\n",
      "Number of valid partitioning schemes given DAG: 80\n",
      "Number of valid execution plans: 62\n",
      "\n",
      "gradersAndSorters Conditioned First-Last Task DAG runtime: 2.05 seconds\n",
      "\n",
      "-------Running: gradersAndSorters - Partitioned DAG-------\n",
      "Number of occupation tasks: 6\n",
      "Number of all possible partitioning schemes: 203\n",
      "Number of valid partitioning schemes given DAG: 188\n",
      "Number of valid execution plans: 165\n",
      "\n",
      "gradersAndSorters Partitioned DAG runtime: 5.27 seconds\n",
      "\n",
      "-------Running: gradersAndSorters - Conditioned Partitioned DAG-------\n",
      "Number of occupation tasks: 6\n",
      "Number of all possible partitioning schemes: 203\n",
      "Number of valid partitioning schemes given DAG: 126\n",
      "Number of valid execution plans: 103\n",
      "\n",
      "gradersAndSorters Conditioned Partitioned DAG runtime: 3.37 seconds\n",
      "\n",
      "\n",
      "*************gradersAndSorters runtime: 0.24 minutes*************\n",
      "\n",
      "\n",
      "-------Running: reinforcingIron - First-Last Task DAG-------\n",
      "Number of occupation tasks: 7\n",
      "Number of all possible partitioning schemes: 877\n",
      "Number of valid partitioning schemes given DAG: 376\n",
      "Number of valid execution plans: 329\n",
      "\n",
      "reinforcingIron First-Last Task DAG runtime: 11.70 seconds\n",
      "\n",
      "-------Running: reinforcingIron - Conditioned First-Last Task DAG-------\n",
      "Number of occupation tasks: 7\n",
      "Number of all possible partitioning schemes: 877\n",
      "Number of valid partitioning schemes given DAG: 300\n",
      "Number of valid execution plans: 253\n",
      "\n",
      "reinforcingIron Conditioned First-Last Task DAG runtime: 8.94 seconds\n",
      "\n",
      "-------Running: reinforcingIron - Partitioned DAG-------\n",
      "Number of occupation tasks: 7\n",
      "Number of all possible partitioning schemes: 877\n",
      "Number of valid partitioning schemes given DAG: 825\n",
      "Number of valid execution plans: 749\n",
      "\n",
      "reinforcingIron Partitioned DAG runtime: 27.43 seconds\n",
      "\n",
      "-------Running: reinforcingIron - Conditioned Partitioned DAG-------\n",
      "Number of occupation tasks: 7\n",
      "Number of all possible partitioning schemes: 877\n",
      "Number of valid partitioning schemes given DAG: 512\n",
      "Number of valid execution plans: 436\n",
      "\n",
      "reinforcingIron Conditioned Partitioned DAG runtime: 16.10 seconds\n",
      "\n",
      "\n",
      "*************reinforcingIron runtime: 1.07 minutes*************\n",
      "\n",
      "\n",
      "-------Running: insuranceAppraisers - First-Last Task DAG-------\n",
      "Number of occupation tasks: 7\n",
      "Number of all possible partitioning schemes: 877\n",
      "Number of valid partitioning schemes given DAG: 758\n",
      "Number of valid execution plans: 672\n",
      "\n",
      "insuranceAppraisers First-Last Task DAG runtime: 22.62 seconds\n",
      "\n",
      "-------Running: insuranceAppraisers - Conditioned First-Last Task DAG-------\n",
      "Number of occupation tasks: 7\n",
      "Number of all possible partitioning schemes: 877\n",
      "Number of valid partitioning schemes given DAG: 616\n",
      "Number of valid execution plans: 539\n",
      "\n",
      "insuranceAppraisers Conditioned First-Last Task DAG runtime: 18.18 seconds\n",
      "\n",
      "-------Running: insuranceAppraisers - Partitioned DAG-------\n",
      "Number of occupation tasks: 7\n",
      "Number of all possible partitioning schemes: 877\n",
      "Number of valid partitioning schemes given DAG: 877\n",
      "Number of valid execution plans: 801\n",
      "\n",
      "insuranceAppraisers Partitioned DAG runtime: 26.44 seconds\n",
      "\n",
      "-------Running: insuranceAppraisers - Conditioned Partitioned DAG-------\n",
      "Number of occupation tasks: 7\n",
      "Number of all possible partitioning schemes: 877\n",
      "Number of valid partitioning schemes given DAG: 576\n",
      "Number of valid execution plans: 511\n",
      "\n",
      "insuranceAppraisers Conditioned Partitioned DAG runtime: 17.03 seconds\n",
      "\n",
      "\n",
      "*************insuranceAppraisers runtime: 1.40 minutes*************\n",
      "\n",
      "\n",
      "-------Running: floorSanders - First-Last Task DAG-------\n",
      "Number of occupation tasks: 7\n",
      "Number of all possible partitioning schemes: 877\n",
      "Number of valid partitioning schemes given DAG: 624\n",
      "Number of valid execution plans: 578\n",
      "(Multiple Execution Plans for some Alpha)\n",
      "\n",
      "floorSanders First-Last Task DAG runtime: 22.25 seconds\n",
      "\n",
      "-------Running: floorSanders - Conditioned First-Last Task DAG-------\n",
      "Number of occupation tasks: 7\n",
      "Number of all possible partitioning schemes: 877\n",
      "Number of valid partitioning schemes given DAG: 336\n",
      "Number of valid execution plans: 290\n",
      "(Multiple Execution Plans for some Alpha)\n",
      "\n",
      "floorSanders Conditioned First-Last Task DAG runtime: 11.28 seconds\n",
      "\n",
      "-------Running: floorSanders - Partitioned DAG-------\n",
      "Number of occupation tasks: 7\n",
      "Number of all possible partitioning schemes: 877\n",
      "Number of valid partitioning schemes given DAG: 778\n",
      "Number of valid execution plans: 699\n",
      "(Multiple Execution Plans for some Alpha)\n",
      "\n",
      "floorSanders Partitioned DAG runtime: 27.85 seconds\n",
      "\n",
      "-------Running: floorSanders - Conditioned Partitioned DAG-------\n",
      "Number of occupation tasks: 7\n",
      "Number of all possible partitioning schemes: 877\n",
      "Number of valid partitioning schemes given DAG: 576\n",
      "Number of valid execution plans: 508\n",
      "(Multiple Execution Plans for some Alpha)\n",
      "\n",
      "floorSanders Conditioned Partitioned DAG runtime: 20.35 seconds\n",
      "\n",
      "\n",
      "*************floorSanders runtime: 1.36 minutes*************\n",
      "\n",
      "\n",
      "-------Running: dataEntryKeyer - First-Last Task DAG-------\n",
      "Number of occupation tasks: 9\n",
      "Number of all possible partitioning schemes: 21147\n",
      "Number of valid partitioning schemes given DAG: 1504\n",
      "Number of valid execution plans: 1246\n",
      "\n",
      "dataEntryKeyer First-Last Task DAG runtime: 78.34 seconds\n",
      "\n",
      "-------Running: dataEntryKeyer - Conditioned First-Last Task DAG-------\n",
      "Number of occupation tasks: 9\n",
      "Number of all possible partitioning schemes: 21147\n",
      "Number of valid partitioning schemes given DAG: 1400\n",
      "Number of valid execution plans: 1142\n",
      "\n",
      "dataEntryKeyer Conditioned First-Last Task DAG runtime: 73.65 seconds\n",
      "\n",
      "-------Running: dataEntryKeyer - Partitioned DAG-------\n",
      "Number of occupation tasks: 9\n",
      "Number of all possible partitioning schemes: 21147\n",
      "Number of valid partitioning schemes given DAG: 2189\n",
      "Number of valid execution plans: 1991\n",
      "(Multiple Execution Plans for some Alpha)\n",
      "\n",
      "dataEntryKeyer Partitioned DAG runtime: 106.86 seconds\n",
      "\n",
      "-------Running: dataEntryKeyer - Conditioned Partitioned DAG-------\n",
      "Number of occupation tasks: 9\n",
      "Number of all possible partitioning schemes: 21147\n",
      "Number of valid partitioning schemes given DAG: 1096\n",
      "Number of valid execution plans: 957\n",
      "\n",
      "dataEntryKeyer Conditioned Partitioned DAG runtime: 62.76 seconds\n",
      "\n",
      "\n",
      "*************dataEntryKeyer runtime: 5.36 minutes*************\n",
      "\n",
      "\n",
      "\n",
      "Total Runtime: 14.75 minutes\n"
     ]
    }
   ],
   "source": [
    "for occupation in occupation_list:\n",
    "    occupation_start_time = time.time()\n",
    "\n",
    "    # generate occupation-specific strings\n",
    "    GPT_input_occupation, plot_title_occupation, occupation_code, occupation_folder = pick_occupation(occupation)\n",
    "    \n",
    "    # Manual DAG\n",
    "    M_input_path = f'{occupation_folder}/{occupation}_manual_DAG_df.csv'\n",
    "    M_output_path = f'{occupation_folder}/{occupation}_costMin_{suffix}manual.csv'\n",
    "\n",
    "    # First Last Task DAG\n",
    "    FLT_input_path = f'{occupation_folder}/{occupation}_firstLastTaskGPT_DAG_df.csv'\n",
    "    FLToutput_path = f'{occupation_folder}/{occupation}_costMin_{suffix}firstLastTask.csv'\n",
    "\n",
    "    # Conditioned First Last Task DAG\n",
    "    CFLT_input_path = f'{occupation_folder}/{occupation}_conditionedGPT_fromFirstLastTask_DAG_df.csv'\n",
    "    CFLT_output_path = f'{occupation_folder}/{occupation}_costMin_{suffix}firstLastTask_conditioned.csv'\n",
    "\n",
    "    # Partitioned DAG\n",
    "    P_input_path = f'{occupation_folder}/{occupation}_partitionedGPT_DAG_df.csv'\n",
    "    P_output_path = f'{occupation_folder}/{occupation}_costMin_{suffix}partitioned.csv'\n",
    "\n",
    "    # Conditioned Partitioned DAG\n",
    "    CP_input_path = f'{occupation_folder}/{occupation}_conditionedGPT_fromPartitioned_DAG_df.csv'\n",
    "    CP_output_path = f'{occupation_folder}/{occupation}_costMin_{suffix}partitioned_conditioned.csv'\n",
    "    \n",
    "\n",
    "    # create list of all DAGs\n",
    "    if occupation == 'travelAgents' or occupation == 'insuranceUnderwriters':\n",
    "        DAG_indicator_list = ['Manual DAG', 'First-Last Task DAG', 'Conditioned First-Last Task DAG', 'Partitioned DAG', 'Conditioned Partitioned DAG']\n",
    "        input_paths_list = [M_input_path, FLT_input_path, CFLT_input_path, P_input_path, CP_input_path]\n",
    "        output_paths_list = [M_output_path, FLToutput_path, CFLT_output_path, P_output_path, CP_output_path]\n",
    "    else:\n",
    "        DAG_indicator_list = ['First-Last Task DAG', 'Conditioned First-Last Task DAG', 'Partitioned DAG', 'Conditioned Partitioned DAG']\n",
    "        input_paths_list = [FLT_input_path, CFLT_input_path, P_input_path, CP_input_path]\n",
    "        output_paths_list = [FLToutput_path, CFLT_output_path, P_output_path, CP_output_path]\n",
    "\n",
    "    for DAG_indicator, input_path, output_path in zip(DAG_indicator_list, input_paths_list, output_paths_list):\n",
    "        print(f'\\n-------Running: {occupation} - {DAG_indicator}-------')\n",
    "        \n",
    "        DAG_start_time = time.time()\n",
    "        DAG_costMin(input_path, output_path, n=1000)\n",
    "        DAG_end_time = time.time()\n",
    "\n",
    "        DAG_execution_time = DAG_end_time - DAG_start_time\n",
    "        print(f\"\\n{occupation} {DAG_indicator} runtime: {DAG_execution_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "    occupation_end_time = time.time()\n",
    "    occupation_execution_time = (occupation_end_time - occupation_start_time)/60\n",
    "    print(f\"\\n\\n*************{occupation} runtime: {occupation_execution_time:.2f} minutes*************\\n\")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = (end_time - start_time)/60\n",
    "print(f\"\\n\\nTotal Runtime: {execution_time:.2f} minutes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
