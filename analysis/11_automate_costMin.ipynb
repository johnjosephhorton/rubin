{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b861f4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('libraries.py') as f:\n",
    "    code = f.read()\n",
    "exec(code)\n",
    "\n",
    "with open('functions.py') as f:\n",
    "    code = f.read()\n",
    "exec(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "280bdd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine user\n",
    "user = getpass.getuser()\n",
    "if user == 'peymansh':\n",
    "    main_folder_path = '/Users/peymansh/Dropbox (MIT)/Research/AI and Occupations/ai-exposure'\n",
    "    data_path = f'{main_folder_path}/output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54980713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tasks(onet_data_path,\n",
    "              occupation_code):\n",
    "\n",
    "    # Load the data\n",
    "    onet = pd.read_csv(onet_data_path)\n",
    "    onet = onet.sort_values(by=['year', 'occ_code', 'occ_title', 'task_id'])\n",
    "    onet = onet[onet['year'] == 2023].reset_index(drop=True)\n",
    "\n",
    "    # Get list of tasks\n",
    "    my_df = onet[(onet.occ_code == f'{occupation_code}') & (onet.year == 2023)]\n",
    "    tasks = my_df['task'].unique().tolist()\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b7085e",
   "metadata": {},
   "source": [
    "### Generate all possible partition schemes for the set of tasks (ignoring structre of the DAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4a503b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def partitions(set_):\n",
    "    if not set_:\n",
    "        yield []\n",
    "        return\n",
    "    for i in range(1, len(set_) + 1):\n",
    "        for part in combinations(set_, i):\n",
    "            remaining = set(set_) - set(part)\n",
    "            if not remaining:\n",
    "                yield [list(part)]\n",
    "            else:\n",
    "                for b in partitions(list(remaining)):\n",
    "                    yield [list(part)] + b\n",
    "\n",
    "def generate_unique_partitions(numbers):\n",
    "    all_partitions = set()\n",
    "    for partition in partitions(numbers):\n",
    "        # Create a frozenset of frozensets to make each partition hashable and order-independent\n",
    "        partition_set = frozenset(frozenset(part) for part in partition)\n",
    "        all_partitions.add(partition_set)\n",
    "    \n",
    "    # Convert the frozensets back to lists for the final output\n",
    "    unique_partitions = [list(map(list, partition)) for partition in all_partitions]\n",
    "\n",
    "    # Sort elements\n",
    "    unique_partitions = sorted([sorted(x) for x in unique_partitions], key=len)\n",
    "    return unique_partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2081384b",
   "metadata": {},
   "source": [
    "### Check if partition scheme is \"valid\" (i.e., if its non-singleton partitions are a connected graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "14339429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_connected(matrix):\n",
    "    # Number of nodes in the matrix\n",
    "    num_nodes = matrix.shape[0]\n",
    "    \n",
    "    # Visited array to keep track of visited nodes\n",
    "    visited = np.zeros(num_nodes, dtype=bool)\n",
    "    \n",
    "    # Helper function to perform DFS\n",
    "    def dfs(node):\n",
    "        visited[node] = True\n",
    "        # Visit all the neighbors of the current node\n",
    "        for neighbor in range(num_nodes):\n",
    "            if matrix[node, neighbor] == 1 and not visited[neighbor]:\n",
    "                dfs(neighbor)\n",
    "            elif matrix[neighbor, node] == 1 and not visited[neighbor]:\n",
    "                dfs(neighbor)\n",
    "    \n",
    "    # Start DFS from the first node (node 0)\n",
    "    dfs(0)\n",
    "    \n",
    "    # If all nodes are visited, the matrix is connected\n",
    "    return np.all(visited)\n",
    "\n",
    "\n",
    "def validate_partition_using_connectedness(adjacency_matrix, tasks_list):\n",
    "    # Return valid if Singleton\n",
    "    if len(tasks_list) == 1:\n",
    "        return True\n",
    "    # Check if partition forms connected graph\n",
    "    else:\n",
    "        # Subset original adjacency matrix\n",
    "        subset_matrix = adjacency_matrix[np.ix_(tasks_list, tasks_list)]\n",
    "\n",
    "        # check if subset matrix is a connected graph\n",
    "        subset_matrix_connected = is_connected(subset_matrix)\n",
    "\n",
    "        # return true if connected and false otherwise\n",
    "        return subset_matrix_connected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61692d1b",
   "metadata": {},
   "source": [
    "### Compute costs of all \"valid\" execution plans\n",
    "#### New check for validity: automated cost of tasks in non-singleton partition must be less than human costs doing partition tasks separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3b358c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_partition_boundary(adjacency_matrix, partition):\n",
    "    # create a matrix whose columns are nodes not in the partition and whose rows are nodes in the partition\n",
    "    # (subset adjacency matrix to outgoing edges of partition nodes --i.e., rows-- and incoming edges of non-partition nodes --i.e., columns.)\n",
    "    reduced_matrix = np.delete(adjacency_matrix, partition, axis=1) \n",
    "    reduced_matrix = reduced_matrix[partition, :]\n",
    "\n",
    "    # find nodes in partition w/ an edge to non-partition nodes\n",
    "    partition_boundary_tasks = [i for i in partition if np.any(reduced_matrix[partition.index(i), :])]\n",
    "\n",
    "    return partition_boundary_tasks\n",
    "\n",
    "\n",
    "def compute_partition_cost(adjacency_matrix, M_dict, A_dict, D_dict, AI_quality, partition):\n",
    "    # initialize task_done_by_human as False\n",
    "    # (only if partition is singleton and human cost <= automated cost partition is done manually)\n",
    "    task_done_by_human = False\n",
    "\n",
    "    # initialize partition boundary tasks as empty set []\n",
    "    partition_boundary_tasks = []\n",
    "\n",
    "    # if partition is a singleton \n",
    "    # pick minimum of human and management cost\n",
    "    if len(partition) == 1:\n",
    "        partition_is_valid = True # single-node partition is always valid\n",
    "\n",
    "        # calculate human cost\n",
    "        human_cost = sum(M_dict[key] for key in partition)\n",
    "\n",
    "        # calculate management cost\n",
    "        AI_cost = sum(A_dict[key] for key in partition)\n",
    "        difficulty = sum(D_dict[key] for key in partition)\n",
    "        management_cost = AI_cost * (AI_quality ** (-1 * difficulty))\n",
    "        \n",
    "        # pick the minimum of the two\n",
    "        if human_cost < management_cost:\n",
    "            partition_cost = human_cost\n",
    "            task_done_by_human = True\n",
    "        else:\n",
    "            partition_cost = management_cost\n",
    "            partition_boundary_tasks = partition\n",
    "    \n",
    "\n",
    "    # if partition not a singleton \n",
    "    # calculate management cost and return if partition passes a sanity check\n",
    "    if len(partition) > 1:\n",
    "        # calculate human cost\n",
    "        human_cost = sum(M_dict[key] for key in partition)\n",
    "\n",
    "        # calculate management cost\n",
    "        # first get boundary tasks in partition\n",
    "        partition_boundary_tasks = get_partition_boundary(adjacency_matrix, partition)\n",
    "\n",
    "        # sanity check: no partition should have inner boundary of empty set\n",
    "        if len(partition_boundary_tasks) == 0:\n",
    "            # raise ValueError(f'Inner boundary of partition {partition} is empty set.')\n",
    "            return 100000000, [], [], False\n",
    "        \n",
    "        # if partition has at least one boundary task calculate management cost\n",
    "        # use boundary tasks for calculating management costs and partition tasks for difficulty\n",
    "        AI_cost = sum(A_dict[key] for key in partition_boundary_tasks)\n",
    "        difficulty = sum(D_dict[key] for key in partition)\n",
    "        management_cost = AI_cost * (AI_quality ** (-1 * difficulty))\n",
    "\n",
    "        # sanity check for partition validity: \n",
    "        # if human cost < management cost partition is invalid (should not have been formed)\n",
    "        if human_cost < management_cost:\n",
    "            partition_cost = 100000000 # (value doesn't matter)\n",
    "            partition_is_valid = False\n",
    "        else:\n",
    "            partition_cost = management_cost\n",
    "            partition_is_valid = True\n",
    "            partition_boundary_tasks\n",
    "    \n",
    "    return partition_cost, partition_boundary_tasks, task_done_by_human, partition_is_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "694fca2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Random Thought: maybe better to sort valid_partitions on descending partition order to avoid recalculating single node partitions everytime? \n",
    "# tho the downside is that we have to first do the heavy calculations first...\n",
    "\n",
    "\n",
    "def execute_plans(adjacency_matrix, valid_partitions, M_dict, A_dict, D_dict, alpha):\n",
    "    execution_plan = []\n",
    "    execution_plan_augmented_tasks = []\n",
    "    execution_plan_human_tasks = []\n",
    "    execution_plan_cost = []\n",
    "    counter = 0\n",
    "    for scheme in valid_partitions:\n",
    "        # initialize scheme cost\n",
    "        # and partitions that are done manually\n",
    "        scheme_cost = 0\n",
    "        augmented_tasks = []\n",
    "        human_tasks = []\n",
    "        \n",
    "        for partition in scheme:\n",
    "            # calculate partition cost \n",
    "            partition_cost, partition_boundary_tasks, task_done_by_human, partition_is_valid = compute_partition_cost(adjacency_matrix, M_dict, A_dict, D_dict, alpha, partition)\n",
    "        \n",
    "            # if (automated) partition is invalid ignore partition scheme\n",
    "            # and stop calculating costs of further partitions\n",
    "            if not partition_is_valid:\n",
    "                break\n",
    "\n",
    "            if task_done_by_human:\n",
    "                human_tasks.append(partition)\n",
    "            \n",
    "            if not task_done_by_human:\n",
    "                for boundary_task in partition_boundary_tasks:\n",
    "                    augmented_tasks.append([boundary_task])\n",
    "\n",
    "            # if (automated) partition passes sanity check\n",
    "            # add this partition's cost to partition scheme cost\n",
    "            scheme_cost += partition_cost\n",
    "        \n",
    "        # if stopped because an (automated) partition wasn't valid\n",
    "        # ignore current partition scheme and continue\n",
    "        if not partition_is_valid:\n",
    "            continue\n",
    "        \n",
    "        # if partition scheme makes sense append costs\n",
    "        execution_plan.append(scheme)\n",
    "        execution_plan_augmented_tasks.append(augmented_tasks)\n",
    "        execution_plan_human_tasks.append(human_tasks)\n",
    "        execution_plan_cost.append(scheme_cost)\n",
    "\n",
    "    return execution_plan, execution_plan_augmented_tasks, execution_plan_human_tasks, execution_plan_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7354c2d",
   "metadata": {},
   "source": [
    "### Combine steps into a function to run a for loop over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e122fa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DAG_costMin(input_path, output_path, unique_partitions, n=1000):\n",
    "    # set alpha as AI quality metric\n",
    "    epsilon = 1e-8\n",
    "    alpha_list = np.linspace(epsilon, 1-epsilon, n).tolist()\n",
    "\n",
    "\n",
    "\n",
    "    # read DAG\n",
    "    dag_df = pd.read_csv(input_path)\n",
    "\n",
    "    # remove edges if comment column labeled with \"TriangleRemovedFlag\" (edge is there for plotting purposes and is not part of the actual DAG)\n",
    "    if 'comment' in dag_df.columns:\n",
    "        dag_df = dag_df[~dag_df['comment'].str.endswith('TriangleRemovedFlag')]\n",
    "\n",
    "    # get task stats\n",
    "    tasks_stats = pd.read_csv(f'{occupation_folder}/{occupation}_taskStats.csv')\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # extract list of tasks and create a dictionary for indexing tasks\n",
    "    tasks_list = tasks_stats['task'].unique()\n",
    "    tasks_dict = {i: node for i, node in enumerate(tasks_list, start=0)}\n",
    "\n",
    "    # create numpy array of adjacency matrix\n",
    "    adjacency_matrix = np.zeros((len(tasks_list), len(tasks_list)), dtype=int)\n",
    "    aux_dict = {value: key for key, value in tasks_dict.items()}\n",
    "    for _, row in dag_df.iterrows():\n",
    "        source_index = aux_dict[row['source']]\n",
    "        target_index = aux_dict[row['target']]\n",
    "        adjacency_matrix[source_index, target_index] = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # add task_dict key and reset index\n",
    "    aux_dict = {value: key for key, value in tasks_dict.items()}\n",
    "    tasks_stats['dict_index'] = tasks_stats.apply(lambda row: aux_dict[row.task], axis=1)\n",
    "    tasks_stats = tasks_stats.sort_values(by='dict_index')\n",
    "    tasks_stats = tasks_stats.set_index('dict_index', drop=False)\n",
    "    tasks_stats.index.name = None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # create dictionaries for human cost, management cost, and difficulty\n",
    "    M_dict = dict(zip(tasks_stats['dict_index'], tasks_stats['human_cost']))\n",
    "    A_dict = dict(zip(tasks_stats['dict_index'], tasks_stats['management_cost']))\n",
    "    D_dict = dict(zip(tasks_stats['dict_index'], tasks_stats['difficulty']))\n",
    "\n",
    "\n",
    "\n",
    "    # Get valid partitioning schemes\n",
    "    generate_valid_partitions_start = time.time()\n",
    "    valid_partitions = []\n",
    "    for scheme in unique_partitions:\n",
    "        # Set valid partitions count to 0\n",
    "        valid_partition_count = 0\n",
    "        for partition in scheme:\n",
    "            valid_partition = validate_partition_using_connectedness(adjacency_matrix, partition)\n",
    "            if valid_partition:\n",
    "                valid_partition_count += 1\n",
    "        \n",
    "        # If number of valid partitions within a partition scheme is equal to \n",
    "        # number of partitions in partition scheme then partition scheme is valid\n",
    "        if valid_partition_count == len(scheme):\n",
    "            valid_partitions.append(scheme)\n",
    "    generate_valid_partitions_time = (time.time() - generate_valid_partitions_start)/60\n",
    "    print(f\"valid execution plans generation: {generate_valid_partitions_time:.2f} minutes\")\n",
    "\n",
    "    # Print stats\n",
    "    print(f'Number of valid partitioning schemes given DAG structure: {len(valid_partitions)}')\n",
    "\n",
    "\n",
    "    \n",
    "    # run once to get stat\n",
    "    execution_plan, execution_plan_augmented_tasks, execution_plan_human_tasks, execution_plan_cost = execute_plans(adjacency_matrix, valid_partitions, M_dict, A_dict, D_dict, 0.5)\n",
    "    print(f'Number of valid execution plans: {len(execution_plan)}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    random.seed(1)\n",
    "    minimum_cost_list = []\n",
    "    number_of_optimal_schemes_list = []\n",
    "    optimal_execution_plan_list = []\n",
    "    optimal_plan_augmentedTasks_list = []\n",
    "    optimal_plan_augmentedTasks_count_list = []\n",
    "    optimal_plan_humanTasks_list = []\n",
    "    optimal_plan_humanTasks_count_list = []\n",
    "    for counter, alpha in enumerate(alpha_list):\n",
    "        # if counter % 100 == 0:\n",
    "        #     print(f'-- Running {counter}th alpha --')\n",
    "\n",
    "        # get list of execution plans and costs for this alpha\n",
    "        execution_plan, execution_plan_augmented_tasks, execution_plan_human_tasks, execution_plan_cost = execute_plans(adjacency_matrix, valid_partitions, M_dict, A_dict, D_dict, alpha)\n",
    "\n",
    "        # choose minimum\n",
    "        minimum_cost = min(execution_plan_cost)\n",
    "        minimum_cost_index = [index for index, value in enumerate(execution_plan_cost) if value == minimum_cost]\n",
    "\n",
    "        # in rare cases there are more than one optimal plan\n",
    "        if len(minimum_cost_index) > 1:\n",
    "            optimal_execution_scheme = [execution_plan[index] for index in minimum_cost_index]\n",
    "            optimal_execution_human_tasks = [execution_plan_human_tasks[index] for index in minimum_cost_index]\n",
    "            optimal_execution_augmented_tasks = [execution_plan_augmented_tasks[index] for index in minimum_cost_index]\n",
    "            # print(alpha)\n",
    "            # print(optimal_execution_scheme)\n",
    "            # print(optimal_execution_human_tasks)\n",
    "            # print(f'Multiple Execution Plans for alpha={alpha}')\n",
    "        else:\n",
    "            optimal_execution_scheme = execution_plan[minimum_cost_index[0]]\n",
    "            optimal_execution_human_tasks = execution_plan_human_tasks[minimum_cost_index[0]]\n",
    "            optimal_execution_augmented_tasks = execution_plan_augmented_tasks[minimum_cost_index[0]]\n",
    "\n",
    "        # append lists\n",
    "        minimum_cost_list.append(minimum_cost)\n",
    "        number_of_optimal_schemes_list.append(len(minimum_cost_index))\n",
    "        optimal_execution_plan_list.append(optimal_execution_scheme)\n",
    "        optimal_plan_augmentedTasks_list.append(optimal_execution_augmented_tasks)\n",
    "        optimal_plan_augmentedTasks_count_list.append(len(optimal_execution_augmented_tasks))\n",
    "        optimal_plan_humanTasks_list.append(optimal_execution_human_tasks)\n",
    "        optimal_plan_humanTasks_count_list.append(len(optimal_execution_human_tasks))\n",
    "\n",
    "    # save outputs\n",
    "    output_df = pd.DataFrame({\n",
    "        'alpha': alpha_list,\n",
    "        'optimal_schemes_count': number_of_optimal_schemes_list,\n",
    "        'cost': minimum_cost_list,\n",
    "        'optimal_scheme': optimal_execution_plan_list,\n",
    "        'optimal_scheme_augmented_tasks': optimal_plan_augmentedTasks_list,\n",
    "        'augmented_tasks_count': optimal_plan_augmentedTasks_count_list,\n",
    "        'optimal_scheme_human_tasks': optimal_plan_humanTasks_list,\n",
    "        'human_tasks_count': optimal_plan_humanTasks_count_list\n",
    "    })\n",
    "    output_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538ec907",
   "metadata": {},
   "source": [
    "## Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ee7f28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of alphas to sweept over: 100\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# number of alphas to sweep over\n",
    "n = 100\n",
    "print(f'Number of alphas to sweept over: {n}')\n",
    "\n",
    "onet_data_path = f'{data_path}/data/onet_occupations_yearly.csv'\n",
    "\n",
    "occupation_list = ['pileDriverOperators', 'dredgeOperators', 'gradersAndSortersForAgriculturalProducts',\n",
    "                   'insuranceUnderwriters', 'insuranceAppraisersForAutoDamage', 'floorSandersAndFinishers', \n",
    "                   'reinforcingIronAndRebarWorkers', 'travelAgents', 'dataEntryKeyer', \n",
    "                   'athletesAndSportsCompetitors', 'audiovisualEquipmentInstallerAndRepairers', 'hearingAidSpecialists', \n",
    "                   'personalCareAides', 'proofreadersAndCopyMarkers', 'chiropractors', \n",
    "                   'shippingReceivingAndInventoryClerks', 'cooksShortOrder', 'orthodontists',\n",
    "                   'subwayAndStreetcarOperators', 'packersAndPackagersHand', 'hoistAndWinchOperators', \n",
    "                   'forgingMachineSettersOperatorsAndTenders', 'avionicsTechnicians', 'dishwashers', \n",
    "                   'dispatchersExceptPoliceFireAndAmbulance', 'familyMedicinePhysicians', 'MachineFeedersAndOffbearers'\n",
    "                   ]\n",
    "\n",
    "# occupation_list = ['travelAgents', 'insuranceUnderwriters', 'pileDriverOperators'\n",
    "#                    ]\n",
    "\n",
    "\n",
    "\n",
    "# occupation_list = ['pileDriverOperators', 'dredgeOperators', 'gradersAndSortersForAgriculturalProducts',\n",
    "#                    'insuranceUnderwriters', 'insuranceAppraisersForAutoDamage', 'floorSandersAndFinishers', \n",
    "#                    'reinforcingIronAndRebarWorkers', 'travelAgents', 'dataEntryKeyer', \n",
    "#                    'athletesAndSportsCompetitors'\n",
    "#                    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a3a99b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------- Running: pileDriverOperators ----------------------\n",
      "Number of non-target tasks: 5\n",
      "Time to generate all possible partition schemes: 0.00 seconds\n",
      "Number of all possible partitioning schemes: 52\n",
      "\n",
      "-------Running: pileDriverOperators - Manual DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 26\n",
      "Number of valid execution plans: 24\n",
      "\n",
      "pileDriverOperators Manual DAG runtime: 0.05 seconds\n",
      "\n",
      "-------Running: pileDriverOperators - Naive DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 30\n",
      "Number of valid execution plans: 15\n",
      "\n",
      "pileDriverOperators Naive DAG runtime: 0.05 seconds\n",
      "\n",
      "-------Running: pileDriverOperators - Conditioned Naive DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 26\n",
      "Number of valid execution plans: 15\n",
      "\n",
      "pileDriverOperators Conditioned Naive DAG runtime: 0.05 seconds\n",
      "\n",
      "-------Running: pileDriverOperators - First-Last Task DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 30\n",
      "Number of valid execution plans: 15\n",
      "\n",
      "pileDriverOperators First-Last Task DAG runtime: 0.05 seconds\n",
      "\n",
      "-------Running: pileDriverOperators - Conditioned First-Last Task DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 26\n",
      "Number of valid execution plans: 15\n",
      "\n",
      "pileDriverOperators Conditioned First-Last Task DAG runtime: 0.05 seconds\n",
      "\n",
      "-------Running: pileDriverOperators - Partitioned DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 52\n",
      "Number of valid execution plans: 27\n",
      "\n",
      "pileDriverOperators Partitioned DAG runtime: 0.10 seconds\n",
      "\n",
      "-------Running: pileDriverOperators - Conditioned Partitioned DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 34\n",
      "Number of valid execution plans: 21\n",
      "\n",
      "pileDriverOperators Conditioned Partitioned DAG runtime: 0.06 seconds\n",
      "\n",
      "\n",
      "************* pileDriverOperators runtime: 0.01 minutes *************\n",
      "\n",
      "runtime since start: 0.01 minutes\n",
      "\n",
      "\n",
      "---------------------- Running: dredgeOperators ----------------------\n",
      "Number of non-target tasks: 6\n",
      "Time to generate all possible partition schemes: 0.01 seconds\n",
      "Number of all possible partitioning schemes: 203\n",
      "\n",
      "-------Running: dredgeOperators - Naive DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 80\n",
      "Number of valid execution plans: 22\n",
      "\n",
      "dredgeOperators Naive DAG runtime: 0.14 seconds\n",
      "\n",
      "-------Running: dredgeOperators - Conditioned Naive DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 32\n",
      "Number of valid execution plans: 26\n",
      "\n",
      "dredgeOperators Conditioned Naive DAG runtime: 0.06 seconds\n",
      "\n",
      "-------Running: dredgeOperators - First-Last Task DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 60\n",
      "Number of valid execution plans: 21\n",
      "\n",
      "dredgeOperators First-Last Task DAG runtime: 0.11 seconds\n",
      "\n",
      "-------Running: dredgeOperators - Conditioned First-Last Task DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 32\n",
      "Number of valid execution plans: 14\n",
      "\n",
      "dredgeOperators Conditioned First-Last Task DAG runtime: 0.06 seconds\n",
      "\n",
      "-------Running: dredgeOperators - Partitioned DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 158\n",
      "Number of valid execution plans: 40\n",
      "\n",
      "dredgeOperators Partitioned DAG runtime: 0.28 seconds\n",
      "\n",
      "-------Running: dredgeOperators - Conditioned Partitioned DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 32\n",
      "Number of valid execution plans: 29\n",
      "\n",
      "dredgeOperators Conditioned Partitioned DAG runtime: 0.07 seconds\n",
      "\n",
      "\n",
      "************* dredgeOperators runtime: 0.02 minutes *************\n",
      "\n",
      "runtime since start: 0.03 minutes\n",
      "\n",
      "\n",
      "---------------------- Running: gradersAndSortersForAgriculturalProducts ----------------------\n",
      "Number of non-target tasks: 6\n",
      "Number of all possible partitioning schemes: 203\n",
      "\n",
      "-------Running: gradersAndSortersForAgriculturalProducts - Naive DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 104\n",
      "Number of valid execution plans: 50\n",
      "\n",
      "gradersAndSortersForAgriculturalProducts Naive DAG runtime: 0.19 seconds\n",
      "\n",
      "-------Running: gradersAndSortersForAgriculturalProducts - Conditioned Naive DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 94\n",
      "Number of valid execution plans: 46\n",
      "\n",
      "gradersAndSortersForAgriculturalProducts Conditioned Naive DAG runtime: 0.18 seconds\n",
      "\n",
      "-------Running: gradersAndSortersForAgriculturalProducts - First-Last Task DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 141\n",
      "Number of valid execution plans: 78\n",
      "\n",
      "gradersAndSortersForAgriculturalProducts First-Last Task DAG runtime: 0.27 seconds\n",
      "\n",
      "-------Running: gradersAndSortersForAgriculturalProducts - Conditioned First-Last Task DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 94\n",
      "Number of valid execution plans: 90\n",
      "\n",
      "gradersAndSortersForAgriculturalProducts Conditioned First-Last Task DAG runtime: 0.17 seconds\n",
      "\n",
      "-------Running: gradersAndSortersForAgriculturalProducts - Partitioned DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 104\n",
      "Number of valid execution plans: 58\n",
      "\n",
      "gradersAndSortersForAgriculturalProducts Partitioned DAG runtime: 0.21 seconds\n",
      "\n",
      "-------Running: gradersAndSortersForAgriculturalProducts - Conditioned Partitioned DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 104\n",
      "Number of valid execution plans: 58\n",
      "\n",
      "gradersAndSortersForAgriculturalProducts Conditioned Partitioned DAG runtime: 0.19 seconds\n",
      "\n",
      "\n",
      "************* gradersAndSortersForAgriculturalProducts runtime: 0.03 minutes *************\n",
      "\n",
      "runtime since start: 0.06 minutes\n",
      "\n",
      "\n",
      "---------------------- Running: insuranceUnderwriters ----------------------\n",
      "Number of non-target tasks: 7\n",
      "Time to generate all possible partition schemes: 0.12 seconds\n",
      "Number of all possible partitioning schemes: 877\n",
      "\n",
      "-------Running: insuranceUnderwriters - Manual DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 192\n",
      "Number of valid execution plans: 82\n",
      "\n",
      "insuranceUnderwriters Manual DAG runtime: 0.39 seconds\n",
      "\n",
      "-------Running: insuranceUnderwriters - Naive DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 758\n",
      "Number of valid execution plans: 119\n",
      "\n",
      "insuranceUnderwriters Naive DAG runtime: 1.92 seconds\n",
      "\n",
      "-------Running: insuranceUnderwriters - Conditioned Naive DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 200\n",
      "Number of valid execution plans: 79\n",
      "\n",
      "insuranceUnderwriters Conditioned Naive DAG runtime: 0.41 seconds\n",
      "\n",
      "-------Running: insuranceUnderwriters - First-Last Task DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 758\n",
      "Number of valid execution plans: 130\n",
      "\n",
      "insuranceUnderwriters First-Last Task DAG runtime: 1.37 seconds\n",
      "\n",
      "-------Running: insuranceUnderwriters - Conditioned First-Last Task DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 383\n",
      "Number of valid execution plans: 130\n",
      "\n",
      "insuranceUnderwriters Conditioned First-Last Task DAG runtime: 1.33 seconds\n",
      "\n",
      "-------Running: insuranceUnderwriters - Partitioned DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 758\n",
      "Number of valid execution plans: 115\n",
      "\n",
      "insuranceUnderwriters Partitioned DAG runtime: 1.47 seconds\n",
      "\n",
      "-------Running: insuranceUnderwriters - Conditioned Partitioned DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 308\n",
      "Number of valid execution plans: 119\n",
      "\n",
      "insuranceUnderwriters Conditioned Partitioned DAG runtime: 0.64 seconds\n",
      "\n",
      "\n",
      "************* insuranceUnderwriters runtime: 0.13 minutes *************\n",
      "\n",
      "runtime since start: 0.19 minutes\n",
      "\n",
      "\n",
      "---------------------- Running: insuranceAppraisersForAutoDamage ----------------------\n",
      "Number of non-target tasks: 7\n",
      "Number of all possible partitioning schemes: 877\n",
      "\n",
      "-------Running: insuranceAppraisersForAutoDamage - Naive DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 758\n",
      "Number of valid execution plans: 210\n",
      "\n",
      "insuranceAppraisersForAutoDamage Naive DAG runtime: 2.05 seconds\n",
      "\n",
      "-------Running: insuranceAppraisersForAutoDamage - Conditioned Naive DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 616\n",
      "Number of valid execution plans: 163\n",
      "\n",
      "insuranceAppraisersForAutoDamage Conditioned Naive DAG runtime: 1.76 seconds\n",
      "\n",
      "-------Running: insuranceAppraisersForAutoDamage - First-Last Task DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 616\n",
      "Number of valid execution plans: 165\n",
      "\n",
      "insuranceAppraisersForAutoDamage First-Last Task DAG runtime: 1.20 seconds\n",
      "\n",
      "-------Running: insuranceAppraisersForAutoDamage - Conditioned First-Last Task DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 546\n",
      "Number of valid execution plans: 139\n",
      "\n",
      "insuranceAppraisersForAutoDamage Conditioned First-Last Task DAG runtime: 1.62 seconds\n",
      "\n",
      "-------Running: insuranceAppraisersForAutoDamage - Partitioned DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 825\n",
      "Number of valid execution plans: 244\n",
      "\n",
      "insuranceAppraisersForAutoDamage Partitioned DAG runtime: 2.15 seconds\n",
      "\n",
      "-------Running: insuranceAppraisersForAutoDamage - Conditioned Partitioned DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 641\n",
      "Number of valid execution plans: 173\n",
      "\n",
      "insuranceAppraisersForAutoDamage Conditioned Partitioned DAG runtime: 1.85 seconds\n",
      "\n",
      "\n",
      "************* insuranceAppraisersForAutoDamage runtime: 0.18 minutes *************\n",
      "\n",
      "runtime since start: 0.37 minutes\n",
      "\n",
      "\n",
      "---------------------- Running: floorSandersAndFinishers ----------------------\n",
      "Number of non-target tasks: 7\n",
      "Number of all possible partitioning schemes: 877\n",
      "\n",
      "-------Running: floorSandersAndFinishers - Naive DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 624\n",
      "Number of valid execution plans: 115\n",
      "\n",
      "floorSandersAndFinishers Naive DAG runtime: 1.16 seconds\n",
      "\n",
      "-------Running: floorSandersAndFinishers - Conditioned Naive DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 551\n",
      "Number of valid execution plans: 104\n",
      "\n",
      "floorSandersAndFinishers Conditioned Naive DAG runtime: 1.64 seconds\n",
      "\n",
      "-------Running: floorSandersAndFinishers - First-Last Task DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 551\n",
      "Number of valid execution plans: 106\n",
      "\n",
      "floorSandersAndFinishers First-Last Task DAG runtime: 1.04 seconds\n",
      "\n",
      "-------Running: floorSandersAndFinishers - Conditioned First-Last Task DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 403\n",
      "Number of valid execution plans: 82\n",
      "\n",
      "floorSandersAndFinishers Conditioned First-Last Task DAG runtime: 0.78 seconds\n",
      "\n",
      "-------Running: floorSandersAndFinishers - Partitioned DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 778\n",
      "Number of valid execution plans: 143\n",
      "\n",
      "floorSandersAndFinishers Partitioned DAG runtime: 2.00 seconds\n",
      "\n",
      "-------Running: floorSandersAndFinishers - Conditioned Partitioned DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 576\n",
      "Number of valid execution plans: 109\n",
      "\n",
      "floorSandersAndFinishers Conditioned Partitioned DAG runtime: 1.12 seconds\n",
      "\n",
      "\n",
      "************* floorSandersAndFinishers runtime: 0.14 minutes *************\n",
      "\n",
      "runtime since start: 0.51 minutes\n",
      "\n",
      "\n",
      "---------------------- Running: reinforcingIronAndRebarWorkers ----------------------\n",
      "Number of non-target tasks: 7\n",
      "Number of all possible partitioning schemes: 877\n",
      "\n",
      "-------Running: reinforcingIronAndRebarWorkers - Naive DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 825\n",
      "Number of valid execution plans: 321\n",
      "\n",
      "reinforcingIronAndRebarWorkers Naive DAG runtime: 2.33 seconds\n",
      "\n",
      "-------Running: reinforcingIronAndRebarWorkers - Conditioned Naive DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 437\n",
      "Number of valid execution plans: 165\n",
      "\n",
      "reinforcingIronAndRebarWorkers Conditioned Naive DAG runtime: 1.45 seconds\n",
      "\n",
      "-------Running: reinforcingIronAndRebarWorkers - First-Last Task DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 376\n",
      "Number of valid execution plans: 93\n",
      "\n",
      "reinforcingIronAndRebarWorkers First-Last Task DAG runtime: 0.80 seconds\n",
      "\n",
      "-------Running: reinforcingIronAndRebarWorkers - Conditioned First-Last Task DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 306\n",
      "Number of valid execution plans: 80\n",
      "\n",
      "reinforcingIronAndRebarWorkers Conditioned First-Last Task DAG runtime: 0.64 seconds\n",
      "\n",
      "-------Running: reinforcingIronAndRebarWorkers - Partitioned DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 825\n",
      "Number of valid execution plans: 339\n",
      "\n",
      "reinforcingIronAndRebarWorkers Partitioned DAG runtime: 2.25 seconds\n",
      "\n",
      "-------Running: reinforcingIronAndRebarWorkers - Conditioned Partitioned DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 641\n",
      "Number of valid execution plans: 260\n",
      "\n",
      "reinforcingIronAndRebarWorkers Conditioned Partitioned DAG runtime: 1.88 seconds\n",
      "\n",
      "\n",
      "************* reinforcingIronAndRebarWorkers runtime: 0.16 minutes *************\n",
      "\n",
      "runtime since start: 0.67 minutes\n",
      "\n",
      "\n",
      "---------------------- Running: travelAgents ----------------------\n",
      "Number of non-target tasks: 8\n",
      "Time to generate all possible partition schemes: 1.54 seconds\n",
      "Number of all possible partitioning schemes: 4140\n",
      "\n",
      "-------Running: travelAgents - Manual DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 192\n",
      "Number of valid execution plans: 107\n",
      "\n",
      "travelAgents Manual DAG runtime: 0.48 seconds\n",
      "\n",
      "-------Running: travelAgents - Naive DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 2106\n",
      "Number of valid execution plans: 125\n",
      "\n",
      "travelAgents Naive DAG runtime: 4.13 seconds\n",
      "\n",
      "-------Running: travelAgents - Conditioned Naive DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 428\n",
      "Number of valid execution plans: 38\n",
      "\n",
      "travelAgents Conditioned Naive DAG runtime: 0.83 seconds\n",
      "\n",
      "-------Running: travelAgents - First-Last Task DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 2428\n",
      "Number of valid execution plans: 244\n",
      "\n",
      "travelAgents First-Last Task DAG runtime: 5.64 seconds\n",
      "\n",
      "-------Running: travelAgents - Conditioned First-Last Task DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 1432\n",
      "Number of valid execution plans: 152\n",
      "\n",
      "travelAgents Conditioned First-Last Task DAG runtime: 3.27 seconds\n",
      "\n",
      "-------Running: travelAgents - Partitioned DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 3749\n",
      "Number of valid execution plans: 317\n",
      "\n",
      "travelAgents Partitioned DAG runtime: 7.52 seconds\n",
      "\n",
      "-------Running: travelAgents - Conditioned Partitioned DAG-------\n",
      "valid execution plans generation: 0.00 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 550\n",
      "Number of valid execution plans: 78\n",
      "\n",
      "travelAgents Conditioned Partitioned DAG runtime: 1.71 seconds\n",
      "\n",
      "\n",
      "************* travelAgents runtime: 0.42 minutes *************\n",
      "\n",
      "runtime since start: 1.09 minutes\n",
      "\n",
      "\n",
      "---------------------- Running: dataEntryKeyer ----------------------\n",
      "Number of non-target tasks: 9\n",
      "Time to generate all possible partition schemes: 21.00 seconds\n",
      "Number of all possible partitioning schemes: 21147\n",
      "\n",
      "-------Running: dataEntryKeyer - Naive DAG-------\n",
      "valid execution plans generation: 0.01 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 3355\n",
      "Number of valid execution plans: 2660\n",
      "\n",
      "dataEntryKeyer Naive DAG runtime: 13.40 seconds\n",
      "\n",
      "-------Running: dataEntryKeyer - Conditioned Naive DAG-------\n",
      "valid execution plans generation: 0.01 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 2204\n",
      "Number of valid execution plans: 1783\n",
      "\n",
      "dataEntryKeyer Conditioned Naive DAG runtime: 8.47 seconds\n",
      "\n",
      "-------Running: dataEntryKeyer - First-Last Task DAG-------\n",
      "valid execution plans generation: 0.01 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 3112\n",
      "Number of valid execution plans: 2200\n",
      "\n",
      "dataEntryKeyer First-Last Task DAG runtime: 11.34 seconds\n",
      "\n",
      "-------Running: dataEntryKeyer - Conditioned First-Last Task DAG-------\n",
      "valid execution plans generation: 0.01 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 2262\n",
      "Number of valid execution plans: 1659\n",
      "\n",
      "dataEntryKeyer Conditioned First-Last Task DAG runtime: 8.63 seconds\n",
      "\n",
      "-------Running: dataEntryKeyer - Partitioned DAG-------\n",
      "valid execution plans generation: 0.01 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 2189\n",
      "Number of valid execution plans: 1926\n",
      "\n",
      "dataEntryKeyer Partitioned DAG runtime: 9.05 seconds\n",
      "\n",
      "-------Running: dataEntryKeyer - Conditioned Partitioned DAG-------\n",
      "valid execution plans generation: 0.01 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 672\n",
      "Number of valid execution plans: 655\n",
      "\n",
      "dataEntryKeyer Conditioned Partitioned DAG runtime: 2.79 seconds\n",
      "\n",
      "\n",
      "************* dataEntryKeyer runtime: 1.25 minutes *************\n",
      "\n",
      "runtime since start: 2.34 minutes\n",
      "\n",
      "\n",
      "---------------------- Running: athletesAndSportsCompetitors ----------------------\n",
      "Number of non-target tasks: 9\n",
      "Number of all possible partitioning schemes: 21147\n",
      "\n",
      "-------Running: athletesAndSportsCompetitors - Naive DAG-------\n",
      "valid execution plans generation: 0.01 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 8508\n",
      "Number of valid execution plans: 755\n",
      "\n",
      "athletesAndSportsCompetitors Naive DAG runtime: 26.06 seconds\n",
      "\n",
      "-------Running: athletesAndSportsCompetitors - Conditioned Naive DAG-------\n",
      "valid execution plans generation: 0.01 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 970\n",
      "Number of valid execution plans: 141\n",
      "\n",
      "athletesAndSportsCompetitors Conditioned Naive DAG runtime: 3.30 seconds\n",
      "\n",
      "-------Running: athletesAndSportsCompetitors - First-Last Task DAG-------\n",
      "valid execution plans generation: 0.01 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 824\n",
      "Number of valid execution plans: 210\n",
      "\n",
      "athletesAndSportsCompetitors First-Last Task DAG runtime: 2.87 seconds\n",
      "\n",
      "-------Running: athletesAndSportsCompetitors - Conditioned First-Last Task DAG-------\n",
      "valid execution plans generation: 0.01 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 128\n",
      "Number of valid execution plans: 63\n",
      "\n",
      "athletesAndSportsCompetitors Conditioned First-Last Task DAG runtime: 0.68 seconds\n",
      "\n",
      "-------Running: athletesAndSportsCompetitors - Partitioned DAG-------\n",
      "valid execution plans generation: 0.01 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 9422\n",
      "Number of valid execution plans: 763\n",
      "\n",
      "athletesAndSportsCompetitors Partitioned DAG runtime: 28.11 seconds\n",
      "\n",
      "-------Running: athletesAndSportsCompetitors - Conditioned Partitioned DAG-------\n",
      "valid execution plans generation: 0.01 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 1425\n",
      "Number of valid execution plans: 51\n",
      "\n",
      "athletesAndSportsCompetitors Conditioned Partitioned DAG runtime: 4.20 seconds\n",
      "\n",
      "\n",
      "************* athletesAndSportsCompetitors runtime: 1.09 minutes *************\n",
      "\n",
      "runtime since start: 3.44 minutes\n",
      "\n",
      "\n",
      "---------------------- Running: audiovisualEquipmentInstallerAndRepairers ----------------------\n",
      "Number of non-target tasks: 11\n",
      "Time to generate all possible partition schemes: 5309.86 seconds\n",
      "Number of all possible partitioning schemes: 678570\n",
      "\n",
      "-------Running: audiovisualEquipmentInstallerAndRepairers - Naive DAG-------\n",
      "valid execution plans generation: 0.28 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 404556\n",
      "Number of valid execution plans: 13074\n",
      "\n",
      "audiovisualEquipmentInstallerAndRepairers Naive DAG runtime: 1107.46 seconds\n",
      "\n",
      "-------Running: audiovisualEquipmentInstallerAndRepairers - Conditioned Naive DAG-------\n",
      "valid execution plans generation: 0.25 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 7074\n",
      "Number of valid execution plans: 1115\n",
      "\n",
      "audiovisualEquipmentInstallerAndRepairers Conditioned Naive DAG runtime: 36.04 seconds\n",
      "\n",
      "-------Running: audiovisualEquipmentInstallerAndRepairers - First-Last Task DAG-------\n",
      "valid execution plans generation: 0.28 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 290780\n",
      "Number of valid execution plans: 8346\n",
      "\n",
      "audiovisualEquipmentInstallerAndRepairers First-Last Task DAG runtime: 798.62 seconds\n",
      "\n",
      "-------Running: audiovisualEquipmentInstallerAndRepairers - Conditioned First-Last Task DAG-------\n",
      "valid execution plans generation: 0.27 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 8502\n",
      "Number of valid execution plans: 702\n",
      "\n",
      "audiovisualEquipmentInstallerAndRepairers Conditioned First-Last Task DAG runtime: 39.02 seconds\n",
      "\n",
      "-------Running: audiovisualEquipmentInstallerAndRepairers - Partitioned DAG-------\n",
      "valid execution plans generation: 0.29 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 501378\n",
      "Number of valid execution plans: 21977\n",
      "\n",
      "audiovisualEquipmentInstallerAndRepairers Partitioned DAG runtime: 1362.97 seconds\n",
      "\n",
      "-------Running: audiovisualEquipmentInstallerAndRepairers - Conditioned Partitioned DAG-------\n",
      "valid execution plans generation: 0.26 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 13886\n",
      "Number of valid execution plans: 2036\n",
      "\n",
      "audiovisualEquipmentInstallerAndRepairers Conditioned Partitioned DAG runtime: 55.02 seconds\n",
      "\n",
      "\n",
      "************* audiovisualEquipmentInstallerAndRepairers runtime: 145.16 minutes *************\n",
      "\n",
      "runtime since start: 148.59 minutes\n",
      "\n",
      "\n",
      "---------------------- Running: hearingAidSpecialists ----------------------\n",
      "Number of non-target tasks: 11\n",
      "Number of all possible partitioning schemes: 678570\n",
      "\n",
      "-------Running: hearingAidSpecialists - Naive DAG-------\n",
      "valid execution plans generation: 0.29 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 142700\n",
      "Number of valid execution plans: 96\n",
      "\n",
      "hearingAidSpecialists Naive DAG runtime: 335.02 seconds\n",
      "\n",
      "-------Running: hearingAidSpecialists - Conditioned Naive DAG-------\n",
      "valid execution plans generation: 0.26 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 17652\n",
      "Number of valid execution plans: 40\n",
      "\n",
      "hearingAidSpecialists Conditioned Naive DAG runtime: 55.42 seconds\n",
      "\n",
      "-------Running: hearingAidSpecialists - First-Last Task DAG-------\n",
      "valid execution plans generation: 0.28 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 51044\n",
      "Number of valid execution plans: 56\n",
      "\n",
      "hearingAidSpecialists First-Last Task DAG runtime: 125.44 seconds\n",
      "\n",
      "-------Running: hearingAidSpecialists - Conditioned First-Last Task DAG-------\n",
      "valid execution plans generation: 0.25 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 2200\n",
      "Number of valid execution plans: 30\n",
      "\n",
      "hearingAidSpecialists Conditioned First-Last Task DAG runtime: 19.32 seconds\n",
      "\n",
      "-------Running: hearingAidSpecialists - Partitioned DAG-------\n",
      "valid execution plans generation: 0.27 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 92975\n",
      "Number of valid execution plans: 80\n",
      "\n",
      "hearingAidSpecialists Partitioned DAG runtime: 213.11 seconds\n",
      "\n",
      "-------Running: hearingAidSpecialists - Conditioned Partitioned DAG-------\n",
      "valid execution plans generation: 0.27 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 42207\n",
      "Number of valid execution plans: 90\n",
      "\n",
      "hearingAidSpecialists Conditioned Partitioned DAG runtime: 107.77 seconds\n",
      "\n",
      "\n",
      "************* hearingAidSpecialists runtime: 14.27 minutes *************\n",
      "\n",
      "runtime since start: 162.87 minutes\n",
      "\n",
      "\n",
      "---------------------- Running: personalCareAides ----------------------\n",
      "Number of non-target tasks: 11\n",
      "Number of all possible partitioning schemes: 678570\n",
      "\n",
      "-------Running: personalCareAides - Naive DAG-------\n",
      "valid execution plans generation: 0.26 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 30012\n",
      "Number of valid execution plans: 30\n",
      "\n",
      "personalCareAides Naive DAG runtime: 77.03 seconds\n",
      "\n",
      "-------Running: personalCareAides - Conditioned Naive DAG-------\n",
      "valid execution plans generation: 0.25 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 7252\n",
      "Number of valid execution plans: 27\n",
      "\n",
      "personalCareAides Conditioned Naive DAG runtime: 30.81 seconds\n",
      "\n",
      "-------Running: personalCareAides - First-Last Task DAG-------\n",
      "valid execution plans generation: 0.25 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 3008\n",
      "Number of valid execution plans: 7\n",
      "\n",
      "personalCareAides First-Last Task DAG runtime: 20.59 seconds\n",
      "\n",
      "-------Running: personalCareAides - Conditioned First-Last Task DAG-------\n",
      "valid execution plans generation: 0.25 minutes\n",
      "Number of valid partitioning schemes given DAG structure: 1184\n",
      "Number of valid execution plans: 12\n",
      "\n",
      "personalCareAides Conditioned First-Last Task DAG runtime: 17.27 seconds\n",
      "\n",
      "-------Running: personalCareAides - Partitioned DAG-------\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/peymansh/Dropbox (MIT)/Research/AI and Occupations/ai-exposure/output/daily_tasks_occupations_analysis/personalCareAides/personalCareAides_P_GPT_DAG_df.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 85\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------Running: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moccupation\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDAG_indicator\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     84\u001b[0m DAG_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 85\u001b[0m DAG_costMin(input_path, output_path, unique_partitions, n)\n\u001b[1;32m     86\u001b[0m DAG_end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     88\u001b[0m DAG_execution_time \u001b[38;5;241m=\u001b[39m DAG_end_time \u001b[38;5;241m-\u001b[39m DAG_start_time\n",
      "Cell \u001b[0;32mIn[28], line 9\u001b[0m, in \u001b[0;36mDAG_costMin\u001b[0;34m(input_path, output_path, unique_partitions, n)\u001b[0m\n\u001b[1;32m      4\u001b[0m alpha_list \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(epsilon, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mepsilon, n)\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# read DAG\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m dag_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(input_path)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# remove edges if comment column labeled with \"TriangleRemovedFlag\" (edge is there for plotting purposes and is not part of the actual DAG)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomment\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m dag_df\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/peymansh/Dropbox (MIT)/Research/AI and Occupations/ai-exposure/output/daily_tasks_occupations_analysis/personalCareAides/personalCareAides_P_GPT_DAG_df.csv'"
     ]
    }
   ],
   "source": [
    "num_tasks_current = 0\n",
    "num_tasks_previous = 0\n",
    "for occupation in occupation_list:\n",
    "    print(f'\\n---------------------- Running: {occupation} ----------------------')\n",
    "    occupation_start_time = time.time()\n",
    "\n",
    "    # generate occupation-specific strings\n",
    "    GPT_input_occupation, plot_title_occupation, occupation_code, occupation_folder = pick_occupation(occupation)\n",
    "\n",
    "\n",
    "    # Get occupation tasks to create all possible partitions\n",
    "    tasks = get_tasks(onet_data_path, occupation_code)\n",
    "    num_tasks_current = len(tasks)\n",
    "    print(f'Number of non-target tasks: {num_tasks_current}')\n",
    "\n",
    "    if num_tasks_current < 10:\n",
    "        n = 100\n",
    "    else: \n",
    "        n = 100\n",
    "\n",
    "    # if number of tasks in new occupation has increased generate new set of possible partitions\n",
    "    if num_tasks_current != num_tasks_previous:\n",
    "        unique_partitions_start_time = time.time()\n",
    "\n",
    "        # Generate list of numbers for non-\"Target\" tasks in occupation\n",
    "        tasks_list_numbers = list(range(num_tasks_current))\n",
    "\n",
    "        # Generate all possible partitioning schemes\n",
    "        unique_partitions = generate_unique_partitions(tasks_list_numbers)\n",
    "        unique_partitions_end_time = time.time()\n",
    "\n",
    "        unique_partitions_execution_time = unique_partitions_end_time - unique_partitions_start_time\n",
    "        print(f'Time to generate all possible partition schemes: {unique_partitions_execution_time:.2f} seconds')\n",
    "    \n",
    "    # update num_tasks_previous for next iteration and print stats\n",
    "    num_tasks_previous = num_tasks_current\n",
    "    print(f'Number of all possible partitioning schemes: {len(unique_partitions)}')\n",
    "\n",
    "\n",
    "    # Manual DAG\n",
    "    M_input_path = f'{occupation_folder}/{occupation}_M_DAG_df.csv'\n",
    "    M_output_path = f'{occupation_folder}/{occupation}_costMin_M.csv'\n",
    "\n",
    "    # First Last Task DAG\n",
    "    N_input_path = f'{occupation_folder}/{occupation}_N_GPT_DAG_df.csv'\n",
    "    N_output_path = f'{occupation_folder}/{occupation}_costMin_N.csv'\n",
    "\n",
    "    # First Last Task DAG\n",
    "    CN_input_path = f'{occupation_folder}/{occupation}_CN_GPT_DAG_df.csv'\n",
    "    CN_output_path = f'{occupation_folder}/{occupation}_costMin_CN.csv'\n",
    "\n",
    "    # First Last Task DAG\n",
    "    FLT_input_path = f'{occupation_folder}/{occupation}_FLT_GPT_DAG_df.csv'\n",
    "    FLT_output_path = f'{occupation_folder}/{occupation}_costMin_FLT.csv'\n",
    "\n",
    "    # Conditioned First Last Task DAG\n",
    "    CFLT_input_path = f'{occupation_folder}/{occupation}_CFLT_GPT_DAG_df.csv'\n",
    "    CFLT_output_path = f'{occupation_folder}/{occupation}_costMin_CFLT.csv'\n",
    "\n",
    "    # Partitioned DAG\n",
    "    P_input_path = f'{occupation_folder}/{occupation}_P_GPT_DAG_df.csv'\n",
    "    P_output_path = f'{occupation_folder}/{occupation}_costMin_P.csv'\n",
    "\n",
    "    # Conditioned Partitioned DAG\n",
    "    CP_input_path = f'{occupation_folder}/{occupation}_CP_GPT_DAG_df.csv'\n",
    "    CP_output_path = f'{occupation_folder}/{occupation}_costMin_CP.csv'\n",
    "    \n",
    "\n",
    "\n",
    "    # create list of all DAGs\n",
    "    if occupation in ['travelAgents', 'insuranceUnderwriters', 'pileDriverOperators']:\n",
    "        DAG_indicator_list = ['Manual DAG', 'Naive DAG', 'Conditioned Naive DAG', 'First-Last Task DAG', 'Conditioned First-Last Task DAG', 'Partitioned DAG', 'Conditioned Partitioned DAG']\n",
    "        input_paths_list = [M_input_path, N_input_path, CN_input_path, FLT_input_path, CFLT_input_path, P_input_path, CP_input_path]\n",
    "        output_paths_list = [M_output_path, N_output_path, CN_output_path, FLT_output_path, CFLT_output_path, P_output_path, CP_output_path]\n",
    "    else:\n",
    "        DAG_indicator_list = ['Naive DAG', 'Conditioned Naive DAG', 'First-Last Task DAG', 'Conditioned First-Last Task DAG', 'Partitioned DAG', 'Conditioned Partitioned DAG']\n",
    "        input_paths_list = [N_input_path, CN_input_path, FLT_input_path, CFLT_input_path, P_input_path, CP_input_path]\n",
    "        output_paths_list = [N_output_path, CN_output_path, FLT_output_path, CFLT_output_path, P_output_path, CP_output_path]\n",
    "\n",
    "\n",
    "    for DAG_indicator, input_path, output_path in zip(DAG_indicator_list, input_paths_list, output_paths_list):\n",
    "        print(f'\\n-------Running: {occupation} - {DAG_indicator}-------')\n",
    "        \n",
    "        DAG_start_time = time.time()\n",
    "        DAG_costMin(input_path, output_path, unique_partitions, n)\n",
    "        DAG_end_time = time.time()\n",
    "\n",
    "        DAG_execution_time = DAG_end_time - DAG_start_time\n",
    "        print(f\"\\n{occupation} {DAG_indicator} runtime: {DAG_execution_time:.2f} seconds\")\n",
    "\n",
    "    occupation_end_time = time.time()\n",
    "    occupation_execution_time = (occupation_end_time - occupation_start_time)/60\n",
    "    print(f\"\\n\\n************* {occupation} runtime: {occupation_execution_time:.2f} minutes *************\")\n",
    "    runtime_since_start = (time.time() - start_time)/60\n",
    "    print(f\"\\nruntime since start: {runtime_since_start:.2f} minutes\\n\")\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = (end_time - start_time)/60\n",
    "print(f\"\\n\\nTotal Runtime: {execution_time:.2f} minutes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
