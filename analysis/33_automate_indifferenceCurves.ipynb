{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b861f4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('libraries.py') as f:\n",
    "    code = f.read()\n",
    "exec(code)\n",
    "\n",
    "with open('functions.py') as f:\n",
    "    code = f.read()\n",
    "exec(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "280bdd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine user\n",
    "user = getpass.getuser()\n",
    "if user == 'peymansh':\n",
    "    main_folder_path = '/Users/peymansh/Dropbox (MIT)/Research/AI and Occupations/ai-exposure'\n",
    "    data_path = f'{main_folder_path}/output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "54980713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tasks(onet_data_path,\n",
    "              occupation_code):\n",
    "\n",
    "    # Load the data\n",
    "    onet = pd.read_csv(onet_data_path)\n",
    "    onet = onet.sort_values(by=['year', 'occ_code', 'occ_title', 'task_id'])\n",
    "    onet = onet[onet['year'] == 2023].reset_index(drop=True)\n",
    "\n",
    "    # Get list of tasks\n",
    "    my_df = onet[(onet.occ_code == f'{occupation_code}') & (onet.year == 2023)]\n",
    "    tasks = my_df['task'].unique().tolist()\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b7085e",
   "metadata": {},
   "source": [
    "### Generate all possible partition schemes for the set of tasks (ignoring structre of the DAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f4a503b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def partitions(set_):\n",
    "    if not set_:\n",
    "        yield []\n",
    "        return\n",
    "    for i in range(1, len(set_) + 1):\n",
    "        for part in combinations(set_, i):\n",
    "            remaining = set(set_) - set(part)\n",
    "            if not remaining:\n",
    "                yield [list(part)]\n",
    "            else:\n",
    "                for b in partitions(list(remaining)):\n",
    "                    yield [list(part)] + b\n",
    "\n",
    "def generate_unique_partitions(numbers):\n",
    "    all_partitions = set()\n",
    "    for partition in partitions(numbers):\n",
    "        # Create a frozenset of frozensets to make each partition hashable and order-independent\n",
    "        partition_set = frozenset(frozenset(part) for part in partition)\n",
    "        all_partitions.add(partition_set)\n",
    "    \n",
    "    # Convert the frozensets back to lists for the final output\n",
    "    unique_partitions = [list(map(list, partition)) for partition in all_partitions]\n",
    "\n",
    "    # Sort elements\n",
    "    unique_partitions = sorted([sorted(x) for x in unique_partitions], key=len)\n",
    "    return unique_partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2081384b",
   "metadata": {},
   "source": [
    "### Check if partition scheme is \"valid\" (i.e., if its non-singleton partitions are a connected graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "14339429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_connected(matrix):\n",
    "    # Number of nodes in the matrix\n",
    "    num_nodes = matrix.shape[0]\n",
    "    \n",
    "    # Visited array to keep track of visited nodes\n",
    "    visited = np.zeros(num_nodes, dtype=bool)\n",
    "    \n",
    "    # Helper function to perform DFS\n",
    "    def dfs(node):\n",
    "        visited[node] = True\n",
    "        # Visit all the neighbors of the current node\n",
    "        for neighbor in range(num_nodes):\n",
    "            if matrix[node, neighbor] == 1 and not visited[neighbor]:\n",
    "                dfs(neighbor)\n",
    "            elif matrix[neighbor, node] == 1 and not visited[neighbor]:\n",
    "                dfs(neighbor)\n",
    "    \n",
    "    # Start DFS from the first node (node 0)\n",
    "    dfs(0)\n",
    "    \n",
    "    # If all nodes are visited, the matrix is connected\n",
    "    return np.all(visited)\n",
    "\n",
    "\n",
    "def validate_partition_using_connectedness(adjacency_matrix, tasks_list):\n",
    "    # Return valid if Singleton\n",
    "    if len(tasks_list) == 1:\n",
    "        return True\n",
    "    # Check if partition forms connected graph\n",
    "    else:\n",
    "        # Subset original adjacency matrix\n",
    "        subset_matrix = adjacency_matrix[np.ix_(tasks_list, tasks_list)]\n",
    "\n",
    "        # check if subset matrix is a connected graph\n",
    "        subset_matrix_connected = is_connected(subset_matrix)\n",
    "\n",
    "        # return true if connected and false otherwise\n",
    "        return subset_matrix_connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bac775ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_partition_boundary(adjacency_matrix, partition):\n",
    "    # create a matrix whose columns are nodes not in the partition and whose rows are nodes in the partition\n",
    "    # (subset adjacency matrix to outgoing edges of partition nodes --i.e., rows-- and incoming edges of non-partition nodes --i.e., columns.)\n",
    "    reduced_matrix = np.delete(adjacency_matrix, partition, axis=1) \n",
    "    reduced_matrix = reduced_matrix[partition, :]\n",
    "\n",
    "    # find nodes in partition w/ an edge to non-partition nodes\n",
    "    partition_boundary_tasks = [i for i in partition if np.any(reduced_matrix[partition.index(i), :])]\n",
    "\n",
    "    return partition_boundary_tasks\n",
    "\n",
    "\n",
    "def compute_plan_cost(adjacency_matrix, M_dict, A_dict, D_dict, AI_quality, execution_plan, human_tasks):\n",
    "    # initialize costs\n",
    "    total_cost = 0\n",
    "    labor_cost = 0\n",
    "    management_cost = 0\n",
    "\n",
    "    for partition in execution_plan:\n",
    "        if len(partition) == 1:\n",
    "            if partition[0] in human_tasks:\n",
    "                partition_cost = sum(M_dict[key] for key in partition)\n",
    "                labor_cost += partition_cost\n",
    "            else:\n",
    "                AI_cost = sum(A_dict[key] for key in partition)\n",
    "                difficulty = sum(D_dict[key] for key in partition)\n",
    "                partition_cost = AI_cost * (AI_quality ** (-1 * difficulty))\n",
    "                management_cost += partition_cost\n",
    "        else:\n",
    "            # calculate automated-chain management cost\n",
    "            partition_boundary_tasks = get_partition_boundary(adjacency_matrix, partition)\n",
    "            AI_cost = sum(A_dict[key] for key in partition_boundary_tasks)\n",
    "            difficulty = sum(D_dict[key] for key in partition)\n",
    "            partition_cost = AI_cost * (AI_quality ** (-1 * difficulty))\n",
    "            management_cost += partition_cost\n",
    "        \n",
    "        total_cost += partition_cost\n",
    "\n",
    "    return total_cost, labor_cost, management_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7354c2d",
   "metadata": {},
   "source": [
    "### Combine steps into a function to run a for loop over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "754628e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DAG_indiffCurve(input_path, output_path, altogether_output_path, unique_partitions, alpha_list):\n",
    "    # read DAG\n",
    "    dag_df = pd.read_csv(input_path)\n",
    "\n",
    "    # remove edges if comment column labeled with \"TriangleRemovedFlag\" (edge is there for plotting purposes and is not part of the actual DAG)\n",
    "    if 'comment' in dag_df.columns:\n",
    "        dag_df = dag_df[~dag_df['comment'].str.endswith('TriangleRemovedFlag')]\n",
    "\n",
    "    # get task stats\n",
    "    tasks_stats = pd.read_csv(f'{occupation_folder}/{occupation}_taskStats.csv')\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # extract list of tasks and create a dictionary for indexing tasks\n",
    "    tasks_list = tasks_stats['task'].unique()\n",
    "    tasks_dict = {i: node for i, node in enumerate(tasks_list, start=0)}\n",
    "\n",
    "    # create numpy array of adjacency matrix\n",
    "    adjacency_matrix = np.zeros((len(tasks_list), len(tasks_list)), dtype=int)\n",
    "    aux_dict = {value: key for key, value in tasks_dict.items()}\n",
    "    for _, row in dag_df.iterrows():\n",
    "        source_index = aux_dict[row['source']]\n",
    "        target_index = aux_dict[row['target']]\n",
    "        adjacency_matrix[source_index, target_index] = 1\n",
    "\n",
    "\n",
    "\n",
    "    # add task_dict key and reset index\n",
    "    aux_dict = {value: key for key, value in tasks_dict.items()}\n",
    "    tasks_stats['dict_index'] = tasks_stats.apply(lambda row: aux_dict[row.task], axis=1)\n",
    "    tasks_stats = tasks_stats.sort_values(by='dict_index')\n",
    "    tasks_stats = tasks_stats.set_index('dict_index', drop=False)\n",
    "    tasks_stats.index.name = None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # create dictionaries for human cost, management cost, and difficulty\n",
    "    M_dict = dict(zip(tasks_stats['dict_index'], tasks_stats['human_cost']))\n",
    "    A_dict = dict(zip(tasks_stats['dict_index'], tasks_stats['management_cost']))\n",
    "    D_dict = dict(zip(tasks_stats['dict_index'], tasks_stats['difficulty']))\n",
    "\n",
    "\n",
    "\n",
    "    # Get valid partitioning schemes\n",
    "    valid_partitions = []\n",
    "    for scheme in unique_partitions:\n",
    "        # Set valid partitions count to 0\n",
    "        valid_partition_count = 0\n",
    "        for partition in scheme:\n",
    "            valid_partition = validate_partition_using_connectedness(adjacency_matrix, partition)\n",
    "            if valid_partition:\n",
    "                valid_partition_count += 1\n",
    "        \n",
    "        # If number of valid partitions within a partition scheme is equal to \n",
    "        # number of partitions in partition scheme then partition scheme is valid\n",
    "        if valid_partition_count == len(scheme):\n",
    "            valid_partitions.append(scheme)\n",
    "\n",
    "    # Print stats\n",
    "    print(f'Number of valid partitioning schemes given DAG structure: {len(valid_partitions)}')\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    # get how many \"singleton\" partitions there are in valid partition\n",
    "    valid_execution_plans = pd.DataFrame()\n",
    "    for my_valid_partition in valid_partitions:\n",
    "        singleton_partitions = [lst[0] for lst in my_valid_partition if len(lst) == 1]\n",
    "        #singleton_partitions = [lst for lst in my_valid_partition if len(lst) == 1]\n",
    "\n",
    "        # get the power set of \"singleton\" partitions\n",
    "        # goal is to generate ways singleton tasks can be done by human or AI\n",
    "        all_combinations = [[]]\n",
    "        for r in range(1, len(singleton_partitions) + 1):\n",
    "            combinations_r = itertools.combinations(singleton_partitions, r)\n",
    "            all_combinations.extend(combinations_r)\n",
    "\n",
    "        # Convert the combinations to a list of lists (optional)\n",
    "        all_combinations = [list(comb) for comb in all_combinations]\n",
    "        all_combinations\n",
    "\n",
    "        # repeat my_valid_partition for each combination in all_combinations to create a dataframe later\n",
    "        my_valid_partition_repeated = [my_valid_partition for _ in range(len(all_combinations))]\n",
    "        aux_df = pd.DataFrame({'execution_plan': my_valid_partition_repeated, \n",
    "                            'human_tasks': all_combinations})\n",
    "        \n",
    "        # append to valid_execution_plans\n",
    "        valid_execution_plans = pd.concat([valid_execution_plans, aux_df], ignore_index=True)\n",
    "    print(f'Number of indifference points: {len(valid_execution_plans)}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # calculate plan costs for each alpha\n",
    "    execution_plan_costs_df = pd.DataFrame()\n",
    "    for counter, alpha in enumerate(alpha_list):\n",
    "        my_alpha_execution_plan_costs_df = pd.DataFrame()\n",
    "        for execution_plan, human_tasks in zip(valid_execution_plans['execution_plan'], valid_execution_plans['human_tasks']):\n",
    "            # calculate plan costs\n",
    "            total_cost, labor_cost, management_cost = compute_plan_cost(adjacency_matrix, M_dict, A_dict, D_dict, alpha, execution_plan, human_tasks)\n",
    "\n",
    "            # create a dataframe to store execution plan costs\n",
    "            aux_df = pd.DataFrame({'alpha': [alpha], \n",
    "                                    'execution_plan': [execution_plan],\n",
    "                                    'human_tasks': [human_tasks],\n",
    "                                    'total_cost': [total_cost],\n",
    "                                    'labor_cost': [labor_cost],\n",
    "                                    'management_cost': [management_cost]})\n",
    "            \n",
    "            # append to execution_plan_costs_df\n",
    "            my_alpha_execution_plan_costs_df = pd.concat([my_alpha_execution_plan_costs_df, aux_df], ignore_index=True)\n",
    "        \n",
    "\n",
    "        # find optimal execution plan\n",
    "        my_alpha_execution_plan_costs_df['min_total_cost_flag'] = (my_alpha_execution_plan_costs_df['total_cost'] == my_alpha_execution_plan_costs_df['total_cost'].min())\n",
    "\n",
    "        # append to master dataframe\n",
    "        execution_plan_costs_df = pd.concat([execution_plan_costs_df, my_alpha_execution_plan_costs_df], ignore_index=True)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # plot indifference curves\n",
    "    # Create a 2x5 grid of subplots\n",
    "    fig, axs = plt.subplots(2, 5, figsize=(18, 9))\n",
    "\n",
    "    # Iterate over each subplot position and add a plot\n",
    "    for i in range(2): \n",
    "        for j in range(5): \n",
    "            alpha_index = (i % 5) * 5 + j\n",
    "            my_alpha = alpha_list[alpha_index+1] # ignore alpha=epsilon\n",
    "\n",
    "            # subset corresponding alpha's data from master dataset\n",
    "            my_alpha_execution_plan_costs_df = execution_plan_costs_df[execution_plan_costs_df['alpha']==my_alpha]\n",
    "            #unique_pair_count = my_alpha_execution_plan_costs_df.drop_duplicates(subset=['labor_cost', 'management_cost']).shape[0]\n",
    "\n",
    "            # keep lower envelope data\n",
    "            idx = my_alpha_execution_plan_costs_df.groupby('labor_cost')['management_cost'].idxmin()\n",
    "            lower_envelope_df = my_alpha_execution_plan_costs_df.loc[idx]\n",
    "            \n",
    "\n",
    "            axs[i, j].scatter(lower_envelope_df.labor_cost, lower_envelope_df.management_cost, s=25)\n",
    "            axs[i, j].scatter(lower_envelope_df[lower_envelope_df['min_total_cost_flag']==True].labor_cost, \n",
    "                    lower_envelope_df[lower_envelope_df['min_total_cost_flag']==True].management_cost,\n",
    "                    color='red',\n",
    "                    label = 'Optimal Plan')\n",
    "            \n",
    "            axs[i, j].title.set_text(r'IC for $\\alpha$' + f'={np.round(my_alpha,1)}')\n",
    "            if i == 1:\n",
    "                axs[i, j].set_xlabel('Labor Cost (in minutes)')\n",
    "            if j == 0:\n",
    "                axs[i, j].set_ylabel('AI Management Cost (in minutes)')\n",
    "            axs[i, j].legend(loc = 'upper right')\n",
    "\n",
    "            axs[i, j].set_xlim(-20, max(execution_plan_costs_df.labor_cost) + 20)\n",
    "            axs[i, j].set_ylim(-20, 600)\n",
    "            #axs[i, j].set_ylim(-20, max(execution_plan_costs_df[execution_plan_costs_df.alpha != epsilon].management_cost) + 20)\n",
    "\n",
    "\n",
    "    fig.suptitle(f'(Lower Envelope of) Indifference Curves for {plot_title_occupation}: {DAG_indicator}', fontsize=16)\n",
    "\n",
    "    # Save the plot\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.savefig(altogether_output_path, dpi=300)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # close plot\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538ec907",
   "metadata": {},
   "source": [
    "## Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8ee7f28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# set alpha as AI quality metric\n",
    "epsilon = 1e-8\n",
    "alpha_list = [epsilon, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1-epsilon]\n",
    "\n",
    "onet_data_path = f'{data_path}/data/onet_occupations_yearly.csv'\n",
    "\n",
    "occupation_list = ['pileDriverOperators', 'dredgeOperators', 'gradersAndSortersForAgriculturalProducts',\n",
    "                   'insuranceUnderwriters', 'insuranceAppraisersForAutoDamage', 'floorSandersAndFinishers', \n",
    "                   'reinforcingIronAndRebarWorkers', 'travelAgents', 'dataEntryKeyer', \n",
    "                   'athletesAndSportsCompetitors', 'audiovisualEquipmentInstallerAndRepairers', 'hearingAidSpecialists', \n",
    "                   'personalCareAides', 'proofreadersAndCopyMarkers', 'chiropractors', \n",
    "                   'shippingReceivingAndInventoryClerks', 'cooksShortOrder', 'orthodontists',\n",
    "                   'subwayAndStreetcarOperators', 'packersAndPackagersHand', 'hoistAndWinchOperators', \n",
    "                   'forgingMachineSettersOperatorsAndTenders', 'avionicsTechnicians', 'dishwashers', \n",
    "                   'dispatchersExceptPoliceFireAndAmbulance', 'familyMedicinePhysicians', 'MachineFeedersAndOffbearers'\n",
    "                   ]\n",
    "\n",
    "occupation_list = ['travelAgents', 'insuranceUnderwriters', 'pileDriverOperators'\n",
    "                   ]\n",
    "\n",
    "\n",
    "\n",
    "occupation_list = ['pileDriverOperators', 'dredgeOperators', 'gradersAndSortersForAgriculturalProducts',\n",
    "                   'insuranceUnderwriters', 'insuranceAppraisersForAutoDamage', 'floorSandersAndFinishers', \n",
    "                   'reinforcingIronAndRebarWorkers', 'travelAgents', 'dataEntryKeyer', \n",
    "                   'athletesAndSportsCompetitors'\n",
    "                   ]\n",
    "\n",
    "#occupation_list = ['travelAgents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a3a99b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------- Running: pileDriverOperators ----------------------\n",
      "Number of non-target tasks: 5\n",
      "Time to generate all possible partition schemes: 0.00 seconds\n",
      "Number of all possible partitioning schemes: 52\n",
      "\n",
      "-------Running: pileDriverOperators - Manual DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 26\n",
      "Number of indifference points: 128\n",
      "\n",
      "pileDriverOperators Manual DAG runtime: 1.63 seconds\n",
      "\n",
      "-------Running: pileDriverOperators - Naive DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 30\n",
      "Number of indifference points: 141\n",
      "\n",
      "pileDriverOperators Naive DAG runtime: 1.74 seconds\n",
      "\n",
      "-------Running: pileDriverOperators - Conditioned Naive DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 26\n",
      "Number of indifference points: 128\n",
      "\n",
      "pileDriverOperators Conditioned Naive DAG runtime: 1.64 seconds\n",
      "\n",
      "-------Running: pileDriverOperators - First-Last Task DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 30\n",
      "Number of indifference points: 141\n",
      "\n",
      "pileDriverOperators First-Last Task DAG runtime: 1.69 seconds\n",
      "\n",
      "-------Running: pileDriverOperators - Conditioned First-Last Task DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 26\n",
      "Number of indifference points: 128\n",
      "\n",
      "pileDriverOperators Conditioned First-Last Task DAG runtime: 1.65 seconds\n",
      "\n",
      "-------Running: pileDriverOperators - Partitioned DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 52\n",
      "Number of indifference points: 203\n",
      "\n",
      "pileDriverOperators Partitioned DAG runtime: 1.82 seconds\n",
      "\n",
      "-------Running: pileDriverOperators - Conditioned Partitioned DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 34\n",
      "Number of indifference points: 150\n",
      "\n",
      "pileDriverOperators Conditioned Partitioned DAG runtime: 2.10 seconds\n",
      "\n",
      "\n",
      "************* pileDriverOperators runtime: 0.21 minutes *************\n",
      "\n",
      "runtime since start: 0.21 minutes\n",
      "\n",
      "\n",
      "---------------------- Running: dredgeOperators ----------------------\n",
      "Number of non-target tasks: 6\n",
      "Time to generate all possible partition schemes: 0.01 seconds\n",
      "Number of all possible partitioning schemes: 203\n",
      "\n",
      "-------Running: dredgeOperators - Naive DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 80\n",
      "Number of indifference points: 464\n",
      "\n",
      "dredgeOperators Naive DAG runtime: 2.36 seconds\n",
      "\n",
      "-------Running: dredgeOperators - Conditioned Naive DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 32\n",
      "Number of indifference points: 256\n",
      "\n",
      "dredgeOperators Conditioned Naive DAG runtime: 1.91 seconds\n",
      "\n",
      "-------Running: dredgeOperators - First-Last Task DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 60\n",
      "Number of indifference points: 383\n",
      "\n",
      "dredgeOperators First-Last Task DAG runtime: 2.20 seconds\n",
      "\n",
      "-------Running: dredgeOperators - Conditioned First-Last Task DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 32\n",
      "Number of indifference points: 241\n",
      "\n",
      "dredgeOperators Conditioned First-Last Task DAG runtime: 1.88 seconds\n",
      "\n",
      "-------Running: dredgeOperators - Partitioned DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 158\n",
      "Number of indifference points: 718\n",
      "\n",
      "dredgeOperators Partitioned DAG runtime: 3.07 seconds\n",
      "\n",
      "-------Running: dredgeOperators - Conditioned Partitioned DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 32\n",
      "Number of indifference points: 241\n",
      "\n",
      "dredgeOperators Conditioned Partitioned DAG runtime: 1.95 seconds\n",
      "\n",
      "\n",
      "************* dredgeOperators runtime: 0.23 minutes *************\n",
      "\n",
      "runtime since start: 0.44 minutes\n",
      "\n",
      "\n",
      "---------------------- Running: gradersAndSortersForAgriculturalProducts ----------------------\n",
      "Number of non-target tasks: 6\n",
      "Number of all possible partitioning schemes: 203\n",
      "\n",
      "-------Running: gradersAndSortersForAgriculturalProducts - Naive DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 104\n",
      "Number of indifference points: 557\n",
      "\n",
      "gradersAndSortersForAgriculturalProducts Naive DAG runtime: 2.62 seconds\n",
      "\n",
      "-------Running: gradersAndSortersForAgriculturalProducts - Conditioned Naive DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 94\n",
      "Number of indifference points: 517\n",
      "\n",
      "gradersAndSortersForAgriculturalProducts Conditioned Naive DAG runtime: 2.56 seconds\n",
      "\n",
      "-------Running: gradersAndSortersForAgriculturalProducts - First-Last Task DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 141\n",
      "Number of indifference points: 671\n",
      "\n",
      "gradersAndSortersForAgriculturalProducts First-Last Task DAG runtime: 2.88 seconds\n",
      "\n",
      "-------Running: gradersAndSortersForAgriculturalProducts - Conditioned First-Last Task DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 94\n",
      "Number of indifference points: 517\n",
      "\n",
      "gradersAndSortersForAgriculturalProducts Conditioned First-Last Task DAG runtime: 2.81 seconds\n",
      "\n",
      "-------Running: gradersAndSortersForAgriculturalProducts - Partitioned DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 104\n",
      "Number of indifference points: 557\n",
      "\n",
      "gradersAndSortersForAgriculturalProducts Partitioned DAG runtime: 2.60 seconds\n",
      "\n",
      "-------Running: gradersAndSortersForAgriculturalProducts - Conditioned Partitioned DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 104\n",
      "Number of indifference points: 557\n",
      "\n",
      "gradersAndSortersForAgriculturalProducts Conditioned Partitioned DAG runtime: 2.61 seconds\n",
      "\n",
      "\n",
      "************* gradersAndSortersForAgriculturalProducts runtime: 0.27 minutes *************\n",
      "\n",
      "runtime since start: 0.71 minutes\n",
      "\n",
      "\n",
      "---------------------- Running: insuranceUnderwriters ----------------------\n",
      "Number of non-target tasks: 7\n",
      "Time to generate all possible partition schemes: 0.12 seconds\n",
      "Number of all possible partitioning schemes: 877\n",
      "\n",
      "-------Running: insuranceUnderwriters - Manual DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 192\n",
      "Number of indifference points: 1352\n",
      "\n",
      "insuranceUnderwriters Manual DAG runtime: 4.44 seconds\n",
      "\n",
      "-------Running: insuranceUnderwriters - Naive DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 758\n",
      "Number of indifference points: 3682\n",
      "\n",
      "insuranceUnderwriters Naive DAG runtime: 10.41 seconds\n",
      "\n",
      "-------Running: insuranceUnderwriters - Conditioned Naive DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 200\n",
      "Number of indifference points: 1480\n",
      "\n",
      "insuranceUnderwriters Conditioned Naive DAG runtime: 4.81 seconds\n",
      "\n",
      "-------Running: insuranceUnderwriters - First-Last Task DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 758\n",
      "Number of indifference points: 3682\n",
      "\n",
      "insuranceUnderwriters First-Last Task DAG runtime: 10.33 seconds\n",
      "\n",
      "-------Running: insuranceUnderwriters - Conditioned First-Last Task DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 383\n",
      "Number of indifference points: 2200\n",
      "\n",
      "insuranceUnderwriters Conditioned First-Last Task DAG runtime: 6.55 seconds\n",
      "\n",
      "-------Running: insuranceUnderwriters - Partitioned DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 758\n",
      "Number of indifference points: 3682\n",
      "\n",
      "insuranceUnderwriters Partitioned DAG runtime: 10.34 seconds\n",
      "\n",
      "-------Running: insuranceUnderwriters - Conditioned Partitioned DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 308\n",
      "Number of indifference points: 1898\n",
      "\n",
      "insuranceUnderwriters Conditioned Partitioned DAG runtime: 5.74 seconds\n",
      "\n",
      "\n",
      "************* insuranceUnderwriters runtime: 0.88 minutes *************\n",
      "\n",
      "runtime since start: 1.60 minutes\n",
      "\n",
      "\n",
      "---------------------- Running: insuranceAppraisersForAutoDamage ----------------------\n",
      "Number of non-target tasks: 7\n",
      "Number of all possible partitioning schemes: 877\n",
      "\n",
      "-------Running: insuranceAppraisersForAutoDamage - Naive DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 758\n",
      "Number of indifference points: 3682\n",
      "\n",
      "insuranceAppraisersForAutoDamage Naive DAG runtime: 10.68 seconds\n",
      "\n",
      "-------Running: insuranceAppraisersForAutoDamage - Conditioned Naive DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 616\n",
      "Number of indifference points: 3140\n",
      "\n",
      "insuranceAppraisersForAutoDamage Conditioned Naive DAG runtime: 9.04 seconds\n",
      "\n",
      "-------Running: insuranceAppraisersForAutoDamage - First-Last Task DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 616\n",
      "Number of indifference points: 3140\n",
      "\n",
      "insuranceAppraisersForAutoDamage First-Last Task DAG runtime: 9.16 seconds\n",
      "\n",
      "-------Running: insuranceAppraisersForAutoDamage - Conditioned First-Last Task DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 546\n",
      "Number of indifference points: 2865\n",
      "\n",
      "insuranceAppraisersForAutoDamage Conditioned First-Last Task DAG runtime: 8.52 seconds\n",
      "\n",
      "-------Running: insuranceAppraisersForAutoDamage - Partitioned DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 825\n",
      "Number of indifference points: 3937\n",
      "\n",
      "insuranceAppraisersForAutoDamage Partitioned DAG runtime: 11.15 seconds\n",
      "\n",
      "-------Running: insuranceAppraisersForAutoDamage - Conditioned Partitioned DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 641\n",
      "Number of indifference points: 3219\n",
      "\n",
      "insuranceAppraisersForAutoDamage Conditioned Partitioned DAG runtime: 9.25 seconds\n",
      "\n",
      "\n",
      "************* insuranceAppraisersForAutoDamage runtime: 0.97 minutes *************\n",
      "\n",
      "runtime since start: 2.57 minutes\n",
      "\n",
      "\n",
      "---------------------- Running: floorSandersAndFinishers ----------------------\n",
      "Number of non-target tasks: 7\n",
      "Number of all possible partitioning schemes: 877\n",
      "\n",
      "-------Running: floorSandersAndFinishers - Naive DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 624\n",
      "Number of indifference points: 3172\n",
      "\n",
      "floorSandersAndFinishers Naive DAG runtime: 9.19 seconds\n",
      "\n",
      "-------Running: floorSandersAndFinishers - Conditioned Naive DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 551\n",
      "Number of indifference points: 2890\n",
      "\n",
      "floorSandersAndFinishers Conditioned Naive DAG runtime: 8.25 seconds\n",
      "\n",
      "-------Running: floorSandersAndFinishers - First-Last Task DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 551\n",
      "Number of indifference points: 2890\n",
      "\n",
      "floorSandersAndFinishers First-Last Task DAG runtime: 8.32 seconds\n",
      "\n",
      "-------Running: floorSandersAndFinishers - Conditioned First-Last Task DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 403\n",
      "Number of indifference points: 2305\n",
      "\n",
      "floorSandersAndFinishers Conditioned First-Last Task DAG runtime: 6.83 seconds\n",
      "\n",
      "-------Running: floorSandersAndFinishers - Partitioned DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 778\n",
      "Number of indifference points: 3749\n",
      "\n",
      "floorSandersAndFinishers Partitioned DAG runtime: 10.60 seconds\n",
      "\n",
      "-------Running: floorSandersAndFinishers - Conditioned Partitioned DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 576\n",
      "Number of indifference points: 2907\n",
      "\n",
      "floorSandersAndFinishers Conditioned Partitioned DAG runtime: 8.21 seconds\n",
      "\n",
      "\n",
      "************* floorSandersAndFinishers runtime: 0.86 minutes *************\n",
      "\n",
      "runtime since start: 3.43 minutes\n",
      "\n",
      "\n",
      "---------------------- Running: reinforcingIronAndRebarWorkers ----------------------\n",
      "Number of non-target tasks: 7\n",
      "Number of all possible partitioning schemes: 877\n",
      "\n",
      "-------Running: reinforcingIronAndRebarWorkers - Naive DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 825\n",
      "Number of indifference points: 3937\n",
      "\n",
      "reinforcingIronAndRebarWorkers Naive DAG runtime: 10.83 seconds\n",
      "\n",
      "-------Running: reinforcingIronAndRebarWorkers - Conditioned Naive DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 437\n",
      "Number of indifference points: 2412\n",
      "\n",
      "reinforcingIronAndRebarWorkers Conditioned Naive DAG runtime: 7.64 seconds\n",
      "\n",
      "-------Running: reinforcingIronAndRebarWorkers - First-Last Task DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 376\n",
      "Number of indifference points: 2287\n",
      "\n",
      "reinforcingIronAndRebarWorkers First-Last Task DAG runtime: 6.72 seconds\n",
      "\n",
      "-------Running: reinforcingIronAndRebarWorkers - Conditioned First-Last Task DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 306\n",
      "Number of indifference points: 1965\n",
      "\n",
      "reinforcingIronAndRebarWorkers Conditioned First-Last Task DAG runtime: 5.87 seconds\n",
      "\n",
      "-------Running: reinforcingIronAndRebarWorkers - Partitioned DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 825\n",
      "Number of indifference points: 3937\n",
      "\n",
      "reinforcingIronAndRebarWorkers Partitioned DAG runtime: 11.01 seconds\n",
      "\n",
      "-------Running: reinforcingIronAndRebarWorkers - Conditioned Partitioned DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 641\n",
      "Number of indifference points: 3219\n",
      "\n",
      "reinforcingIronAndRebarWorkers Conditioned Partitioned DAG runtime: 9.34 seconds\n",
      "\n",
      "\n",
      "************* reinforcingIronAndRebarWorkers runtime: 0.86 minutes *************\n",
      "\n",
      "runtime since start: 4.29 minutes\n",
      "\n",
      "\n",
      "---------------------- Running: travelAgents ----------------------\n",
      "Number of non-target tasks: 8\n",
      "Time to generate all possible partition schemes: 1.58 seconds\n",
      "Number of all possible partitioning schemes: 4140\n",
      "\n",
      "-------Running: travelAgents - Manual DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 192\n",
      "Number of indifference points: 2438\n",
      "\n",
      "travelAgents Manual DAG runtime: 7.30 seconds\n",
      "\n",
      "-------Running: travelAgents - Naive DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 2106\n",
      "Number of indifference points: 12622\n",
      "\n",
      "travelAgents Naive DAG runtime: 36.80 seconds\n",
      "\n",
      "-------Running: travelAgents - Conditioned Naive DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 428\n",
      "Number of indifference points: 4280\n",
      "\n",
      "travelAgents Conditioned Naive DAG runtime: 11.94 seconds\n",
      "\n",
      "-------Running: travelAgents - First-Last Task DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 1754\n",
      "Number of indifference points: 11543\n",
      "\n",
      "travelAgents First-Last Task DAG runtime: 33.32 seconds\n",
      "\n",
      "-------Running: travelAgents - Conditioned First-Last Task DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 1152\n",
      "Number of indifference points: 8301\n",
      "\n",
      "travelAgents Conditioned First-Last Task DAG runtime: 23.15 seconds\n",
      "\n",
      "-------Running: travelAgents - Partitioned DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 3749\n",
      "Number of indifference points: 19445\n",
      "\n",
      "travelAgents Partitioned DAG runtime: 60.05 seconds\n",
      "\n",
      "-------Running: travelAgents - Conditioned Partitioned DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 550\n",
      "Number of indifference points: 5038\n",
      "\n",
      "travelAgents Conditioned Partitioned DAG runtime: 13.95 seconds\n",
      "\n",
      "\n",
      "************* travelAgents runtime: 3.14 minutes *************\n",
      "\n",
      "runtime since start: 7.43 minutes\n",
      "\n",
      "\n",
      "---------------------- Running: dataEntryKeyer ----------------------\n",
      "Number of non-target tasks: 9\n",
      "Time to generate all possible partition schemes: 22.27 seconds\n",
      "Number of all possible partitioning schemes: 21147\n",
      "\n",
      "-------Running: dataEntryKeyer - Naive DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 3355\n",
      "Number of indifference points: 30245\n",
      "\n",
      "dataEntryKeyer Naive DAG runtime: 111.70 seconds\n",
      "\n",
      "-------Running: dataEntryKeyer - Conditioned Naive DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 2204\n",
      "Number of indifference points: 21467\n",
      "\n",
      "dataEntryKeyer Conditioned Naive DAG runtime: 71.02 seconds\n",
      "\n",
      "-------Running: dataEntryKeyer - First-Last Task DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 3112\n",
      "Number of indifference points: 27494\n",
      "\n",
      "dataEntryKeyer First-Last Task DAG runtime: 94.59 seconds\n",
      "\n",
      "-------Running: dataEntryKeyer - Conditioned First-Last Task DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 2262\n",
      "Number of indifference points: 21688\n",
      "\n",
      "dataEntryKeyer Conditioned First-Last Task DAG runtime: 72.56 seconds\n",
      "\n",
      "-------Running: dataEntryKeyer - Partitioned DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 2189\n",
      "Number of indifference points: 25708\n",
      "\n",
      "dataEntryKeyer Partitioned DAG runtime: 87.07 seconds\n",
      "\n",
      "-------Running: dataEntryKeyer - Conditioned Partitioned DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 672\n",
      "Number of indifference points: 11120\n",
      "\n",
      "dataEntryKeyer Conditioned Partitioned DAG runtime: 32.18 seconds\n",
      "\n",
      "\n",
      "************* dataEntryKeyer runtime: 8.20 minutes *************\n",
      "\n",
      "runtime since start: 15.63 minutes\n",
      "\n",
      "\n",
      "---------------------- Running: athletesAndSportsCompetitors ----------------------\n",
      "Number of non-target tasks: 9\n",
      "Number of all possible partitioning schemes: 21147\n",
      "\n",
      "-------Running: athletesAndSportsCompetitors - Naive DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 8508\n",
      "Number of indifference points: 56860\n",
      "\n",
      "athletesAndSportsCompetitors Naive DAG runtime: 260.13 seconds\n",
      "\n",
      "-------Running: athletesAndSportsCompetitors - Conditioned Naive DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 970\n",
      "Number of indifference points: 10835\n",
      "\n",
      "athletesAndSportsCompetitors Conditioned Naive DAG runtime: 32.63 seconds\n",
      "\n",
      "-------Running: athletesAndSportsCompetitors - First-Last Task DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 824\n",
      "Number of indifference points: 13060\n",
      "\n",
      "athletesAndSportsCompetitors First-Last Task DAG runtime: 39.35 seconds\n",
      "\n",
      "-------Running: athletesAndSportsCompetitors - Conditioned First-Last Task DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 128\n",
      "Number of indifference points: 3688\n",
      "\n",
      "athletesAndSportsCompetitors Conditioned First-Last Task DAG runtime: 10.73 seconds\n",
      "\n",
      "-------Running: athletesAndSportsCompetitors - Partitioned DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 9422\n",
      "Number of indifference points: 60669\n",
      "\n",
      "athletesAndSportsCompetitors Partitioned DAG runtime: 278.14 seconds\n",
      "\n",
      "-------Running: athletesAndSportsCompetitors - Conditioned Partitioned DAG-------\n",
      "Number of valid partitioning schemes given DAG structure: 1425\n",
      "Number of indifference points: 12944\n",
      "\n",
      "athletesAndSportsCompetitors Conditioned Partitioned DAG runtime: 37.93 seconds\n",
      "\n",
      "\n",
      "************* athletesAndSportsCompetitors runtime: 10.99 minutes *************\n",
      "\n",
      "runtime since start: 26.61 minutes\n",
      "\n",
      "\n",
      "\n",
      "Total Runtime: 26.61 minutes\n"
     ]
    }
   ],
   "source": [
    "num_tasks_current = 0\n",
    "num_tasks_previous = 0\n",
    "for occupation in occupation_list:\n",
    "    print(f'\\n---------------------- Running: {occupation} ----------------------')\n",
    "    occupation_start_time = time.time()\n",
    "\n",
    "    # generate occupation-specific strings\n",
    "    GPT_input_occupation, plot_title_occupation, occupation_code, occupation_folder = pick_occupation(occupation)\n",
    "\n",
    "\n",
    "    # Get occupation tasks to create all possible partitions\n",
    "    tasks = get_tasks(onet_data_path, occupation_code)\n",
    "    num_tasks_current = len(tasks)\n",
    "    print(f'Number of non-target tasks: {num_tasks_current}')\n",
    "\n",
    "    if num_tasks_current < 10:\n",
    "        n = 1000\n",
    "    else: \n",
    "        n = 100\n",
    "\n",
    "    # if number of tasks in new occupation has increased generate new set of possible partitions\n",
    "    if num_tasks_current != num_tasks_previous:\n",
    "        unique_partitions_start_time = time.time()\n",
    "\n",
    "        # Generate list of numbers for non-\"Target\" tasks in occupation\n",
    "        tasks_list_numbers = list(range(num_tasks_current))\n",
    "\n",
    "        # Generate all possible partitioning schemes\n",
    "        unique_partitions = generate_unique_partitions(tasks_list_numbers)\n",
    "        unique_partitions_end_time = time.time()\n",
    "\n",
    "        unique_partitions_execution_time = unique_partitions_end_time - unique_partitions_start_time\n",
    "        print(f'Time to generate all possible partition schemes: {unique_partitions_execution_time:.2f} seconds')\n",
    "    \n",
    "    # update num_tasks_previous for next iteration and print stats\n",
    "    num_tasks_previous = num_tasks_current\n",
    "    print(f'Number of all possible partitioning schemes: {len(unique_partitions)}')\n",
    "\n",
    "\n",
    "    # Manual DAG\n",
    "    M_input_path = f'{occupation_folder}/{occupation}_M_DAG_df.csv'\n",
    "    M_output_path = f'{occupation_folder}/indiffCurves/{occupation}_indiffCurves_M.png'\n",
    "    M_altogether_output_path = f'{data_path}/daily_tasks_occupations_analysis/plots/indiffCurves/M/{occupation}_indiffCurves_M.png'\n",
    "\n",
    "    # First Last Task DAG\n",
    "    N_input_path = f'{occupation_folder}/{occupation}_N_GPT_DAG_df.csv'\n",
    "    N_output_path = f'{occupation_folder}/indiffCurves/{occupation}_indiffCurves_N.png'\n",
    "    N_altogether_output_path = f'{data_path}/daily_tasks_occupations_analysis/plots/indiffCurves/N/{occupation}_indiffCurves_N.png'\n",
    "\n",
    "    # First Last Task DAG\n",
    "    CN_input_path = f'{occupation_folder}/{occupation}_CN_GPT_DAG_df.csv'\n",
    "    CN_output_path = f'{occupation_folder}/indiffCurves/{occupation}_indiffCurves_CN.png'\n",
    "    CN_altogether_output_path = f'{data_path}/daily_tasks_occupations_analysis/plots/indiffCurves/CN/{occupation}_indiffCurves_CN.png'\n",
    "\n",
    "    # First Last Task DAG\n",
    "    FLT_input_path = f'{occupation_folder}/{occupation}_FLT_GPT_DAG_df.csv'\n",
    "    FLT_output_path = f'{occupation_folder}/indiffCurves/{occupation}_indiffCurves_FLT.png'\n",
    "    FLT_altogether_output_path = f'{data_path}/daily_tasks_occupations_analysis/plots/indiffCurves/FLT/{occupation}_indiffCurves_FLT.png'\n",
    "\n",
    "    # Conditioned First Last Task DAG\n",
    "    CFLT_input_path = f'{occupation_folder}/{occupation}_CFLT_GPT_DAG_df.csv'\n",
    "    CFLT_output_path = f'{occupation_folder}/indiffCurves/{occupation}_indiffCurves_CFLT.png'\n",
    "    CFLT_altogether_output_path = f'{data_path}/daily_tasks_occupations_analysis/plots/indiffCurves/CFLT/{occupation}_indiffCurves_CFLT.png'\n",
    "\n",
    "    # Partitioned DAG\n",
    "    P_input_path = f'{occupation_folder}/{occupation}_P_GPT_DAG_df.csv'\n",
    "    P_output_path = f'{occupation_folder}/indiffCurves/{occupation}_indiffCurves_P.png'\n",
    "    P_altogether_output_path = f'{data_path}/daily_tasks_occupations_analysis/plots/indiffCurves/P/{occupation}_indiffCurves_P.png'\n",
    "\n",
    "    # Conditioned Partitioned DAG\n",
    "    CP_input_path = f'{occupation_folder}/{occupation}_CP_GPT_DAG_df.csv'\n",
    "    CP_output_path = f'{occupation_folder}/indiffCurves/{occupation}_indiffCurves_CP.png'\n",
    "    CP_altogether_output_path = f'{data_path}/daily_tasks_occupations_analysis/plots/indiffCurves/CP/{occupation}_indiffCurves_CP.png'\n",
    "\n",
    "\n",
    "    # create list of all DAGs\n",
    "    if occupation in ['travelAgents', 'insuranceUnderwriters', 'pileDriverOperators']:\n",
    "        DAG_indicator_list = ['Manual DAG', 'Naive DAG', 'Conditioned Naive DAG', 'First-Last Task DAG', 'Conditioned First-Last Task DAG', 'Partitioned DAG', 'Conditioned Partitioned DAG']\n",
    "        input_paths_list = [M_input_path, N_input_path, CN_input_path, FLT_input_path, CFLT_input_path, P_input_path, CP_input_path]\n",
    "        output_paths_list = [M_output_path, N_output_path, CN_output_path, FLT_output_path, CFLT_output_path, P_output_path, CP_output_path]\n",
    "        altogether_output_paths_list = [M_altogether_output_path, N_altogether_output_path, CN_altogether_output_path, FLT_altogether_output_path, CFLT_altogether_output_path, P_altogether_output_path, CP_altogether_output_path]\n",
    "    else:\n",
    "        DAG_indicator_list = ['Naive DAG', 'Conditioned Naive DAG', 'First-Last Task DAG', 'Conditioned First-Last Task DAG', 'Partitioned DAG', 'Conditioned Partitioned DAG']\n",
    "        input_paths_list = [N_input_path, CN_input_path, FLT_input_path, CFLT_input_path, P_input_path, CP_input_path]\n",
    "        output_paths_list = [N_output_path, CN_output_path, FLT_output_path, CFLT_output_path, P_output_path, CP_output_path]\n",
    "        altogether_output_paths_list = [N_altogether_output_path, CN_altogether_output_path, FLT_altogether_output_path, CFLT_altogether_output_path, P_altogether_output_path, CP_altogether_output_path]\n",
    "\n",
    "\n",
    "    for DAG_indicator, input_path, output_path, altogether_output_path in zip(DAG_indicator_list, input_paths_list, output_paths_list, altogether_output_paths_list):\n",
    "        print(f'\\n-------Running: {occupation} - {DAG_indicator}-------')\n",
    "        \n",
    "        DAG_start_time = time.time()\n",
    "        DAG_indiffCurve(input_path, output_path, altogether_output_path, unique_partitions, alpha_list)\n",
    "        DAG_end_time = time.time()\n",
    "\n",
    "        DAG_execution_time = DAG_end_time - DAG_start_time\n",
    "        print(f\"\\n{occupation} {DAG_indicator} runtime: {DAG_execution_time:.2f} seconds\")\n",
    "\n",
    "    occupation_end_time = time.time()\n",
    "    occupation_execution_time = (occupation_end_time - occupation_start_time)/60\n",
    "    print(f\"\\n\\n************* {occupation} runtime: {occupation_execution_time:.2f} minutes *************\")\n",
    "    runtime_since_start = (time.time() - start_time)/60\n",
    "    print(f\"\\nruntime since start: {runtime_since_start:.2f} minutes\\n\")\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = (end_time - start_time)/60\n",
    "print(f\"\\n\\nTotal Runtime: {execution_time:.2f} minutes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
