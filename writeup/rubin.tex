\documentclass{article}
\usepackage{graphicx} % Required for inserting images

\usepackage{fullpage}

\usepackage{subcaption}
\usepackage{subcaption}
\usepackage{float}
\usepackage{dialogue}
\usepackage{tikz}
\usepackage{natbib}
\usepackage{setspace}
\usepackage{tabularx}
\usepackage{multirow}
\usepackage{comment}
\usepackage{hyperref}

\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{tcolorbox}

\usepackage{color-edits}

\addauthor[BL]{bl}{blue}

%%%%%%%%%%%%%%%%%%%%
% For appendix math formulas
\theoremstyle{plain}
    \ifx\thechapter\undefined
      \newtheorem{lem}{\protect\lemmaname}
    \else
      \newtheorem{lem}{\protect\lemmaname}[chapter]
    \fi
\theoremstyle{plain}
    \ifx\thechapter\undefined
  \newtheorem{cor}{\protect\corollaryname}
\else
      \newtheorem{cor}{\protect\corollaryname}[chapter]
    \fi
\providecommand{\corollaryname}{Corollary}
\providecommand{\lemmaname}{Lemma}
%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%
% For illustration of AI task automation flow
\usetikzlibrary{shapes.geometric, arrows, positioning, arrows.meta, fit, decorations.pathreplacing, calc}

% Define styles
\tikzstyle{task} = [rectangle, minimum width=1cm, minimum height=1cm, text centered, draw=black, fill=gray!20, rounded corners, text width=2.2cm, align=center]
\tikzstyle{decision} = [rectangle, minimum width=4cm, minimum height=2cm, text centered, draw=black, fill=green!20, rounded corners, text width=3cm, align=center]
\tikzstyle{process} = [rectangle, minimum width=2.5cm, minimum height=2cm, text centered, draw=black, fill=orange!40, rounded corners, text width=3cm, align=center]
\tikzstyle{process2} = [rectangle, minimum width=2.5cm, minimum height=2cm, text centered, draw=black, fill=gray!10, text width=3cm, align=center]
\tikzstyle{smallbox} = [rectangle, minimum width=1cm, minimum height=1cm, text centered, draw=black, fill=gray!20, text width=1.5cm, align=center]
\tikzstyle{arrow} = [thick,->,>=stealth]
%%%%%%%%%%%%%%%%%%%%



\DeclareMathOperator{\CostBlock}{CostBlock}
\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}
\newtheorem{observation}{Observation}
\DeclareMathOperator{\minCost}{minCost}

\begin{document}
%\title{The Economics of Generative and Agentic AI}
% John's footnote: \footnote{I used AI extensively to write this paper, particularly Claude 3.5 Sonnet and o1 pro from OpenAI. Thanks for complementing my labor, AI agents!}
\title{AI, Tasks and Judgement}
\author{}
\date{\today{}}



\newcommand{\T}[0]{\mathcal{T}}
\newcommand{\J}[0]{\mathcal{J}}
\newcommand{\machine}[1]{\langle #1 \rangle}
\newcommand{\human}[1]{( #1 )}
\newcommand{\cost}[1]{C\{ #1 \}}
\newcommand{\costdo}[1]{T_H\{ #1 \}}
\newcommand{\costmanage}[1]{T_M\{ #1 \}}
\newcommand{\timecost}[1]{t_{#1}}
\newcommand{\hccost}[1]{c_{#1}}
\newcommand{\labor}[1]{l_{#1}}
\newcommand{\handofftime}[1]{t^{s}_{#1}}
\newcommand{\humantime}[1]{t^{h}_{#1}}
\newcommand{\machinetime}[1]{t^{m}_{#1}}
\newcommand{\humanhc}[1]{c^{h}_{#1}}
\newcommand{\machinehc}[1]{c^{m}_{#1}}



\newcommand{\topic}[1]{\paragraph{#1}}
%\newcommand{\topic}[1]{#1}

\renewcommand{\arraystretch}{1.75} % Increase row height for visual consistency in job design Table 

\maketitle

\begin{abstract}
\noindent
This paper presents a simple task‐based model of Agentic AI and human labor.  
Unlike existing task models, it explicitly considers the interdependence of tasks in a sequence.  
Tasks can be efficiently ``chained'' together, meaning that each task produces something that feeds directly into the next without human intervention.  
A task may optimally be added to an automated chain even when humans have an absolute advantage at that task in isolation, overturning the usual comparative advantage logic.  
The workers in the model face a ``hand-off'' cost for switching between jobs.
This source of friction determines how tasks are bundled into jobs and which tasks are assigned to AI.
The model accommodates two distinct modes of AI deployment: (1) automation, where AI completes tasks without human oversight, and (2) augmentation, where AI assists humans in completing tasks.
We embed the model of production into a general equilibrium framework to study how an AI quality shock affects worker wages and employment. 
%The model predicts that firms will reconfigure job structures following improvements beyond a certain level in AI quality, leading to wage cuts for some workers and (potential) wage gains for others.
\end{abstract}

\onehalfspacing

%%%%%%%%%%%%%%%% Introduction %%%%%%%%%%%%%%%%
\section{Introduction}
We present a simple task-based model of AI and human labor that focuses on the interdependence of tasks in the productive process.
We start with a model of production that is a sequence of tasks that must be done in order.
Those tasks differ both in the amount of human capital they require and how long they take to complete.
They also differ in how easily they can be ``handed-off'' from one worker to the next.
These costs endogenize the division of labor in the production process.  From this baseline model we explore the effect of AI and the resulting automation of tasks.
We then investigate how AI advancements affect this division in the short run---where human capital needs remain fixed but task durations shrink---and in the long run---where both human capital requirements and task times can adjust.
Finally, we explore the consequences for labor demand and wage outcomes under both scenarios.

There are, of course, numerous economic models of the division of labor \citep{becker1992division, deming2017growing}---why do we need another?
While we model the division of labor, our focus is on the impact of AI automation in the production process.  As we shall see, the extent of automation depends on the sequencing of tasks and their prerequisite structure.  In other words, task adjacency will matter in our model of AI labor, which we describe next.

We consider how the development of AI tools that can assist with or automate certain tasks changes the division of labor.  
In the model, three modes of task completion are recognized: manual, augmented, and automated.
\emph{Manual} task completion means that a human carries out the entire task without any AI assistance.  
\emph{Augmented} task completion involves a human performing the task with the use of AI.  For example, a human describes the parameters of the task to an AI tool, the AI then executes the task, and its output is reviewed and approved by the human.
In contrast, we say a task has been \emph{automated} if it is completed by an AI end-to-end without any direct human intervention.  While any task can be completed either manually or via AI augmentation, there is a crucial restriction on automation: tasks can only be automated as prerequisites of an augmented task.  For example, as part of a request to complete one task, an AI might also be assigned to complete one or more preceding tasks as part of that single request.  Any such preceding task is said to be automated.

Although augmented and automated tasks both involve AI, they differ in one crucial respect: augmented tasks demand direct human oversight of the AI’s output, whereas automated tasks do not.
Figure~\ref{fig:task_division} illustrates these concepts using a sequence of five tasks.  
Tasks 1 and 5 are performed manually by a human.  
Tasks 2, 3, and 4 form an machine chain and are done using AI.
Tasks 2 and 3 are automated because their outputs feed directly into subsequent AI tasks without human review.
Task 4 is augmented because its output is evaluated by a human before proceeding. 
\begin{figure}[ht]
  \begin{center}
  \caption{Illustrative Example for Division of Labor}
  \label{fig:task_division}
  \begin{tikzpicture}[scale=0.9, transform shape,
    node distance=0.25cm and 0.6cm,
    every node/.style={rectangle, rounded corners, draw, align=center, minimum width=2cm, minimum height=1cm},
    manual/.style={fill=gray!10},
    automated/.style={fill=green!30},
    augmented/.style={fill=orange!30},
    labelbox/.style={draw, rectangle, rounded corners, fill=blue!20, font=\bfseries, minimum width=2cm, minimum height=1cm},
    >=latex
  ]
    % Task nodes
    \node[manual]    (T1) {Task 1\\(Manual)};
    \node[automated, right=of T1] (T2) {Task 2\\(Automated)};
    \node[automated, right=of T2] (T3) {Task 3\\(Automated)};
    \node[augmented, right=of T3] (T4) {Task 4\\(Augmented)};
    \node[manual,    right=of T4] (T5) {Task 5\\(Manual)};

    % Arrows between tasks (keep these bold)
    \draw[->, thick] (T1) -- (T2);
    \draw[->, thick] (T2) -- (T3);
    \draw[->, thick] (T3) -- (T4);
    \draw[->, thick] (T4) -- (T5);

    % AI brace and label over tasks 2–4 (lighter)
    \draw[decorate, decoration={brace, amplitude=6pt}, thin]
      ($(T2.north west)+(0,0.2)$) -- ($(T4.north east)+(0,0.2)$)
      node[midway, above=8pt, labelbox] (AI) {AI};

    % Human label below, aligned with AI
    \node[labelbox, below=2.5cm of AI] (Human) {Human};

    % Lines from T1, T4, and T5 down to Human (lighter)
    \draw[thin] (T1.south) -- (Human.north);
    \draw[thin] (T4.south) -- (Human.north);
    \draw[thin] (T5.south) -- (Human.north);
  \end{tikzpicture}
  \end{center}
  \footnotesize{
  \emph{Notes:} This figure illustrates division of labor across five tasks: Tasks 1 and 5 are done manually by human; Tasks 2--3 are AI‐automated (done with AI without direct human intervention); Task 4 is AI‐augmented (done with AI but with human oversight). The brace above tasks 2--4 indicates an AI chain, and that AI is involved in completing those tasks; downward lines show which tasks require human execution or oversight. 
  }
\end{figure}

The decision to deploy AI on a given task compares the cost of manual execution to the unified AI-based execution cost.  
At first glance, this might seem like another way of stating that tasks get assigned to whichever factor has the comparative advantage in that task, but this is not the case: the position of tasks within the productive process profoundly changes the optimal allocation of tasks between humans and machines.
When a single task is performed by an AI, there is always a human requesting the task and evaluating its output in an AI-augmented manner.  
But with two or more tasks it is possible to re-configure production so that an AI completing one task passes its output directly into the next task without human intervention (i.e., the task is automated).  
The machine chain (Tasks 2--4) in Figure~\ref{fig:task_division} illustrates this case: Tasks 2 and 3 are fully automated (their outputs flow from one AI task to the next without direct human intervention) while Task 4, is AI-augmented with human oversight at the end of the chain.
This chaining is potentially a source of large productivity gains, \emph{but} it requires AIs that can perform each task with a high probability of success.  
The model’s basic setup shares conceptual similarities with the O-ring model of production \citep{kremer1993}, and the role humans  play in the model as offering judgment on AI outputs is consistent with the emphasis in \cite{agrawal2019exploring}.

A key implication of the model is that chaining tasks together can reverse comparative advantage assignments for individual tasks.
It can be efficient to deploy an AI on a task even when humans hold a comparative advantage in that task in isolation.
A surprising result of chaining is strong AI performance on one task can shift another task from human to machine execution through chaining, even if the AI’s capability on the second task is inferior to that of a human.
Task 3 in Figure~\ref{fig:task_division} illustrates this possibility: with appropriate parameter values, Task 3 can be most efficient under manual execution in isolation, yet overall production costs are minimized when it is bundled with Tasks~2 and~4 in an AI chain.

Because of chaining, it matters what tasks are ``next'' to each other in a productive process.
Recall that tasks in our model have both a human capital (i.e, skill) requirement and a time requirement.
In some sequences, adjacent tasks differ sharply in their time and skill profiles---the two cost dimensions that are focal in our model.
We refer to such cases as ``tent‐poll tasks.''
These arise when a time‐consuming, low‐skill task is immediately followed by a short, high‐skill task.
Figure~\ref{fig:tent_poll} gives one such example.
Each task in the figure is represented by a rectangle of width $\timecost{}$ (time requirement) and height $\hccost{}$ (human capital requirement).
\begin{figure}[h!]
  \caption{Illustration of Tent‐Poll Tasks} 
  \label{fig:tent_poll}
  \begin{center}
    \includegraphics[width=\textwidth]{plots/tent_poll.png}
  \end{center}
  \begin{footnotesize}
    \emph{Note:} This figure illustrates tent‐poll tasks.  
    The width and height of each rectangle specify the time and human capital requirements of the task, respectively.
    Tasks 1 and 3 have a high time cost and low human capital requirement (wide and short) whereas Task 2 exhibits a low time cost and high human capital requirement (narrow and tall).  
  \end{footnotesize}
\end{figure}
The sharp contrast between the $(\hccost{}, \timecost{})$ pairs of tent-poll tasks creates substantial inefficiencies, discouraging AI chaining and instead pushing firms toward individual task specialization.
The same economic forces that historically drove the division of labor (namely, minimizing frictions and inefficiencies) now define the boundaries of where AI can be effectively deployed.
Even when two consecutive tasks are each AI‐able in isolation, chaining them together may still not be viable.
Consequently, the decision to assign a task to AI depends not only on the task's own AI-ability, but also on the characteristics of its neighbors.

Assigning tasks to factors of production is not a completely trivial optimization problem, even computationally.
For an occupation with $n$ tasks, the number of possible production arrangements grows exponentially in $n$. 
%we show that there are $F(2n + 1)$ possible production arrangements, where $F(k)$ is the $k$th Fibonacci number.
However, we show how the optimization problem of partitioning tasks into jobs can be solved numerically in $O(n^2)$ time using dynamic programming (DP).  The joint problem of optimizing labor and the use of AI automation (including optimal chaining) can also be solved in polynomial time, subject to an error term that can be made arbitrarily small.
Although we do not do it in this paper, this algorithmic approach could be combined with micro-details of task content and composition (as in \cite{frey2017future, felten2021occupational, eloundou2023gpts}) to create rich estimates of how technological change in various tasks would impact workers.

\blcomment{May want to omit the commentary on individual task improvements for now, and focus on generalized AI improvements.  If so, the following two paragraphs should change.}
It might be hard for firms or even for it to be obvious beyond just the allocation of tasks to factors of production, the model provides a way to calculate the return to investing in AI capabilities in specific tasks.
For tasks far from economical automation (i.e., done by humans), marginal investments in AI capabilities offer no immediate return.
Once capabilities exceed the threshold where AI replaces humans even in isolation, improvements in AI capabilities offer a return, but at a diminishing rate.
But once the chaining threshold is passed, the returns to investing in AI for that focal task discontinuously increase.
These non-linearities in the returns to investment in AI creates interesting optimal investment path dynamics.

In the $n = 2$ task case, with a high discount rate, it can be optimal to invest heavily in a single AI capability, leaving the other task to always be done by humans.
With a low discount rate, the optimal path can change dramatically. 
As with other growth models, there is a ``get on the turnpike'' effect: the optimal path is to invest heavily in AI for the lagging task until it reaches parity with the more advanced task, with both of them chained, after which we have balanced investment across AI tasks.
Depending on the starting point, before getting on the turnpike, it is sometimes optimal to continue to invest in the leading task for some amount of time, in order to enjoy lower costs while getting the lagging task up to parity.

The chaining feature of the model connects to---and potentially reconciles---competing views about automation in production. 
Despite the emphasis on task-level substitution between AI and labor in most of the AI and labor literature \citep{autor2003skill, acemoglu2018automation}, \cite{bresnahan2002information} argues that that meaningful substitution happens primarily at the system level. 
One could interpret the model as showing how task-level decisions aggregate into system-level automation through chaining.
In the model, there is no Ship-of-Theseus requirement that tasks are automated one by one but rather than entire chains can be automated all at once---consistent with the \cite{bresnahan2002information} perspective.

Although the model is developed as a kind of algorithmic cost function, it ultimately produces cost functions with standard properties, which we embed within a more general model of the economy.  
The model predicts that improvements in AI will inherently reduce labor use per unit of the good and, consequently, its price.  
Whether this increases or decreases the demand for labor, even for that task, depends on the elasticity of demand for that good in the product market.  

In the model, with highly capable AIs, the human role shrinks to asking and judging. 
This perhaps sounds like an uninspiring role but it is not necessarily a low-paid one. 
Consider the famed music producer Rick Rubin, who is not poor, discussing his market value in an interview with Anderson Cooper:
\begin{dialogue}
    \speak{Rick Rubin} I've no technical ability. And I know nothing about music.
    \speak{Anderson Cooper} Well, you must know something.
    \speak{Rick Rubin} I know what I like and what I don't like. I'm decisive about what I like and what I don't like.
    \speak{Anderson Cooper} So what are you being paid for?
    \speak{Rick Rubin} The confidence that I have in my taste, and my ability to express what I feel, has proven helpful for artists.
\end{dialogue}
We might be paid for being hepful to AIs.
And this help might be valuable, even if we have no ability to do the tasks ourselves.
In other words, automation can enable new forms of labor-labor substitution by separating task execution from task evaluation, allowing workers to leverage judgment skills even in domains where they lack execution abilities, potentially upending the allocation of workers to occupations in hard-to-forsee ways (see \cite{autor2013putting} on this human capital-task-wage relationship).

Finally, improvements in AI quality generate nonlinear effects on labor demand and wages.
In the short run, higher AI performance reduces task time costs, potentially lowering labor demand and putting downward pressure on wages.
If one‐off gains from reassigning tasks to workers outweigh pure time savings enabled by AI advances in existing job structures, firms will reconfigure tasks in the short run, potentially boosting demand (and wages) for some roles despite overall AI efficiency gains.
In the long run, worker retraining and unrestricted task reallocation yield new wage schedules that reflect updated human capital and time cost parameters.  
These threshold effects imply that marginal AI advances may have little impact until they cross a short‐run redesign or long‐run restructuring tipping point, after which labor demand and job structures shift abruptly.  
Our framework thus offers clear, testable predictions on when and how AI-driven productivity gains trigger structural reorganization in labor markets.



%%%%%%%%%%%%%%%% Task-Based Model of Production %%%%%%%%%%%%%%%%
\section{A Task-Based Model of Production}
\label{sec:taskbased_prod}

In this section we develop a framework that treats the production process of an occupation as a collection of tasks. We explore how firms split those tasks into jobs to balance the benefits of specialization against handoff costs. We first consider costs from the perspective of a worker, then later use this to motivate the cost function faced by a firm designing the job design.  We then discuss the structure of optimal designs and provide a geometric interpretation.

%We then introduce a model of AI augmentation and automation in which tasks can be completed in different ways, and consider the joint optimization of job structure and automation strategy.

\subsection{Tasks and Job Design}
\label{sec:job_design}

Suppose production of a (final) good requires completing an ordered set of tasks, denoted by:
\begin{equation}
\label{eq:tasks}
\T = \{1,2,\ldots,n\}.
\end{equation}
We refer to $\T$ as the production process of the good.
The firm can partition the production process $\T$ into one more more distinct ``jobs,'' where each job is a contiguous block of tasks to be performed by a single worker.
%$j \in \{1, \cdots, J \}$ , denoted by $\J_j$, performed by a single worker.
If the partition is into $k \geq 1$ jobs, then for each $j \in \{1, \dotsc, k\}$ we denote job $j$ by $J_k \subseteq \T$.  Jobs are indexed in order of tasks, so that if $j < j'$ and $i \in J_j$, $i' \in J_{j'}$ then $i < i'$.  We also have
\[
\bigcup_{j=1}^J J_j = \T
\]
and for all $j,j' \in \{1,\dots,k\}$ where $j \neq j'$ we have
\[
J_j \cap J_{j'} = \emptyset.
\]
We refer to any collection of jobs satisfying the above conditions as a ``job design'' for the occupation, and denote it with $\J = \{J_j\}_{j=1}^{k}$.

With $|\T| = n$ tasks, there are $2^{(n - 1)}$ unique ways of designing jobs.
For example, if $n = 3$, the production process of the final good consists of three tasks, $\{1,2,3\}$, with $2^{(3-1)}=4$ unique job designs.  The following notation will be useful in examples.
Let $[.]$ denote the tasks assigned to a worker in a job.
The four possible designs in this example are: $\{[1][2][3], \, [1,2][3], \, [1][2,3], \, [1,2,3]\}$.
The $[1,2][3]$ design, for example, means that one worker is assigned to do tasks 1 and 2 in a single job, $[1,2]$, whereas task 3 is assigned to a different worker in another job, $[3]$.
Later, we will discuss what factors guide the firm’s choice among different job designs.


%\subsection{Human Capital, Labor Costs, and Optimal Job Design}

%\blcomment{I recommend introducing handoff/switching costs in this section, then having a discussion about why this is important (with example).  As opposed to having multiple calculations for job costs, which might confuse the reader.}

\subsection{Worker Costs}

%We now describe our model of labor costs for a given job design.  We begin by considering costs from the perspective of a worker, then later use this to motivate the cost function faced by a firm designing the job design.  We then discuss the structure of optimal designs and provide a geometric interpretation.

Fix a job design $\J$.  The firm hires one worker for each job $j \in \{1, \cdots, k\}$.  
Worker $j$ completes all tasks $i \in J_j$ associated with their job. 
Performing any task $i$ requires the worker to first acquire the necessary skills, incurring a one-time human capital investment cost \( \hccost{i} > 0 \).
The task itself takes time $\timecost{i}>0$ to complete. 
Note that the human capital cost $\hccost{i}$ is paid by the worker only once upon acquisition, whereas the time cost $\timecost{i}$ applies to every unit of the good produced.
In other words, once the necessary skill (i.e., human capital) is acquired, labor (i.e., time) is the only input used in production.
For example, it might cost \$10 to learn how to file a test procedure specification (TPS) report, and once the worker has acquired this skill, it takes $15$ minutes to produce each report.
Thus, after paying the \$10 learning cost, the worker can produce one report every $15$ minutes.
The total human capital acquired ex ante by the worker employed in job $j$ is thus:
\[
\sum_{i \in J_j} \hccost{i},
\]
while the total time spent on tasks to produce a unit of output is:
\[
\sum_{i \in J_j} \timecost{i}.
\]
Finally, we introduce an additional switching or ``hand-off cost” friction: a cost associated with job transitions that, while not requiring additional human capital, does take time.
This time reflects the effort of context switching between workers in the production process.
Within a job, all tasks are performed by the same worker, so no hand-off occurs.
But for any pair of consecutive jobs $J_j, J_{j+1}$, the final task of job $J_j$---say task $i$---must be handed off by worker $j$ to worker $j+1$ before work can continue. 
The hand-off time is an intrinsic property of this task $i$---not the job---and arises specifically when transitioning from the final task of job $j$ to the first task of job $j+1$. We write $\handofftime{i}$ for the hand-off cost associated with task $i$, which we emphasize is incurred only if task $i$ is the final task of a job.

For notational convenience, we will also write $\handofftime{j}$ to denote the additional hand-off time spent by the worker assigned to job $j$.  This notation implicitly assumes a fixed job design.\footnote{
Suppose task $i$ is the final task in job $j$.
For convenience, we define $\handofftime{j} := \handofftime{i}$.}
Thus, although we use the subscript $j$ to indicate the hand-off between jobs, this cost fundamentally originates from the task itself. Also, for the final job $J_k$ in job design $\J = \{J_j\}_{j=1}^k$, we define $\handofftime{k} = 0$ for convenience, as the final job in the job design involves no hand-off to a subsequent worker.  Under this notation, the total time taken by a worker to complete a unit of output from job $j$, including hand-off costs, is
\[ \handofftime{j} + \sum_{i \in J_j} \timecost{i}. \]
%For simplicity, rather than explicitly indexing the final task of each job, we denote the hand-off cost between jobs $j$ and $j+1$ as $\handofftime{j}$.

\subsection{Total Cost of a Job Design}

Given the cost model faced by a worker, we can now solve for wage rates that determine labor costs faced by the firm. Both the product and human capital markets are perfectly competitive, and workers are \emph{ex ante} identical, as in \cite{becker1992division}.
Workers value leisure at $v_L$ and supply one unit of labor inelastically.
Hence, if the wage in job $j$ is $w_j$, the worker's income is simply $w_j$.
To remain indifferent between jobs, workers must receive wages that covers not only the value of their time but also compensates them for the cost of human capital they have acquired.
Thus, the wage rate in job $j$ must satisfy\footnote{Notice that while wages may differ across jobs, they are structured such that workers remain indifferent between acquiring different types of human capital for different jobs.}:
\begin{align}
\label{eq:wage}
w_j = v_L + \sum_{i \in J_j} \hccost{i}.
\end{align}
The firm must pay workers for their time, regardless of which tasks they are employed to complete; hence, the wage bill paid to worker per unit of output is:
\begin{align}
\label{eq:wagebill}
\text{WageBill}_j = \Biggl(v_L + \sum_{i \in J_j} \hccost{i} \Biggr) \Biggl(\handofftime{j} + \sum_{i \in J_j} \timecost{i} \Biggr).
\end{align}

The firm's objective is to minimize the total cost of producing the final good by optimizing the job design.  The optimal production cost per unit of the good is thus the solution to the following expression:
\begin{align}
\label{eq:totalcost_with_handoff}
\underset{\J}{min} \ 
\text{TotalCost}(\J; \hccost{}, \timecost{}) 
= \sum_{J_j \in \J} \text{WageBill}_j = 
\sum_{J_j \in \J} \Biggl[\Biggl(v_L + \sum_{i \in J_j} \hccost{i} \Biggr) \Biggl(\handofftime{j} + \sum_{i \in J_j} \timecost{i} \Biggr)\Biggr]
\end{align}
where $\hccost{}$ and $\timecost{}$ are vectors of task skill and time requirements.\footnote{Note a slight abuse of notation: we take $\handofftime{j}$ in the expression for $\text{TotalCost}(\J; \hccost{}, \timecost{})$ to be with respect to the job design $\J$.}

%\blcomment{Note here that the optimal job design, given $\hccost{}$ and $\timecost{}$, can be found in polynomial time via dynamic programming.}

While there are exponentially many possible job designs, a simple dynamic program can be used to construct the optimal job design in time $O(n^2)$.

\begin{proposition}
    Given fixed skill and time costs $\hccost{} = (\hccost{1}, \dotsc, \hccost{n})$ and $\timecost{} = (\timecost{1}, \dotsc, \timecost{n})$, the cost-minimizing job design $\J$ can be computed in time $O(n^2)$ by dynamic programming.
\end{proposition}
\begin{proof}
    We first note the following recursive formulation of the optimization problem. For all $m \leq n$, let $C[m]$ denote the minimum cost of a job design for tasks $1$ through $m$, \emph{including hand-off costs for task $m$}.  Note then that $C[n]$ is the cost of the optimal job design for all tasks, recalling that we defined $\handofftime{n} = 0$ so the handoff-costs for task $n$ are always $0$.
    
    We now show how to calculate $C[m]$ recursively.  As a base case we have $C[0] = 0$.  For $m \geq 1$ we have
    \[ 
    C[m] = \min_{s < m} \Biggl\{ C[s] + \Biggl[\Biggl(v_L + \sum_{i = s+1}^m \hccost{i} \Biggr) \Biggl(\handofftime{m} + \sum_{i = s+1}^m \timecost{i} \Biggr)\Biggr] \Biggr\}.
    \]
    In other words, we optimize over the choice of the final job $\{s+1, \dotsc, m\}$, accounting recursively for the optimal job design for remaining jobs.  Using this formulation, we can calculate each $C[m]$ in time $O(m)$ by considering each potential choice of $s$.  Doing so for each $m = 1, 2, \dotsc, n$ yields the value of $C[n]$ (and corresponding job design) in total time $O(n^2)$.
\end{proof}

\subsection{A Geometric Interpretation}

Equation~\ref{eq:wagebill} admits a nice geometric interpretation.  
We can represent the production process as a sequence of stacked rectangles whose heights are $\hccost{i}$ and widths are $\timecost{i}$.  
Figure~\ref{fig:wage_bill} illustrates an occupation with just two tasks and thus two job designs: [1][2] and [1,2].
For simplicity we assume $v_L=0$ in the graph, and for now we assume hand-off costs are also $0$.
In both panels, the numbered, solid‐lined rectangles denote the two tasks.
Visually, a job corresponds to the bounding box around its tasks, and its wage bill equals the area of that box (shaded in blue).
In the [1][2] design (left panel), each task is handled by a different worker: the wage bill for job 1 is the shaded area of rectangle 1, and the wage bill for job 2 is the shaded area of rectangle 2.  
In the [1,2] design (right panel), both tasks are assigned to the same worker, so the occupation has a single job whose wage bill is the area of the shaded rectangle whose width is the sum of the two tasks’ time costs and whose height is the sum of their human capital costs.  
\begin{figure}[h!]
  \caption{Geometric Illustration of the Wage Bill} 
  \label{fig:wage_bill}
  \begin{center}
    \includegraphics[width=\textwidth]{plots/job_design.png}
  \end{center}
  \begin{footnotesize}
    \emph{Note:} Each panel of the graph shows the geometric representation of the wage bill for a job design of an occupation with two tasks (assuming $v_L=0$ and no hand-off costs).  
    The shaded areas represent wage bills of jobs. 
    In the left panel, two separate jobs cover tasks [1] and [2].
    Wage bill of each job is the area of its corresponding task's rectangle.
    In the right panel, a single job covers both tasks: [1,2].
    The wage bill of this job is the area of the rectangle with width $\timecost{1}+\timecost{2}$ and height $\hccost{1}+\hccost{2}$.
  \end{footnotesize}
\end{figure}

If we re-introduce non-zero switching costs, the firm’s cost‐minimization problem still admits a geometric interpretation.  
Figure~\ref{fig:job_design} represents 
%the production process from Table~\ref{tab:job_design} 
a three-task production process
as stacked rectangles of height $\hccost{i}$ and width $\timecost{i}$.
\begin{figure}[htbp]
  \begin{center}
  \caption{Geometric interpretation of job designs for the \(n=3\) tasks example} \label{fig:job_design}
  \begin{subfigure}[b]{0.6\textwidth}
    \includegraphics[width=\textwidth]{plots/combined_grid_no_handoff.png}
    \caption{Job design without hand-off costs}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.6\textwidth}
    \includegraphics[width=\textwidth]{plots/combined_grid_with_handoff.png}
    \caption{Job design with hand-off costs}
  \end{subfigure}
  \end{center}
  \footnotesize{\emph{Notes:} This figure illustrates the geometric interpretation of firm's job design problem presented in Table~\ref{tab:job_design}. Each panel visualizes the production process as a sequence of stacked rectangles, where the area of each rectangle (the bounding box around a job) represents its wage bill. Panel (a) corresponds to the scenario without hand-off costs, leading to the optimal design of [1][2][3] (top left graph). Panel (b) incorporates hand-off costs, which alters the cost structure and makes the [1,2][3] design cost minimizing (bottom left graph).}
\end{figure}
Panel (a) depicts the job design if all hand‐off costs are zero; Panel (b) shows the same example with hand‐off costs (corresponding to Panel B).
Visually, the firm trades off two opposing forces.
Consolidating tasks into a single job avoids boundary costs but creates inefficiencies captured by cross‐bundling areas.  
Splitting tasks into separate jobs eliminates those inefficiencies yet incurs hand‐off time costs at each job boundary.  
These boundary costs scale with the cumulative human capital of the switching worker, so the height of the pink hand‐off rectangle in Panel (b) equals the sum of human‐capital heights for that job.
By balancing these effects, the firm selects the most cost‐effective job design.  
Without hand‐off costs, the optimal arrangement is [1][2][3] (top left of Panel (a)); with hand‐offs, it shifts to [1,2][3] (bottom left of Panel (b)).  


\begin{comment}
The firm seeks to minimize the total cost of producing the final good by optimally designing jobs.
The overall production cost per unit of the good is the solution to:
\begin{align}
\label{eq:totalcost_no_handoff}
\underset{\{\J_j\}_{j=1}^J}{min} \ 
\text{TotalCost}(\J; \hccost{}, \timecost{})
= 
\sum_{j=1}^J \Biggl[\Biggl(v_L + \sum_{i \in \J_j} \hccost{i} \Biggr) \Biggl(\sum_{i \in \J_j} \timecost{i} \Biggr)\Biggr],
\end{align}
where $\hccost{}$ and $\timecost{}$ are vectors of task skill and time requirements. 
\end{comment}

\subsection{The Role of Hand-off Costs: Limits to Full Division of Labor}

In the earlier  production example with three tasks, suppose workers value leisure at $v_L = 1$, all hand-off costs are zero, and tasks are characterized by human capital requirements and time costs specified below:
\[
\begin{array}{c|ccc}
\textbf{Task} & \hccost{i} & \timecost{i} \\ \hline
1 & 3  & 1 \\
2 & 1 & 2  \\
3 & 2   & 1.5 \\
\end{array}
\]
The wage bill for each individual job as well as total production cost for each job design is given in Panel A of Table~\ref{tab:job_design}.
The lowest‐cost configuration, [1][2][3], assigns each task to a different worker, allowing each individual to specialize in a single task.  
In fact, this conclusion holds for any arbitrary set of parameter values since, for any nonnegative $x,y,w,z$, we have:
\[
  xy + wz \le (x + w)(y + z),
\]
meaning that bundling any two tasks cannot reduce the total cost.  
Geometrically, for any number of tasks, the sum of areas of individual rectangles never exceeds the area of the single bounding rectangle that covers two or more tasks assigned to one worker.

\begin{table}[htbp]
\caption{Example job design costs for a production process with $n=3$ tasks}
\begin{center}
\resizebox{0.75\textwidth}{!}{%
\begin{tabular}{c}
% Panel A: Without Hand-off Costs
\begin{minipage}{\textwidth}
\centering
\hspace*{4cm} Panel (A): Without Hand-off Costs \\[1ex]
\begin{tabular}{|
  >{\centering\arraybackslash}m{1.7cm}|
  >{\centering\arraybackslash}m{0.9cm}|
  >{\centering\arraybackslash}m{1.8cm}|
  >{\centering\arraybackslash}m{1.8cm}|
  >{\centering\arraybackslash}m{1.8cm}|
  >{\centering\arraybackslash}m{1.6cm}|
  >{\centering\arraybackslash}m{1.7cm}|
  >{\centering\arraybackslash}m{1.7cm}|
  }
\hline
\textbf{Job Design} & \textbf{Job} & \textbf{Job Tasks} & $v_L+\sum\hccost{i}$ & $\sum\timecost{i}$ & \textbf{Job Cost} & \textbf{Total Cost} & \textbf{Optimal Design} \\
\hline
\multirow{3}{*}{[1][2][3]} 
  & 1 & $\{1\}$   & 4   & 1    & 4    & \multirow{3}{*}{12.5} & \multirow{3}{*}{\checkmark} \\
\cline{2-6}
  & 2 & $\{2\}$   & 2   & 2    & 4    &  &  \\
\cline{2-6}
  & 3 & $\{3\}$   & 3   & 1.5  & 4.5  &  &  \\
\hline
\multirow{2}{*}{[1,2][3]}
  & 1 & $\{1,2\}$ & 5   & 3    & 15   & \multirow{2}{*}{19.5} &  \\
\cline{2-6}
  & 2 & $\{3\}$   & 3   & 1.5  & 4.5  &  &  \\
\hline
\multirow{2}{*}{[1][2,3]}
  & 1 & $\{1\}$   & 4   & 1    & 4    & \multirow{2}{*}{18} &  \\
\cline{2-6}
  & 2 & $\{2,3\}$ & 4   & 3.5  & 14   &  &  \\
\hline
[1,2,3] & 1 & $\{1,2,3\}$ & 7   & 4.5  & 31.5 & 31.5 &  \\
\hline
\end{tabular}
\end{minipage} \\[25ex]
% Panel B: Including Hand-off Costs
\begin{minipage}{\textwidth}
\centering
\hspace*{4cm} Panel (B): Including Hand-off Costs \\[1ex]
\begin{tabular}{|
  >{\centering\arraybackslash}m{1.7cm}|
  >{\centering\arraybackslash}m{0.9cm}|
  >{\centering\arraybackslash}m{1.8cm}|
  >{\centering\arraybackslash}m{1.8cm}|
  >{\centering\arraybackslash}m{1.8cm}|
  >{\centering\arraybackslash}m{1.6cm}|
  >{\centering\arraybackslash}m{1.7cm}|
  >{\centering\arraybackslash}m{1.7cm}|
  }
\hline
\textbf{Job Design} & \textbf{Job} & \textbf{Job Tasks} & $v_L+\sum\hccost{i}$ & $\handofftime{} + \sum\timecost{i}$ & \textbf{Job Cost} & \textbf{Total Cost} & \textbf{Optimal Design} \\
\hline
\multirow{3}{*}{[1][2][3]} 
  & 1 & $\{1\}$   & 4   & 3.5  & 14   & \multirow{3}{*}{23.5} &  \\
\cline{2-6}
  & 2 & $\{2\}$   & 2   & 2.5  & 5    &  &  \\
\cline{2-6}
  & 3 & $\{3\}$   & 3   & 1.5  & 4.5  &  &  \\
\hline
\multirow{2}{*}{[1,2][3]}
  & 1 & $\{1,2\}$ & 5   & 3.5  & 17.5 & \multirow{2}{*}{22} & \multirow{2}{*}{\checkmark} \\
\cline{2-6}
  & 2 & $\{3\}$   & 3   & 1.5  & 4.5  &  &  \\
\hline
\multirow{2}{*}{[1][2,3]}
  & 1 & $\{1\}$   & 4   & 3.5  & 14   & \multirow{2}{*}{28} &  \\
\cline{2-6}
  & 2 & $\{2,3\}$ & 4   & 3.5  & 14   &  &  \\
\hline
[1,2,3] & 1 & $\{1,2,3\}$ & 7   & 4.5  & 31.5 & 31.5 &  \\
\hline
\end{tabular}
\end{minipage}
\end{tabular}
}
\label{tab:job_design}
\end{center}
\footnotesize{\emph{Notes:} This table shows production costs for each job design in a production process with $n=3$ tasks. 
Panel (A) gives the production costs in absence of hand-off costs whereas Panel (B) includes hand-off costs. While in absence of hand-off friction assigning each task to a single worker is optimal, the cost-minimizing way of producing the good changes after the introduction of hand-off costs. The human capital requirements, task times, hand-off times, and value of leisure are specified in text.
}
\end{table}


%\subsection{Frictional Limits to Full Division of Labor}
%\label{sec:handoff_intro}
To summarize: without the friction of hand-off costs, the firm always minimizes production costs by assigning one worker to each task.
%To assume away this trivial arrangement we introduce the ``hand-off cost” friction: a cost associated with job transitions that, while not requiring additional human capital, does take time.
%This cost reflects the expense of context switching between workers in the production process, and applies only when a task sits at a job boundary.  
%Within a job, all tasks are performed by the same worker, so no hand-off occurs and no such cost is incurred.
%The hand-off cost is an intrinsic property of a task---not the job---and arises specifically when transitioning from the final task of job $j$ to the first task of job $j+1$.  
%In such a case, the worker assigned to job $j$ incurs an additional hand-off time cost $\handofftime{j} \ge 0$.
%For simplicity, rather than explicitly indexing the final task of each job, we denote the hand-off cost between jobs $j$ and $j+1$ as $\handofftime{j}$.\footnote{Suppose task $x$ is the final task in job $j$.For convenience, we define $\handofftime{j} := \handofftime{x}$.}
%Thus, although we use the subscript $j$ to indicate the hand-off between jobs, this cost fundamentally originates from the task itself.
When hand-off costs are non-zero, however, the firm's problem becomes nontrivial due to the tension between specializing workers to tasks (which reduces the human capital investments required per worker) and incurring more hand-off costs (which increases the total time spent per unit of production).
%The firm's objective is to minimize the following expression, which differs from equation \ref{eq:totalcost_no_handoff} only by the extra $\handofftime{j}$ term added to the time cost component of the job's wage bill:
%\begin{align}
%\label{eq:totalcost_with_handoff}
%\underset{\{\J_j\}_{j=1}^J}{min} \ 
%\text{TotalCost}(\J; \hccost{}, \timecost{}) 
%= 
%\sum_{j=1}^J \Biggl[\Biggl(v_L + \sum_{i \in \J_j} \hccost{i} \Biggr) \Biggl(\handofftime{j} + \sum_{i \in \J_j} \timecost{i} \Biggr)\Biggr].
%\end{align}
Panel B of Table~\ref{tab:job_design} shows the potential job designs of the previous example with hand-off costs specified in this table, and illustrated in Figure~\ref{fig:job_design}:
\[
\begin{array}{c|ccc}
\textbf{Task} & \hccost{i} & \timecost{i} & \handofftime{} \\ \hline
1 & 3  & 1   & 2.5 \\
2 & 1 & 2   & 0.5 \\
3 & 2   & 1.5 & 0 \\
\end{array}
\]
Notice that while the earlier optimal job design (i.e., the [1][2][3] design in Panel A) assigned a single worker to each task, after introduction of the hand-off friction in Panel B the cost-minimizing production method becomes the [1,2][3] design.
In the new optimal design, the firm minimizes its cost by bundling tasks 1 and 2 together in a single job to avoid the substantial hand-off cost between these tasks in the previously optimal [1][2][3] design.

\begin{comment}
\subsection{Geometric Representation of Cost Minimization}
The firm’s cost‐minimization problem admits a geometric interpretation as well.  
Figure~\ref{fig:job_design} represents the production process from Table~\ref{tab:job_design} as stacked rectangles of height $\hccost{i}$ and width $\timecost{i}$.
\begin{figure}[htbp]
  \begin{center}
  \caption{Geometric interpretation of job designs for the \(n=3\) tasks example} \label{fig:job_design}
  \begin{subfigure}[b]{0.93\textwidth}
    \includegraphics[width=\textwidth]{plots/combined_grid_no_handoff.png}
    \caption{Job design without hand-off costs}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.93\textwidth}
    \includegraphics[width=\textwidth]{plots/combined_grid_with_handoff.png}
    \caption{Job design with hand-off costs}
  \end{subfigure}
  \end{center}
  \footnotesize{\emph{Notes:} This figure illustrates the geometric interpretation of firm's job design problem presented in Table~\ref{tab:job_design}. Each panel visualizes the production process as a sequence of stacked rectangles, where the area of each rectangle (the bounding box around a job) represents its wage bill. Panel (a) corresponds to the scenario without hand-off costs, leading to the optimal design of [1][2][3] (top left graph). Panel (b) incorporates hand-off costs, which alters the cost structure and makes the [1,2][3] design cost minimizing (bottom left graph).}
\end{figure}
Panel (a) depicts the job design without hand‐off costs (corresponding to Panel A of Table~\ref{tab:job_design}); Panel (b) shows the same example with hand‐off costs (corresponding to Panel B).  
Visually, the firm trades off two opposing forces.
Consolidating tasks into a single job avoids boundary costs but creates inefficiencies captured by cross‐bundling areas.  
Splitting tasks into separate jobs eliminates those inefficiencies yet incurs hand‐off time costs at each job boundary.  
These boundary costs scale with the cumulative human capital of the switching worker, so the height of the pink hand‐off rectangle in Panel (b) equals the sum of human‐capital heights for that job.
By balancing these effects, the firm selects the most cost‐effective job design.  
Without hand‐off costs, the optimal arrangement is [1][2][3] (top left of Panel (a)); with hand‐offs, it shifts to [1,2][3] (bottom left of Panel (b)).  

\end{comment}


\section{AI-Assisted Task Completion}

In the previous section we considered job designs in a scenario where  tasks have fixed skill and time costs.  In this section we extend this model to allow tasks to be completed in different ways, motivated by AI-powered automation and assistance.  We first introduce a simple extension where AI assistance can be employed for individual tasks, then move on to our full model where groups of consecutive tasks can be chained together via automation.  Once our model is introduced, we provide computational methods for optimizing the choice of automation strategy and for jointly optimizing both automation and job design.

\subsection{Using AI for Individual Tasks: AI Augmentation}

We first extend our model by allowing each individual task to be performed in two distinct modes of production:
\begin{enumerate}
\item Manually, where the task is executed by a human worker without AI assistance.
\item Augmented, where the task is executed by AI, and its output is subsequently reviewed by a human.
\end{enumerate}
This choice influences the skill and time costs for a task.  The manual execution of a task $i$ requires skill cost $\humanhc{i} > 0$ and time cost $\humantime{i} > 0$.
Alternatively, if the worker opts to use AI to augment their execution of the task, they incur a potentially different time cost $\machinetime{i} > 0$ for the attempt.  For example, this could be the time required to issue a ``prompt'' to the AI and then evaluate the generated output. 
%$\timecost{e} > 0$.
Operating the AI also requires incurring one-time skill cost $\machinehc{i} > 0$ which may be different from $\humanhc{i}$.  Note that the skill and/or time cost of using AI for a task may exceed the cost of doing the task manually.

An attempt to complete a task with AI is not guaranteed to succeed. If the worker attempts to use AI for task $i$, the AI successfully completes the task with some probability $q_i$ and fails with probability $1-q_i$. 
The success probability can be viewed as $q_i=\alpha^{d_i}$ where $\alpha \in [0,1]$ is a task-independent measure of AI quality and $d_i$ is a measure of the task's completion difficulty for an AI.  Note that the more difficult a task is the less likely any AI attempt at it will be, while a higher-quality AI will be more likely to succeed at any task.

The worker learns whether the AI succeeded or failed only after evaluation of the output.
If the AI fails, the worker can provide a new prompt and evaluate its output, incurring the same time cost $\machinetime{i}$ again.
%Let $\machinetime{} = \timecost{p} + \timecost{e}$ denote the total ``management'' time cost associated with using the AI for an augmented task.
%For now, assume the worker can manage all tasks similarly by paying the task-specific management time cost.
Figure~\ref{fig:flow} illustrates this process graphically.

\begin{figure}[h!]
  \begin{center}
  \caption{Using AI to complete a task} \label{fig:flow}
\resizebox{1\textwidth}{!}{
\begin{tikzpicture}[node distance=1.8cm]

    % Task Sequence
    \node (task1) [task] {Task 1};
    \node (task2) [task, right=1.75cm of task1] {Task 2};
    \node (task3) [decision, right=1.75cm of task2] {Task 3: \\ \textbf{Can AI do this task?}};
    \node (task4) [task, right=1.75cm of task3] {Task 4};
    \node (task5) [task, right=1.75cm of task4] {Task 5};

    % AI Processes
    \node (prompt) [process, below=2.5cm of task2, xshift=-1cm] {Ask AI to do the task \\ (``prompt'')};
    \node (attempt) [process2, right=0.75cm of prompt] {AI produces an output};
    \node (evaluate) [process, right=0.75cm of attempt] {Is the work acceptable?};

    % Define a coordinate 1cm to the right of the evaluate box
    \coordinate (extendEval) at ([xshift=1cm]evaluate.east);

    % Success/Failure Nodes
    \node (yes) [smallbox, right=1cm of extendEval, yshift=1cm] {Yes};
    \node (no) [smallbox, right=1cm of extendEval, yshift=-1cm] {No};

    % Arrows
    \draw [arrow] (task1.east) -- 
    %node[midway, above] {$\humantime{} + \handofftime{}$} 
    (task2.west);
    \draw [arrow] (task2.east) -- 
    %node[midway, above] {$\humantime{} + \handofftime{}$} 
    (task3.west);
    \draw [arrow] (task3.east) -- 
    %node[midway, above] {$\humantime{} + \handofftime{}$} 
    (task4.west);
    \draw [arrow] (task4.east) -- 
    %node[midway, above] {$\humantime{} + \handofftime{}$} 
    (task5.west);
    \draw [arrow] (task3.south) to[out=-125,in=45] 
    %node[midway, above] {$\timecost{p}$} 
    (prompt.north);
    \draw [arrow] (prompt.east) -- (attempt.west);
    \draw [arrow] (attempt.east) -- (evaluate.west);
    
    % Draw extension line before branching
    \draw [arrow] (evaluate.east) -- 
    %node[midway, above] {$\timecost{e}$} 
    (extendEval);
    
    % Arrows from the extended coordinate
    \draw [arrow] (extendEval) -- node[midway, above] {$q \ \ \ $} (yes.west);
    \draw [arrow] (extendEval) -- node[midway, below] {$1-q \ \ \ \ $} (no.west);

    \draw [arrow] (yes.north) to[out=90,in=-145] 
    %node[midway, right] {$\ \ \ \ \ \handofftime{}$} 
    (task4.west);
    \draw [arrow] (no.south) to[out=-165,in=-30] (prompt.south);

\end{tikzpicture}}
   \end{center}
  \footnotesize{
  \emph{Notes:} This figure illustrates the iterative process of using AI to complete an augmented task.  
  %For simplicity, we assume that all tasks have the same human time cost, $\humantime{}$, and hand-off time requirement, $\handofftime{}$.  
  To complete Task 3, the human 
  %can either perform the task manually at a cost of $\humantime{}$, or 
  chooses to
  provide an AI prompt. 
  %at a cost of $\timecost{p}$. 
  The AI then generates an output, and the human evaluates whether it meets their needs. 
  %at a cost of $\timecost{e}$.
  If it does not (which occurs with probability $1-q$), the process repeats with a refined prompt.  
  Each iteration of prompting for task 3 requires a total time cost of $\machinetime{3}$.
  %Each iteration of prompting requires a total machine time of $\machinetime{} = \timecost{p} + \timecost{e}$.
  }
\end{figure}
Assuming that each AI attempt is independent, the expected time worker spends performing task $i$ in AI-augmented manner is
$$\machinetime{i} \Biggl( \sum_{\ell=1}^{\infty} \ell\,q_i\,(1 - q_i)^{\ell - 1} \Biggr) = \frac{\machinetime{i}}{q_i}.$$

Definitions~\ref{def:manual_task} and~\ref{def:augmented_task} formalize the two modes of performing a single task explicitly.

\begin{definition}[Manual Task]
\label{def:manual_task}
A task $i$ is said to be performed manually if it is executed entirely by a human worker without AI assistance.
The associated skill and time costs for a manual task are denoted by $(\humanhc{i}, \humantime{i})$.
\end{definition}

\begin{definition}[Augmented Task]
\label{def:augmented_task}
A task $i$ is said to be augmented if it is executed by the AI, after which its output is reviewed and approved by a human worker.
The associated skill and (expected) time costs of managing a single augmented task are denoted by $(\machinehc{i}, \frac{\machinetime{i}}{q_i})$, where $q_i \in (0,1]$ is the AI's probability of successfully completing the task.
\end{definition}

\subsubsection{Aside: Task-Level AI Exposure}

The decision whether or not to deploy the AI on an individual task depends on whether the manual cost exceeds the AI management cost.  Thinking of a single task in isolation, Observation~\ref{obs:single} provides the condition under which it is worthwhile to employ AI augmentation, in terms of the AI's success probability and management cost.

\begin{observation}[Single Task Augmentation Criterion] 
\label{obs:single}
It is less costly to augment a task $i$, rather than perform that task manually, if and only if the AI success probability $q_i$ exceeds the threshold
$$\underline{q} := \frac{\machinehc{i} \; \machinetime{i}}{\humanhc{i} \; \humantime{i}}.$$
\end{observation}
\begin{proof}
Augmentation of task $i$ is preferable to manual execution when:
$$\frac{\machinehc{i} \; \machinetime{i}}{q_i} \leq \humanhc{i} \; \humantime{i} \quad \Longleftrightarrow \quad q_i \geq \frac{\machinehc{i} \; \machinetime{i}}{\humanhc{i} \; \humantime{i}} = \underline{q}.$$
\end{proof}

This criterion has intuitive comparative statics: automation becomes more attractive when the manual execution cost is high, the management cost is low, or the AI's success probability $q_i$ is high (or equivalently, the task's completion difficulty $d_i$ is low).
One implication is that improvements in prompting and evaluation tools---thereby reducing $\machinetime{i}$---can lower the management cost and make automation more appealing, even if task difficulty remains unchanged.
Although the assumptions of independent success probabilities and constant management costs might seem strong, they are relatively mild and can be adjusted by redefining parameters if necessary (e.g., if outcomes are positively correlated, the effective success probability can be treated as lower; see Sections~\ref{sec:correlated_successes} and~\ref{sec:constant_management_costs}).

For a given AI success probability $q_i$, the expression below shows how the overall cost parameters of a task are set by the trade-off between its manual execution and AI-augmentation costs.  That is,
$$(\hccost{i}, \timecost{i}) = argmin \Bigl\{\frac{\machinehc{i} \; \machinetime{i}}{q_i},\, \humanhc{i} \; \humantime{i}\Bigr\}.$$
Geometrically, this says that each task can be represented by two distinct rectangles: one with height $\humanhc{}$ and width $\humantime{}$ and another with height $\machinehc{}$ and width $\frac{\machinetime{}}{q}$.
Whichever one of the two admits a smaller area will determine the cost characteristics of performing the task in isolation in the production process.

%manual vs AI-assisted.  This corresponds to choosing between two different $(t,c)$ pairs for the task.  Hand-off costs are not affected. Example: a condition for optimal choice between these options for a single-task job.

\subsection{AI Automation and Multi-Task Chaining}

We now consider more complex modes of AI-assisted production in which a single AI call can attempt to perform multiple tasks.  We begin by formally introducing task automation and AI chains.
\begin{definition}[Automated Task]
\label{def:automated_task}
A task is said to be automated if it is executed entirely by AI without direct human intervention, and its output is passed directly to a subsequent AI-executed task. The direct human costs (in both skill and time dimension) associated with an automated task are zero.
\end{definition}

\begin{definition}[AI Chain]
\label{def:ai_chain}
An AI (or machine) chain is a contiguous block of two or more sequential tasks executed by AI, in which all tasks but the final one are automated and the final task is augmented.
An AI chain spanning tasks $(\ell,\dots,r)$ has tasks $(\ell,\dots,r-1)$ automated and task $r$ augmented.
The skill and time costs of an AI chain are given by:
\[
\left(\machinehc{r}, \frac{\machinetime{r}}{\prod_{s=\ell}^{r} q_s}\right),
\]
where $q_s$ denotes the AI success probability for task $s$.
\end{definition}

We can think of an AI chain as a single aggregate ``meta-task" that is being delegated to an AI.  Successful completion requires that the AI complete all tasks in $(\ell, \dotsc, r)$.  The human worker who manages the AI execution of this chain need only prompt for and evaluate the goal task, $r$; all other tasks in the chain are assumed to be fully automated ``under the hood" and hence beneath the awareness of the human worker.  Managing an AI attempt at the chain therefore has the same costs as augmenting task $r$: namely, skill cost $\machinehc{r}$ and time cost (per attempt) $\machinetime{r}$.  Successful completion of the chain requires that the AI complete \emph{every} constituent task successfully.  Assuming independent failures, this occurs with probability $\prod_{s=\ell}^r q_s$, which we can view as the success probability for the aggregate chained task.  Thus, as in our single-task analysis, the total skill and time costs are as described in Definition~\ref{def:ai_chain}.

Given a collection of tasks $\T = \{1, \dotsc, n\}$, an \emph{automation strategy} is a collection $\mathcal{S}$ of disjoint AI chains.  The strategy $\S$ effectively labels all tasks as being manual, augmented, or automated.  The chains in $\S$ need not cover all tasks in $\T$; any task that does not appear in an AI chain is a manual task.  Any task that is the final task in a chain is augmented and any non-final task in an AI chain is automated.  Singleton chains are allowed, representing tasks augmented individually.

We can alternatively think of an automation strategy $\S$ as a collection of meta-tasks, one for every manual task and every chain in $\S$.  Each manual task $i$ has skill and time costs $(\humanhc{i}, \humantime{i})$, while each chain $S = (\ell, \dotsc, r)$ has skill and time costs $(\machinehc{r}, \machinetime{r}/\prod_{s=\ell}^{r}q_s)$.

\subsubsection{Example: Automation Strategies for Two Tasks}

Let us consider an example with two tasks.  In the two-tasks setting, each task can be executed according to the following constraints:
\begin{enumerate}
\item Task $1$ can be executed manually, augmented by AI, or automated by AI.
\item Task $2$, being the last task, can only be executed manually or augmented by AI, since automation requires a subsequent AI-executed task which cannot apply to Task 2.
\end{enumerate}

For notation, when a human performs the task without AI, we denote it as $\human{\cdot}$.
When an AI attempts the task, we denote it as $\machine{\cdot}$.
In the three tasks occupation example from earlier, if in the [1][2][3] design the first task is done by AI and the other two by humans without AI, we would write $\machine{1}\human{2}\human{3}$.

Denote the corresponding AI success probabilities of Task 1 and 2 with \(q_1\) and \(q_2\). 
Let $\cost{.}$ show the total cost of completing an arrangement of tasks.
With two tasks, there are four possible ``direct'' production arrangements:
\begin{align*}
    \cost{\human{1}\human{2}} &= \humanhc{1} \; \humantime{1} + \humanhc{2} \; \humantime{2} & \text{(fully human)}, \\
    \cost{\machine{1}\human{2}} &= \machinehc{1} \; \frac{\machinetime{1}}{q_1} + \humanhc{2} \; \humantime{2} & \text{(partial augmentation)}, \\
    \cost{\human{1}\machine{2}} &= \humanhc{1} \; \humantime{1} + \machinehc{2} \; \frac{\machinetime{2}}{q_2} & \text{(partial augmentation)}, \\
    \cost{\machine{1}\machine{2}} &= \machinehc{1} \; \frac{\machinetime{1}}{q_1} + \machinehc{2} \; \frac{\machinetime{2}}{q_2} & \text{(independent augmentation)}.
\end{align*}
In the arrangement $\machine{1}\human{2}$, task 1 is augmented; in $\human{1}\machine{2}$, task 2 is augmented; and in $\machine{1}\machine{2}$, both tasks 1 and 2 are augmented.  

There is also a fifth arrangement where the tasks are chained, and the (automated) first task is used as input for the (augmented) second task without human intervention.
When tasks are chained, denoted by $\machine{1|2}$, they are executed by the AI with a single prompt and final evaluation.
The AI must succeed in \emph{both} tasks for the chain to be successful in a single attempt.
The cost of this arrangement is:
\begin{align*}
\cost{\machine{1|2}} &= \machinehc{2} \; \frac{\machinetime{2}}{q_1 q_2} & \text{(chained automation)}.
\end{align*}
This captures the notion of agentic AI that can complete a sequence of tasks autonomously, without human intervention between the two tasks.
The complete cost function for this production is given by:
\begin{align}
  \min \left\{ 
  \humanhc{1} \; \humantime{1} + \humanhc{2} \; \humantime{2}, \;\; 
  \machinehc{1} \; \frac{\machinetime{1}}{q_1} + \humanhc{2} \; \humantime{2}, \;\; 
  \humanhc{1} \; \humantime{1} + \machinehc{2} \; \frac{\machinetime{2}}{q_2}, \;\; 
  \machinehc{1} \; \frac{\machinetime{1}}{q_1} + \machinehc{2} \; \frac{\machinetime{2}}{q_2}, \;\; 
  \machinehc{2} \; \frac{\machinetime{2}}{q_1 q_2}
  \right\}.
\end{align}
Note that as each term is linear in the cost parameters, the overall cost function is convex.

Figure~\ref{fig:two_tasks} shows the cost-minimizing production arrangement for different levels of \(q_1\) and \(q_2\), with time costs \(\humantime{1} = \humantime{2} = 3\) and skill costs as well as management time costs all set to 1: \(\machinetime{1} = \machinetime{2} = 1\) and \(\humanhc{1} = \humanhc{2} = \machinehc{1} = \machinehc{2} = 1\).
The figure partitions the \(q_1\) and \(q_2\) space into five regions, corresponding to the five production arrangements.
According to Observation~\ref{obs:single}, the ratio 
\[
\underline{q} := \frac{\machinehc{} \; \machinetime{}}{\humanhc{} \; \humantime{}}
\]
is the threshold for augmenting a task.
Interior to this \(\underline{q}\)-box, we strictly have human production for both tasks, or \(\human{1}\human{2}\).
Investing in \(q_1\) and \(q_2\) offers no immediate return in the \(\human{1}\human{2}\) region.
However, once either task switches augmentation, we gain from increasing AI quality further, but at a diminishing rate, so long as the other task is still done by humans.
These regions are the \(\machine{1}\human{2}\) and \(\human{1}\machine{2}\) regions.

\begin{figure}[h!]
  \caption{Cost-minimizing production arrangements with two tasks with different AI success probabilities} \label{fig:two_tasks}
  \begin{center}
  \includegraphics[width = 0.8 \textwidth]{plots/two_tasks.pdf} \\
  \end{center}
\begin{footnotesize}
  \emph{Note:} This contour plot shows the cost-minimizing production arrangement for different levels of \(q_1\) and \(q_2\).
  The regions are \(\human{1}\human{2}\) (both done fully by humans), \(\machine{1}\machine{2}\) (both done by AI with human oversight), \(\machine{1}\human{2}\) (Task 1 done by AI with human oversight, Task 2 done fully by human), \(\human{1}\machine{2}\) (Task 1 done fully by human, Task 2 done by AI with human oversight), and \(\machine{1|2}\) (both tasks done by AI, Task 1 automated and Task 2 with human oversight).
\end{footnotesize}
\end{figure}

The most interesting region is \(\machine{1|2}\).
Note that its boundaries with the partially augmented regions (i.e., \(\machine{1}\human{2}\) and \(\human{1}\machine{2}\)) are sloped, meaning that improvements in one task's AI quality can bring it into the \(\machine{1|2}\) automation chain region, without an intervening augmentation step.

This curved boundary is the reason chaining can be optimal even when humans have a comparative advantage in one of the tasks in isolation.
Proposition~\ref{proposition:interdependence} formalizes this idea, which can be shown simply with a numerical example.

\begin{proposition}[Task Interdependence] \label{proposition:interdependence}
Assume that both tasks share the same human cost parameters $(\humanhc{}, \humantime{})$, and the same machine cost parameters, $(\machinehc{}, \machinetime{})$.
A task may be optimally executed as part of a chain even if humans have a comparative advantage when performing that task in isolation.
In particular,
\[
\cost{\human{1}\machine{2}} < \cost{\machine{1}\machine{2}}
\]
does not imply
\[
\cost{\human{1}\machine{2}} < \cost{\machine{1|2}}.
\]
\end{proposition}
\begin{proof}
A single counterexample suffices to show this.
Take both human and AI skill requirements to be the same and normalized to one: \(\humanhc{} = \machinehc{} = 1\).
Consider the parameter values $q_1 = \frac{3}{5}$, $q_2 = \frac{4}{5}$, $\humantime{} = \frac{3}{2}$, and $\machinetime{} = 1$.
For task 1 in isolation, human performance is more cost-effective:
\[
\humantime{} = \frac{3}{2} < \frac{5}{3} = \frac{\machinetime{}}{q_1}.
\]
However, the chained tasks arrangement has a lower cost despite the human's comparative advantage in task 1:
\begin{align*}
    \cost{\human{1}\machine{2}} &= \; \humantime{} + \frac{\machinetime{}}{q_2} = \frac{11}{4}, \\
    \cost{\machine{1|2}} &= \frac{\machinetime{}}{q_1 q_2} = \frac{25}{12} < \frac{11}{4}.
\end{align*}
\end{proof}
%In Appendix~\ref{app:AI_capability_inv_comp_stat} we discuss the comparative statics of investment in AI capabilities.

%Tasks chaining as a model of automation. 
%Example with two tasks.  Note convexity as more tasks are chained.  This corresponds to combining a set of adjacent tasks into one meta-task with a corresponding $(t,c)$ pair.  Again, hand-off costs are not affected.


\subsection{Short-Term Optimization: Automation Design}

We now turn to the optimization problem of calculating an optimal automation strategy.  We begin with a ``short-term" optimization problem: the job design and worker wages are assumed to be fixed, so the goal is to find the choice of automation strategy for a single job that minimizes the total time cost.  This optimization problem is motivated to short-run benefits of AI: where worker skills are fixed but AI automation can still be employed to speed up tasks through some combination of augmentation and automation.  We will later consider the joint optimization of job design and automation strategy.

Since the job design is fixed, it suffices to optimize for each job separately, so from this point onward we assume that there is a single job with $n$ tasks.  It turns out that the time-optimal production strategy can be calculated via dynamic programming in $O(n^2)$ time.

\begin{proposition}
Given $n$ tasks organized into a single job, the time-optimal automation strategy can be calculated in time $O(n^2)$ via dynamic programming.    
\end{proposition}
\begin{proof}
    We first note the following recursive formulation of the optimization problem. For all $m \leq n$, let $C[m]$ denote the minimum time needed to complete a job consisting of tasks $1$ through $m$.  Note that, because of the way we defined $C[m]$, task $m$ cannot be automated in any minimum-time solution that determines $C[m]$; it can only be augmented or manual.  Note also that $C[n]$ is the time cost of the optimal solution for all tasks.
    
    We now show how to calculate $C[m]$ recursively.  As a base case we have $C[0] = 0$.  For $m \geq 1$, $C[m]$ is the lesser of
    \[ C[m-1] + \humantime{m} \]
    and
    \[ \min_{r < m} \Biggl\{ C[r] + \frac{\machinetime{m}}{\prod_{s=r+1}^m q_i} \Biggr\}.
    \]
    In other words, we either complete task $m$ manually (in which case we separately optimize over tasks $1$ through $m-1$) or we augment task $m$, and then optimize over the length of the AI chain that ends with $m$.  This could be a singleton chain with no automation (corresponding to $r = m-1$), or a longer chain that begins with task $r+1$ corresponding to a choice of $r < m-1$.  Regardless of the choice of $r$, we then separately optimize the production strategy for tasks $1$ through $r$.
    
    Using this formulation, we can calculate each $C[m]$ in time $O(m)$ by considering each potential choice of $r$.  Doing so for each $m = 1, 2, \dotsc, n$ yields the value of $C[n]$ (and corresponding automation strategy) in total time $O(n^2)$.
\end{proof}

\subsection{Job-level AI Exposure and the Fragmentation Index}

Proposition~\ref{proposition:interdependence} shows that the total exposure of a job to AI automation cannot be determined by considering task-level exposure alone. Even a task that can be completed more effectively manually than by AI could still be optimally automated by AI in order to better synergize with an aggregate automation strategy.  Whether this occurs depends on the relationship between other nearby tasks in the production process.  But how?

Intuitively, a run of consecutive tasks that an AI can perform effectively is a natural candidate for an AI chain.  Jobs that contain such runs of tasks are therefore likely to benefit most from AI automation.  On the other hand, a job for which AI-friendly tasks are separated by intermediate tasks that an AI is likely to fail is less exposed to large-scale automation, even though its task-level exposure to AI may appear high.

To make this intuition more precise, consider the special case where AI management costs are normalized: $\machinetime{i} = 1$ for all $i$.  That is, the time required to prompt and check an AI process is independent of the task being delegated to an AI tool.  Under this assumption, we will define a measure of the dispersion of AI-exposed tasks in a production process, which we refer to as the \emph{fragmentation index} of a job.  We then show that the fragmentation index of a job approximates (up to constant factors) the time cost of an optimal automation strategy for that job.  In other words, jobs for which the fragmentation index is high will tend to yield less benefit from AI automation in the short-term where worker wages and job boundaries are fixed.

To define the fragmentation index, consider a random process in which each task $i$ succeeds independently with probability $q_i$; any task that does not succeed is said to fail.  Write $F$ for the set of tasks that fail, and $\mathcal{C} = \{C_1, \dotsc, C_k\}$ for the random variable representing the collection of maximal connected components of non-failed tasks.  The weight of each $C_j \in \mathcal{C}$ is defined to be $\omega(C_j) = \min\{ 1, \sum_{i \in C_j} \humantime{i} \}$.  That is, each $C_j$ has weight $1$ unless the sum of the manual time costs for each of its tasks is less than $1$.

Given a realization of $\mathcal{C}$ and $F$, we define the realized fragmentation to be 
\[ \sum_{i \in F}\min\left\{\humantime{i}, \frac{\machinetime{i}}{q_i}\right\} + \sum_{C_j \in \mathcal{C}} \omega(C_j).\]
The \emph{fragmentation index} is defined to be the expected value of the realized fragmentation.

Intuitively, we expect the fragmentation index to be lower when highly automatable tasks (that is, those for which the AI are likely to succeed) are clustered together, since a large cluster of highly automatable tasks are more likely to realize as a single connected component when failures are realized.

We will show that the fragmentation index is within a constant factor of the cost of the optimal automation strategy for a given job's task sequence.

\begin{proposition}
\label{prop:fragmentation}
    Fix a single job with a sequence of $n$ tasks $\T = \{1, \dotsc, n\}$, each with $\machinetime{i} = 1$.  Let $FI$ denote its fragmentation index and let $OPT$ denote the minimum time cost over all automation strategies.  Then $\tfrac{1}{8}OPT \leq FI \leq \tfrac{5}{4}OPT$.
    If we further assume $\humantime{i} \geq 1$ for all $i$, then $\tfrac{1}{4}OPT \leq FI \leq \tfrac{5}{4}OPT$.
\end{proposition}

We prove Proposition~\ref{prop:fragmentation} in the Appendix.  \blcomment{TODO} The key take-away from Proposition~\ref{prop:fragmentation} is that jobs with high fragmentation index---i.e., those for which the expected number of \emph{consecutive} successful task executions by an AI is low---will tend to have higher time costs even under optimal use of AI chaining.  A key driver of efficiency gains via AI automation is therefore not simply the expected number of tasks that can be automated effectively, but the number of \emph{adjacent} tasks in the production process that have high exposure to AI.

\subsection{Long-Term Optimization: Joint Design of Jobs and Automation}

We now consider full joint optimization of job design and automation strategy, accounting for both time and skill costs of workers assigned to the resulting jobs.  In other words, the firm's goal is to choose both the set of AI chains to implement---yielding a vector of skill and time costs---along with a job design for the resulting tasks and chains.

\subsubsection{Recursive Formulation of Optimization Problem}
\label{sec:recursive_formulation}
%Finding the minimum cost arrangement of tasks and the optimal job design can be formulated as a dynamic programming problem.
Here we present a recursive formulation of the firm's cost minimization problem and in section \ref{sec:DP_approximation} propose an approach to calculate an approximation of the optimal solution via dynamic programming.

Consider an occupation with $n$ tasks $\T = \{1, 2, \ldots, n\}$.
Let $V(i)$ denote the minimum cost required to complete tasks $1$ through $i$, including hand-off costs to a subsequent worker.  Note then that $V(n)$ is the solution to the desired optimization problem, since $\handofftime{n} = 0$ by assumption.  Note also that it is implicitly assumed in the definition of $V(i)$ that it optimizes over job designs in which the final job terminates after the completion of job $i$.
%Define $V(i,j)$ as the minimum cost required to complete tasks $1$ through $i$, given exactly $j$ distinct jobs have been created so far.
%The function $V(i,j)$ includes all job hand-off costs incurred between previous jobs \emph{and} the current job $j$, which, by construction, ends precisely with task $i$.

We next introduce an auxiliary function $W(i,\; \hccost{},\; \timecost{})$.
This function denotes the minimum cost of completing tasks $1$ through $i$, as well as some additional set of tasks assigned as a single job to a worker (referred to as the ``active worker'').  It is assumed that the tasks assigned to the active worker have total time cost $\timecost{}$ and total skill cost $\hccost{}$, including any hand-off costs for the active job.  Crucially, the minimum is taken over automation strategies and job designs including those that expand the number of tasks assigned to the active worker (e.g., by assigning task $i$ to the worker).
%The function $W(i,\; \hccost{},\; \timecost{})$ includes hand-off costs between previous jobs but, unlike $V(i)$, excludes any hand-off cost associated with the current active job.
%The active worker's assigned job may contain zero or more tasks.
%, with cumulative skill and time costs given by:
%\[
%\hccost{\J} = \sum_{k \in \J} \hccost{k}, 
%\quad
%\timecost{\J} = \sum_{k \in \J} \timecost{k}.
%\]
%Note that the set $\J$ assigned to active worker $j$ is not necessarily final, as additional tasks beyond task $i$ could still be assigned to the worker in subsequent steps.
In this sense, $W(i,\; \hccost{},\; \timecost{})$ captures the minimum cost across all feasible job designs and automation strategies that may potentially expand active worker $j$'s task assignment.

%Below definition links the two cost functions $V(\cdot)$ and $W(\cdot)$.
%\begin{definition}
%\label{def:V_W}
Note that, for all $i \leq n$, we have 
\[ V(i) = W(i,\; 0,\; \handofftime{i}). \]
%\end{definition}
This is because, in $V(i)$, all job designs must end with a job that completes at task $i$ and hands off to the following worker.  
%job $j$ ends precisely with task $i$, as no further tasks are considered at this stage.
Consequently, the hand-off cost associated with task $i$ must be incurred by the final worker.
Equivalently, this can be thought of as assigning worker $j$ an additional task with zero skill requirement but a time cost equal to the hand-off cost of task $i$ right after task $i$ itself.
This scenario is represented explicitly by $W(i,\; 0,\; \handofftime{i})$.

%The solution to the firm's overall cost minimization problem is given by $V(n,\; J)$, where $J$ denotes the optimal number of jobs.
%Note that, by the definition given in \ref{sec:handoff_intro}, the last task in the production process has no hand-off costs associated with it (i.e., $\handofftime{n} = 0$).
%Thus, for the last task we trivially have $V(n, J) = W(n,\; J,\; 0,\; 0)$.
Proposition~\ref{prop:recursive_optimality} describes a recursive formulation of the function $W(i,\; \hccost{},\; \timecost{})$.

\begin{proposition}[Recursive Formulation of Job Design Problem]
\label{prop:recursive_optimality}
Define the base case for $i=0$ as:
\[
W(0,\; \hccost{},\; \timecost{}) 
= 
\left(v_L + \hccost{}\right) \timecost{}, 
\quad
\text{for all $\hccost{}, \timecost{}$}.
\]
Then, for each $i \geq 1$, the minimum cost function $W(i,\; \hccost{},\; \timecost{})$ satisfies the following recursive relation:
\begin{align*}
W(i,\; \hccost{},\; \timecost{})
= \min\Biggl\{ 
& \left(v_L + \hccost{}\right) \timecost{} \; + \; V(i), \\
& \ W(i-1,\; \hccost{} + \humanhc{i},\; \timecost{} + \humantime{i}), \\
& \ \min_{r < i} \ W\left(r,\; \hccost{} + \machinehc{i},\; \timecost{} + \frac{\machinetime{i}}{\prod_{s=r+1}^{i} q_s}\right)
\Biggr\}.
\end{align*}
The cost of the optimal job design for a given sequence of $n$ tasks is then $V(n) = W(n,\; 0,\; 0)$.
\end{proposition}

The recursive formulation in Proposition~\ref{prop:recursive_optimality} evaluates the minimum cost among three distinct alternatives at each step:
\begin{itemize}
    \item \textbf{Option (1):} The term $\left(v_L + \hccost{}\right) \timecost{} \; + \; V(i)$ corresponds to not adding any further tasks to the job of the active worker.  All tasks $1$ through $i$ will be completed by other workers. 
    The active worker's total cost is then $\left(v_L + \hccost{}\right) \timecost{}$, and $V(i)$ is the total cost of completing tasks $1$ through $i$ (including hand-off costs to the active worker).

    \item \textbf{Option (2):} The term $W(i-1,\; \hccost{} + \humanhc{i},\; \timecost{} + \humantime{i})$ corresponds to adding task $i$ to the job of the active worker $j$ for manual completion.
    In this case, the manual execution costs $(\humanhc{i}, \humantime{i})$ of task $i$ are added to the accumulated costs of tasks already assigned to the active worker, extending their job to include task $i$ as well.

    \item \textbf{Option (3):} The term $\min_{r < i} \ W\left(r,\; \hccost{} + \machinehc{i},\; \timecost{\J} + \frac{\machinetime{i}}{\prod_{s=r+1}^{i} q_s}\right)$ also corresponds to adding tasks to the active worker's job, but by having them perform task $i$ in an AI-augmented manner. 
    This way task $i$ is chained with zero or more preceding (automated) tasks, adding the associated AI management costs to the active worker's skill and time costs.  The index $r$ corresponds to the highest-index task that is not added to this AI chain, which can be any value between $0$ and $i-1$.
\end{itemize}
Note that in evaluating option (3) of the recursive step for $W(i,\; \hccost{},\; \timecost{})$, task $i$ can only be augmented (rather than automated) as each step of the recursion adds a full AI chain to an active worker's job.
Automation strategies in which task $i$ is automated are considered when performing task calculations $W(r, \hccost{}, \timecost{})$ with $r > i$.


\subsubsection{Calculating an Approximately Optimal Solution}
\label{sec:DP_approximation}
Given our recursive formulation, we wish to use dynamic programming to solve for the jointly optimal job design and automation strategy by filling in the values of $W(i,\; \hccost{},\; \timecost{})$ for all $i$, $\hccost{}$, and $\timecost{}$.  Unfortunately, $\hccost{}$ and $\timecost{}$ take on continuous values.  To make this a finite table, we will discretize all skill costs $\hccost{}$ and time costs $\timecost{}$ to appropriate powers of $(1+\epsilon)$, where $\epsilon > 0$ is an arbitrarily small error term.

Let us first determine the range of powers of $(1+\epsilon)$ that we must consider. 
Suppose that all manual and augmented skill and time costs, as well as all hand-off costs, lie in $[1/M, M]$ for some $M > 0$.  That is, these parameters require $O(\log M)$ bits to represent.  In this case, note that any subsequence of tasks could be completed at a total cost of at most $2nM^2$ by performing them all manually.  We therefore need not consider any solution containing a job with total cost greater than $2nM^2$.  In particular, since any non-zero skill cost for any job is at least $1/M$, we need not consider any joint plan in which a job has total time cost greater than $2nM^3$.  Furthermore, each job has total skill cost lying between $1/M$ and $nM$ (as skill costs combined additively) and time cost at least $1/M$ (as each AI chain's time cost is at least the management cost of its final task).

We conclude that when filling table $W(i, \hccost{}, \timecost{})$, it suffices to consider skill costs $\hccost{}$ lying in $[1/M, nM]$ and time costs $\timecost{}$ lying in $[1/M, 2nM^3]$.  There are $O(\epsilon \log(nM))$ powers of $(1+\epsilon)$ in each of these ranges, so our table will have $O(n \epsilon^2 \log^2(nM))$ total entries.  Each entry can be filled in time $O(n)$ by considering the recursive formulation in Proposition~\ref{prop:recursive_optimality}, for a total runtime of $O(n^2 \epsilon^2 \log^2(nM))$.

To bound the error introduced by this discretization, consider the recursive formulation in Proposition~\ref{prop:recursive_optimality} and suppose that $\hccost{}$ and $\timecost{}$ are rounded down to the nearest power of $(1+\epsilon)$.  Since time and skill costs are multiplied together to calculate the total cost of a proposed job, this discretization introduces a multiplicative error of at most $(1+\epsilon)^2$ into our cost calculation for the first option when minimizing in the recursive definition of $W(i, \hccost{}, \timecost{})$. For the other two options, note that we accumulate time and skill costs additively when chaining tasks together for a single worker.  As $\hccost{}$ and $\timecost{}$ are rounded to a power of $(1+\epsilon)$, adding additional (accurate) skill and time costs and subsequently rounding maintains a multiplicative error of at most $(1+\epsilon)$ on the total time and skill costs.  

We conclude that if we fill in our table for all $W(i,\; j,\; \hccost{},\; \timecost{})$ where $i \leq n$ and $\hccost{}$ and $\timecost{}$ are discretized into powers of $(1+\epsilon)$, rounding down to nearest values of $(1+\epsilon)$ on recursive calls into the table, we obtain a $(1 + O(\epsilon))$ approximation to the optimal solution.


\blcomment{Got to here}





\begin{comment}
\subsection{Two-Task Production with the Possibility of Chaining: Task Automation}
Although we will eventually consider longer sequences of tasks, most of the important points of the model can be illustrated with just two tasks.
Consider a job consisting of two sequential tasks, indexed as $1$ and $2$.
We start by formally introducing task automation and AI chains.
\begin{definition}[Automated Task]
\label{def:automated_task}
A task is said to be automated if it is executed entirely by AI without direct human intervention, and its output is passed directly to a subsequent AI-executed task.
The direct human costs (in both skill and time dimension) associated with an automated task are zero.
\end{definition}

\begin{definition}[AI Chain]
\label{def:ai_chain}
An AI (or machine) chain is a contiguous block of two or more sequential tasks executed by AI, in which all tasks but the final one are automated, and the final task is augmented.
An AI chain spanning tasks $(1,\dots,r)$ has tasks $(1,\dots,r-1)$ automated and task $r$ augmented.
The skill and time costs of an AI chain are given by:
\[
\left(\machinehc{r}, \frac{\machinetime{r}}{\prod_{s=1}^{r} q_s}\right),
\]
where $q_s$ denotes the AI success probability for task $s$.
\end{definition}

In the two-tasks setting, each task can be executed according to the following constraints:
\begin{enumerate}
\item Task $1$ can be executed manually, augmented by AI, or automated by AI.
\item Task $2$, being the last task, can only be executed manually or augmented by AI, since automation requires a subsequent AI-executed task which cannot apply to Task 2.
\end{enumerate}

For notation, when a human performs the task without AI, we denote it as $\human{\cdot}$.
When an AI attempts the task, we denote it as $\machine{\cdot}$.
In the three tasks occupation example from earlier, if in the [1][2][3] design the first task is done by AI and the other two by humans without AI, we would write $\machine{1}\human{2}\human{3}$.

Denote the corresponding AI success probabilities of Task 1 and 2 with \(q_1\) and \(q_2\). 
Let $\cost{.}$ show the total cost of completing an arrangement of tasks.
With two tasks, there are four possible ``direct'' production arrangements:
\begin{align*}
    \cost{\human{1}\human{2}} &= \humanhc{1} \; \humantime{1} + \humanhc{2} \; \humantime{2} & \text{(fully human)}, \\
    \cost{\machine{1}\human{2}} &= \machinehc{1} \; \frac{\machinetime{1}}{q_1} + \humanhc{2} \; \humantime{2} & \text{(partial augmentation)}, \\
    \cost{\human{1}\machine{2}} &= \humanhc{1} \; \humantime{1} + \machinehc{2} \; \frac{\machinetime{2}}{q_2} & \text{(partial augmentation)}, \\
    \cost{\machine{1}\machine{2}} &= \machinehc{1} \; \frac{\machinetime{1}}{q_1} + \machinehc{2} \; \frac{\machinetime{2}}{q_2} & \text{(independent augmentation)}.
\end{align*}
In the arrangement $\machine{1}\human{2}$, task 1 is augmented; in $\human{1}\machine{2}$, task 2 is augmented; and in $\machine{1}\machine{2}$, both tasks 1 and 2 are augmented.  

There is also a fifth arrangement where the tasks are chained, and the (automated) first task is used as input for the (augmented) second task without human intervention.
When tasks are chained, denoted by $\machine{1|2}$, they are executed by the AI with a single prompt and final evaluation.
The AI must succeed in \emph{both} tasks for the chain to be successful in a single attempt.
The cost of this arrangement is:
\begin{align*}
\cost{\machine{1|2}} &= \machinehc{2} \; \frac{\machinetime{2}}{q_1 q_2} & \text{(chained automation)}.
\end{align*}
This captures the notion of agentic AI that can complete a sequence of tasks autonomously, without human intervention between the two tasks.
The complete cost function for this production is given by:
\begin{align}
  \min \left\{ 
  \humanhc{1} \; \humantime{1} + \humanhc{2} \; \humantime{2}, \;\; 
  \machinehc{1} \; \frac{\machinetime{1}}{q_1} + \humanhc{2} \; \humantime{2}, \;\; 
  \humanhc{1} \; \humantime{1} + \machinehc{2} \; \frac{\machinetime{2}}{q_2}, \;\; 
  \machinehc{1} \; \frac{\machinetime{1}}{q_1} + \machinehc{2} \; \frac{\machinetime{2}}{q_2}, \;\; 
  \machinehc{2} \; \frac{\machinetime{2}}{q_1 q_2}
  \right\}.
\end{align}
Note that as each term is linear in the cost parameters, the overall cost function is convex.

\end{comment}

\begin{comment}
\subsection{Production with \(n > 2\) Tasks: Dynamic Programming}
Now consider a production process consisting of a sequence of \(n\) tasks, indexed as \(\{1, 2, \ldots, n\}\).
First, Table~\ref{tab:tree} illustrates that increasing the number of tasks from $n=2$ to $n=3$ introduces substantially more complexity in number of possible production arrangements (form 5 for $n=2$ to 13 for $n=3$).
\begin{table}
  \centering
  \caption{The possible scenarios with \(n \in \{1,2,3\}\) tasks production}
  \label{tab:tree}
  \begin{tabular}{ccc}
  \hline
  1 Task & 2 Tasks & 3 Tasks \\
  \hline
  $(1)$ & $(1)(2)$ & $(1)(2)(3)$ \\
  $\langle 1 \rangle$ & $(1)\langle 2 \rangle$ & $(1)\langle 2\rangle(3)$ \\
   & $\langle 1 \rangle(2)$ & $(1)(2)\langle 3\rangle$ \\
   & $\langle 1 \rangle\langle 2 \rangle$ & $(1)\langle 2\rangle\langle 3\rangle$ \\
   & $\langle 1|2 \rangle$ & $(1)\langle 2|3\rangle$ \\
   & & $\langle 1\rangle(2)(3)$ \\
   & & $\langle 1\rangle\langle 2\rangle(3)$ \\
   & & $\langle 1|2\rangle(3)$ \\
   & & $\langle 1\rangle(2)\langle 3\rangle$ \\
   & & $\langle 1\rangle\langle 2\rangle\langle 3\rangle$ \\
   & & $\langle 1|2\rangle\langle 3\rangle$ \\
   & & $\langle 1\rangle\langle 2|3\rangle$ \\
   & & $\langle 1|2|3\rangle$ \\
  \hline
  \end{tabular}
\end{table}
The number of valid arrangements in the general case with $n$ tasks is given by Proposition~\ref{proposition:num_arrangements}.
Specifically, the proposition shows that the number of ways to arrange \(n\) tasks is the Fibonacci number \(F(2n+1)\), where \(F(0) = 1\).
For example, when \(n=1\), there are two possibilities---either \(\human{1}\) or \(\machine{1}\)---so \(F(3) = 2\).
With two tasks, we have \(F(5) = 5\) possible arrangements; with three tasks, we have $F(7)=13$ arrangements, and so on.

\begin{proposition}[Recursion for Valid Arrangements] \label{proposition:num_arrangements}
  Let \(f(n)\) denote the number of valid arrangements of \(n\) tasks in a job, where each task can be either performed fully by a human (exactly one task per human block) or as part of a machine chain (a consecutive sequence of automated and augmented tasks). Then the following recurrence holds:
  \[
  f(n) = f(n-1) + \sum_{s=1}^{n} f(n-s),
  \]
  with the base case \(f(0) = 1\).
\end{proposition}

\begin{proof}
Consider the first block in the arrangement of \(n\) tasks:
\begin{itemize}
    \item \textbf{Case 1: Human block.} If the first task is performed fully by a human, then the remaining \((n-1)\) tasks can be arranged in any valid way. This contributes \(f(n-1)\) arrangements.
    \item \textbf{Case 2: Machine chain.} If the first block is a machine chain covering \(\ell\) tasks (\(1 \leq \ell \leq n\)), then the remaining \((n-\ell)\) tasks can be arranged in any valid way. Summing over all possible lengths of the first machine chain gives \(\sum_{s=1}^{n} f(n-s)\) arrangements.
\end{itemize}
Adding the contributions from both cases, we obtain:
\[
f(n) = f(n-1) + \sum_{s=1}^{n} f(n-s).
\]
\end{proof}
\end{comment}

\begin{comment}
\subsubsection{Recursive Cost Formulation of DP Problem}
\label{sec:recursive_formulation}
Finding the minimum cost arrangement of tasks and the optimal job design can be formulated as a dynamic programming problem.
Here we present a recursive formulation of the firm's cost minimization problem and in section \ref{sec:DP_approximation} propose an approach to calculate an approximation of the DP problem's solution.

Consider an occupation with $n$ tasks, indexed by \(i = 1, 2, \ldots, n\).
Define $V(i,j)$ as the minimum cost required to complete tasks $1$ through $i$, given exactly $j$ distinct jobs have been created so far.
The function $V(i,j)$ includes all job hand-off costs incurred between previous jobs \emph{and} the current job $j$, which, by construction, ends precisely with task $i$.

To fully characterize the DP solution, we introduce an auxiliary function $W(i,\; j,\; \hccost{\J},\; \timecost{\J})$.
This function denotes the minimum cost of completing tasks $1$ through $i$, as well as an additional set of tasks $\J$ assigned to worker $j$ (referred to as ``active worker''). 
This function $W(i,\; j,\; \hccost{\J},\; \timecost{\J})$ includes hand-off costs between previous jobs but, unlike $V(i,j)$, excludes any hand-off cost associated with the current active job.
The active worker $j$'s assigned set $\J$ may contain zero or more tasks, with cumulative skill and time costs given by:
\[
\hccost{\J} = \sum_{k \in \J} \hccost{k}, 
\quad
\timecost{\J} = \sum_{k \in \J} \timecost{k}.
\]
Note that the set $\J$ assigned to active worker $j$ is not necessarily final, as additional tasks beyond task $i$ could still be assigned to the worker in subsequent steps.
In this sense, $W(i,\; j,\; \hccost{\J},\; \timecost{\J})$ captures the minimum cost across all feasible execution plans that may potentially expand active worker $j$'s task assignment.

Below definition links the two cost functions $V(\cdot)$ and $W(\cdot)$.
\begin{definition}
\label{def:V_W}
For all $i \leq n$, we have $V(i,j) = W(i,\; j,\; 0,\; \handofftime{i})$.
\end{definition}
Definition~\ref{def:V_W} reflects the idea that, in $V(i,j)$, job $j$ ends precisely with task $i$, as no further tasks are considered at this stage.
Consequently, the hand-off cost associated with task $i$ must be incurred immediately by worker $j$.
Equivalently, this can be thought of as assigning worker $j$ an additional task with zero skill requirement but a time cost equal to the hand-off cost of task $i$ right after task $i$ itself.
This scenario is represented explicitly by $W(i,\; j,\; 0,\; \handofftime{i})$.

The solution to the firm's overall cost minimization problem is given by $V(n,\; J)$, where $J$ denotes the optimal number of jobs.
Note that, by the definition given in \ref{sec:handoff_intro}, the last task in the production process has no hand-off costs associated with it (i.e., $\handofftime{n} = 0$).
Thus, for the last task we trivially have $V(n, J) = W(n,\; J,\; 0,\; 0)$.
The optimal solution of the dynamic programming problem is characterized by the recursive formulation provided in Proposition~\ref{prop:recursive_optimality}.

\begin{proposition}[Recursive Formulation of Job Design Problem]
\label{prop:recursive_optimality}
Define the base case for $i=0$ as:
\[
W(0,\; 0,\; \hccost{\J},\; \timecost{\J}) 
= 
\left(v_L + \hccost{\J}\right) \timecost{\J}, 
\quad
\text{for all $\hccost{\J}, \timecost{\J}$}.
\]
Then, for each $i \geq 1$, the minimum cost function $W(i,\; j,\; \hccost{\J},\; \timecost{\J})$ satisfies the following recursive relation:
\begin{align*}
W(i,\; j,\; \hccost{\J},\; \timecost{\J})
= \min\Biggl\{ 
& \left(v_L + \hccost{\J}\right) \timecost{\J} \; + \; V(i,j), \\
& \ W(i-1,\; j,\; \hccost{\J} + \humanhc{i},\; \timecost{\J} + \humantime{i}), \\
& \ \min_{r \geq 1} \ W\left(i - r,\; j,\; \hccost{\J} + \machinehc{i},\; \timecost{\J} + \frac{\machinetime{i}}{\prod_{s=i-r+1}^{i} q_s}\right)
\Biggr\}.
\end{align*}
The cost of the optimal job design for a sequence of $n$ tasks is $V(n,\; J) = W(n,\; J,\; 0,\; 0)$, where $J$ is the optimally determined number of jobs.
\end{proposition}

The recursive formulation in Proposition~\ref{prop:recursive_optimality} evaluates the minimum cost among three distinct alternatives at each step:
\begin{itemize}
    \item \textbf{Option (1):} The term $\left(v_L + \hccost{\J}\right) \timecost{\J} \; + \; V(i,j)$ corresponds to terminating active worker $j$'s job at task $i$, and assigning the tasks in set $\J$ to worker $j+1$. 
    This requires worker $j$ to incur the hand-off cost of task $i$, which is captured through $V(i,j)$.

    \item \textbf{Option (2):} The term $W(i-1,\; j,\; \hccost{\J} + \humanhc{i},\; \timecost{\J} + \humantime{i})$ corresponds to assigning task $i$ to the current active worker $j$ for manual completion. 
    In this case, the manual execution costs $(\humanhc{i}, \humantime{i})$ of task $i$ are added to the accumulated costs of tasks already assigned to worker $j$, extending their job (from task $i-1$) to include task $i$ as well.

    \item \textbf{Option (3):} The term $\min_{r \geq 1} \ W\left(i - r,\; j,\; \hccost{\J} + \machinehc{i},\; \timecost{\J} + \frac{\machinetime{i}}{\prod_{s=i-r+1}^{i} q_s}\right)$ also corresponds to extending active worker $j$'s job from $i-1$ to $i$, but by having them perform task $i$ in an AI-augmented manner. 
    This way task $i$ is chained with zero or more preceding (automated) tasks, adding the associated optimal AI management costs to the active worker $j$'s task set at task $i-1$.
\end{itemize}
Note that in evaluating option (3) of the recursive step for $W(i,\; j,\; \hccost{\J},\; \timecost{\J})$, task $i$ can only be augmented (rather than automated) as there are no subsequent tasks in the sequence at that stage.
Automation of task $i$ is permissible only in cost calculations for subsequent tasks $i+1, \dots, n$.



\subsection{Approximation of the DP Problem's Solution}
\label{sec:DP_approximation}
We can solve for the optimal cost in the dynamic programming problem, filling in the values of $W(i,\; j,\; \hccost{},\; \timecost{})$ for all $i$, $\hccost{}$, and $\timecost{}$.  
To make this a finite table, we will discretize all skill costs $\hccost{}$ and time costs $\timecost{}$ to powers of $(1+\epsilon)$, where $\epsilon > 0$ is an arbitrarily small error term.
As time and skill costs are multiplied together to generate total costs, this discretization introduces a multiplicative error of at most $(1+\epsilon)^2$ into our cost calculations.

Moreover, note that we also accumulate time and skill costs additively when chaining tasks together for a single worker.  
But this results in a total multiplicative error of at most $(1+\epsilon)$ on the total time and skill costs, given that each individual time and skill cost is subject to a multiplicative rounding error up to $(1+\epsilon)$.

Thus, if we fill in our table for all $W(i,\; j,\; \hccost{},\; \timecost{})$ where $i \leq n$ and $\hccost{}$ and $\timecost{}$ are discretized into powers of $(1+\epsilon)$, ranging from the smallest individual task's time and skill costs up to the sum of the time and skill costs over all $n$ tasks (representing the worst-case accumulated cost), we obtain a $(1 + O(\epsilon))$ approximation to the optimal solution.
This computation runs in time polynomial in $n$, $\frac{1}{\epsilon}$. % and the ratio between the minimum and maximum individual task costs?
In particular, the algorithm computes solutions for:
\begin{itemize}
\item $n$ task indices (from $1$ to $n$),
\item $O(\frac{n}{\epsilon})$ discretized time buckets,
\item $O(\frac{n}{\epsilon})$ discretized skill buckets.
\end{itemize}
Multiplying these yields a total time complexity of:
\[
O\left(n \times \frac{n}{\epsilon} \times \frac{n}{\epsilon}\right) = O\left(\frac{n^3}{\epsilon^2}\right).
\]
\end{comment}




%%%%%%%%%%%%%%%% AI Advancements and Job Redesign %%%%%%%%%%%%%%%%
\section{AI Advancements and Job Redesign}
\label{sec:job_redesign}

So far, we have discussed how the firm decides to design jobs in a static environment taking task costs ($\hccost{}, \timecost{}$) as given.
In this section we discuss how the two cost components are affected following an AI shock.
An exogenous improvement in AI quality---captured by an increase in $\alpha$---potentially lowers the cost of completing task $i$ in both dimensions:\footnote{For simplicity, we abstract away from specifying how the human capital cost changes as AI improves. In our analysis the exact form of cost reductions in the human capital dimension is not important.}
\[
\widetilde{\timecost{i}}(\alpha) = min\{\humantime{}{}[i], \frac{\machinetime{}{}}{\widetilde{q_{i}}}\} \le min\{\humantime{}{}[i], \frac{\machinetime{}{}}{q_{i}}\} = \timecost{i},
\qquad
\widetilde{\hccost{i}}(\alpha) \le \hccost{i},
\]
where $\widetilde{q_{i}} := \widetilde{q_{i}}(\alpha) \geq q_{i}$ is the improved AI quality. 
We suppress the dependencies of both cost parameters on $\alpha$ for simplicity of notation but maintain the assumption that both time and human capital costs implicitly depend on the AI quality parameter.
Note that AI improvements can be disproportionate across tasks (hence, the $i$ subscript) and thus time and human capital cost savings may vary across occupation tasks.
In other words, some tasks may see large declines in time or human capital costs, while others may experience minimal (or no) cost reductions.  
%The AI improvement can also generate entirely new “oversight” tasks (e.g., prompt‐engineering, exception handling) with their own \(\bigl(\hccost{o},\,\timecost{o}\bigr)\).

We investigate AI’s impact over two horizons.
In the short run, due to frictions, AI advances drive down only the time costs of each task while the human capital costs remain fixed.
Faced with faster completion times, the firm can either plug the higher quality AI into its existing job structure to pocket the immediate time cost savings, or pay a one‐off redesign fee to reorganize tasks and fully capitalize on the new AI capabilities.

In the long run, costs in both time and human capital dimensions can flexibly adjust.
The firm essentially re-solves its job design problem specified in Equation~\ref{eq:totalcost_with_handoff} given the new cost parameters \((\widetilde{\hccost{}}, \widetilde{\timecost{}})\).


\subsection{Short Run AI Improvements}

In the short run, each task’s human‐capital requirement \(c_{i}\) is fixed at its previous level, while AI advances lower time costs from \(t_{i}\) to \(\widetilde t_{i}\).  
These lower time costs can render the existing job design \(\{\J^{(0)}\}\) suboptimal, but reorganizing tasks requires a one‐off redesign expense.  
The firm must choose between:  
\begin{enumerate}
  \item Keeping the current job design \(\{\J^{(0)}\}\) and capturing only the direct time‐cost savings, or  
  \item Paying the redesign fee to shift to the new optimal job structure \(\{\J^*\}\) and fully exploit the improved AI.
\end{enumerate}
We look at each scenario separately.

\paragraph{Scenario (1): No Job Redesign.}
Firm's gains from AI improvements at its previous job design will be:
\begin{equation}
\label{eq:no_redesign_gains}
\text{NoRedesignGains}(\J^{(0)}, \alpha)
:=
\text{TotalCost}(\J^{(0)}; \hccost{}, \timecost{}) - \text{TotalCost}(\J^{(0)}; \widetilde{\hccost{}}, \widetilde{\timecost{}}).
\end{equation}
This is the net gains \emph{only} from immediate time cost savings in the old job structure.
Note that by definition, the time cost savings is weakly greater than zero, so the firm always deploys the new technology.\footnote{None of the implications of the model will change if we assume adoption of the new technology comes at a nonzero, fixed cost.}
%Also, assuming reductions in costs in both dimensions are smooth the function above is a continuous function of $\alpha$.

\paragraph{Scenario (2): Redesigning Jobs.}
If the firm chooses to restructure jobs to the new optimal design \(\{\J^*\}\) its cost savings from this change will be:
\begin{equation}
\label{eq:job_redesign_direct_savings}
\text{DirectRedesignGains}(\J^{(0)}, \alpha)
:=
\text{TotalCost}(\J^{(0)}; \hccost{}, \timecost{}) - \text{TotalCost}(\J^{*}, \widetilde{\hccost{}}, \widetilde{\timecost{}}).
\end{equation}
This is the savings from \emph{both} exploiting the reduced time costs \emph{and} job redesign.
Reallocating tasks to new jobs is costly though.
The firm must incur two one-off costs for redesigning jobs:
\begin{enumerate}
\item A fixed cost per job definition change: each time the firm redesigns a job it must incur a fixed redesign cost $\kappa$ for that job change.
This can be interpreted as the administrative costs associated with reorganizing that job.
\item A training cost for the \emph{new} set of skills workers need in their new jobs: the firm must compensate workers for acquiring new human capital.\footnote{If a task is removed from worker's job, no transfer is made between the worker and the firm, and the worker's human capital for doing that task immediately deprecates to 0.}
\end{enumerate}
The one-time cost of redesigning jobs from $\J^{(0)}$ to $\J^{*}$ is:
\begin{equation}
\label{eq:job_redesign_cost}
\text{RedesignCosts}(\J^{(0)}, \alpha)
:=
\sum_{j=1}^{J}
\Bigl[
\underbrace{\kappa\,\mathbf1\{\J_j^*\neq\J_j^{(0)}\}}_{\text{Administrative redesign cost}}
\;+\;
\underbrace{\sum_{i\in\J_j^*\setminus\J_j^{(0)}}\hccost{i}}_{\substack{
\text{Training cost of new tasks}\\ 
\text{in the new design of job $j$}}
}
\Bigr].
\end{equation}
Notice that the redesign costs also depends on the AI quality parameter $\alpha$ since that determines the optimal job design $\J^{*}$.
Total gains from job redesign will thus be:
\begin{equation}
\label{eq:job_redesign_gain}
\text{TotalRedesignGains}(\J^{(0)}, \alpha)
:=
\text{DirectRedesignGains}(\J^{(0)}, \alpha)
\;-\;
\text{RedesignCosts}(\J^{(0)}, \alpha).
\end{equation}

Proposition~\ref{prop:shortrun_redesign} characterizes the firm’s short-run redesign decision.
\begin{proposition}[Short-Run Job Redesign Decision] 
\label{prop:shortrun_redesign}
Let $\J^{(0)}$ be the current optimal partition (which by assumption is not the plan that fully automates every task in one long chain) and let $\J^*$ be the re-optimized partition under some improved AI quality.
The firm switches from $\J^{(0)}$ to $\J^*$ in the short run if and only if:
\[
\mathrm{TotalCost}\bigl(\J^{(0)};\,\widetilde{\hccost{}},\,\widetilde{\timecost{}}\bigr)
\;-\;
\mathrm{TotalCost}\bigl(\J^*;\,\widetilde{\hccost{}},\,\widetilde{\timecost{}}\bigr)
\;\ge\;
\mathrm{RedesignCost}\bigl(\J^{(0)},\,\J^*\bigr).
\]
Furthermore, for any pre-shock design $\J^{(0)}$ (other than full automation) there exists a unique threshold $\tilde{\alpha}$ such that for all $\alpha>\tilde{\alpha}$ the above inequality holds strictly and the firm strictly prefers to redesign jobs.
\end{proposition}
See Appendix~\ref{app:shortrun_redesign_proof} for the proof.
In words, Proposition~\ref{prop:shortrun_redesign} states that so long as pure gains from redesigning jobs is larger than its costs the firm will reallocate tasks even in the short run.
Moreover, the existence of a unique AI‐quality threshold implies a tipping‐point effect: although any AI improvements will reduce production costs, it is not worthwhile to redesign jobs in the short run until AI quality exceeds a certain threshold, at which point restructuring becomes optimal. 


\subsection{Long Run AI Improvements}  

Workers can retrain (redeploy human capital) and firms freely re‐partition tasks.
The firm essentially re-solves its problem using the new time cost parameters \((\widetilde{\hccost{}}, \widetilde{\timecost{}})\), yielding a new, long-run optimal design \(\{\widetilde{\J_j}\}\).  
In the new design:
\begin{itemize}
  \item The adjusted time costs \(\widetilde{\timecost{i}}\) weakly decrease, and some tasks may drop out entirely if $\alpha$ is high enough (full automation, where either the time cost component or the human capital component of the task shrinks to 0).
  \item The hand‐off component of the wage bill,
  \[
    \sum_{j=1}^J \Bigl(v_L + \sum_{i\in\J_j}\widetilde{\hccost{i}}\Bigr)\,\widetilde{\handofftime{j}},
  \]
  potentially falls because:
  \begin{itemize}
    \item the human‐capital terms decrease; and/or
    \item \(\widetilde{\handofftime{j}}\)s decline if AI chains tasks across jobs more efficiently, or assists with hand‐offs.
  \end{itemize}
  \item New oversight tasks \(\{o\}\) enter \(\T\), redirecting effort toward exception handling and quality control. These tasks typically require less human capital \(\widetilde{\hccost{o}}\) than those they replace, lowering overall human capital requirements across the occupation.
\end{itemize}
One can imagine that the firm incurs a redesign cost similar to Equation~\ref{eq:job_redesign_cost} for the long-run redesign problem as well.

The next section introduces a general equilibrium model with many goods and provides a concrete framework to study implications of AI advances on workers.


%%%%%%%%%%%%%%%% General Equilibrium %%%%%%%%%%%%%%%%
\begin{comment}
\section{General Equilibrium}
\label{sec:GE}

\subsection{Task-Based Production}
\label{sec:prod_GE}

We now connect the model of production introduced in Section \ref{sec:taskbased_prod} into a general equilibrium framework.
Consider an economy with $K$ final goods and the same production function as discussed earlier.
A single firm produces and trades all goods under perfect competition in separate markets.
For each good $k \in \{1, 2,\ldots,K\}$, production requires completing an ordered set of tasks, denoted by:
\[
\T_k = \{1,2,\ldots,n_k\}.
\]
We refer to $\T_k$ as the production process for good $k$.
Notice that the equation above is essentially the same as Equation~\ref{eq:tasks} with the only difference being a subscript $k$ that denotes a typical final good in the $K$-good economy.

Suppose the firm breaks down the production process $\T_k$ into $J^k$ jobs, each of which consist of a contiguous block of tasks.
Let $\J_j^k$ denote the collection of tasks in job $j \in \{1, 2, \ldots, J^k\}$ in the production process of final good $k$.
With this notation, the four potential job designs in the earlier example with $n_k=3$ tasks can be expressed as:
\begin{align*}
\{[1][2][3]\}_k \Longleftrightarrow \ J^k = 3:  & \quad \J^k_1 = \{1\}, \quad \ \ \ \J^k_2 = \{2\}, \quad \ \ \J^k_3 = \{3\}, \\
\{[1,2][3]\}_k \Longleftrightarrow \ J^k = 2: & \quad \J^k_1 = \{1, 2\}, \ \ \ \J^k_2 = \{3\}, \\
\{[1][2,3]\}_k \Longleftrightarrow \ J^k = 2: & \quad \J^k_1 = \{1\}, \quad \ \ \ \J^k_2 = \{2, 3\}, \\
\{[1,2,3]\}_k \Longleftrightarrow \ J^k = 1: & \quad \J^k_1 = \{1,2,3\}.
\end{align*}

Assume that the worker employed in job $j$ produces an intermediate good $x_j^k$ and sells it to the firm in a perfectly competitive market.
The firm buys all intermediate goods $\{x_1^k, \ldots, x_{J^k}^k\}$ from workers and produces the final good $x_k$ at no additional cost using a Leontief production function:
\[
x_k(x_1^k, \ldots, x_{J^k}^k) = min\{x_1^k, \ldots, x_{J^k}^k\}.
\]
This implies that, in equilibrium, the amount of final good $x_k$ produced is the same as the amount of each intermediate good $x_j^k$ used in production of that final good.
This is merely a technical assumption reflecting the fact that to produce one unit of the final good each set of tasks in $\T_k$, across all $J^k$ jobs in sector $k$, must be performed exactly once.
For example, in the case with $n_k=3$ in equilibrium we have:
\[
x_k = x_1^k = x_2^k = x_3^k
\]
regardless of how the jobs are designed.

We also assume that tasks in $\T_k\!$ are performed in fixed proportions.
For instance, if task $m \in \T_k$ takes 30 minutes and task $n \in \T_k$ (with $m \neq n$) takes 45 minutes, then producing one unit of good $k$ requires a total of 75 minutes spent on $m$ \underline{and} $n$ as both tasks must be performed exactly once; it is not possible to perform task $m$ multiple times while performing task $n$ only once.
We formalize this assumption in Appendix~\ref{app:GE} where we explicitly characterize the equilibrium.


\subsection{Consumption} 
\label{sec:household_GE}
A representative household supplies one unit of labor inelastically and has a CES utility function over the $K$ final goods.
The household's utility is:
\[
U(x_{1}, \ldots, x_{K}) = \Bigl(\sum_{k=1}^{K} \delta_k \,x_k^{\tfrac{\sigma - 1}{\sigma}}\Bigr)^{\tfrac{\sigma}{\sigma-1}},
\quad
0 < \delta_k < 1,
\quad
\sum_{k=1}^{K} \delta_k = 1,
\quad
\sigma > 0,
\]  
where $x_k$ denotes final good $k$.
Goods are substitutes if $ \sigma > 1$, complements if $0 < \sigma < 1$, and $\sigma = 1$ corresponds to the Cobb-Douglas case.  
The household faces budget constraint:  
\[
\sum_{k=1}^K p^k \,x_k = I,
\]  
where $p^k$ is price of final good $k$ and $I$ is the total income earned from supplying labor to different jobs across all sectors.  
The income, $I$, is the total sum of earnings from producing intermediate goods, which the household takes as given when choosing how much of each final good to consume.


\subsection{Equilibrium}
\label{sec:eq_GE}
Let $k \in \{1, \cdots, K\}$ index sectors (or final goods) and $j \in \{1,\cdots, J^k \}$ index jobs within sectors.
Denote total labor employed in sector $k$ with $L_k$.
Equilibrium prices $\big\{ \big\{ w_j^k, p_j^k \big\}_{j=1}^{J^k} \big\}_{k=1}^K$ are: 
\begin{align*}
\labor{j}^k =  \handofftime{j}^k + \sum_{i \in \J_j^k} \timecost{ij}^{k},
& \qquad
w_j^k =  v_L + \sum_{i \in \J_j^k} \hccost{ij}^{k}, 
& \qquad
p_j^k = w_j^k \labor{j}^k, \\
\labor{}^k = \sum_{j=1}^{J^k} \labor{j}^k,
& \qquad
w^k = \frac{\sum_{j=1}^{J_k} w_j^k \labor{j}^k}{\sum_{j=1}^{J^k} \labor{j}^k},
& \qquad
p^k = w^k \labor{}^k,
\end{align*}
and equilibrium allocations $\big\{ x_k^*, L_k^* \big\}_{k=1}^K$ are:
\begin{align*}
x_k^* = \frac{R_k}{\sum_{\ell=1}^K \labor{}^\ell\,R_\ell},
& \qquad
L_k^* = \labor{}^k\,x_k^* = \sum_{j=1}^{J^k} \labor{j}^k\,x_k^*,
\end{align*}
where
\[
R_k = \Bigl(\frac{p^1}{p^k} \cdot \frac{\delta_k}{\delta_1}\Bigr)^{\sigma}.
\]
The model implies that the job design in production process $\T_k$ (and thus human capital and time costs of tasks) determines $p^k$ and $\labor{}^k$, thereby fully determining the consumption bundle $\{x_k^*\}$ and the labor allocations $\{L_k^*\}$ in equilibrium.
Appendix~\ref{app:GE} gives the full derivation details and further discusses comparative statics with respect to deploying AI for completing tasks (either in an augmented manner or automated manner).



\subsection{Implications of AI Advancements for Wages and Employment}

Here we briefly discuss the implications of an AI advancement on workers wages.

\subsubsection{Short Run}
[TODO: Double Check. These are the results for comparative statics, meaning that only cost changes at a time. Maybe changing multiple things at once would have different implications.]

Only task time durations fall in the short run.
If the firm does not redesign jobs wages remain unchanged as only human capital requirements of a job determines its wage.
Employment, however, will decline for some workers---those whose tasks are now completed faster than before by the help of AI.

If the firm redesigns jobs, wages and/or employment can potentially increase for some while decreasing for others.
Assuming no new tasks are created, redesigning jobs will move at least one task from one job to another.
Since wages are only determined by human capital requirements the wage of worker(s) being assigned new task(s) will increase whereas the wage of worker(s) whose task(s) are removed will fall.
While wages for some workers increases after a redesign, employment may not necessarily follow the same trend.
In particular, one can imagine a case where even despite a worker is assigned a new task in the redesigned job, the total time requirements of all their tasks still goes down.
Generally, if total time requirements of tasks within a job goes up, employment for that job will rise; otherwise, employment will fall.

If new tasks are introduced in the short run, depending on how they are allocated to jobs, wages could go up (if total human capital requirements increase) or down (if total human capital requirements decrease).
Similarly, employment could rise (if total time requirements increase) or fall (if total time requirements decrease).

\subsubsection{Long Run}  
Workers optimally invest in the updated skill set $\{\widetilde{\hccost{i}}\}$, yielding a new wage schedule. Depending on the new cost pairs $\bigl(\widetilde{\hccost{i}},\,\widetilde{\timecost{i}}\bigr)$, worker wages may rise, fall, or remain unchanged.
\end{comment}



%%%%%%%%%%%%%%%% Empirics %%%%%%%%%%%%%%%%
\section{Empirics}

We turn to the 2023 O*NET dataset to motivate the ordered-task-sequence view of jobs. 
O*NET provides a comprehensive list of U.S. occupations, each paired with a corresponding set of tasks. 
These tasks are organized into three levels, ranging from the most specific to the most general: \textit{task}, \textit{detailed work activity}, and \textit{work activity}.
To clarify these distinctions, Table \ref{tab:task_examples} provides examples of tasks at each level for the \textit{``Accountants and Auditors''} occupation. 
The table helps illustrate how tasks become broader as they move from the task level to the work activity level.
\begin{table}[htbp]
\begin{center}
\caption{Examples of Tasks, Detailed Work Activities, and Work Activities}
\label{tab:task_examples}
\resizebox{\textwidth}{!}{
\begin{tabular}{|p{0.4\textwidth}|p{0.37\textwidth}|p{0.55\textwidth}|}
\hline
\multicolumn{1}{|c|}{\textbf{Work Activity}} & \multicolumn{1}{c|}{\textbf{Detailed Work Activity}} & \multicolumn{1}{c|}{\textbf{Task}} \\ \hline
Developing Objectives and Strategies & Develop business or financial information systems. & Develop, implement, modify, and document recordkeeping and accounting systems, making use of current computer technology. \\ \hline
Processing Information & Verify accuracy of financial information. & Review taxpayer accounts, and conduct audits on-site, by correspondence, or by summoning taxpayer to office. \\ \hline
Processing Information & Verify accuracy of financial information. & Prepare, analyze, or verify annual reports, financial statements, and other records, using accepted accounting and statistical procedures to assess financial condition and facilitate financial planning. \\ \hline
Processing Information & Verify accuracy of records. & Inspect cash on hand, notes receivable and payable, negotiable securities, and canceled checks to confirm records are accurate. \\ \hline
Processing Information & Verify accuracy of records. & Examine inventory to verify journal and ledger entries. \\ \hline
\end{tabular}
}
\end{center}
\vspace{-0.15cm}
\textit{Note: This table provides a subset of tasks associated with the``Accountants and Auditors'' occupation.}
\end{table}
In the 2023 dataset, there are 748 unique occupations, 17,945 unique tasks, 2,081 unique detailed work activities, and 38 unique work activities.\footnote{Originally, the O*NET dataset included 798 unique occupations. We exclude 50 of them, all containing the word ``Teachers,'' as these occupations exhibit significant task overlap with highly similar tasks which could otherwise overrepresent the same job in the results.}

In our analysis, we focus on detailed work activities as the main task unit in an occupation. 
From here onward, when we refer to a “task” in the O*NET dataset, we are specifically referring to the detailed work activity associated with each occupation. 
With this definition, the dataset contains 15,645 unique occupation-task pairs, with the average occupation consisting of 21 tasks.

We define the task pair co-occurrence score between tasks $i$ and $j$  as:
$$C_{ij} = \frac{\text{Number of unique occupations in which both $i$ and $j$ appear}}{\text{Number of unique occupations in which at least one of $i$ or $j$ appears}}.$$
For any task pair, this measure ranges from 0 to 1, with higher values indicating a greater likelihood of the tasks appearing together in an occupation.
For task $i$, the (individual) task co-occurrence score is defined as the average of the pairwise co-occurrence scores across all its task pairs. Specifically:
$$C_{i}=\frac{1}{n-1}\sum_{j\neq i}C_{ij},$$ 
where $n$ is the number of unique tasks in the dataset.
Figure \ref{fig:task_cooc} shows the distribution of individual task co-occurrence scores. 
To check that these co-occurrences are not driven by chance, we perform a placebo test by randomly assigning tasks to occupations and plotting both the original and randomized distributions in the same graph. 
As shown in the figure, the blue distribution (original co-occurrence) has a noticeably higher mass on the right tail compared to the orange distribution (randomized co-occurrence), suggesting that a meaningful subset of tasks frequently co-occur across multiple occupations. 
This is counterbalanced by the higher mass on the left tail, indicating that some tasks tend to be specialized and appear only in a few occupations in the original dataset.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.8\textwidth]{plots/indiv_task_cooccurrence_score_histogram.png}
  \caption{Distribution of task co-occurrence scores. Higher scores indicate tasks that frequently appear together within occupations.}
  \label{fig:task_cooc}
\end{figure}

Next, we examine how co-occurring tasks are distributed across occupations. 
Figure \ref{fig:occ_cooc} displays the distribution of occupation co-occurrence scores, defined as the average pairwise co-occurrence score of the tasks that comprise each occupation.
Formally, for occupation $o$, the co-occurrence score is given by:
$$C^o=\frac{1}{|\T_o| ( |\T_o|-1)} \sum_{i\in\T_o} \sum_{j\in\T_o,j\neq i} C_{ij},$$
where $\T_o$ denotes the set of tasks in $o$. 
A higher occupation co-occurrence score suggests that the tasks within the occupation are more likely to appear in pairs with other tasks, indicating a greater likelihood of completing the occupation in “blocks” or “pairs” of tasks. 
We observe in the graph that the majority of occupations exhibit a substantial degree of co-occurrence, which is clearly not random.

% Peyman: here come up with a nice intuition about what this exactly shows. Something like: "A co-occurrence score of 0.1, for example, roughly means that 10\% of an occupation’s tasks are likely those that can be performed in pairs."

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.8\textwidth]{plots/indiv_occupation_cooccurrence_score_histogram.png}
  \caption{Distribution of occupation co-occurrence scores. Higher scores indicate occupations whose tasks frequently appear together across different occupations.}
  \label{fig:occ_cooc}
\end{figure}

Another way to evaluate how tasks are shared between occupations is to use a measure similar to task co-occurrence, but defined specifically for occupations. 
That is, instead of defining a metric at the task level and aggregating it at the occupation level, we directly define the measure at the occupation level. 
This is the approach we take next.
Let
$$S^{xy} = \frac{\text{Number of common tasks between $x$ and $y$}}{\text{Number of all unique tasks across $x$ and $y$}}$$
represent the pairwise occupation similarity score between occupations $x$ and $y$. 
The similarity score quantifies the overlap in tasks between a pair of occupations. 
As with the task-level measure, for occupation $x$, the (individual) occupation similarity score is defined as the average of the pairwise similarity scores across all occupation pairs. 
Specifically:
$$S^{x}=\frac{1}{q-1}\sum_{y\neq x}S^{xy},$$ where $q$ is the total number of unique occupations.
Figure \ref{fig:occ_similarity} shows the distribution of occupation similarity scores. 
We observe that task overlap between occupations is meaningfully different from the scenario in which tasks are randomly assigned to occupations, providing evidence in support of occupations sharing common tasks (though not necessarily in pairs, according to this measure).

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.8\textwidth]{plots/occupation_similarity_score_histogram.png}
  \caption{Distribution of occupation similarity scores. Higher scores indicate occupations whose tasks are shared across more occupations.}
  \label{fig:occ_similarity}
\end{figure}

% Peyman: The occupation similarity-weighted measure doesn't make sense, and thus I cut it from the draft. First, because we decided to remove the "Teachers" occupations which motivated the use of a weighted measure in the first place. Secondly, because the measure isn't perfect as it overweights pairs appearing in occupations with very little task overlap (b/c the small occupation overlap score is inverted). In the graph the orange bars show a higher weighted score exactly because they appear in fewer occupations which have lower task overlap.

% We also calculate the occupation-similarity-weighted task pair scores. In doing so, we weight every task pair occurrence by the inverse of pairwise occupation similarity scores for any two pair of occupations the task pair appears in. 
% Formally: 
% [To fill with a "proper" measure if decided to include it]

% \begin{figure}[htbp]
%  \centering
%  \includegraphics[width=0.8\textwidth]{plots/task_pair_weightedScore_histogram.png}
%  \caption{Distribution of occupation-similarity-weighted task pair scores for task pairs appearing in more than 10 occupations. This metric accounts for both the frequency of task co-occurrence and the similarity between occupations containing these task pairs.}
%  \label{fig:weighted_pairs}
% \end{figure}

Next, let us examine how often specific task combinations occur across different occupations. 
Figure \ref{fig:pair_counts} plots the frequency of co-occurring task pairs. 
Note that the y-axis represents the frequency on a logarithmic scale. 
In the placebo test, almost all task pairs appear in only one or two occupations, whereas in the original data, many pairs appear in multiple occupations. 
Since it is possible that a non-trivial number of pairs co-occur across different occupations due to the way O*NET defines tasks and occupations, we conservatively focus on task pairs that appear in more than 10 occupations and refer to them as “highly co-occurring” tasks.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.8\textwidth]{plots/task_pair_counts_histogram.png}
  \caption{Histogram showing the frequency of task pairs. This visualizes the raw count of how often specific task combinations occur across different occupations. Task pairs to the right of the red dashed line indicate the “highly co-occurring” subset.}
  \label{fig:pair_counts}
\end{figure}

Out of more than 100,000 co-occurring pairs, only 588 are classified as highly co-occurring tasks. 
Although this represents a small fraction of the total co-occurrences, it provides a meaningful subset for analysis.
Within this subset, we observe tasks that appear only a few times in combination with others, as well as tasks that frequently occur across multiple pairs. 
Figure \ref{fig:high_cooc_task} illustrates the distribution of task repetition counts within the highly co-occurring pairs. 
While many tasks appear only a handful of times (on the left side of the graph), some are observed as frequently as 30 or 40 times in different pairs.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.8\textwidth]{plots/highly_cooccurring_tasks_task_repetition_count.png}
  \caption{Distribution of task repetition counts within highly co-occurring tasks. The figure highlights the frequency of tasks appearing in multiple pairs.}
  \label{fig:high_cooc_task}
\end{figure}

Figure \ref{fig:high_cooc_occ} complements the previous finding by showing the distribution of how often a task pair from the same occupation appears within the subset of highly co-occurring combinations.
The more frequently an occupation’s (unique) task pairs appear in this subset, the more likely it is that the occupation consists of different “blocks” of tasks\textemdash if there are no common tasks across appearing pairs\textemdash or that there are potentially more ways to combine or automate tasks\textemdash if the appearing pairs share some tasks.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.8\textwidth]{plots/highly_cooccurring_tasks_occupation_repetition_count.png}
  \caption{Distribution of task pair occurrences within highly co-occurring combinations across occupations. The figure illustrates task pair repetition at the occupation level.}
  \label{fig:high_cooc_occ}
\end{figure}

A somewhat surprising result is that when we aggregate occupations at the two-digit SOC code level, we find that our notion of high task co-occurrence is confined to occupations within two-digit occupation groups. 
This suggests that there will be little to no spillover effects from technological impacts in one group to another.
This occurs despite the fact that these groups share a non-trivial number of tasks with one another. 
Figure \ref{fig:occ_gp_task_heatmap} presents a heatmap showing the number of shared tasks between two-digit SOC occupation groups. 
Although many pairs have zero or one shared task, we also observe a significant number of common tasks. 
However, none of these shared tasks are highly co-occurring tasks, implying that they are more specific to individual occupation groups.
Put differently, these shared tasks correspond to the very small co-occurrence scores on the left side of Figure \ref{fig:task_cooc}.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\textwidth]{plots/occupation_group_common_tasks_heatmap.png}
  \caption{Heatmap showing the number of shared tasks between two-digit SOC occupation groups. Lighter cells indicate fewer shared tasks, while darker cells represent more shared tasks. The number in each cell gives the number of shared tasks between the row and column occupation group.}
  \label{fig:occ_gp_task_heatmap}
\end{figure}



%%%%%%%%%%%%%%%% Discussion %%%%%%%%%%%%%%%%
\section{Discussion}
Below, we discuss some of the implications and features of the model. 
%\subsection{The importance of task adjacency means that automation dispersion is likely}

\subsection{How consequential is linear production?}
If two tasks can proceed in parallel, we can simply model them as having no hand-off costs, of $\handofftime{} = 0$.
It never makes sense to combine two tasks within a single job if with hand-off in between because a less expensive occupation can always be created as $(C_1 + C_2) (t_1 + t_2) > c_1 t_1 + c_2 t_2$.


A lot of multi-tasking in jobs is really more like ``async'' in programming: you get blocked on some task, so you switch to some other task in the iterim.
Despite this, production is still linear---it's just not exactly linear in time.
There are still a sequence of tasks done in order, it is just that you can pause on one for some period of time.



\subsection{YADOLM: Yet Another Division of Labor Model}
We need to get into the micro-details of the production process to understand how AI might be used and how it might change the division of labor. 
Extant models are too stylized to be paired with, say tasks-specific engineering estimates focusing on the content of the tasks.
Second, the model is not just about the division of labor but also the returns to investing in AI capabilities.

Adam Smith attributed the division of labor being limited only by the extent of the market. 
When considering the production of physical goods, this is perhaps a reasonable description. 
But for most knowledge work or complex work generally, modern authors have emphasized the costs of conveying context to some other worker.
For example, \cite{becker1992division} provides a model of the division of labor, with workers choosing to invest in task-specific human capital.
In the model, what constrains further specialization is the cost of coordination between workers, which is just assumed to grow with the size of the team.
There is no notion of the order in which tasks are done, nor some notion of an occupation per se. 

The tasks and sequences of tasks is not completely arbitrary but dictated by the physical, logical, and engineering constraints of the production process.
Some tasks do need to be done in a certain order because some workers will be working on the intermediate goods produced by others.  
Consider the paradigmatic high-skilled knowledge workers creating technology products.
A product manager has to have an idea for how to meet a customer's need. 
That need might be articulated by a customer support rep or a by an analyst pouring over feedback data, or results from a customer survey.
A product designer might need come up with with a sketch for how it might work. 
A financial analyst would model out potential revenue. 
This likely happens in concert with an engineering manager to designan engineering estimate based on preliminary designs. 
Engineer actually needs to build the product and test it.  
Legal has to sign-off and the terms-of-use need to updated.
Once built, it needs to be marketed and supported going forward.
While parallization in tasks is possible, it is constrained by some tasks needing input from other tasks being completed: customer service cannot write a support script until they know what the product is and how it works. 
Engineers can not build it until they have a design.
A designer will not to able to design until they know what problem is being solved and what constraints are being placed on the solution.
And so on.
The \cite{lazear2004balanced} model of balanced entrepreneurship makes the point that for a brand-new startup building its first product, the entrepreneur needs to be able to do everything. 

This modern process requires intense coordination and considerable social skills in a way that putting a head on a pin would not. 
\cite{deming2017growing} provides a model where workers trade with each other to complete tasks; greater social skills unlock benefits from trade in tasks.
The data is very much consistent with his view of increased need to coordinate tasks:
various teams described above might write detailed memos and spend considerable time in meetings, talking and presenting to each other to accompish these hand-offs.
A person with a keen understanding of others likely does this better. 

While the product process is not pin-like, it is also not a free-free-all or self-organized process with trade in tasks: 
each worker is paid to do their part of the process and was hired with a good understanding of the process and their role in it. 
No engineer is free to say ``What has finance done for me lately?'' and hold up a product they are directed to work on.
This is not to ignore the vast literature on incentives problems within firms or the need for coordination, but a lot of coordination has because we have designed jobs with understandable input/output relationships with other workers and peope will do what is expected of them.

\subsection{What about more complex patterns of production?}
Sometimes what triggers a task is not the completion of a previous task, but some other event. 
A customer walks into the store; a vendor calls; a machine breaks; the load of lumber arrives.
And what task is done next could depend on context. 
This could make production not a linear sequence of tasks, but a tree of tasks. 
Progress could be more like a Markov process. 
This would clearly complicate things, but without formally modeling it, it is clear that these considerations would make full automation more difficult.

\subsection{The division of labor tends to create interdependence of tasks within jobs}
Economic forces create dependencies between tasks within jobs. 
Consider pin manufacturing: each step (washing wire, spooling, straightening, cutting, grinding) serves as input to the next, with failures at any point endangering the final product. 
The limit to this division of labor is not technical but economic, as Smith noted.
These tasks could be split more finely, but the costs of switching and communication between workers would outweigh the benefits.
While specialization is primarily constrained by market size, it also faces switching and communication costs when work is handed off between workers. 
These costs create serial dependencies between tasks done with a job---the tasks that make up a job are precisely those tasks that are hard to hand-off to someone else. 
It is unclear why this would be different when we try to automate tasks with machines.


\subsection{Correlated sucessess probabilities do not change the model much} \label{sec:correlated_successes}
There is some unrealism in the model that makes the presentation simpler but elides from pracical considerations.
The model assumes that failures and sucesses are independent, when they might be correlated.
If $\rho$ is the correlation between outcomes, then the expected number of attempts is:
\begin{align}
\mathbb{E}[T] = \frac{1 - q\rho}{q(1 - \rho)} 
\end{align}
rather than $1/q$.
If outcomes are positively correlated, that makes failures more consequential, as the expected number of attempts will be higher. 
This will tend to reduce the value of automation.
But note that we could just think of that task as simply having a $q' = \frac{q(1 - \rho)}{1 - q\rho}$ success rate.
This would, of course, change the realized sequences of tasks, but as we are taking expectations, it does not change the model.

\subsection{Constant management costs do not change the model much} \label{sec:constant_management_costs}
In terms of the constant management cost assumption, we might expect that subsequent attempts are easier fix and less costly, perhaps requiring less work. 
However, this does not change the basic structure of the problem much---if we imagine that, say, costs are declining linearly in the number of tasks, say by $\gamma$ each subsequent task, then we would simply have $\machinetime{} (1-\gamma) / q$ costs instead, with the costs still proportional to $1/q$. 
But in this case, we could just treat $\machinetime{}$ as being $\machinetime{} (1-\gamma)$. 
  
\subsection{Are management costs low skill?}
Prompting and evaluation are human skills.
How high are $c_p$ and $c_e$?
One question is simply how long theose tasks take to do; other is how widely held these skills are in the population.
There is no inherent reason to think that eitehr will itself be a low-skill task.
Most of management is deciding what you want done, asking right people to do it, in a way that leads to an effective outcome, and then monitoring the process to see if it acheiving the desired goals.
  
The decision to use an AI bears similarities to the decision to delegate some task to a subordinate or team.
Doing this well requires being a judge of talent, scoping and explaining projects in ways people will understand, giving good, actionable feedback, and so on. 
And conditional upon delegation, the skill of using AI bears similarities to the management of people and teams. 
Deciding whether the output is sufficient requires judgment, whether the output is human-produced or otherwise. 
But given humans are harder to change the machines, it seems likely that AIs will continue to be modified to make it so that humans can manage them more easily. 
  
\subsection{For evaluation, is the intermediate output a search good, inspection good, or credence good?}
The costs of judging the model's output could vary widely depending on the nature of the task and the person assiged to it.
An analogy can be drawn to the process by which consumers evaluate goods. 
Search goods are trivially easy to evaluate, whereas inspection goods might have prohibitively expensive evaluation costs. 
Or, goods that are credence goods---goods that that the consumer has to take on faith work---might have de facto infinite evaluation costs.
Some goods might be inspection goods for some people and search goods for others. 
If a task requires true expertise to evaluate, the cost of evaluation might be de facto infinite.
  
\subsection{There will be efforts to lower evaluation costs}
Economics classifies goods by the evaluation costs required to assess them, with some tasks like LLM-generated ad copy requiring minimal oversight while others like surgical plans or judicial opinions demand much more rigorous evaluation.
For some tasks, the human is the final arbiter and can immediately decide if the outcome is sufficient, with no further sources needed. 
For example, a model-generated meeting agenda can be evaluated at a glance. 
Other information goods require more costly inspection, like computer code which LLMs can produce but must be tested across different inputs (though test-driven development helps systematize this verification). 
Similarly, math problems often use guess-and-verify approaches or require checking if answers are sensible, even when following standard procedures. 
While critics often point to ChatGPT's factual errors, AIs that can cite sources effectively transform these inspection goods into more easily verifiable search goods.
  
\subsection{One-off nature of AI output hampers the ability to use reviews to evaluate}
Some information goods are consumed over time, and learning about their quality might take time. 
A person might not know if they enjoyed a movie until they have actually watched it. 
For information experience goods, we tend to rely heavily on reviews. 
But this only works when many people potentially evaluate the same good. 
With generative AI, the information good is likely generated uniquely for that particular worker. 
A non-lawyer could not verify whether a commercial contract is likely to hold up to scrutiny by the courts. 
A course of advised medical treatment might be very difficult to judge by a non-expert.
This will likely limit the ability to use reviews to evaluate the quality of AI output.

\subsection{Model evaluation in a work context is an economic consideration, not a purely technical one}
Consider the task ``answer questions about the text in a document'' and whether an AI can do this task depends on the payoff to doing it correctly. 
The firm might be fine letting a machine do low-level customer service support; we might be very hesitant to let it handle queries from major institutional investors, in part because what constitutes ``good enough'' differs.
But also, the next task might be follow-questions about the state of the business that only the CFO can credibly answer.
  
  % endregion: Division of labor creates interdependence of tasks within jobs

%A key point is that even the static assignment of tasks to humans or AI depends not just on isolated comparative advantage, but on %the relationships between tasks.
\subsection{Chained tasks create systems}
Once a task is changed, it can be thought of as a new, single task.
What constitutes a ``task'' moves to higher and higher levels of abstraction: 
From ``find typos in this ad copy'' to ``create ad copy'' to ``create a marketing campaign, launch, execute and monitor performance'' to ``increase sales'' to ``run the business profitably'' to $\ldots$.  
Note that with this chaining tasks can become increasingly large and abstract as models increase, generating something that looks like an entire system and not just a task \cite{bresnahan2020artificial}.

\subsection{Chained tasks can be re-factored by machines as they see fit}
We might also imagine that once fully chained, the system is free to ``re-factor'' production within the chain---it simply takes inputs and generates outputs.
The details of how this is done is up to the model. 
In the language of our model, system-level substitution would just be characterized as long chains of task automation.

% region: Chaining tasks 
% endregion: Chaining tasksh
% region: Division of labor creates interdependence of tasks within jobs

\subsection{Ability implies judgement but lack of ability does not imply lack of judgement}
Do not deny the antecedent.
While the ability to perform a task often implies the ability to evaluate it (as performers must understand their goal), the reverse is not necessarily true---there are many cases where humans can effectively judge and direct task completion without being able to execute the task themselves. 
This is particularly relevant for highly skilled work, where the pool of qualified evaluators may be larger than those who can perform the task, and mirrors traditional management relationships where managers direct work they cannot personally execute. 
Just as a person with broken arms could still evaluate if a coffee was properly served despite being unable to serve it themselves, the key insight is that prompting and judgment capabilities can be decoupled from task execution abilities when delegating work to AI systems.

\subsection{AI systems could potentially evaluate their own outputs}
While AI systems could potentially evaluate their own outputs, this misses a key point: if an AI model could reliably improve its own evaluation process, those improvements likely would already be incorporated into the model's training and deployment.
Modern AI systems do engage in more sophisticated self-evaluation and reasoning during inference. 
However, what remains is human asking and human evaluation.
This could be entirey deskilled, reduced to cliking a button and rubber-stamp acceptence of what comes out of the model---similar to using a vending machine.
But is could also remain a highly skilled task on both ends.

\subsection{Incentives for investment}
One concern in Acemoglu model is what he calls ``so-so'' technologies that automate but show little net productivity benefit, merely displacing labor: ```Examples of so-so technologies include automated customer service, which has displaced human service representatives but is generally deemed to be low quality and thus unlikely to have generated large productivity gains.''
How likely is it that a ``so-so'' technology will emerge?
If we think of technological improvements as being endogenous, not that it only makes sense to invest in some AI technology if the firm can overshoot the break-even condition. 
Recall that the firm is indifferent to using AI when $\machinetime{} / \bar{q} = \humantime{}$. 
Let us suppose the current state of the art is such that $q_0 < \bar{q}$.
Small improvements from $q_0$ provide no value until they exceed $\bar{q}$. 
If the firm can get the AI technology up to $q^*$, and let us suppose you will sell $x$ units at the ``old'' price, 
the firm's cost-savings will $(\humantime{} - \machinetime{} / q^*) x = C_{q_0}(q^*)$, where $C$ is the one-time cost of improving the technology.

The optimal investment is thus $q^* = \sqrt{\frac{x}{|C'(q^*)|}}$.
It will only be made, however, if profitable to do so, considering the full costs of $C_{q_0}(q^*)$.
In short, if the R\&D gets done, it's likely only to be done of its important (large $x$) and if it is done, it is likely to overshoot the status quo considerably.  
It also seems likely, given that nature of AI, that once it is deployed, usage provides training data that enables continuous improvement in $q$, furthering lowering costs. 
Human workers also learn, but that human capital is not easily transferred to other workers. 


\subsection{Disappeared occupations often just assign prompting and judging tasks to customers}
Although there are advantages to thinking in terms of tasks, most labor market participants thing in terms of ``occupations.'' 
Our training and human capital acquistion is structured as occupations.
People want to know which whole occupations will disappear, and what occupations have good prospects. 
The approach gives a way to think about an occupation ``disappearing.''

In the model, an occupation only disappears when all of its task are subsumed in an automation chain.
In this case, AI, but we can think of AI as capital more generally that can be directed by humans. 
Take an job that truly disappeared: elevator operator. 
The tasks were 1) ``Announce the direction of the elevator,'' 2) ``ask people what floors they are going to'' 3) ``bring the elevator to the appropriate floors'', 4) ``open the doors'' as well as some other non-sequential tasks like inspect for defects or machine failures.  
This got turned into an automation chain where the customer was given the ``prompting'' task of selecting a floor; the evaluation task is just seeing that the elevator was the appropriate floor---an inspection good.
If it was hard to know if you had gotten the right floor, we might expect that task to still be done by humans.

Or consider retail in the past where all items were on shelves behind counters. 
The consumer would prompt the clerk to fetch items (perhaps asking for recommendations) and then the clerk would handle the merchandize. 
It was not until Piggly Wiggly allowed customers to select the merchandise directly that this task disappeared. 

\subsection{Jobs many tasks and complex dependencies are more resistant to full auomation}
Jobs with few tasks are more prone to full automation.
All else equal, a job with a single task is more prone to automation compared to one with multiple distinct tasks.
Jobs where the next task is unpredictable are more resistant to full automation.
The model highlights the benefits to combining multiple tasks into an automation ``chain.''
But if task 1 and task 2 rarely occur together, chaining them together is not likely to work well if that requires some set up.

\subsection{Generative AI might allow for a kind of pseudo-human capital acquistiion.}
Substitution to another human might require a hand-off if all the rest of the tasks still need to be done by the ``original'' human. 
But AI augmentation might allow for job re-design. 
Consider that for some occupations, there are necessary tasks such that $\humantime{}$ is essentially infinite, or so high that it would be uneconomic for that person to pursue that job because their effective efficiency wage would be lower than their next best alternative.  

Take, for example, a master carpenter versus a handyman.
There are many tasks in common between the two: driving to the job site, carrying tools, buying supplies, swinging a hammer, etc.
But what is distinguishing is that there are tasks required of the master carpenter that the handyman is incapable of performing: 
reading complex blueprints, organizing other trades, picking building code-appropriate grades of lumber and building methods.
Because they lack these skills, their carpenter wage is essentially 0, below the handman wage, and so they are a handyman.
If generative AI is inequality-reducing, this will be the mechanism: taking people that currently lack certain skills and letting them ``jump'' up. 

This framing gives an interesting characterization of the human capital acquisition process generally: 
learn skills that will lower your performance costs across tasks \emph{if} you can make the job requiring those tasks better than your best job option.
The skills you acquire needed to make that job marginal. 
For example, the task ``read an MRI scan to detect a bone fracture'' is highly remunerative but only if learned in with all the other tasks in the ``Radiologist'' task sequence.
Licensing aside---this skill alone is essentially worthless.  
With AI augmentation, the marginal blocking skill might no longer be blocking. 

However, that task has to be marginal (assuming other blocking tasks are not also automated). 
For example, identifying a bone fracture in an X-ray does not mean a person is ready to be a radiologist.
I.e., if there was only one task that precluded them from doing some occupation, then AI might allow them to do that occupation.
Allowing more people to do more tasks could have an indirect productivity effect. 
Ironically, the harder the task to perform, the more potential for AI to unlock this substitution potential, as the pool of potential prompters and judges is much larger than the pool of doers.

% \subsection{Equilibrium considerations}
% If a sector has a large increase in AI usage, labor demand will fall. 
% Let $l_j(w)$ be the labor demand for good $j$ at wage $w$ to produce 1 unit of output.
% The product market price is $p_j = w l_j(w; q_1, q_2, \dots, q_n)$.
% Let $\epsilon_j$ be the elasticity of product market demand for sector $j$, with demand curve $d_j(p_j)$.
% Total headcount is $L = d_j(p_j) l_j(w)$.
% Suppose we some AI improvement in a task $q_i$---the partial equilibrium effect on labor used in sector $j$ is
% \begin{equation}
% \frac{\partial L}{\partial q_i} 
% \;=\; 
% d_j\bigl(p_j\bigr)\;\frac{\partial l_j}{\partial q_i}\;
% \bigl(\,1 \;-\;\epsilon_j\bigr).
% \end{equation}
% giving us the familiar result that the effect on labor in that sector, the larger the more elastic the product market.
% If we consider the general equilibrium, it depends on the elasticity of the demand for labor in other sectors and how large the AI improvement is, i.e., how much does the $q_i$ task matter in other sectors.
% If the net effect is to lower total labor, this would put downward pressure on wages. 
% How large this pressure is depends in part on how substitutable labor is across various sectors.
% A decline in wages would in-turn would in turn limit the incentives to invest AI improvements, at least at the firm level.
% However, if the instead the increase in $q_i$ allows new services to be provided, this might have an offsetting effect on wages. 

% Suppose there is some AGI singularity, where all goods cost just $\machinetime{}$ to produce---the only human labor used is the management of the AI and AI is perfect.
% The demand for labor is minimal, seemingly implying low wages, but also goods are so cheap that the demand for leisure might be very high, as all product needs can be met with little income.

\subsection{Agentic AI and the Task-Based Production}
Multiple AIs working in concert, or so-called ``Agentic AI,'' has captured the imagination of researchers and practitioners alike.
The enthusiasm reflects the usefulness of the economist's task-based view of production: many goods are produced by the completion of identifiable tasks.
Furthermore, those tasks often have a recursive sub-structure, allowing them to be decomposed into smaller, simpler tasks.
Those simpler tasks might more plausibly done by AIs, particularly as model capabilities improve and the AI agent is specialized for that task. 
Adam Smith and Henry Ford would both see the point immediately. 

% But even with powerful AI models, in designing AI agents for work, specialization is not just for humans.
% The ``agentic'' of agentic AI captures the notion that an AI working on a particular task should be specialized for that task: 
% The agent should have the resources, knowledge, and capabilities needed for that task and that task alone.
% It will need inputs from other agents and will pass off completed tasks to other agents.
% While engineers might cast this as simply reflecting good software engineering principles---separation of concerns, modularity, clean interfaces between sub-components---it also describes an effective production process in general.
% In short, enthusiasm for Agentic AI is partially enthusiasm for the division of labor---old wine in new bottles.

A natural question, of course, is how far might Agentic AI go?
This is difficult to answer credibly, as technological progress in AI is happening quickly and the answer depends on entrepreneurial activity we cannot hope to fully anticipate.
Predictions based on task content seem inherently difficult; as a close analogy, our failure to predict the extent of offshoring---arguably a far simpler forecasting problem---should be humbling \citep{ozimek2019overboard}.
Even at present, we see AI models that can do super-human work in some domains, but then make childish mistakes in others, with no obvious or unifying point of view that could explain the gaps \citep{vafa2024large}.
This incoherence makes the standard economist trick with new technology---treat it as a fall in the cost of ``X'' where ``X'' is, say, prediction, rote computation, light, or locomotive force---difficult to apply.

Although we cannot credibly claim to know what AIs can or will do, we can describe in general terms how they are---and likely will be---used in production.
Stepping back, the distinctive feature of generative AI is in the name: it generates---writing, code, images, music, and videos---in response to human requests, or ``prompts.''
But these model generations only become (potentially) economically valuable when humans judge these model outputs as suitable for their needs.
If the model outputs are generally poor or too unreliable for a given application, the human might eschew AI and do the task themselves; if the model outputs are good enough, the human role might simpy be juding the output and giving feedback to the AI as needed (with less capable AIs requiring more human supervision).

The key question---should an AI do a task instead of a human, given the costs and benefits?---is not a technical question, but an economic one.
It is also both a practical question and a research question: practitioners want to know how to efficiently redesign the productive process; researchers want to know what this transformation implies for the economy and the labor market.
Policy makers in particular are interested in whether technology can be guided to be more complementary to human labor rather than displacing it \citep{acemoglu2018automation}.

Answering these questions about AI and human labor requires a model of the productive process.
Although much progress can be made using our standad tools (see \citep{korinek2018artificial}), \cite{acemoglu2024task} argues persuasively that the standard production function approach (i.e., $Y = F(K, L)$) is not adequate for understanding the impact of technology on labor markets, and that instead a task-based approach is needed \citep{aghion2024ai}.

The task-based approach dispenses with a single aggregate production function to instead modeling the productive process in terms of tasks which can be assigned to humans or machines---and perhaps humans of different skill-levels.
The equilibrium is then some allocation of tasks to different factors of production, based on which factor has the comparative advantage in that task.
Despite the greater granularity, the task-based approach does not directly consider the interdependence of tasks in the productive process: it does not matter in the model where a task ``sits'' within some occupation or process. 
This is a useful simplification, but actual production involves the output of a completed task often being used as input to the next task.
A natural question is whether this interdependence of tasks matters for the factor assignment question in the case of AI? 



%%%%%%%%%%%%%%%% Conclusion %%%%%%%%%%%%%%%%
\section{Conclusion}

For those interested in AI that complements human capabilities---there are some direct ones complemented in this framework: asking and judging.
But it also suggests asking and judging has particularly high value when it bookends long sequences of AI-chained tasks.
Asking a model to proofread a memo for typos is not particularly high value;
asking a model to do foundational and autonomous research on drug discovery by pointing it in a promising direction could be enormously valuable on the margin if that skill itself is rare.
In other domains, this same phenomenon might benefit less-skilled workers where actually doing the task is the bottleneck.
This seems to be the case in \cite{brynjolfsson2023generative}, for example.
  
When we think of AI model improvements, some of it clearly the raw capabilities on, say, performance benchmarks. 
But it is also about improving the AI's ability to interact with the world. 
An AI that can control a computer GUI built for humans can do a lot more things in a world of remote work.
When we think of the tasks an AI can potentially do, we should be thinking not just in terms of raw model capabilities but also its ability to interact with the rest of the world.

Job redesign will take advantage of the fact that skills in judging output are separate from the skill of creating some output.
There are food critics who cannot cook; record producers who cannot play instruments; technologists who cannot program, and so on.
As AI makes it so that humans no longer have to do every task in a job, AI might open up jobs to people who are otherwise blocked by a skill they lack.

\bibliographystyle{aer}
\bibliography{rubin}

\newpage
\appendix
\section*{Appendix}


%%%%%%%%%%%%%%%% Comparative Statics of Investment in AI Capabilities %%%%%%%%%%%%%%%%
\section{Comparative Statics of Investment in AI Capabilities}
\label{app:AI_capability_inv_comp_stat}
The returns to investment in AI for a particular task are affected by AI capabilities in other tasks.
Before a task is automated, there is no return to investment in an AI that does that task.
Once a task is automated, there are returns to investment in a task, but these are unaffected by the other task's AI capabilities.
Once we move into the \(\machine{1|2}\) region, the returns to investment in one task are affected by the other task's AI capabilities.
The cost reduction gets steeper immediately when switching into the \(\machine{1|2}\) region but then flattens out, as the second derivative of the cost function with respect to \(q_i\) is positive.
These properties are formalized in Proposition~\ref{prop:comparative_statics}.

\begin{proposition}[Comparative Statics] \label{prop:comparative_statics}
  The effect of improving AI capabilities has the following properties:
  \begin{enumerate}
  \item In human-only production, improvements in AI have no effect on costs:
  \[
  \frac{\partial \cost{\human{1}\human{2}}}{\partial q_i} = 0 \quad \text{for } i \in \{1,2\}.
  \]
  \item In independent AI production, improvements reduce costs independently:
  \[
  \frac{\partial \cost{\machine{1}\machine{2}}}{\partial q_i} = -\frac{\machinetime{}}{q_i^2}, \quad \frac{\partial^2 \cost{\machine{1}\machine{2}}}{\partial q_1 \partial q_2} = 0.
  \]
  \item In mixed production, only improvements in the specific task matter:
  \[
  \frac{\partial \cost{\machine{1}\human{2}}}{\partial q_1} = -\frac{\machinetime{}}{q_1^2}, \quad \frac{\partial \cost{\machine{1}\human{2}}}{\partial q_2} = 0.
  \]
  \item In chained production, improvements are complementary:
  \[
  \frac{\partial \cost{\machine{1|2}}}{\partial q_i} = -\frac{\machinetime{}}{q_i^2 q_j}, \quad \frac{\partial^2 \cost{\machine{1|2}}}{\partial q_1 \partial q_2} = \frac{\machinetime{}}{q_1^2 q_2^2} > 0,
  \]
  where \(j \neq i\).
  \end{enumerate}

  In chained production, improvements in AI capabilities eventually flatten out, as the second derivative of the cost function with respect to \(q_i\) is positive.
  \begin{equation}
      \frac{\partial^2}{\partial q_1 \partial q_2} \cost{\machine{1|2}} = \frac{\machinetime{}}{q_1^2 q_2^2} > 0.
  \end{equation}

\end{proposition}
 
We will later consider the more general \(n\) task case, but note that immediate adjacency is not required for a task where humans have a comparative advantage to be pulled into a chain.
Consider a scenario with \(n\) tasks, each with the same success probability \(q\) and the same \(\machinetime{}\) and \(\humantime{}\).
To start, assume all tasks are done by humans and that chaining is more cost-efficient than separate automation, implying that:
\[
n\, \humantime{} < \frac{\machinetime{}}{q^n}.
\]
Now suppose we can increase the \(q\) of the first task by \(\delta q\). 
All tasks will be done by machine, in one chain, if it is possible to have:
\begin{align}
  \delta > \frac{\machinetime{}}{n\, \humantime{}{}\, q^{n}} - 1.
\end{align} 


\subsection{Optimal investment paths in the two-task case}
A natural question is how firms or a social planner should allocate R\&D effort to improve AI capabilities.
In the two task case, rather than taking \(q_1\) and \(q_2\) as given, we can consider the optimal investment paths, or allocation of R\&D effort.
Suppose we can improve \(q_1\) and \(q_2\) at a rate \(r\) per unit of time.
If we have \(T\) periods, then 
\[
\begin{aligned}
\text{Choose } &q_1(\cdot), \; q_2(\cdot) \quad \text{for } t \in [0, T],\\[1em]
\text{to minimize } &
   \int_{0}^{T}
   e^{-\rho t} \, C\bigl(q_1(t), q_2(t)\bigr) \, dt, \\[1em]
\text{subject to:} & \\[-1em]
&(1)\quad q_1(0) = q_{1,0}, \quad q_2(0) = q_{2,0}, \\[6pt]
&(2)\quad q_1'(t) + q_2'(t) \le r, \quad \text{for almost all } t \in [0, T], \\[6pt]
&(3)\quad q_1(t) \geq 0, \quad q_2(t) \geq 0, \quad \forall t \in [0, T]. \\[6pt]
\end{aligned}
\label{eq:dp_problem}
\]
where \(q_{1,0}\) and \(q_{2,0}\) are the initial AI capabilities in the two tasks.
The properties of the optimal paths for this dynamic programming problem are analyzed in detail in Appendix~\ref{app:dp_proof}. 
There, we outline the structure of the solution, provide comparative statics, and derive the necessary conditions for optimality.

Figure~\ref{fig:optimal_paths} shows numerical optimal investment paths to minimize total costs using the same parameters as in Figure~\ref{fig:two_tasks}.
We also set the discount rate \(\rho = 0\) and the total amount of R\&D resources per period to \(r = 1\).
We discretized the \(q_1\) and \(q_2\) space into a grid (so investments had to be made each period on one task or the other) and then used dynamic programming to find the optimal path.
Paths for a few select initial conditions are shown on the graph.

\begin{figure}
  \begin{center}
  \caption{Optimal investment paths to minimize costs} \label{fig:optimal_paths}
  \includegraphics[width = 0.8 \textwidth]{plots/optimal_paths.pdf}
  \end{center}
  \begin{footnotesize}
  \emph{Note:} This plot shows the optimal investment paths to minimize costs, using the same parameters as in Figure~\ref{fig:two_tasks}, with a number of different initial conditions.
\end{footnotesize}
\end{figure}

We can see that the optimal path features a ``turnpike'' component, where we move toward the 45-degree line and then make equal investments in $q_1$ and $q_2$.
However, it does not typically go there directly; if already in a semi-automated region, it will increase capabilities in that task for some time, taking advantage of the relatively steep slope.
In the $\machine{1|2}$ region, the optimal path is to move directly toward the 45-degree line, and then continue along it.

\subsection{Investment horizon effects}
The investment horizon can have important effects on the optimal path.
Figure~\ref{fig:horizon_effects} illustrates this by choosing about the same starting positions, but varying the number of steps \(T\) in the dynamic program.
As in Figure~\ref{fig:optimal_paths}, a dynamic program is used to find the optimal path that minimizes costs.

We can see that time horizons can create fundamental differences in the optimal path.
With a relatively short horizon, the optimal path is simply to keep investing in the already-automated task.
The reason is that with this horizon, we never get to the \(\machine{1|2}\) region.
With a slightly longer horizon, we just keep going farther in \(q_1\), neglecting \(q_2\) altogether.
With a long-enough horizon, however, it is beneficial to actually stop improving \(q_1\) and begin investing in \(q_2\).
This is despite the fact that improving \(q_2\) offers no direct benefits at the $\machine{1}\human{2}$ region.
However, it is worth it because it gets us to the \(\machine{1|2}\) region.
We then make a beeline for the 45 degree line, at which point we then make equal investments in \(q_1\) and \(q_2\).

\begin{figure}
  \begin{center}
  \caption{Horizon effects} \label{fig:horizon_effects}
  \includegraphics[width = 0.8 \textwidth]{plots/horizon_effects.pdf}
  \end{center}
\end{figure}




\subsection{Powerful AI means powerful prompts}
There are good reasons to think that handoff costs are similar to prompting and evaluation costs.
AI, no matter how good, is not a mind-reader; neither are your coworkers.
Consider the AI system as a function:
\begin{align}
f : \mathcal{P} \longrightarrow \mathcal{O},
\end{align}
where \(\mathcal{P}\) is the set of all possible prompts (inputs), and \(\mathcal{O}\) is the set of all possible outputs the AI can produce.
If the AI is powerful enough to generate a large range of outputs \(\mathcal{O}\), ensuring that every desired output can be uniquely generated requires (at minimum) a surjective mapping:
\begin{align}
\forall o \in \mathcal{O}, \; \exists p \in \mathcal{P} \; \text{such that} \; f(p) = o.
\end{align}
If we require that each output is generated by exactly one unique prompt, then \(f\) must be a bijection, and:
\begin{align}
|\mathcal{P}| = |\mathcal{O}|.
\end{align}
In other words, the cardinality of the prompt space must match or exceed the cardinality of the output space.

Using an information-theoretic perspective, if the AI can reliably produce \(N\) distinct outputs, it effectively has to “choose” among \(N\) possibilities. 
To specify which of those \(N\) outputs is desired, the prompt must carry at least:
\begin{align}
\log_2(N) \quad \text{bits of information.}
\end{align}
As \(N\) (the size of the AI's output repertoire) grows, the information capacity of the prompt must also grow proportionally.
To summarize, as the AI’s capacity expands, the size of the output space \(|\mathcal{O}|\) increases, and so must the size of the prompt space \(|\mathcal{P}|\) to allow precise mapping from inputs to outputs:
\begin{align}
|\mathcal{P}| \geq |\mathcal{O}|.
\end{align}
This means that increasingly powerful AI systems require increasingly sophisticated prompts to uniquely and effectively specify desired outputs.




%%%%%%%%%%%%%%%% Short Run Job Redesign Proof %%%%%%%%%%%%%%%%
\section{Proof of Proposition~\ref{prop:shortrun_redesign}}
\label{app:shortrun_redesign_proof}

In this Appendix we provide the proof of Proposition~\ref{prop:shortrun_redesign}.

\begin{proof}
Define
\[
\Delta\mathrm{Gain}(\J^{(0)}, \alpha)
:=
\mathrm{TotalRedesignGains}(\J^{(0)}, \alpha)\;-\;\text{NoRedesignGains}(\J^{(0)}, \alpha),
\]
the extra payoff from redesign versus pure time‐savings under the advanced AI.  
By construction the firm redesigns exactly when $\Delta\mathrm{Gain}(\alpha)\ge0$.  
Using the definition of each term from Equation~\ref{eq:job_redesign_direct_savings} and~\ref{eq:job_redesign_gain}, the firm redesigns jobs when:
\begin{align*}
\Delta\text{Gain}(\J^{(0)}, \alpha)
& =
\text{TotalCost}(\J^{(0)}; \hccost{}, \timecost{}) - \text{TotalCost}(\J^{*}, \widetilde{\hccost{}}, \widetilde{\timecost{}})
-
\text{RedesignCosts}(\J^{(0)}, \J^{*}) \nonumber \\
& \quad -
\Bigl[\text{TotalCost}(\J^{(0)}; \hccost{}, \timecost{}) - \text{TotalCost}(\J^{(0)}; \widetilde{\hccost{}}, \widetilde{\timecost{}})\Bigr] \nonumber \\
& =
\text{TotalCost}(\J^{(0)}; \widetilde{\hccost{}}, \widetilde{\timecost{}})
- 
\text{TotalCost}(\J^{*}, \widetilde{\hccost{}}, \widetilde{\timecost{}})
-
\text{RedesignCosts}(\J^{(0)}, \J^{*}) \nonumber \\
& \geq 0, \nonumber
\end{align*}
which establishes the first claim.

For the threshold argument, fix $\alpha_0$ such that $\J^{(0)}$ is optimal at $\alpha_0$.
For any partition $\J$ define
\[
C_{\J}(\alpha)
:=
\mathrm{TotalCost}\bigl(\J; \widetilde{\hccost{}}(\alpha), \widetilde{\timecost{}}(\alpha)\bigr).
\]
Since $\widetilde t_{ij}(\alpha)$ and $\widetilde c_{ij}(\alpha)$ are weakly decreasing and continuous in~$\alpha$, each $C_{\J}(\alpha)$ is also weakly decreasing and continuous.
Let
\[
D(\alpha)
:=
\bigl[C_{\J^{(0)}}(\alpha)-C_{\J^*}(\alpha)\bigr]
\;-\;
\mathrm{RedesignCost}.
\]
Because $\J^{(0)}$ is optimal at $\alpha_0$, $D(\alpha_0)\le0$.  
By assumption there exists $\alpha_1>\alpha_0$ for which $D(\alpha_1)>0$ and the firm redesigns jobs to some $\J^{*} \neq \J^{(0)}$.  
\footnote{This argument requires that as $\alpha$ increases some optimal $\J^{*} \neq \J^{(0)}$ exists.
This requirement rules out the fully-automated plan in which an exceptionally efficient AI does all the tasks in one long automated chain: if we start with the fully-automated plan no matter how much we improve the AI quality, no other job structure will become optimal.}
Continuity of $D$ on $[\alpha_0,\alpha_1]$ implies, via the Intermediate Value Theorem, a unique $\tilde\alpha\in(\alpha_0,\alpha_1)$ with $D(\tilde\alpha)=0$.  
Moreover, since $D(\alpha)$ is strictly increasing whenever $C_{\J^{(0)}}-C_{\J^*}$ strictly increases, $\tilde\alpha$ is the unique AI‐quality threshold above which the firm strictly prefers redesign.
\end{proof}



\begin{comment}
%%%%%%%%%%%%%%%% Equilibrium in the Task-Based Economy %%%%%%%%%%%%%%%%
\section{Equilibrium in the Task-Based Economy}
\label{app:GE}

In this appendix, we obtain equilibrium prices and allocations for the model specified in Section~\ref{sec:GE}.


\paragraph{Goods Prices.}  
In each sector, a worker employed in job $j$ produces an intermediate good $x_j$, which is sold back to the firm in a competitive market.  
Let $\labor{j}$ denote the amount of labor per unit of good $x_j$ employed in job $j$.
That is:  
\[
\labor{j} = \handofftime{j} + \sum_{i \in \J_j} \timecost{ij}.
\]  
The production cost per unit of $x_j$ can thus be written as:  
\[
\text{WageBill}_j = \Biggl(v_L + \sum_{i \in \J_j} \hccost{ij} \Biggr) \Biggl(\handofftime{j} + \sum_{i \in \J_j} \timecost{ij} \Biggr) = w_j \,\labor{j},
\]  
with $w_j$ being the wage rate for job $j$.
Markets are perfectly competitive, therefore the price of intermediate good $j$, $p_j$, equals the marginal cost of its production $w_j\,\labor{j}$:
\[
p_j = w_j \labor{j}.
\]  
Furthermore, given the Leontief production function, perfect competition in the final good market implies that the price of final good, $p$, equals the sum of the prices of its constituent intermediate goods:
\[
p = \sum_{j=1}^J p_j = \sum_{j=1}^J w_j \labor{j}.
\]  
To maintain consistency in notation between the final and intermediate goods markets, define  
\[
w \, \labor{} \equiv \sum_{j=1}^J w_j \labor{j},
\]
so that $p = w \, \labor{}$.  
If we let $\labor{}$ be the total amount of time (or labor) spent producing the final good, i.e.,
\[
\labor{} = \sum_{j=1}^J \labor{j},
\]
then $w$ can be interpreted as the weighted average wage rate of the entire sector:
\[
w = \frac{\sum_{j=1}^J w_j \labor{j}}{\sum_{j=1}^J \labor{j}}.
\]

We must mention that once $\labor{}$ is determined all $\labor{j}$s (for $j \in \{1,\ldots,J\}$) are pinned down.
This is due to the assumption earlier that tasks are done in fixed proportions.
Formally, the fixed proportions assumption implies that for some $\gamma_j > 0$ we have:  
\[
\frac{\labor{j}}{\labor{1}} = \gamma_j,
\]  
with $\gamma_1 = 1$.  
Using the definition of $\labor{}$ we get: 
\[
\labor{} = \sum_{j=1}^J \labor{1} \Bigl(\frac{\labor{j}}{\labor{1}} \Bigr) = \labor{1} \sum_{j=1}^J \gamma_j 
\quad 
\Longrightarrow
\quad 
\frac{\labor{}}{\labor{1}} = \sum_{j=1}^J \gamma_j,
\]  
and thus:  
\[
\labor{j} = \Bigg( \frac{\gamma_j}{\sum_{j=1}^J \gamma_j} \Bigg) \labor{}.
\]  
Therefore, it is without loss to focus our attention on working with $\labor{}$, because once that is determined, the labor for each subsequent job is specified.


\paragraph{Labor Market Clearing.}  
Since the household supplies one unit of labor inelastically to all jobs across all sectors, the market clearing condition satisfies:  
\[
\sum_{k=1}^K \Biggl( \sum_{j=1}^{J_k} \labor{j}^k\,x_j^k \Biggr) = 1.
\]  
Given the Leontief production, this can be expressed as:  
\[
\sum_{k=1}^K \Biggl( \sum_{j=1}^{J_k} \labor{j}^k \Biggr) x_k = \sum_{k=1}^K \labor{}^k x_k = 1,
\]  
With this, we can rewrite the household's earned income as:  
\[
I = \sum_{k=1}^{K} \Bigg( \sum_{j=1}^{J_k} w_j^k \labor{j}^k \Bigg) x_k 
= v_L + \Bigg[ \sum_{k=1}^{K} \Bigg( \sum_{j=1}^{J_k} \bigg( \sum_{i \in \J_j} \hccost{ij}^k \bigg) \labor{j}^k \Bigg) x_k \Bigg],
\]  
implying that the household budget consists of two parts: a part that compensates the worker for his foregone leisure and a part that rewards him for the human capital he has acquired.


\paragraph{Sectoral Employment and Equilibrium Allocations.}
The consumer chooses $\{x_k\}$ to maximize
\[
U(x_1,\dots,x_K) = \Bigl(\sum_{k=1}^K \delta_k \,x_k^{\tfrac{\sigma-1}{\sigma}}\Bigr)^{\tfrac{\sigma}{\sigma-1}},
\]
subject to
\[
\sum_{k=1}^K p^k\, x_k = I.
\]
By the standard first-order conditions, the ratio of marginal utilities equals the ratio of prices:
\[
\frac{\partial U/\partial x_f}{\partial U/\partial x_g} = \frac{p^f}{p^g} \quad \forall f,g.
\]
From CES properties, we obtain
\[
\left(\frac{x_f}{x_g}\right)^{-\tfrac{1}{\sigma}} = \frac{p^f}{p^g}\,\cdot\,\frac{\delta_g}{\delta_f},
\quad
\Longrightarrow
\quad
\frac{x_f}{x_g} = \left(\frac{p^g}{p^f}\,\cdot\,\frac{\delta_f}{\delta_g}\right)^{\sigma}.
\]
Define
\[
R_f = \frac{x_f}{x_1} = \Bigl(\frac{p^1}{p^f} \cdot \frac{\delta_f}{\delta_1}\Bigr)^{\sigma},
\]
with $R_1 = 1$.
Substitute $x_f = R_f\,x_1$ into the labor market clearing condition $\sum_{k=1}^K \labor{}^k\, x_k = 1$:
\[
\sum_{k=1}^K \labor{}^k\,(R_k\,x_1) = x_1\Bigl[\sum_{k=1}^K \labor{}^k\,R_k\Bigr] = 1,
\]
which yields
\[
x_1^* = \frac{1}{\sum_{k=1}^K \labor{}^k\,R_k},
\quad
x_f^* = R_f\,x_1^* = \frac{R_f}{\sum_{k=1}^K \labor{}^k\,R_k}.
\]

Labor used in sector $k$ is given by $L_k^* = \labor{}^k\,x_k^*$.
Thus, the equilibrium can be summarized as
\begin{align*}
w_j^k = \Biggl(v_L + \sum_{i \in \J_j^k} \hccost{ij}^{k}\Biggr), 
& \qquad
\labor{j}^k = \Biggl(\handofftime{j}^k + \sum_{i \in \J_j^k} \timecost{ij}^{k}\Biggr), \\
p_j^k = w_j^k \labor{j}^k,
& \qquad
p^k = w^k \labor{}^k = \sum_{j=1}^{J_k} w_j^k \labor{j}^k, \\
x_k^* = \frac{R_k}{\sum_{\ell=1}^K \labor{}^\ell\,R_\ell},
& \qquad
L_k^* = \labor{}^k\,x_k^* = \sum_{j=1}^{J_k} \labor{j}^k\,x_k^*,
\end{align*}
where
\[
R_k = \Bigl(\frac{p^1}{p^k} \cdot \frac{\delta_k}{\delta_1}\Bigr)^{\sigma}.
\]
In this way, the job design of the production process $\T_k$ (and thus the corresponding $\hccost{ij}^k$s and $\timecost{ij}^k$s) determines $p^k$, which then determines the consumption bundle $\{x_k^*\}$ and the labor allocations $\{L_k^*\}$.


\subsection{Comparative Statics with Respect to Improved AI Quality}

Suppose AI affects a subset $\mathcal{A}_1 \subseteq \T_1$ of tasks in good~1’s production process.  
This reduces the wage bill for good $1$:
\[
\sum_{j=1}^{J_1} \Biggl( v_L + \sum_{i \in \J_j^1} \hccost{ij}^{1} \Biggr) \labor{j}^1,
\]
which in turn lowers $p^1$, while potentially also altering the job design.  
The following comparative statics apply.

\paragraph{Price Effects.}
Only $p^1 = w^1 \labor{}^1$ falls; the prices $p^f$ for $f\neq 1$ remain unchanged (unless tasks in those sectors are also automated).

\paragraph{Effects on Consumption.}
We find
\[
\frac{\partial x_{1}^*}{\partial p^1}
=
-\,
\frac{\,p^1 \;+\;\sigma\,\bigl(\sum_{k\neq 1}\labor{}^kR_{k}\bigr)\,}{
       p^1\,\Bigl(\sum_{k}\labor{}^kR_{k}\Bigr)^{2}}
<0,
\qquad
\frac{\partial x_{f}^*}{\partial p^1}
=
(\sigma-1)
\,\frac{\,R_{f}\,}{\Bigl(\sum_{k}\labor{}^kR_{k}\Bigr)^{2}}
\quad (\text{for } f\neq 1).
\]
Hence, when $p^1$ decreases (i.e., when automation makes good~1 cheaper), $x_{1}^*$ unambiguously rises, while $x_{f}^*$ moves in the opposite direction if $\sigma>1$ (indicating substitutes) or in the same direction if $0<\sigma<1$ (indicating complements).

\paragraph{Effects on Sectoral Labor Shares.}
Similarly, 
\[
\frac{\partial L_{1}^*}{\partial p^1}
=
x_{1}^*\,(1-\sigma)\bigl(1 - p^1\,x_{1}^*\bigr),
\qquad
\frac{\partial L_{f}^*}{\partial p^1}
=
(\sigma-1)\,
\frac{\,\labor{}^f\, R_{f}\,}{\Bigl(\sum_{k} \labor{}^k\, R_{k}\Bigr)^{2}}
\quad (\text{for } f\neq 1).
\]
For $\sigma>1$, since $\frac{\partial L_{f}^*}{\partial p^1}>0$, a reduction in $p^1$ leads to a lower $L_f^*$ for $f\neq 1$, thereby shifting labor towards good~1, which is consistent with substitutability.  
If $0<\sigma<1$, goods behave more like complements, and lowering $p^1$ increases labor usage in the other sectors.  
In all cases, total labor remains equal to $1$.


%%%%%%%%%%%%%%%% Optimal Paths in the Dynamic Programming Problem %%%%%%%%%%%%%%%%
\section{Optimal Paths in the Dynamic Programming Problem}
\label{app:dp_proof}

In this appendix, we analyze the properties of the optimal paths for the dynamic programming problem specified in \pageref{eq:dp_problem}.  
The solution follows this structure: allocate all resources to the larger of $q_{1}$ and $q_{2}$ until a specific point, then switch to investing all resources in the other task’s capability until parity between $q_{1}$ and $q_{2}$ is achieved.  
After reaching parity, resources are evenly distributed between both tasks.  
While we are unable to analytically determine the exact values of $q_{1}$ and $q_{2}$ at the turning point, we provide comparative statics with respect to the initial values and the discount rate.

We reformulate the problem as a maximization problem, and omit time dependencies in all variables for simplicity of notation.
\begin{align*}
\max_{q_{1},q_{2}} & \int_{0}^{T}-e^{-\rho t}C(q_{1},q_{2})dt\\
s.t. & \frac{dq_{1}}{dt}+\frac{dq_{2}}{dt}+s(t)=r,\\
 & q_{1},q_{2}\geq0,\\
 & q_{1}(0)=q_{1,0},\quad q_{2}(0)=q_{2,0}.
\end{align*}
Here, $q_{1},q_{2}$ are the state variables, while $\frac{dq_{1}}{dt}$ and $\frac{dq_{2}}{dt}$ are control variables.  
We form the Hamiltonian as follows: 
\[
H=-e^{-\rho t}C(q_{1},q_{2})+\lambda_{1}\frac{dq_{1}}{dt}+\lambda_{2}\frac{dq_{2}}{dt}+\mu\left(r-\frac{dq_{1}}{dt}-\frac{dq_{2}}{dt}\right),
\]
where $\lambda_{1},\lambda_{2}$ are costate variables, and $\mu$ is the Lagrange multiplier associated with the investment constraint.  
The necessary conditions for an interior solution are: %% \underline{interior}

\begin{align*}
\frac{dq_{i}}{dt} & =\frac{\partial H}{\partial\lambda_{i}},\tag{State Dynamics}\\[1ex]
\frac{d\lambda_{i}}{dt} & =-\frac{\partial H}{\partial q_{i}},\tag{Costate Dynamics}\\[1ex]
\frac{\partial H}{\partial\left(\frac{dq_{i}}{dt}\right)} & =0,\tag{Stationarity}\\[1ex]
\mu\left(r-\frac{dq_{1}}{dt}-\frac{dq_{2}}{dt}-s\right) & =0.\tag{Complementary Slackness}
\end{align*}
Expanding the formulas, we obtain:
\begin{align*}
\frac{dq_{1}}{dt} & =\frac{dq_{1}}{dt},\\[1ex]
\frac{dq_{2}}{dt} & =\frac{dq_{2}}{dt},\\[1ex]
\frac{d\lambda_{1}}{dt} & =e^{-\rho t}\frac{\partial C}{\partial q_{1}},\\[1ex]
\frac{d\lambda_{2}}{dt} & =e^{-\rho t}\frac{\partial C}{\partial q_{2}},\\[1ex]
\lambda_{1}-\mu & =0,\\[1ex]
\lambda_{2}-\mu & =0,\\[1ex]
\mu>0\ \text{and}\ \frac{dq_{1}}{dt}+\frac{dq_{2}}{dt}=r, & \quad \text{or}\ \mu=0\ \text{and}\ \frac{dq_{1}}{dt}+\frac{dq_{2}}{dt}<r.
\end{align*}
The costate dynamics imply
\[
\frac{\frac{d\lambda_{1}}{dt}}{\frac{d\lambda_{2}}{dt}}=\frac{\frac{\partial C}{\partial q_{1}}}{\frac{\partial C}{\partial q_{2}}},
\]
and from the stationarity conditions, we have:
\[
\lambda_{1}=\lambda_{2}=\mu.
\]

The $\mu=0$ case can happen only if:
\[
\frac{\partial C}{\partial q_{1}}=\frac{\partial C}{\partial q_{2}}=0
\]
for all times.  
In this scenario, any $q_{1}$ and $q_{2}$ would suffice since neither contributes to the objective function.  
However, this is not applicable in our setup because, as soon as task $i$ becomes automated, the corresponding partial derivative changes from 0 to $-\frac{\machinetime{}}{q_{i}^{2}}$.\footnote{We assume $\machinetime{}$ and $\handofftime{}$ are such that some level of automation is preferred over no automation.  
Otherwise, the solution would be trivial, and no tasks would be automated.}  
Therefore, we must have $\mu>0$, and the investment endowment is always fully utilized.

If the solution is interior, then  
\[
\lambda_{1}=\lambda_{2}=\mu>0
\]
and the following holds for all $t$:
\[
\bar{\lambda}_{1}+\int_{0}^{t}e^{-\rho s}\frac{\partial C}{\partial q_{1}}ds=\bar{\lambda}_{2}+\int_{0}^{t}e^{-\rho s}\frac{\partial C}{\partial q_{2}}ds.
\]
Assume that at $t=T$ (the horizon), $\lambda_{1}=\lambda_{2}>0$.\footnote{Intuitively, this means that at the horizon, we stop investing in either variable, resulting in a ``steady state.''  
This is reasonable because, once $q=1$, no further investments are required.}  
This implies at the optimum, the marginal cost with respect to task capabilities must be equal.  
Thus:
\[
\forall t:\frac{\partial C}{\partial q_{1}}=\frac{\partial C}{\partial q_{2}}.
\]
Given the functional form of the cost function, such scenario can occur only when both tasks are automated, \underline{and} $q_{1}=q_{2}$.  
Specifically:
\[
\frac{\partial C\{\machine{1|2}\}}{\partial q_{1}}=\frac{\partial C\{\machine{1|2}\}}{\partial q_{2}}\Leftrightarrow-\frac{\machinetime{}}{q_{1}^{2}q_{2}}=-\frac{\machinetime{}}{q_{1}q_{2}^{2}}\Leftrightarrow q_{1}=q_{2}.
\]
Unless this condition is met, we have a corner solution where all the available endowment is allocated to improving only one task’s AI capability.

We conjecture that at a sufficiently long horizon, $q_{1}=q_{2}$, and proceed to determine the optimal trajectories of $q_{1}$ and $q_{2}$ using backward induction.  
Now, imagine we are in the $\machine{1|2}$ region.  
Let $\tilde{T}$ denote the earliest time at which $\frac{\partial C}{\partial q_{1}}=\frac{\partial C}{\partial q_{2}}$ holds.\footnote{We assume that the parameters $\machinetime{}$ and $\handofftime{}$ are such that this equality is guaranteed to occur.  
Otherwise, the solution would trivially involve investing in only one $q$, fully maximizing it before switching to the other until it too is maximized.}  
For $t<\tilde{T}$, we have a corner solution.  
Without loss of generality, assume that $\frac{\partial C}{\partial q_{1}}>\frac{\partial C}{\partial q_{2}}$ when $t<\tilde{T}$.  
With a slight abuse of notation, consider a time $\delta$ arbitrarily close to and just before $\tilde{T}$.  
At such times, we can write:
\[
\frac{\partial C\{\machine{1|2}\}}{\partial q_{1}}\approx-\frac{\machinetime{}}{q_{1}^{2}q_{2}}>-\frac{\machinetime{}}{q_{1}q_{2}^{2}}\approx\frac{\partial C\{\machine{1|2}\}}{\partial q_{2}}.
\]
This simplifies to:
\[
-\frac{1}{q_{1}}>-\frac{1}{q_{2}}\Leftrightarrow q_{1}>q_{2}.
\]
Therefore, for times $t<\tilde{T}$, we must invest exclusively in $q_{2}$ until parity between $q_{1}$ and $q_{2}$ is achieved.  
This also implies that we are in the region below the 45-degree line and are moving toward it.

Now, we continue going backward until we reach either the boundary of $\machine{1}\machine{2}$ or $\machine{1}\human{2}$.  
Here we only consider the case where we hit the boundary of $\machine{1}\machine{2}$.\footnote{The dynamics of transitioning directly from $\machine{1|2}$ to $\machine{1}\human{2}$ are less complicated than transitioning through $\machine{1}\machine{2}$ first and then to $\machine{1}\human{2}$.  
For brevity, we do not describe the direct transition separately, as the mechanism is similar and requires one less step of analysis.}  
Given that we are in the region where $q_{1}>q_{2}$, the following conditions hold:
\[
q_{1}>q_{2}\Leftrightarrow-\frac{\machinetime{}}{q_{1}^{2}}>-\frac{\machinetime{}}{q_{2}^{2}}\Leftrightarrow\frac{\partial C\{\machine{1}\machine{2}\}}{\partial q_{1}}>\frac{\partial C\{\machine{1}\machine{2}\}}{\partial q_{2}}.
\]
Thus, in the $\machine{1}\machine{2}$ region, we must continue investing in $q_{2}$.  
This remains true even if we enter $\machine{1}\machine{2}$ from the point of parity in $\machine{1|2}$.  
In other words, in the moments leading up to $\frac{\partial C}{\partial q_{1}}=\frac{\partial C}{\partial q_{2}}$, we will allocate all resources to $q_{2}$, regardless of whether we will be in $\machine{1|2}$ or $\machine{1}\machine{2}$ at $\tilde{T}$.

Now imagine transitioning from $\machine{1}\machine{2}$ to $\machine{1}\human{2}$.  
The cost function changes from:
\[
C\{\machine{1}\machine{2}\}=\frac{\machinetime{}}{q_{1}}+\frac{\machinetime{}}{q_{2}}
\]
to 
\[
C\{\machine{1}\human{2}\}=\frac{\machinetime{}}{q_{1}}+\handofftime{}.
\]
Let us maintain the assumption that $q_{1}>q_{2}$ as we cross the horizontal boundary in Figure \ref{fig:two_tasks} and enter the new region.  
In the $\machine{1}\machine{2}$ region, we have: $\frac{\partial C}{\partial q_{1}}>\frac{\partial C}{\partial q_{2}}$.  
However, on the $\machine{1}\human{2}$ side, the derivatives change to $\frac{\partial C}{\partial q_{1}}=-\frac{\machinetime{}}{q_{1}^{2}}<0$ and $\frac{\partial C}{\partial q_{2}}=0$.  
This implies that the task contributing more to the objective function differs across these regions.  
However, this does not mean the optimal investment path switches instantaneously.  
While the instantaneous benefits shift at the boundary, the decision maker must account for the continuation value of investments in future periods.  
This is because, despite the discontinuity in the objective function, the state variables change continuously.

Thus, when transitioning from $\machine{1}\machine{2}$ to $\machine{1}\human{2}$, we continue investing in $q_{2}$ even though $q_{1}$ provides a higher instantaneous utility.  
We maintain this allocation until reaching a point where the continuation value of investing in $q_{2}$ equals the benefit of switching to $q_{1}$.  
This point represents a kink in the optimal trajectory of the state variables.  
Let $\hat{T}$ denote the time at which we reach this kink.  
At $\hat{T}$, the following condition must hold:
\begin{equation}
\begin{split}
    & \underbrace{\int_{\hat{T}}^{\tau} e^{-\rho s} \left(\frac{\machinetime{}}{\hat{q}_{1}} + \handofftime{}\right) ds}_{\text{from $\hat{T}$ to automating task 2}} 
    + \underbrace{\int_{\tau}^{\tilde{T}} e^{-\rho s} \left(\frac{\machinetime{}}{\hat{q}_{1}(q_{2,0} + rs)}\right) ds}_{\text{from automation of task 2 to parity of $q$s}} \\
    & \quad + \underbrace{\int_{\tilde{T}}^{\bar{T}} e^{-\rho s} \left(\frac{\machinetime{}}{\hat{q}_{1}^{2}}\right) ds}_{\text{after parity}} 
    = \underbrace{\int_{\hat{T}}^{\bar{T}} e^{-\rho s} \left(\frac{\machinetime{}}{\hat{q}_{1} + rs} + \handofftime{}\right) ds}_{\text{continue investing on $q_{1}$}}.
\end{split}
\label{eq:kink_eq}
\end{equation}
Here, $\hat{q}_{1}$ denotes the value of $q_{1}$ at the kink, $\tau$ is the time we cross the boundary to automating task 2, and $\tilde{T}$ is the time when parity between $q_{1}$ and $q_{2}$ is achieved.  
For $t<\hat{T}$, the right-hand side (RHS) of the equation is smaller than the left-hand side (LHS).  
Thus, the agent continues investing in $q_{1}$ until the two sides are equalized.  
This condition holds regardless of whether we are in the $\machine{1}\human{2}$ region or cross the boundary to $(1)(2)$.  
Specifically: 
\[
\frac{\partial C\{(1)(2)\}}{\partial q_{1}}=\frac{\partial C\{(1)(2)\}}{\partial q_{2}}=0,
\]
whereas:
\[
\frac{\partial C\{\machine{1}\human{2}\}}{\partial q_{1}}=-\frac{\machinetime{}}{q_{1}^{2}}<0=\frac{\partial C\{\machine{1}\human{2}\}}{\partial q_{2}}.
\]
This completes the characterization of the optimal trajectory of the state variables, starting from any point on the $q_{1}$-$q_{2}$ grid.

\subsection{Comparative Statics}

The following lemmas provide comparative statics of optimal trajectories with respect to $q_{2,0}$ and $\rho$.  
We continue to maintain the assumption that we are below the 45 degree line in the $q_{1}$-$q_{2}$ plane (i.e., $q_{1}>q_{2}$ region).
\begin{lem}
$\frac{\partial\hat{T}}{\partial q_{2,0}}<0$.
\end{lem}

\begin{proof}
We have:
\begin{align*}
\frac{\partial\hat{T}}{\partial q_{2,0}} & = -\int_{\tau}^{\tilde{T}} e^{-\rho s}\left(\frac{\machinetime{}}{\hat{q}_{1}(q_{2,0}+rs)^{2}}\right)ds < 0.
\end{align*}

\noindent Lemma 1 states that if the initial value of $q_{2,0}$ increases, the switch from investing in $q_{1}$ to $q_{2}$ occurs earlier.  
This explains the shift in kinks of the optimal paths in Figure \ref{fig:optimal_paths}---moving from light blue to green to dark blue---as they shift upward and to the left.
\end{proof}

\begin{lem}
$\frac{\partial\hat{q}_{1}}{\partial q_{2,0}}<0$.
\end{lem}

\begin{proof}
Note that $\frac{\partial\hat{q}_{1}}{\partial\hat{T}}=r$, because $\hat{T}$ is defined as the time during which all resources ($r$) are allocated exclusively to $q_{1}$ for $t<\hat{T}$.  
Using this, we can write:
\begin{align*}
\frac{\partial\hat{q}_{1}}{\partial q_{2,0}} & =\frac{\partial\hat{q}_{1}}{\partial\hat{T}}\frac{\partial\hat{T}}{\partial q_{2,0}}\\[1ex]
 & = r \times \frac{\partial\hat{T}}{\partial q_{2,0}}\\[1ex]
 & < 0,
\end{align*}
where the last line follows from Lemma 1.
\end{proof}

\begin{lem}
A sufficient condition for $\frac{\partial\hat{T}}{\partial\rho}<0$ is $\frac{\machinetime{}}{\handofftime{}}>Q(\hat{q}_{1})$, where $Q(\hat{q}_{1})=\frac{\hat{q}_{1}^{2}}{1-\hat{q}_{1}}$, the machine-to-human comparative advantage bound, is increasing in $\hat{q}_{1}$.
\end{lem}

\begin{proof}
We take partial derivative of both sides of \eqref{eq:kink_eq} with respect to $\rho$, treating $\hat{T}$ as a variable:
\[
\int_{\hat{T}}^{\tau}e^{-\rho s}\left(\frac{\machinetime{}}{\hat{q}_{1}}+\handofftime{}\right)ds+\int_{\tau}^{\tilde{T}}e^{-\rho s}\left(\frac{\machinetime{}}{\hat{q}_{1}(q_{2,0}+rs)}\right)ds+\int_{\tilde{T}}^{\bar{T}}e^{-\rho s}\left(\frac{\machinetime{}}{\hat{q}_{1}^{2}}\right)ds=\int_{\hat{T}}^{\bar{T}}e^{-\rho s}\left(\frac{\machinetime{}}{\hat{q}_{1}+rs}+\handofftime{}\right)ds.
\]
Differentiating with respect to $\rho$ gives: 
\begin{align*}
-\int_{\hat{T}}^{\tau} s\,e^{-\rho s}\left(\frac{\machinetime{}}{\hat{q}_{1}}+\handofftime{}\right)ds 
-\int_{\tau}^{\tilde{T}} s\,e^{-\rho s}\left(\frac{\machinetime{}}{\hat{q}_{1}(q_{2,0}+rs)}\right)ds 
-\int_{\tilde{T}}^{\bar{T}} s\,e^{-\rho s}\left(\frac{\machinetime{}}{\hat{q}_{1}^{2}}\right)ds
-\left[\frac{\partial\hat{T}}{\partial\rho}\,e^{-\rho\hat{T}}\left(\frac{\machinetime{}}{\hat{q}_{1}}+\handofftime{}\right)\right] \\[1ex]
= -\int_{\hat{T}}^{\bar{T}} s\,e^{-\rho s}\left(\frac{\machinetime{}}{\hat{q}_{1}+rs}+\handofftime{}\right)ds
-\left[\frac{\partial\hat{T}}{\partial\rho}\,e^{-\rho\hat{T}}\left(\frac{\machinetime{}}{\hat{q}_{1}+rs}+ \handofftime{}\right)\right].
\end{align*}
Rearranging terms, we get: 
\begin{align*}
\frac{\partial\hat{T}}{\partial\rho} & =\frac{\int_{\hat{T}}^{\tau} s\,e^{-\rho s}\left(\frac{\machinetime{}}{\hat{q}_{1}}+\handofftime{}\right)ds+\int_{\tau}^{\tilde{T}} s\,e^{-\rho s}\left(\frac{\machinetime{}}{\hat{q}_{1}(q_{2,0}+rs)}\right)ds+\int_{\tilde{T}}^{\bar{T}} s\,e^{-\rho s}\left(\frac{\machinetime{}}{\hat{q}_{1}^{2}}\right)ds-\int_{\hat{T}}^{\bar{T}} s\,e^{-\rho s}\left(\frac{\machinetime{}}{\hat{q}_{1}+rs}+\handofftime{}\right)ds}{e^{-\rho\hat{T}}\left(\frac{\machinetime{}}{\hat{q}_{1}+rs}-\frac{\machinetime{}}{\hat{q}_{1}}\right)}
\end{align*}
Since the denominator is always negative (because $\hat{q}_{1}+rs>\hat{q}_{1}$), the sign of $\frac{\partial\hat{T}}{\partial\rho}$ depends on the numerator.  
Breaking the last integral into three intervals, the numerator becomes:
\begin{align*}
 & \underbrace{\int_{\hat{T}}^{\tau} s\,e^{-\rho s} \left(\frac{\machinetime{}}{\hat{q}_{1}} - \frac{\machinetime{}}{\hat{q}_{1} + rs}\right) ds}_{>0} 
+ \int_{\tau}^{\tilde{T}} s\,e^{-\rho s} \left(\frac{\machinetime{}}{\hat{q}_{1}(q_{2,0} + rs)} - \frac{\machinetime{}}{\hat{q}_{1} + rs} - \handofftime{}\right) ds \\[1ex]
& + \int_{\tilde{T}}^{\bar{T}} s\,e^{-\rho s} \left(\frac{\machinetime{}}{\hat{q}_{1}^{2}} - \frac{\machinetime{}}{\hat{q}_{1} + rs} - \handofftime{}\right) ds.
\end{align*}
Now we look for sufficient conditions that guarantee the numerator is positive.  
First, notice that $\left(-\frac{\machinetime{}}{\hat{q}_{1}+rs}-\handofftime{}\right)$ appears in both the middle and right terms.  
To ensure the numerator is positive, we require:
\[
\frac{\machinetime{}}{\hat{q}_{1}+rs}+\handofftime{}\leq \min\left\{\frac{\machinetime{}}{\hat{q}_{1}^{2}},\frac{\machinetime{}}{\hat{q}_{1}(q_{2,0}+rs)}\right\}.
\]
In the region where $q_{1}>q_{2}$ and $q_{2}+rs\leq\hat{q}_{1}$ until parity is achieved, the minimum is $\frac{\machinetime{}}{\hat{q}_{1}^{2}}$.  
Therefore, the condition becomes: 
\begin{align*}
\frac{\machinetime{}}{\hat{q}_{1}+rs}+\handofftime{} & <\frac{\machinetime{}}{\hat{q}_{1}^{2}}.
\end{align*}
At $t=0$ (just after the investment switch), this simplifies to:
\[
\frac{\machinetime{}}{\hat{q}_{1}}+\handofftime{}<\frac{\machinetime{}}{\hat{q}_{1}^{2}},
\]
or equivalently:
\begin{align*}
\frac{\machinetime{}}{\handofftime{}}\left(\frac{1}{\hat{q}_{1}^{2}}-\frac{1}{\hat{q}_{1}}\right) & >1,\\[1ex]
\frac{\machinetime{}}{\handofftime{}}\frac{1-\hat{q}_{1}}{\hat{q}_{1}^{2}} & >1,\\[1ex]
\frac{\machinetime{}}{\handofftime{}} & >\frac{\hat{q}_{1}^{2}}{1-\hat{q}_{1}},\\[1ex]
\frac{\machinetime{}}{\handofftime{}} & >Q(\hat{q}_{1}).
\end{align*}
Thus, $\frac{\machinetime{}}{\handofftime{}}>Q(\hat{q}_{1})$ is a sufficient condition to ensure $\frac{\partial\hat{T}}{\partial\rho}<0$.  
Intuitively, if machine costs dominate human costs, increasing the discount rate makes the switch occur earlier ($\hat{T}\downarrow$).
\end{proof}

\begin{cor}
The machine-to-human comparative advantage bound decreases as the initial AI capability of the disadvantaged task increases.
\end{cor}

\begin{proof}
Using Lemma 2, we have:
\[
Q(\hat{q}_{1})=\frac{\hat{q}_{1}^{2}}{1-\hat{q}_{1}}.
\]
Taking the derivative with respect to $q_{2,0}$:
\[
\frac{\partial Q(\hat{q}_{1})}{\partial q_{2,0}}=\frac{\partial\left(\frac{\hat{q}_{1}^{2}}{1-\hat{q}_{1}}\right)}{\partial\hat{q}_{1}}\frac{\partial\hat{q}_{1}}{\partial q_{2,0}}<0.
\]
This implies that as $q_{2,0}$ increases, maintaining $\frac{\partial\hat{T}}{\partial\rho}<0$ requires less comparative machine cost advantage (i.e., lower $\frac{\machinetime{}}{\handofftime{}}$).
\end{proof}


\end{document}


%%%%%%%%%%%%%%%% Extending the Model: Theoretical Propositions and Insights %%%%%%%%%%%%%%%%
\section{Extending the Model: Theoretical Propositions and Insights}

\subsection{Chaining with Correlated Success Probabilities}

\begin{proposition}[Chaining with Correlated Success]
Suppose the probability of success on each task is marginally $q_i$, but the success events are correlated with a correlation coefficient $\rho$.  
Let $\text{CostBlock}(i\text{ through }j)$ denote the expected cost of chaining tasks $i$ through $j$.  
Then:
\[
\text{CostBlock}(i\text{ through }j) = \frac{\machinetime{}}{\mathbb{P}(\text{all succeed})},
\]
where $\mathbb{P}(\text{all succeed}) = \mathbb{P}\left(\bigcap_{k=i}^j S_k\right)$ depends on $\rho$.  
If $\rho > 0$, the threshold for cost-effective chaining is strictly higher than in the $\rho = 0$ (independent) case.  
Conversely, if $\rho < 0$, chaining becomes more attractive.
\end{proposition}

\subsection{Chaining in Non-Linear or Tree-Structured Production}

\begin{theorem}[Cost-Minimizing Chaining in a Directed Acyclic Graph]
Let the production process be represented by a DAG $G = (V, E)$, where each node $i \in V$ is a task requiring cost $\handofftime{}[i] \in \mathbb{R}_+$ by humans or $\frac{\machinetime{}}{\prod_{k \in \text{chain}} q[k]}$ if executed in a chained block of tasks.  
The cost-minimization problem:
\[
\min_{\text{valid assignments respecting DAG dependencies}} \sum_{b \in B} \text{CostBlock}(b),
\]
can be solved in $O(|V|^2 2^{|E|})$ using a dynamic program processing nodes in topological order.  
The solution involves sub-DAGs where each is either a single-human-task node or a fully machine-chained component.
\end{theorem}

\subsection{Endogenizing Prompting and Evaluation Costs}

\begin{proposition}[Joint Investment in Capability and Prompt Tuning]
Let a firm allocate resources to improve AI success probabilities $q_i$ and reduce management costs $\machinetime{}$ over time, facing cost functions $R(q_i)$ and $S(\machinetime{})$.  
The total cost per period is:
\[
C(\mathbf{q}, \machinetime{}) = \min\left\{\text{production costs with } q_i \text{ and } \machinetime{}\right\}.
\]
If improvements in $q_i$ and $\machinetime{}$ are complementary (i.e., $\frac{\partial^2 C}{\partial q_i \partial \machinetime{}} < 0$), the firm will invest in both dimensions simultaneously, rather than prioritizing one exclusively.
\end{proposition}

\subsection{Multiple Humans with Heterogeneous Skills}

\begin{proposition}[Heterogeneous Human Costs]
Suppose there are two human types, $H_1$ and $H_2$, with costs $\handofftime{1} < \handofftime{2}$ and management costs $\timecost{m1} < \timecost{m2}$.  
Let $\CostBlock_{i,\text{type}}(\cdots)$ be the expected cost if tasks $i$ through $j$ are done by AI under type $\text{type}$.  
The dynamic program chooses both:
\begin{itemize}
    \item Who supervises each AI chain ($H_1$ or $H_2$),
    \item Who performs human-executed tasks.
\end{itemize}
The segmentation of tasks depends on $\frac{\timecost{m1}}{q_1q_2\cdots q_k}$ versus $\frac{\timecost{m2}}{q_1q_2\cdots q_k}$, which affects allocation efficiency.
\end{proposition}

\subsection{Optimal Partitioning of Chains}

\begin{proposition}[Optimal Chaining Partition]
Suppose a block of $k$ tasks has success probabilities $q_i$.  
The tasks can be chained in one go or partitioned into smaller subchains.  
The cost of $m$ subchains is:
\[
\sum_{\ell=1}^m \frac{\machinetime{}}{\prod_{i \in \ell\text{-th subchain}} q[i]}.
\]
An optimal partition $\Pi^*$ minimizes this sum and can be found via a dynamic program in $O(k^2)$.  
If $\prod_{i=1}^k q[i]$ is sufficiently high, the entire block is assigned to a single chain.
\end{proposition}

\subsection{Learning-by-Doing and Dynamic Probabilities}

\begin{theorem}[Optimal Usage Trajectories Under Learning-by-Doing]
Let $q_i(t)$ be the AI’s success probability on task $i$ at time $t$, improving with usage: $q_i(t+1) = \min\{q_i(t) + \Delta, 1\}$.  
If improvements in $q_i$ are convex in attempts, there exists a threshold policy:
\begin{itemize}
    \item If $q_i(t) < q_i^*$, the firm uses AI for the task to accumulate learning.
    \item If $q_i(t) \ge q_i^*$, the firm assigns the task to AI or humans, depending on cost.
\end{itemize}
\end{theorem}

\subsection{General Equilibrium with Multiple Sectors}

\begin{proposition}[General Equilibrium with Two Goods]
Consider two sectors producing goods $X$ and $Y$, each requiring a sequence of tasks.  
Labor is mobile, and the equilibrium prices $(w^*, p_X^*, p_Y^*)$ satisfy:
\[
L_j(w) = d_j(p_j) l_j(w; q_1, q_2, \dots, q_n),
\]
where $L_j$ is labor demand and $d_j(p_j)$ is product demand.  
If AI improvement $\Delta q$ reduces the cost of key tasks in $X$, the labor effect in $X$ depends on the demand elasticity $\epsilon_j$, while sector $Y$ may experience wage effects or reallocation.
\end{proposition}


\end{comment}
\end{document}

\newcommand{\machinetime}[1]{t^{m}_{#1}}
\newcommand{\humanhc}[1]{c^{h}_{#1}}
\newcommand{\machinehc}[1]{c^{m}_{#1}}



\newcommand{\topic}[1]{\paragraph{#1}}
%\newcommand{\topic}[1]{#1}

\renewcommand{\arraystretch}{1.75} % Increase row height for visual consistency in job design Table 

\maketitle

\begin{abstract}
\noindent
This paper presents a simple task‐based model of Agentic AI and human labor.  
Unlike existing task models, it explicitly considers the interdependence of tasks in a sequence.  
Tasks can be efficiently ``chained'' together, meaning that each task produces something that feeds directly into the next without human intervention.  
A task may optimally be added to an automated chain even when humans have an absolute advantage at that task in isolation, overturning the usual comparative advantage logic.  
The workers in the model face a ``hand-off'' cost for switching between jobs.
This source of friction determines how tasks are bundled into jobs and which tasks are assigned to AI.
The model accommodates two distinct modes of AI deployment: (1) automation, where AI completes tasks without human oversight, and (2) augmentation, where AI assists humans in completing tasks.
We embed the model of production into a general equilibrium framework to study how an AI quality shock affects worker wages and employment. 
%The model predicts that firms will reconfigure job structures following improvements beyond a certain level in AI quality, leading to wage cuts for some workers and (potential) wage gains for others.
\end{abstract}

\onehalfspacing

%%%%%%%%%%%%%%%% Introduction %%%%%%%%%%%%%%%%
\section{Introduction}
We present a simple task-based model of AI and human labor that focuses on the interdependence of tasks in the productive process.
We start with a model of production that is a sequence of tasks that must be done in order.
Those tasks require human capital to perform at all, but differ in how long they take to complete.
They also differ in how easily they can be ``handed-off'' from one worker to the next.
These costs create the division of labor in production, from which we can explore the effect of AI.
We then investigate how AI advancements affect this division in the short run---where human capital needs remain fixed but task durations shrink---and in the long run---where both human capital requirements and task times can adjust.
Finally, we explore the consequences for labor demand and wage outcomes under both scenarios.

There are, of course, numerous economic models of the division of labor \citep{becker1992division, deming2017growing}---why do we need another?
Because the extent of automation depends on the chain of tasks. 
So, task adjacency must matter, as we show it does.

We consider how the development of AI that can do certain tasks changes the division of labor.  
In the model, three modes of task completion are recognized: manual, augmented, and automated.  
In \emph{manual} tasks, a human carries out the entire task without any AI assistance.  
In \emph{augmented} tasks, an AI executes the task but its output is reviewed and approved by a human.
In \emph{automated} tasks, an AI completed the task end-to-end without direct human intervention.
Although augmented and automated tasks share the same cost structure, they differ in one crucial respect: augmented tasks demand direct human oversight of the AI’s output, whereas automated tasks do not.
Figure~\ref{fig:task_division} illustrates these concepts using a sequence of five tasks.  
Tasks 1 and 5 are performed manually by a human.  
Tasks 2, 3, and 4 form an machine chain and are done using AI.
Tasks 2 and 3 are automated because their outputs feed directly into subsequent AI tasks without human review.
Task 4 is augmented because its output is evaluated by a human before proceeding. 
\begin{figure}[ht]
  \begin{center}
  \caption{Illustrative Example for Division of Labor}
  \label{fig:task_division}
  \begin{tikzpicture}[scale=0.9, transform shape,
    node distance=0.25cm and 0.6cm,
    every node/.style={rectangle, rounded corners, draw, align=center, minimum width=2cm, minimum height=1cm},
    manual/.style={fill=gray!10},
    automated/.style={fill=green!30},
    augmented/.style={fill=orange!30},
    labelbox/.style={draw, rectangle, rounded corners, fill=blue!20, font=\bfseries, minimum width=2cm, minimum height=1cm},
    >=latex
  ]
    % Task nodes
    \node[manual]    (T1) {Task 1\\(Manual)};
    \node[automated, right=of T1] (T2) {Task 2\\(Automated)};
    \node[automated, right=of T2] (T3) {Task 3\\(Automated)};
    \node[augmented, right=of T3] (T4) {Task 4\\(Augmented)};
    \node[manual,    right=of T4] (T5) {Task 5\\(Manual)};

    % Arrows between tasks (keep these bold)
    \draw[->, thick] (T1) -- (T2);
    \draw[->, thick] (T2) -- (T3);
    \draw[->, thick] (T3) -- (T4);
    \draw[->, thick] (T4) -- (T5);

    % AI brace and label over tasks 2–4 (lighter)
    \draw[decorate, decoration={brace, amplitude=6pt}, thin]
      ($(T2.north west)+(0,0.2)$) -- ($(T4.north east)+(0,0.2)$)
      node[midway, above=8pt, labelbox] (AI) {AI};

    % Human label below, aligned with AI
    \node[labelbox, below=2.5cm of AI] (Human) {Human};

    % Lines from T1, T4, and T5 down to Human (lighter)
    \draw[thin] (T1.south) -- (Human.north);
    \draw[thin] (T4.south) -- (Human.north);
    \draw[thin] (T5.south) -- (Human.north);
  \end{tikzpicture}
  \end{center}
  \footnotesize{
  \emph{Notes:} This figure illustrates division of labor across five tasks: Tasks 1 and 5 are done manually by human; Tasks 2--3 are AI‐automated (done with AI without direct human intervention); Task 4 is AI‐augmented (done with AI but with human oversight). The brace above tasks 2--4 indicates an AI chain, and that AI is involved in completing those tasks; downward lines show which tasks require human execution or oversight. 
  }
\end{figure}

The decision to deploy AI on a given task compares the cost of manual execution to the unified AI-based execution cost.  
At first glance, this might seem like another way of stating that tasks get assigned to whichever factor has the comparative advantage in that task, but this is not the case: the position of tasks within the productive process profoundly changes the optimal allocation of tasks between humans and machines.
When a single task is performed by an AI, there is always a human requesting the task and evaluating its output in an AI-augmented manner.  
But with two or more tasks it is possible to re-configure production so that an AI completing one task passes its output directly into the next task without human intervention (i.e., the task is automated).  
The machine chain (Tasks 2--4) in Figure~\ref{fig:task_division} illustrates this case: Tasks 2 and 3 are fully automated (their outputs flow from one AI task to the next without direct human intervention) while Task 4, is AI-augmented with human oversight at the end of the chain.
This chaining is potentially a source of large productivity gains, \emph{but} it requires AIs that can perform each task with a high probability of success.  
The model’s basic setup shares conceptual similarities with the O-ring model of production \citep{kremer1993}, and the role humans  play in the model as offering judgment on AI outputs is consistent with the emphasis in \cite{agrawal2019exploring}.

A key implication of the model is that chaining tasks together can reverse comparative advantage assignments for individual tasks.
It can be efficient to deploy an AI on a task even when humans hold a comparative advantage in that task in isolation.
A surprising result of chaining is that improvements in AI performance on one task can shift another task from human to machine execution through chaining, without any direct improvement in the AI’s capability on the second task.
Task 3 in Figure~\ref{fig:task_division} illustrates this possibility: with appropriate parameter values, Task 3 can be most efficient under manual execution in isolation, yet overall production costs are minimized when it is bundled with Tasks~2 and~4 in an AI chain.

Because of chaining, it matters what tasks are ``next'' to each other in a productive process.
In some sequences, adjacent tasks differ sharply in their time and skill profiles---the two cost dimensions that are focal in our model.
We refer to such cases as ``tent‐poll tasks.''
These arise when a time‐consuming, low‐skill task is immediately followed by a short, high‐skill task.
Figure~\ref{fig:tent_poll} gives one such example.
Each task in the figure is represented by a rectangle of width $\timecost{}$ (time requirement) and height $\hccost{}$ (human capital requirement).
\begin{figure}[h!]
  \caption{Illustration of Tent‐Poll Tasks} 
  \label{fig:tent_poll}
  \begin{center}
    \includegraphics[width=\textwidth]{plots/tent_poll.png}
  \end{center}
  \begin{footnotesize}
    \emph{Note:} This figure illustrates tent‐poll tasks.  
    The width and height of each rectangle specify the time and human capital requirements of the task, respectively.
    Tasks 1 and 3 have a high time cost and low human capital requirement (wide and short) whereas Task 2 exhibits a low time cost and high human capital requirement (narrow and tall).  
  \end{footnotesize}
\end{figure}
The sharp contrast between the $(\hccost{}, \timecost{})$ pairs of tent-poll tasks creates substantial inefficiencies, discouraging AI chaining and instead pushing firms toward individual task specialization.
The same economic forces that historically drove the division of labor (namely, minimizing frictions and inefficiencies) now define the boundaries of where AI can be effectively deployed.
Even when two consecutive tasks are each AI‐able in isolation, chaining them together may still not be viable.
Consequently, the decision to assign a task to AI depends not only on the task's own AI-ability, but also on the characteristics of its neighbors.

Assigning tasks to factors of production is not a completely trivial computational problem.
For an occupation with $n$ tasks, we show that there are $F(2n + 1)$ possible production arrangements, where $F(k)$ is the $k$th Fibonacci number.
However, we also show how the allocation problem can be solved numerically in $O(n^2)$ time using dynamic programming (DP).
Although we do not do it in this paper, this algorithmic approach could be combined with micro-details of task content and composition (as in \cite{frey2017future, felten2021occupational, eloundou2023gpts}) to create rich estimates of how technological change in various tasks would impact workers.

It might be hard for firms or even for it to be obvious beyond just the allocation of tasks to factors of production, the model provides a way to calculate the return to investing in AI capabilities in specific tasks.
For tasks far from economical automation (i.e., done by humans), marginal investments in AI capabilities offer no immediate return.
Once capabilities exceed the threshold where AI replaces humans even in isolation, improvements in AI capabilities offer a return, but at a diminishing rate.
But once the chaining threshold is passed, the returns to investing in AI for that focal task discontinuously increase.
These non-linearities in the returns to investment in AI creates interesting optimal investment path dynamics.

In the $n = 2$ task case, with a high discount rate, it can be optimal to invest heavily in a single AI capability, leaving the other task to always be done by humans.
With a low discount rate, the optimal path can change dramatically. 
As with other growth models, there is a ``get on the turnpike'' effect: the optimal path is to invest heavily in AI for the lagging task until it reaches parity with the more advanced task, with both of them chained, after which we have balanced investment across AI tasks.
Depending on the starting point, before getting on the turnpike, it is sometimes optimal to continue to invest in the leading task for some amount of time, in order to enjoy lower costs while getting the lagging task up to parity.

The chaining feature of the model connects to---and potentially reconciles---competing views about automation in production. 
Despite the emphasis on task-level substitution between AI and labor in most of the AI and labor literature \citep{autor2003skill, acemoglu2018automation}, \cite{bresnahan2002information} argues that that meaningful substitution happens primarily at the system level. 
One could interpret the model as showing how task-level decisions aggregate into system-level automation through chaining.
In the model, there is no Ship-of-Theseus requirement that tasks are automated one by one but rather than entire chains can be automated all at once---consistent with the \cite{bresnahan2002information} perspective.

Although the model is developed as a kind of algorithmic cost function, it ultimately produces cost functions with standard properties, which we embed within a more general model of the economy.  
The model predicts that improvements in AI will inherently reduce labor use per unit of the good and, consequently, its price.  
Whether this increases or decreases the demand for labor, even for that task, depends on the elasticity of demand for that good in the product market.  

In the model, with highly capable AIs, the human role shrinks to asking and judging. 
This perhaps sounds like an uninspiring role but it is not necessarily a low-paid one. 
Consider the famed music producer Rick Rubin, who is not poor, discussing his market value in an interview with Anderson Cooper:
\begin{dialogue}
    \speak{Rick Rubin} I've no technical ability. And I know nothing about music.
    \speak{Anderson Cooper} Well, you must know something.
    \speak{Rick Rubin} I know what I like and what I don't like. I'm decisive about what I like and what I don't like.
    \speak{Anderson Cooper} So what are you being paid for?
    \speak{Rick Rubin} The confidence that I have in my taste, and my ability to express what I feel, has proven helpful for artists.
\end{dialogue}
We might be paid for being hepful to AIs.
And this help might be valuable, even if we have no ability to do the tasks ourselves.
In other words, automation can enable new forms of labor-labor substitution by separating task execution from task evaluation, allowing workers to leverage judgment skills even in domains where they lack execution abilities, potentially upending the allocation of workers to occupations in hard-to-forsee ways (see \cite{autor2013putting} on this human capital-task-wage relationship).

Finally, improvements in AI quality generate nonlinear effects on labor demand and wages.
In the short run, higher AI performance reduces task time costs, potentially lowering labor demand and putting downward pressure on wages.
If one‐off gains from reassigning tasks to workers outweigh pure time savings enabled by AI advances in existing job structures, firms will reconfigure tasks in the short run, potentially boosting demand (and wages) for some roles despite overall AI efficiency gains.
In the long run, worker retraining and unrestricted task reallocation yield new wage schedules that reflect updated human capital and time cost parameters.  
These threshold effects imply that marginal AI advances may have little impact until they cross a short‐run redesign or long‐run restructuring tipping point, after which labor demand and job structures shift abruptly.  
Our framework thus offers clear, testable predictions on when and how AI-driven productivity gains trigger structural reorganization in labor markets.



%%%%%%%%%%%%%%%% Task-Based Model of Production %%%%%%%%%%%%%%%%
\section{A Task-Based Model of Production}
\label{sec:taskbased_prod}

To model how AI affects occupations we need some account of why those tasks were put together in the first place.
In this section we develop a framework that treats occupations as a collection tasks, explains how firms design jobs, and shows how AI influences the design choices.


\subsection{Job Design}
\label{sec:job_design}

Suppose production of a (final) good requires completing an ordered set of tasks, denoted by:
\begin{equation}
\label{eq:tasks}
\T = \{1,2,\ldots,n\}.
\end{equation}
We refer to $\T$ as the production process of the good.
The firm can partition the production process $\T$ into $J$ distinct ``jobs,'' where each job $j \in \{1, \cdots, J \}$ is a contiguous block of tasks, denoted by $\J_j$, performed by a single worker.
Formally:
\[
\bigcup_{j=1}^J \J_j = \T, 
\]
and for all $j,j' \in \{1,\dots,J\}$ where $j \neq j'$:
\[
\J_j \cap \J_{j'} = \emptyset.
\]
We refer to any collection of jobs satisfying the above conditions as a ``job design'' for the occupation, and denote it with $\{\J_j\}_{j=1}^{J}$.

With $|\T| = n$ tasks, there are $2^{(n - 1)}$ unique ways of designing jobs.
For example, if $n = 3$, the production process of the final good consists of three tasks, $\{1,2,3\}$, with $2^{(3-1)}=4$ unique job designs.
Let $[.]$ denote the tasks assigned to a worker in a job.
The four possible designs in this example are: $\{[1][2][3], \, [1,2][3], \, [1][2,3], \, [1,2,3]\}$.
The $[1,2][3]$ design, for example, means that one worker is assigned to do tasks 1 and 2 in a single job, $[1,2]$, whereas task 3 is assigned to a different worker in another job, $[3]$.
Later, we will discuss what factors guide the firm’s choice among different job designs.


\subsection{Human Capital}
The firm hires one worker for each job $j \in \{1, \cdots, J\}$.  
The worker completes all tasks $i \in \J_j$ associated with their job. 
Performing any task $i$ requires the worker to first acquire the necessary skills, incurring a one-time human capital investment cost \( \hccost{i} > 0 \).
Once trained, the task takes time $\timecost{i}>0$ to complete. 
Note that the human capital cost $\hccost{i}$ is paid only once upon acquisition, whereas the time cost $\timecost{i}$ applies to every unit of the good produced.
In other words, once the necessary skill (i.e., human capital) is acquired, labor (i.e., time) is the only input used in production.
For example, it might cost \$10 to learn how to file a test procedure specification (TPS) report, and once the worker has acquired this skill, it takes $15$ minutes to produce each report.
Thus, after paying the \$10 learning cost, the worker can produce one report every $15$ minutes.
The total human capital acquired ex ante by the worker employed in job $j$ is thus:
\[
\sum_{i \in \J_j} \hccost{i},
\]
while the total time spent on tasks to produce a unit of output is:
\[
\sum_{i \in \J_j} \timecost{i}.
\]


Both the product and human capital markets are perfectly competitive, and workers are \emph{ex ante} identical, as in \cite{becker1992division}.
Workers value leisure at $v_L$ and supply one unit of labor inelastically.
Hence, if the wage in job $j$ is $w_j$, the worker's income is simply $w_j$.
To remain indifferent between jobs, workers must receive wages that covers not only the value of their time but also compensates them for the cost of human capital they have acquired.
Thus, the wage rate in job $j$ must satisfy\footnote{Notice that while wages may differ across jobs, they are structured such that workers remain indifferent between acquiring different types of human capital for different jobs.}:
\begin{align}
\label{eq:wage}
w_j = v_L + \sum_{i \in \J_j} \hccost{i}.
\end{align}
The firm must pay workers for their time, regardless of which tasks they are employed to complete; hence, the wage bill paid to worker per unit of output is:
\begin{align}
\label{eq:wagebill}
\text{WageBill}_j = \Biggl(v_L + \sum_{i \in \J_j} \hccost{i} \Biggr) \Biggl(\sum_{i \in \J_j} \timecost{i} \Biggr).
\end{align}

Equation~\ref{eq:wagebill} admits a nice geometric interpretation.  
We can represent the production process as a sequence of stacked rectangles whose heights are $\hccost{i}$ and widths are $\timecost{i}$.  
Figure~\ref{fig:wage_bill} illustrates an occupation with just two tasks and thus two job designs: [1][2] and [1,2].
For simplicity we assume $v_L=0$ in the graph.
In both panels, the numbered, solid‐lined rectangles denote the two tasks.
Visually, a job corresponds to the bounding box around its tasks, and its wage bill equals the area of that box (shaded in blue).
In the [1][2] design (left panel), each task is handled by a different worker: the wage bill for job 1 is the shaded area of rectangle 1, and the wage bill for job 2 is the shaded area of rectangle 2.  
In the [1,2] design (right panel), both tasks are assigned to the same worker, so the occupation has a single job whose wage bill is the area of the shaded rectangle whose width is the sum of the two tasks’ time costs and whose height is the sum of their human capital costs.  
\begin{figure}[h!]
  \caption{Geometric Illustration of the Wage Bill} 
  \label{fig:wage_bill}
  \begin{center}
    \includegraphics[width=\textwidth]{plots/job_design.png}
  \end{center}
  \begin{footnotesize}
    \emph{Note:} Each panel of the graph shows the geometric representation of the wage bill for a job design of an occupation with two tasks (assuming $v_L=0$).  
    The shaded areas represent wage bills of jobs. 
    In the left panel, two separate jobs cover tasks [1] and [2].
    Wage bill of each job is the area of its corresponding task's rectangle.
    In the right panel, a single job covers both tasks: [1,2].
    The wage bill of this job is the area of the rectangle with width $\timecost{1}+\timecost{2}$ and height $\hccost{1}+\hccost{2}$.
  \end{footnotesize}
\end{figure}

The firm seeks to minimize the total cost of producing the final good by optimally designing jobs.
The overall production cost per unit of the good is the solution to:
\begin{align}
\label{eq:totalcost_no_handoff}
\underset{\{\J_j\}_{j=1}^J}{min} \ 
\text{TotalCost}(\J; \hccost{}, \timecost{})
= 
\sum_{j=1}^J \Biggl[\Biggl(v_L + \sum_{i \in \J_j} \hccost{i} \Biggr) \Biggl(\sum_{i \in \J_j} \timecost{i} \Biggr)\Biggr],
\end{align}
where $\hccost{}$ and $\timecost{}$ are vectors of task skill and time requirements. 

In the earlier  production example with three tasks, suppose workers value leisure at $v_L = 1$ and tasks are characterized by human capital requirements and time costs specified below:
\[
\begin{array}{c|ccc}
\textbf{Task} & \hccost{i} & \timecost{i} \\ \hline
1 & 3  & 1 \\
2 & 1 & 2  \\
3 & 2   & 1.5 \\
\end{array}
\]
The wage bill for each individual job as well as total production cost for each job design is given in Panel A of Table~\ref{tab:job_design}.
The lowest‐cost configuration, [1][2][3], assigns each task to a different worker, allowing each individual to specialize in a single task.  
In fact, this conclusion holds for any arbitrary set of parameter values since, for any nonnegative $x,y,w,z$, we have:
\[
  xy + wz \le (x + w)(y + z),
\]
meaning that bundling any two tasks cannot reduce the total cost.  
Geometrically, for any number of tasks, the sum of areas of individual rectangles never exceeds the area of the single bounding rectangle that covers two or more tasks assigned to one worker.

\begin{table}[htbp]
\caption{Example job design costs for a production process with $n=3$ tasks}
\resizebox{0.75\textwidth}{!}{%
\begin{tabular}{c}
% Panel A: Without Hand-off Costs
\begin{minipage}{\textwidth}
\centering
\hspace*{4cm} Panel (A): Without Hand-off Costs \\[1ex]
\begin{tabular}{|
  >{\centering\arraybackslash}m{1.7cm}|
  >{\centering\arraybackslash}m{0.9cm}|
  >{\centering\arraybackslash}m{1.8cm}|
  >{\centering\arraybackslash}m{1.8cm}|
  >{\centering\arraybackslash}m{1.8cm}|
  >{\centering\arraybackslash}m{1.6cm}|
  >{\centering\arraybackslash}m{1.7cm}|
  >{\centering\arraybackslash}m{1.7cm}|
  }
\hline
\textbf{Job Design} & \textbf{Job} & \textbf{Job Tasks} & $v_L+\sum\hccost{i}$ & $\sum\timecost{i}$ & \textbf{Job Cost} & \textbf{Total Cost} & \textbf{Optimal Design} \\
\hline
\multirow{3}{*}{[1][2][3]} 
  & 1 & $\{1\}$   & 4   & 1    & 4    & \multirow{3}{*}{12.5} & \multirow{3}{*}{\checkmark} \\
\cline{2-6}
  & 2 & $\{2\}$   & 2   & 2    & 4    &  &  \\
\cline{2-6}
  & 3 & $\{3\}$   & 3   & 1.5  & 4.5  &  &  \\
\hline
\multirow{2}{*}{[1,2][3]}
  & 1 & $\{1,2\}$ & 5   & 3    & 15   & \multirow{2}{*}{19.5} &  \\
\cline{2-6}
  & 2 & $\{3\}$   & 3   & 1.5  & 4.5  &  &  \\
\hline
\multirow{2}{*}{[1][2,3]}
  & 1 & $\{1\}$   & 4   & 1    & 4    & \multirow{2}{*}{18} &  \\
\cline{2-6}
  & 2 & $\{2,3\}$ & 4   & 3.5  & 14   &  &  \\
\hline
[1,2,3] & 1 & $\{1,2,3\}$ & 7   & 4.5  & 31.5 & 31.5 &  \\
\hline
\end{tabular}
\end{minipage} \\[25ex]
% Panel B: Including Hand-off Costs
\begin{minipage}{\textwidth}
\centering
\hspace*{4cm} Panel (B): Including Hand-off Costs \\[1ex]
\begin{tabular}{|
  >{\centering\arraybackslash}m{1.7cm}|
  >{\centering\arraybackslash}m{0.9cm}|
  >{\centering\arraybackslash}m{1.8cm}|
  >{\centering\arraybackslash}m{1.8cm}|
  >{\centering\arraybackslash}m{1.8cm}|
  >{\centering\arraybackslash}m{1.6cm}|
  >{\centering\arraybackslash}m{1.7cm}|
  >{\centering\arraybackslash}m{1.7cm}|
  }
\hline
\textbf{Job Design} & \textbf{Job} & \textbf{Job Tasks} & $v_L+\sum\hccost{i}$ & $\handofftime{} + \sum\timecost{i}$ & \textbf{Job Cost} & \textbf{Total Cost} & \textbf{Optimal Design} \\
\hline
\multirow{3}{*}{[1][2][3]} 
  & 1 & $\{1\}$   & 4   & 3.5  & 14   & \multirow{3}{*}{23.5} &  \\
\cline{2-6}
  & 2 & $\{2\}$   & 2   & 2.5  & 5    &  &  \\
\cline{2-6}
  & 3 & $\{3\}$   & 3   & 1.5  & 4.5  &  &  \\
\hline
\multirow{2}{*}{[1,2][3]}
  & 1 & $\{1,2\}$ & 5   & 3.5  & 17.5 & \multirow{2}{*}{22} & \multirow{2}{*}{\checkmark} \\
\cline{2-6}
  & 2 & $\{3\}$   & 3   & 1.5  & 4.5  &  &  \\
\hline
\multirow{2}{*}{[1][2,3]}
  & 1 & $\{1\}$   & 4   & 3.5  & 14   & \multirow{2}{*}{28} &  \\
\cline{2-6}
  & 2 & $\{2,3\}$ & 4   & 3.5  & 14   &  &  \\
\hline
[1,2,3] & 1 & $\{1,2,3\}$ & 7   & 4.5  & 31.5 & 31.5 &  \\
\hline
\end{tabular}
\end{minipage}
\end{tabular}
}
\label{tab:job_design}
\footnotesize{\\ \\ \\ \emph{Notes:} This table shows production costs for each job design in a production process with $n=3$ tasks. 
Panel (A) gives the production costs in absence of hand-off costs whereas Panel (B) includes hand-off costs. While in absence of hand-off friction assigning each task to a single worker is optimal, the cost-minimizing way of producing the good changes after the introduction of hand-off costs. The human capital requirements, task times, hand-off times, and value of leisure are specified in text.
}
\end{table}


\subsection{Frictional Limits to Full Division of Labor}
\label{sec:handoff_intro}
Without additional frictions, the firm could minimize production costs by assigning one worker to each task.
To assume away this trivial arrangement we introduce the ``hand-off cost” friction: a cost associated with job transitions that, while not requiring additional human capital, does take time.
This cost reflects the expense of context switching between workers in the production process, and applies only when a task sits at a job boundary.  
Within a job, all tasks are performed by the same worker, so no hand-off occurs and no such cost is incurred.
The hand-off cost is an intrinsic property of a task---not the job---and arises specifically when transitioning from the final task of job $j$ to the first task of job $j+1$.  
In such a case, the worker assigned to job $j$ incurs an additional hand-off time cost $\handofftime{j} \ge 0$.
For simplicity, rather than explicitly indexing the final task of each job, we denote the hand-off cost between jobs $j$ and $j+1$ as $\handofftime{j}$.\footnote{
Suppose task $x$ is the final task in job $j$.
For convenience, we define $\handofftime{j} := \handofftime{x}$.}
Thus, although we use the subscript $j$ to indicate the hand-off between jobs, this cost fundamentally originates from the task itself.

While the firm's cost minimization problem remains unchanged, now the solution becomes nontrivial due to the additional hand-off cost incurred after completing the final task in each job.  
The firm's objective is to minimize the following expression, which differs from equation \ref{eq:totalcost_no_handoff} only by the extra $\handofftime{j}$ term added to the time cost component of the job's wage bill:
\begin{align}
\label{eq:totalcost_with_handoff}
\underset{\{\J_j\}_{j=1}^J}{min} \ 
\text{TotalCost}(\J; \hccost{}, \timecost{}) 
= 
\sum_{j=1}^J \Biggl[\Biggl(v_L + \sum_{i \in \J_j} \hccost{i} \Biggr) \Biggl(\handofftime{j} + \sum_{i \in \J_j} \timecost{i} \Biggr)\Biggr].
\end{align}
Panel B of Table~\ref{tab:job_design} shows the potential job designs of the previous example with hand-off costs specified in this table:
\[
\begin{array}{c|ccc}
\textbf{Task} & \hccost{i} & \timecost{i} & \handofftime{} \\ \hline
1 & 3  & 1   & 2.5 \\
2 & 1 & 2   & 0.5 \\
3 & 2   & 1.5 & 0 \\
\end{array}
\]
Notice that while the earlier optimal job design (i.e., the [1][2][3] design in Panel A) assigned a single worker to each task, after introduction of the hand-off friction in Panel B the cost-minimizing production method becomes the [1,2][3] design.
In the new optimal design, the firm minimizes its cost by bundling tasks 1 and 2 together in a single job to avoid the substantial hand-off cost between these tasks in the previously optimal [1][2][3] design.


\subsection{Geometric Representation of Cost Minimization}
The firm’s cost‐minimization problem admits a geometric interpretation as well.  
Figure~\ref{fig:job_design} represents the production process from Table~\ref{tab:job_design} as stacked rectangles of height $\hccost{i}$ and width $\timecost{i}$.
\begin{figure}[htbp]
  \begin{center}
  \caption{Geometric interpretation of job designs for the \(n=3\) tasks example} \label{fig:job_design}
  \begin{subfigure}[b]{0.93\textwidth}
    \includegraphics[width=\textwidth]{plots/combined_grid_no_handoff.png}
    \caption{Job design without hand-off costs}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.93\textwidth}
    \includegraphics[width=\textwidth]{plots/combined_grid_with_handoff.png}
    \caption{Job design with hand-off costs}
  \end{subfigure}
  \end{center}
  \footnotesize{\emph{Notes:} This figure illustrates the geometric interpretation of firm's job design problem presented in Table~\ref{tab:job_design}. Each panel visualizes the production process as a sequence of stacked rectangles, where the area of each rectangle (the bounding box around a job) represents its wage bill. Panel (a) corresponds to the scenario without hand-off costs, leading to the optimal design of [1][2][3] (top left graph). Panel (b) incorporates hand-off costs, which alters the cost structure and makes the [1,2][3] design cost minimizing (bottom left graph).}
\end{figure}
Panel (a) depicts the job design without hand‐off costs (corresponding to Panel A of Table~\ref{tab:job_design}); Panel (b) shows the same example with hand‐off costs (corresponding to Panel B).  
Visually, the firm trades off two opposing forces.
Consolidating tasks into a single job avoids boundary costs but creates inefficiencies captured by cross‐bundling areas.  
Splitting tasks into separate jobs eliminates those inefficiencies yet incurs hand‐off time costs at each job boundary.  
These boundary costs scale with the cumulative human capital of the switching worker, so the height of the pink hand‐off rectangle in Panel (b) equals the sum of human‐capital heights for that job.
By balancing these effects, the firm selects the most cost‐effective job design.  
Without hand‐off costs, the optimal arrangement is [1][2][3] (top left of Panel (a)); with hand‐offs, it shifts to [1,2][3] (bottom left of Panel (b)).  




\subsection{Introduction of AI: Task Augmentation}

Having established the structure of task-based production, we now formally extend our framework by introducing AI into the model.
In this section, we restrict our analysis to a single task and omit the task index $i$ for simplicity of notation.
We defer the analysis of task automation and AI chains, which require at least two tasks, to the subsequent section.

A single task can be completed in two distinct modes of production:
\begin{enumerate}
\item Manually, where the task is executed by a human worker without AI assistance.
\item Augmented, where the task is executed by AI, and its output is subsequently reviewed by a human.
\end{enumerate}
The manual execution of a task requires skill cost $\humanhc{} > 0$ and time cost $\humantime{} > 0$.
Alternatively, if the worker opts to use AI in an augmented way. they issue a ``prompt'' to the AI at a time cost $\timecost{p} > 0$ and evaluate it at additional time cost $\timecost{e} > 0$.
Operating the AI also requires incurring one-time skill cost $\machinehc{} > 0$.

The AI successfully produces an output with probability $q$ and fails with probability $1-q$. 
The success probability can be viewed as $q=\alpha^d$ where $d$ is the task's completion difficulty for an AI with quality $\alpha \in [0,1]$: the more difficult a task is the less likely any AI attempt at it will be.

The worker learns whether the AI succeeded or failed only after evaluation of the output.
If the AI fails, the worker can provide a new prompt and evaluate its output, incurring the same costs $\timecost{p}$ and $\timecost{e}$ again.
Let $\machinetime{} = \timecost{p} + \timecost{e}$ denote the total ``management'' time cost associated with using the AI for an augmented task.
%For now, assume the worker can manage all tasks similarly by paying the task-specific management time cost.
Figure~\ref{fig:flow} illustrates this process graphically.

\begin{figure}[h!]
  \begin{center}
  \caption{Using AI to complete a task} \label{fig:flow}
\resizebox{1\textwidth}{!}{
\begin{tikzpicture}[node distance=1.8cm]

    % Task Sequence
    \node (task1) [task] {Task 1};
    \node (task2) [task, right=1.75cm of task1] {Task 2};
    \node (task3) [decision, right=1.75cm of task2] {Task 3: \\ \textbf{Can AI do this task?}};
    \node (task4) [task, right=1.75cm of task3] {Task 4};
    \node (task5) [task, right=1.75cm of task4] {Task 5};

    % AI Processes
    \node (prompt) [process, below=2.5cm of task2, xshift=-1cm] {Ask AI to do the task \\ (``prompt'')};
    \node (attempt) [process2, right=0.75cm of prompt] {AI produces an output};
    \node (evaluate) [process, right=0.75cm of attempt] {Is the work acceptable?};

    % Define a coordinate 1cm to the right of the evaluate box
    \coordinate (extendEval) at ([xshift=1cm]evaluate.east);

    % Success/Failure Nodes
    \node (yes) [smallbox, right=1cm of extendEval, yshift=1cm] {Yes};
    \node (no) [smallbox, right=1cm of extendEval, yshift=-1cm] {No};

    % Arrows
    \draw [arrow] (task1.east) -- node[midway, above] {$\humantime{} + \handofftime{}$} (task2.west);
    \draw [arrow] (task2.east) -- node[midway, above] {$\humantime{} + \handofftime{}$} (task3.west);
    \draw [arrow] (task3.east) -- node[midway, above] {$\humantime{} + \handofftime{}$} (task4.west);
    \draw [arrow] (task4.east) -- node[midway, above] {$\humantime{} + \handofftime{}$} (task5.west);
    \draw [arrow] (task3.south) to[out=-125,in=45] node[midway, above] {$\timecost{p}$} (prompt.north);
    \draw [arrow] (prompt.east) -- (attempt.west);
    \draw [arrow] (attempt.east) -- (evaluate.west);
    
    % Draw extension line before branching
    \draw [arrow] (evaluate.east) -- node[midway, above] {$\timecost{e}$} (extendEval);
    
    % Arrows from the extended coordinate
    \draw [arrow] (extendEval) -- node[midway, above] {$q \ \ \ $} (yes.west);
    \draw [arrow] (extendEval) -- node[midway, below] {$1-q \ \ \ \ $} (no.west);

    \draw [arrow] (yes.north) to[out=90,in=-145] node[midway, right] {$\ \ \ \ \ \handofftime{}$} (task4.west);
    \draw [arrow] (no.south) to[out=-165,in=-30] (prompt.south);

\end{tikzpicture}}
   \end{center}
  \footnotesize{
  \emph{Notes:} This figure illustrates the iterative process of using AI to complete an augmented task.  
  For simplicity, we assume that all tasks have the same human time cost, $\humantime{}$, and hand-off time requirement, $\handofftime{}$.  
  To complete Task 3, the human can either perform the task manually at a cost of $\humantime{}$, or provide a prompt at a cost of $\timecost{p}$. 
  The AI then generates an output, and the human evaluates whether it meets their needs at a cost of $\timecost{e}$.  
  If it does not, the process repeats with a refined prompt.  
  Each iteration of prompting requires a total machine time of $\machinetime{} = \timecost{p} + \timecost{e}$.}
\end{figure}
Assuming that each AI attempt is independent, the expected time worker spends performing the task in AI-augmented manner is
$$\machinetime{} \Biggl( \sum_{\ell=1}^{\infty} \ell\,q\,(1 - q)^{\ell - 1} \Biggr) = \frac{\machinetime{}}{q}.$$

Definitions~\ref{def:manual_task} and~\ref{def:augmented_task} formalize the two modes of performing a single task explicitly.

\begin{definition}[Manual Task]
\label{def:manual_task}
A task is said to be manual if it is executed entirely by a human worker without AI assistance.
The associated skill and time costs for a manual task are denoted by $(\humanhc{}, \humantime{})$.
\end{definition}

\begin{definition}[Augmented Task]
\label{def:augmented_task}
A task is said to be augmented if it is executed by the AI, after which its output is reviewed and approved by a human worker.
The associated skill and (expected) time costs of managing an augmented task are denoted by $(\machinehc{}, \frac{\machinetime{}}{q})$, where $q \in (0,1]$ is the AI's probability of successfully completing the task.
\end{definition}

The decision whether to deploy the AI depends on whether the manual cost exceeds the AI management cost.
Proposition~\ref{prop:single} provides the single task augmentation criterion in terms of AI's success probability.

\begin{proposition}[Single Task Augmentation Criterion] 
\label{prop:single}
A job with a single task should be augmented if and only if AI quality exceeds the threshold
$$\underline{q} := \frac{\machinehc{} \; \machinetime{}}{\humanhc{} \; \humantime{}}.$$
\end{proposition}

\begin{proof}
Augmentation is optimal when:
$$\frac{\machinehc{} \; \machinetime{}}{q} \leq \humanhc{} \; \humantime{} \quad \Longleftrightarrow \quad q \geq \frac{\machinehc{} \; \machinetime{}}{\humanhc{} \; \humantime{}} = \underline{q}.$$
\end{proof}

This criterion has intuitive comparative statics: automation becomes more attractive when the manual execution cost is high, the management cost is low, or the AI's success probability $q$ is high (or equivalently, the task's completion difficulty $d$ is low).
One implication is that improvements in prompting and evaluation tools---thereby reducing $\timecost{p}$ and $\timecost{e}$---can lower the management cost and make automation more appealing, even if task difficulty remains unchanged.
Although the assumptions of independent success probabilities and constant management costs might seem strong, they are relatively mild and can be adjusted by redefining parameters if necessary (e.g., if outcomes are positively correlated, the effective success probability can be treated as lower; see Sections~\ref{sec:correlated_successes} and~\ref{sec:constant_management_costs}).

For a given AI success probability $q$, the expression below shows how the overall cost parameters of a task are set by the trade-off between its manual execution and AI-augmentation costs.
$$(\hccost{}, \timecost{}) = argmin \Bigl\{\frac{\machinehc{} \; \machinetime{}}{q},\, \humanhc{} \; \humantime{}\Bigr\}.$$
Geometrically, this says that each task can be represented by two distinct rectangles: one with height $\humanhc{}$ and width $\humantime{}$ and another with height $\machinehc{}$ and width $\frac{\machinetime{}}{q}$.
Whichever one of the two admits a smaller area will determine the cost characteristics of the task (in isolation) in the production process.



\subsection{Two-Task Production with the Possibility of Chaining: Task Automation}
Although we will eventually consider longer sequences of tasks, most of the important points of the model can be illustrated with just two tasks.
Consider a job consisting of two sequential tasks, indexed as $1$ and $2$.
We start by formally introducing task automation and AI chains.
\begin{definition}[Automated Task]
\label{def:automated_task}
A task is said to be automated if it is executed entirely by AI without direct human intervention, and its output is passed directly to a subsequent AI-executed task.
The direct human costs (in both skill and time dimension) associated with an automated task are zero.
\end{definition}

\begin{definition}[AI Chain]
\label{def:ai_chain}
An AI (or machine) chain is a contiguous block of two or more sequential tasks executed by AI, in which all tasks but the final one are automated, and the final task is augmented.
An AI chain spanning tasks $(1,\dots,r)$ has tasks $(1,\dots,r-1)$ automated and task $r$ augmented.
The skill and time costs of an AI chain are given by:
\[
\left(\machinehc{r}, \frac{\machinetime{r}}{\prod_{s=1}^{r} q_s}\right),
\]
where $q_s$ denotes the AI success probability for task $s$.
\end{definition}

In the two-tasks setting, each task can be executed according to the following constraints:
\begin{enumerate}
\item Task $1$ can be executed manually, augmented by AI, or automated by AI.
\item Task $2$, being the last task, can only be executed manually or augmented by AI, since automation requires a subsequent AI-executed task which cannot apply to Task 2.
\end{enumerate}

For notation, when a human performs the task without AI, we denote it as $\human{\cdot}$.
When an AI attempts the task, we denote it as $\machine{\cdot}$.
In the three tasks occupation example from earlier, if in the [1][2][3] design the first task is done by AI and the other two by humans without AI, we would write $\machine{1}\human{2}\human{3}$.

Denote the corresponding AI success probabilities of Task 1 and 2 with \(q_1\) and \(q_2\). 
Let $\cost{.}$ show the total cost of completing an arrangement of tasks.
With two tasks, there are four possible ``direct'' production arrangements:
\begin{align*}
    \cost{\human{1}\human{2}} &= \humanhc{1} \; \humantime{1} + \humanhc{2} \; \humantime{2} & \text{(fully human)}, \\
    \cost{\machine{1}\human{2}} &= \machinehc{1} \; \frac{\machinetime{1}}{q_1} + \humanhc{2} \; \humantime{2} & \text{(partial augmentation)}, \\
    \cost{\human{1}\machine{2}} &= \humanhc{1} \; \humantime{1} + \machinehc{2} \; \frac{\machinetime{2}}{q_2} & \text{(partial augmentation)}, \\
    \cost{\machine{1}\machine{2}} &= \machinehc{1} \; \frac{\machinetime{1}}{q_1} + \machinehc{2} \; \frac{\machinetime{2}}{q_2} & \text{(independent augmentation)}.
\end{align*}
In the arrangement $\machine{1}\human{2}$, task 1 is augmented; in $\human{1}\machine{2}$, task 2 is augmented; and in $\machine{1}\machine{2}$, both tasks 1 and 2 are augmented.  

There is also a fifth arrangement where the tasks are chained, and the (automated) first task is used as input for the (augmented) second task without human intervention.
When tasks are chained, denoted by $\machine{1|2}$, they are executed by the AI with a single prompt and final evaluation.
The AI must succeed in \emph{both} tasks for the chain to be successful in a single attempt.
The cost of this arrangement is:
\begin{align*}
\cost{\machine{1|2}} &= \machinehc{2} \; \frac{\machinetime{2}}{q_1 q_2} & \text{(chained automation)}.
\end{align*}
This captures the notion of agentic AI that can complete a sequence of tasks autonomously, without human intervention between the two tasks.
The complete cost function for this production is given by:
\begin{align}
  \min \left\{ 
  \humanhc{1} \; \humantime{1} + \humanhc{2} \; \humantime{2}, \;\; 
  \machinehc{1} \; \frac{\machinetime{1}}{q_1} + \humanhc{2} \; \humantime{2}, \;\; 
  \humanhc{1} \; \humantime{1} + \machinehc{2} \; \frac{\machinetime{2}}{q_2}, \;\; 
  \machinehc{1} \; \frac{\machinetime{1}}{q_1} + \machinehc{2} \; \frac{\machinetime{2}}{q_2}, \;\; 
  \machinehc{2} \; \frac{\machinetime{2}}{q_1 q_2}
  \right\}.
\end{align}
Note that as each term is linear in the cost parameters, the overall cost function is convex.

Figure~\ref{fig:two_tasks} shows the cost-minimizing production arrangement for different levels of \(q_1\) and \(q_2\), with time costs \(\humantime{1} = \humantime{2} = 3\) and skill costs as well as management time costs all set to 1: \(\machinetime{1} = \machinetime{2} = 1\) and \(\humanhc{1} = \humanhc{2} = \machinehc{1} = \machinehc{2} = 1\).
The figure partitions the \(q_1\) and \(q_2\) space into five regions, corresponding to the five production arrangements.
According to Proposition~\ref{prop:single}, the ratio 
\[
\underline{q} := \frac{\machinehc{} \; \machinetime{}}{\humanhc{} \; \humantime{}}
\]
is the threshold for augmenting a task.
Interior to this \(\underline{q}\)-box, we strictly have human production for both tasks, or \(\human{1}\human{2}\).
Investing in \(q_1\) and \(q_2\) offers no immediate return in the \(\human{1}\human{2}\) region.
However, once either task switches augmentation, we gain from increasing AI quality further, but at a diminishing rate, so long as the other task is still done by humans.
These regions are the \(\machine{1}\human{2}\) and \(\human{1}\machine{2}\) regions.

\begin{figure}[h!]
  \caption{Cost-minimizing production arrangements with two tasks with different AI success probabilities} \label{fig:two_tasks}
  \begin{center}
  \includegraphics[width = 0.8 \textwidth]{plots/two_tasks.pdf} \\
  \end{center}
\begin{footnotesize}
  \emph{Note:} This contour plot shows the cost-minimizing production arrangement for different levels of \(q_1\) and \(q_2\).
  The regions are \(\human{1}\human{2}\) (both done fully by humans), \(\machine{1}\machine{2}\) (both done by AI with human oversight), \(\machine{1}\human{2}\) (Task 1 done by AI with human oversight, Task 2 done fully by human), \(\human{1}\machine{2}\) (Task 1 done fully by human, Task 2 done by AI with human oversight), and \(\machine{1|2}\) (both tasks done by AI, Task 1 automated and Task 2 with human oversight).
\end{footnotesize}
\end{figure}

The most interesting region is \(\machine{1|2}\).
Note that its boundaries with the partially augmented regions (i.e., \(\machine{1}\human{2}\) and \(\human{1}\machine{2}\)) are sloped, meaning that improvements in one task's AI quality can bring it into the \(\machine{1|2}\) automation chain region, without an intervening augmentation step.

This curved boundary is the reason chaining can be optimal even when humans have a comparative advantage in one of the tasks in isolation.
Proposition~\ref{proposition:interdependence} formalizes this idea, which can be shown simply with a numerical example.

\begin{proposition}[Task Interdependence] \label{proposition:interdependence}
Assume that both tasks share the same human cost parameters $(\humanhc{}, \humantime{})$, and the same machine cost parameters, $(\machinehc{}, \machinetime{})$.
A task may be optimally executed as part of a chain even if humans have a comparative advantage when performing that task in isolation.
In particular,
\[
\cost{\human{1}\machine{2}} < \cost{\machine{1}\machine{2}}
\]
does not imply
\[
\cost{\human{1}\machine{2}} < \cost{\machine{1|2}}.
\]
\end{proposition}
\begin{proof}
A single counterexample suffices to show this.
Take both human and AI skill requirements to be the same and normalized to one: \(\humanhc{} = \machinehc{} = 1\).
Consider the parameter values $q_1 = \frac{3}{5}$, $q_2 = \frac{4}{5}$, $\humantime{} = \frac{3}{2}$, and $\machinetime{} = 1$.
For task 1 in isolation, human performance is more cost-effective:
\[
\humantime{} = \frac{3}{2} < \frac{5}{3} = \frac{\machinetime{}}{q_1}.
\]
However, the chained tasks arrangement has a lower cost despite the human's comparative advantage in task 1:
\begin{align*}
    \cost{\human{1}\machine{2}} &= \; \humantime{} + \frac{\machinetime{}}{q_2} = \frac{11}{4}, \\
    \cost{\machine{1|2}} &= \frac{\machinetime{}}{q_1 q_2} = \frac{25}{12} < \frac{11}{4}.
\end{align*}
\end{proof}
%In Appendix~\ref{app:AI_capability_inv_comp_stat} we discuss the comparative statics of investment in AI capabilities.


\subsection{Production with \(n > 2\) Tasks: Dynamic Programming}
Now consider a production process consisting of a sequence of \(n\) tasks, indexed as \(\{1, 2, \ldots, n\}\).
First, Table~\ref{tab:tree} illustrates that increasing the number of tasks from $n=2$ to $n=3$ introduces substantially more complexity in number of possible production arrangements (form 5 for $n=2$ to 13 for $n=3$).
\begin{table}
  \centering
  \caption{The possible scenarios with \(n \in \{1,2,3\}\) tasks production}
  \label{tab:tree}
  \begin{tabular}{ccc}
  \hline
  1 Task & 2 Tasks & 3 Tasks \\
  \hline
  $(1)$ & $(1)(2)$ & $(1)(2)(3)$ \\
  $\langle 1 \rangle$ & $(1)\langle 2 \rangle$ & $(1)\langle 2\rangle(3)$ \\
   & $\langle 1 \rangle(2)$ & $(1)(2)\langle 3\rangle$ \\
   & $\langle 1 \rangle\langle 2 \rangle$ & $(1)\langle 2\rangle\langle 3\rangle$ \\
   & $\langle 1|2 \rangle$ & $(1)\langle 2|3\rangle$ \\
   & & $\langle 1\rangle(2)(3)$ \\
   & & $\langle 1\rangle\langle 2\rangle(3)$ \\
   & & $\langle 1|2\rangle(3)$ \\
   & & $\langle 1\rangle(2)\langle 3\rangle$ \\
   & & $\langle 1\rangle\langle 2\rangle\langle 3\rangle$ \\
   & & $\langle 1|2\rangle\langle 3\rangle$ \\
   & & $\langle 1\rangle\langle 2|3\rangle$ \\
   & & $\langle 1|2|3\rangle$ \\
  \hline
  \end{tabular}
\end{table}
The number of valid arrangements in the general case with $n$ tasks is given by Proposition~\ref{proposition:num_arrangements}.
Specifically, the proposition shows that the number of ways to arrange \(n\) tasks is the Fibonacci number \(F(2n+1)\), where \(F(0) = 1\).
For example, when \(n=1\), there are two possibilities---either \(\human{1}\) or \(\machine{1}\)---so \(F(3) = 2\).
With two tasks, we have \(F(5) = 5\) possible arrangements; with three tasks, we have $F(7)=13$ arrangements, and so on.

\begin{proposition}[Recursion for Valid Arrangements] \label{proposition:num_arrangements}
  Let \(f(n)\) denote the number of valid arrangements of \(n\) tasks in a job, where each task can be either performed fully by a human (exactly one task per human block) or as part of a machine chain (a consecutive sequence of automated and augmented tasks). Then the following recurrence holds:
  \[
  f(n) = f(n-1) + \sum_{s=1}^{n} f(n-s),
  \]
  with the base case \(f(0) = 1\).
\end{proposition}

\begin{proof}
Consider the first block in the arrangement of \(n\) tasks:
\begin{itemize}
    \item \textbf{Case 1: Human block.} If the first task is performed fully by a human, then the remaining \((n-1)\) tasks can be arranged in any valid way. This contributes \(f(n-1)\) arrangements.
    \item \textbf{Case 2: AI chain.} If the first block is a machine chain covering \(\ell\) tasks (\(1 \leq \ell \leq n\)), then the remaining \((n-\ell)\) tasks can be arranged in any valid way. Summing over all possible lengths of the first machine chain gives \(\sum_{s=1}^{n} f(n-s)\) arrangements.
\end{itemize}
Adding the contributions from both cases, we obtain:
\[
f(n) = f(n-1) + \sum_{s=1}^{n} f(n-s).
\]
\end{proof}


\subsubsection{Recursive Cost Formulation of DP Problem}
\label{sec:recursive_formulation}
Finding the minimum cost arrangement of tasks and the optimal job design can be formulated as a dynamic programming problem.
Here we present a recursive formulation of the firm's cost minimization problem and in section \ref{sec:DP_approximation} propose an approach to calculate an approximation of the DP problem's solution.

Consider an occupation with $n$ tasks, indexed by \(i = 1, 2, \ldots, n\).
Define $V(i,j)$ as the minimum cost required to complete tasks $1$ through $i$, given exactly $j$ distinct jobs have been created so far.
The function $V(i,j)$ includes all job hand-off costs incurred between previous jobs \emph{and} the current job $j$, which, by construction, ends precisely with task $i$.

To fully characterize the DP solution, we introduce an auxiliary function $W(i,\; j,\; \hccost{\J},\; \timecost{\J})$.
This function denotes the minimum cost of completing tasks $1$ through $i$, as well as an additional set of tasks $\J$ assigned to worker $j$ (referred to as ``active worker''). 
This function $W(i,\; j,\; \hccost{\J},\; \timecost{\J})$ includes hand-off costs between previous jobs but, unlike $V(i,j)$, excludes any hand-off cost associated with the current active job.
The active worker $j$'s assigned set $\J$ may contain zero or more tasks, with cumulative skill and time costs given by:
\[
\hccost{\J} = \sum_{k \in \J} \hccost{k}, 
\quad
\timecost{\J} = \sum_{k \in \J} \timecost{k}.
\]
Note that the set $\J$ assigned to active worker $j$ is not necessarily final, as additional tasks beyond task $i$ could still be assigned to the worker in subsequent steps.
In this sense, $W(i,\; j,\; \hccost{\J},\; \timecost{\J})$ captures the minimum cost across all feasible execution plans that may potentially expand active worker $j$'s task assignment.

Below definition links the two cost functions $V(\cdot)$ and $W(\cdot)$.
\begin{definition}
\label{def:V_W}
For all $i \leq n$, we have $V(i,j) = W(i,\; j,\; 0,\; \handofftime{i})$.
\end{definition}
Definition~\ref{def:V_W} reflects the idea that, in $V(i,j)$, job $j$ ends precisely with task $i$, as no further tasks are considered at this stage.
Consequently, the hand-off cost associated with task $i$ must be incurred immediately by worker $j$.
Equivalently, this can be thought of as assigning worker $j$ an additional task with zero skill requirement but a time cost equal to the hand-off cost of task $i$ right after task $i$ itself.
This scenario is represented explicitly by $W(i,\; j,\; 0,\; \handofftime{i})$.

The solution to the firm's overall cost minimization problem is given by $V(n,\; J)$, where $J$ denotes the optimal number of jobs.
Note that, by the definition given in \ref{sec:handoff_intro}, the last task in the production process has no hand-off costs associated with it (i.e., $\handofftime{n} = 0$).
Thus, for the last task we trivially have $V(n, J) = W(n,\; J,\; 0,\; 0)$.
The optimal solution of the dynamic programming problem is characterized by the recursive formulation provided in Proposition~\ref{prop:recursive_optimality}.

\begin{proposition}[Recursive Formulation of Job Design Problem]
\label{prop:recursive_optimality}
Define the base case for $i=0$ as:
\[
W(0,\; 0,\; \hccost{\J},\; \timecost{\J}) 
= 
\left(v_L + \hccost{\J}\right) \timecost{\J}, 
\quad
\text{for all $\hccost{\J}, \timecost{\J}$}.
\]
Then, for each $i \geq 1$, the minimum cost function $W(i,\; j,\; \hccost{\J},\; \timecost{\J})$ satisfies the following recursive relation:
\begin{align*}
W(i,\; j,\; \hccost{\J},\; \timecost{\J})
= \min\Biggl\{ 
& \left(v_L + \hccost{\J}\right) \timecost{\J} \; + \; V(i,j), \\
& \ W(i-1,\; j,\; \hccost{\J} + \humanhc{i},\; \timecost{\J} + \humantime{i}), \\
& \ \min_{r \geq 1} \ W\left(i - r,\; j,\; \hccost{\J} + \machinehc{i},\; \timecost{\J} + \frac{\machinetime{i}}{\prod_{s=i-r+1}^{i} q_s}\right)
\Biggr\}.
\end{align*}
The cost of the optimal job design for a sequence of $n$ tasks is $V(n,\; J) = W(n,\; J,\; 0,\; 0)$, where $J$ is the optimally determined number of jobs.
\end{proposition}

The recursive formulation in Proposition~\ref{prop:recursive_optimality} evaluates the minimum cost among three distinct alternatives at each step:
\begin{itemize}
    \item \textbf{Option (1):} The term $\left(v_L + \hccost{\J}\right) \timecost{\J} \; + \; V(i,j)$ corresponds to terminating active worker $j$'s job at task $i$, and assigning the tasks in set $\J$ to worker $j+1$. 
    This requires worker $j$ to incur the hand-off cost of task $i$, which is captured through $V(i,j)$.

    \item \textbf{Option (2):} The term $W(i-1,\; j,\; \hccost{\J} + \humanhc{i},\; \timecost{\J} + \humantime{i})$ corresponds to assigning task $i$ to the current active worker $j$ for manual completion. 
    In this case, the manual execution costs $(\humanhc{i}, \humantime{i})$ of task $i$ are added to the accumulated costs of tasks already assigned to worker $j$, extending their job (from task $i-1$) to include task $i$ as well.

    \item \textbf{Option (3):} The term $\min_{r \geq 1} \ W\left(i - r,\; j,\; \hccost{\J} + \machinehc{i},\; \timecost{\J} + \frac{\machinetime{i}}{\prod_{s=i-r+1}^{i} q_s}\right)$ also corresponds to extending active worker $j$'s job from $i-1$ to $i$, but by having them perform task $i$ in an AI-augmented manner. 
    This way task $i$ is chained with zero or more preceding (automated) tasks, adding the associated optimal AI management costs to the active worker $j$'s task set at task $i-1$.
\end{itemize}
Note that in evaluating option (3) of the recursive step for $W(i,\; j,\; \hccost{\J},\; \timecost{\J})$, task $i$ can only be augmented (rather than automated) as there are no subsequent tasks in the sequence at that stage.
Automation of task $i$ is permissible only in cost calculations for subsequent tasks $i+1, \dots, n$.



\subsection{Approximation of the DP Problem's Solution}
\label{sec:DP_approximation}
We can solve for the optimal cost in the dynamic programming problem, filling in the values of $W(i,\; j,\; \hccost{},\; \timecost{})$ for all $i$, $\hccost{}$, and $\timecost{}$.  
To make this a finite table, we will discretize all skill costs $\hccost{}$ and time costs $\timecost{}$ to powers of $(1+\epsilon)$, where $\epsilon > 0$ is an arbitrarily small error term.
As time and skill costs are multiplied together to generate total costs, this discretization introduces a multiplicative error of at most $(1+\epsilon)^2$ into our cost calculations.

Moreover, note that we also accumulate time and skill costs additively when chaining tasks together for a single worker.  
But this results in a total multiplicative error of at most $(1+\epsilon)$ on the total time and skill costs, given that each individual time and skill cost is subject to a multiplicative rounding error up to $(1+\epsilon)$.

Thus, if we fill in our table for all $W(i,\; j,\; \hccost{},\; \timecost{})$ where $i \leq n$ and $\hccost{}$ and $\timecost{}$ are discretized into powers of $(1+\epsilon)$, ranging from the smallest individual task's time and skill costs up to the sum of the time and skill costs over all $n$ tasks (representing the worst-case accumulated cost), we obtain a $(1 + O(\epsilon))$ approximation to the optimal solution.
This computation runs in time polynomial in $n$, $\frac{1}{\epsilon}$. % and the ratio between the minimum and maximum individual task costs?
In particular, the algorithm computes solutions for:
\begin{itemize}
\item $n$ task indices (from $1$ to $n$),
\item $O(\frac{n}{\epsilon})$ discretized time buckets,
\item $O(\frac{n}{\epsilon})$ discretized skill buckets.
\end{itemize}
Multiplying these yields a total time complexity of:
\[
O\left(n \times \frac{n}{\epsilon} \times \frac{n}{\epsilon}\right) = O\left(\frac{n^3}{\epsilon^2}\right).
\]





%%%%%%%%%%%%%%%% AI Advancements and Job Redesign %%%%%%%%%%%%%%%%
\section{AI Advancements and Job Redesign}
\label{sec:job_redesign}

So far, we have discussed how the firm decides to design jobs in a static environment taking task costs ($\hccost{}, \timecost{}$) as given.
In this section we discuss how the two cost components are affected following an AI shock.
An exogenous improvement in AI quality---captured by an increase in $\alpha$---potentially lowers the cost of completing task $i$ in both dimensions:\footnote{For simplicity, we abstract away from specifying how the human capital cost changes as AI improves. In our analysis the exact form of cost reductions in the human capital dimension is not important.}
\[
\widetilde{\timecost{i}}(\alpha) = min\{\humantime{}{}[i], \frac{\machinetime{}{}}{\widetilde{q_{i}}}\} \le min\{\humantime{}{}[i], \frac{\machinetime{}{}}{q_{i}}\} = \timecost{i},
\qquad
\widetilde{\hccost{i}}(\alpha) \le \hccost{i},
\]
where $\widetilde{q_{i}} := \widetilde{q_{i}}(\alpha) \geq q_{i}$ is the improved AI quality. 
We suppress the dependencies of both cost parameters on $\alpha$ for simplicity of notation but maintain the assumption that both time and human capital costs implicitly depend on the AI quality parameter.
Note that AI improvements can be disproportionate across tasks (hence, the $i$ subscript) and thus time and human capital cost savings may vary across occupation tasks.
In other words, some tasks may see large declines in time or human capital costs, while others may experience minimal (or no) cost reductions.  
%The AI improvement can also generate entirely new “oversight” tasks (e.g., prompt‐engineering, exception handling) with their own \(\bigl(\hccost{o},\,\timecost{o}\bigr)\).

We investigate AI’s impact over two horizons.
In the short run, due to frictions, AI advances drive down only the time costs of each task while the human capital costs remain fixed.
Faced with faster completion times, the firm can either plug the higher quality AI into its existing job structure to pocket the immediate time cost savings, or pay a one‐off redesign fee to reorganize tasks and fully capitalize on the new AI capabilities.

In the long run, costs in both time and human capital dimensions can flexibly adjust.
The firm essentially re-solves its job design problem specified in Equation~\ref{eq:totalcost_with_handoff} given the new cost parameters \((\widetilde{\hccost{}}, \widetilde{\timecost{}})\).


\subsection{Short Run AI Improvements}

In the short run, each task’s human‐capital requirement \(c_{i}\) is fixed at its previous level, while AI advances lower time costs from \(t_{i}\) to \(\widetilde t_{i}\).  
These lower time costs can render the existing job design \(\{\J^{(0)}\}\) suboptimal, but reorganizing tasks requires a one‐off redesign expense.  
The firm must choose between:  
\begin{enumerate}
  \item Keeping the current job design \(\{\J^{(0)}\}\) and capturing only the direct time‐cost savings, or  
  \item Paying the redesign fee to shift to the new optimal job structure \(\{\J^*\}\) and fully exploit the improved AI.
\end{enumerate}
We look at each scenario separately.

\paragraph{Scenario (1): No Job Redesign.}
Firm's gains from AI improvements at its previous job design will be:
\begin{equation}
\label{eq:no_redesign_gains}
\text{NoRedesignGains}(\J^{(0)}, \alpha)
:=
\text{TotalCost}(\J^{(0)}; \hccost{}, \timecost{}) - \text{TotalCost}(\J^{(0)}; \widetilde{\hccost{}}, \widetilde{\timecost{}}).
\end{equation}
This is the net gains \emph{only} from immediate time cost savings in the old job structure.
Note that by definition, the time cost savings is weakly greater than zero, so the firm always deploys the new technology.\footnote{None of the implications of the model will change if we assume adoption of the new technology comes at a nonzero, fixed cost.}
%Also, assuming reductions in costs in both dimensions are smooth the function above is a continuous function of $\alpha$.

\paragraph{Scenario (2): Redesigning Jobs.}
If the firm chooses to restructure jobs to the new optimal design \(\{\J^*\}\) its cost savings from this change will be:
\begin{equation}
\label{eq:job_redesign_direct_savings}
\text{DirectRedesignGains}(\J^{(0)}, \alpha)
:=
\text{TotalCost}(\J^{(0)}; \hccost{}, \timecost{}) - \text{TotalCost}(\J^{*}, \widetilde{\hccost{}}, \widetilde{\timecost{}}).
\end{equation}
This is the savings from \emph{both} exploiting the reduced time costs \emph{and} job redesign.
Reallocating tasks to new jobs is costly though.
The firm must incur two one-off costs for redesigning jobs:
\begin{enumerate}
\item A fixed cost per job definition change: each time the firm redesigns a job it must incur a fixed redesign cost $\kappa$ for that job change.
This can be interpreted as the administrative costs associated with reorganizing that job.
\item A training cost for the \emph{new} set of skills workers need in their new jobs: the firm must compensate workers for acquiring new human capital.\footnote{If a task is removed from worker's job, no transfer is made between the worker and the firm, and the worker's human capital for doing that task immediately deprecates to 0.}
\end{enumerate}
The one-time cost of redesigning jobs from $\J^{(0)}$ to $\J^{*}$ is:
\begin{equation}
\label{eq:job_redesign_cost}
\text{RedesignCosts}(\J^{(0)}, \alpha)
:=
\sum_{j=1}^{J}
\Bigl[
\underbrace{\kappa\,\mathbf1\{\J_j^*\neq\J_j^{(0)}\}}_{\text{Administrative redesign cost}}
\;+\;
\underbrace{\sum_{i\in\J_j^*\setminus\J_j^{(0)}}\hccost{i}}_{\substack{
\text{Training cost of new tasks}\\ 
\text{in the new design of job $j$}}
}
\Bigr].
\end{equation}
Notice that the redesign costs also depends on the AI quality parameter $\alpha$ since that determines the optimal job design $\J^{*}$.
Total gains from job redesign will thus be:
\begin{equation}
\label{eq:job_redesign_gain}
\text{TotalRedesignGains}(\J^{(0)}, \alpha)
:=
\text{DirectRedesignGains}(\J^{(0)}, \alpha)
\;-\;
\text{RedesignCosts}(\J^{(0)}, \alpha).
\end{equation}

Proposition~\ref{prop:shortrun_redesign} characterizes the firm’s short-run redesign decision.
\begin{proposition}[Short-Run Job Redesign Decision] 
\label{prop:shortrun_redesign}
Let $\J^{(0)}$ be the current optimal partition (which by assumption is not the plan that fully automates every task in one long chain) and let $\J^*$ be the re-optimized partition under some improved AI quality.
The firm switches from $\J^{(0)}$ to $\J^*$ in the short run if and only if:
\[
\mathrm{TotalCost}\bigl(\J^{(0)};\,\widetilde{\hccost{}},\,\widetilde{\timecost{}}\bigr)
\;-\;
\mathrm{TotalCost}\bigl(\J^*;\,\widetilde{\hccost{}},\,\widetilde{\timecost{}}\bigr)
\;\ge\;
\mathrm{RedesignCost}\bigl(\J^{(0)},\,\J^*\bigr).
\]
Furthermore, for any pre-shock design $\J^{(0)}$ (other than full automation) there exists a unique threshold $\tilde{\alpha}$ such that for all $\alpha>\tilde{\alpha}$ the above inequality holds strictly and the firm strictly prefers to redesign jobs.
\end{proposition}
See Appendix~\ref{app:shortrun_redesign_proof} for the proof.
In words, Proposition~\ref{prop:shortrun_redesign} states that so long as pure gains from redesigning jobs is larger than its costs the firm will reallocate tasks even in the short run.
Moreover, the existence of a unique AI‐quality threshold implies a tipping‐point effect: although any AI improvements will reduce production costs, it is not worthwhile to redesign jobs in the short run until AI quality exceeds a certain threshold, at which point restructuring becomes optimal. 


\subsection{Long Run AI Improvements}  

Workers can retrain (redeploy human capital) and firms freely re‐partition tasks.
The firm essentially re-solves its problem using the new time cost parameters \((\widetilde{\hccost{}}, \widetilde{\timecost{}})\), yielding a new, long-run optimal design \(\{\widetilde{\J_j}\}\).  
In the new design:
\begin{itemize}
  \item The adjusted time costs \(\widetilde{\timecost{i}}\) weakly decrease, and some tasks may drop out entirely if $\alpha$ is high enough (full automation, where either the time cost component or the human capital component of the task shrinks to 0).
  \item The hand‐off component of the wage bill,
  \[
    \sum_{j=1}^J \Bigl(v_L + \sum_{i\in\J_j}\widetilde{\hccost{i}}\Bigr)\,\widetilde{\handofftime{j}},
  \]
  potentially falls because:
  \begin{itemize}
    \item the human‐capital terms decrease; and/or
    \item \(\widetilde{\handofftime{j}}\)s decline if AI chains tasks across jobs more efficiently, or assists with hand‐offs.
  \end{itemize}
  \item New oversight tasks \(\{o\}\) enter \(\T\), redirecting effort toward exception handling and quality control. These tasks typically require less human capital \(\widetilde{\hccost{o}}\) than those they replace, lowering overall human capital requirements across the occupation.
\end{itemize}
One can imagine that the firm incurs a redesign cost similar to Equation~\ref{eq:job_redesign_cost} for the long-run redesign problem as well.

The next section introduces a general equilibrium model with many goods and provides a concrete framework to study implications of AI advances on workers.


%%%%%%%%%%%%%%%% General Equilibrium %%%%%%%%%%%%%%%%
\begin{comment}
\section{General Equilibrium}
\label{sec:GE}

\subsection{Task-Based Production}
\label{sec:prod_GE}

We now connect the model of production introduced in Section \ref{sec:taskbased_prod} into a general equilibrium framework.
Consider an economy with $K$ final goods and the same production function as discussed earlier.
A single firm produces and trades all goods under perfect competition in separate markets.
For each good $k \in \{1, 2,\ldots,K\}$, production requires completing an ordered set of tasks, denoted by:
\[
\T_k = \{1,2,\ldots,n_k\}.
\]
We refer to $\T_k$ as the production process for good $k$.
Notice that the equation above is essentially the same as Equation~\ref{eq:tasks} with the only difference being a subscript $k$ that denotes a typical final good in the $K$-good economy.

Suppose the firm breaks down the production process $\T_k$ into $J^k$ jobs, each of which consist of a contiguous block of tasks.
Let $\J_j^k$ denote the collection of tasks in job $j \in \{1, 2, \ldots, J^k\}$ in the production process of final good $k$.
With this notation, the four potential job designs in the earlier example with $n_k=3$ tasks can be expressed as:
\begin{align*}
\{[1][2][3]\}_k \Longleftrightarrow \ J^k = 3:  & \quad \J^k_1 = \{1\}, \quad \ \ \ \J^k_2 = \{2\}, \quad \ \ \J^k_3 = \{3\}, \\
\{[1,2][3]\}_k \Longleftrightarrow \ J^k = 2: & \quad \J^k_1 = \{1, 2\}, \ \ \ \J^k_2 = \{3\}, \\
\{[1][2,3]\}_k \Longleftrightarrow \ J^k = 2: & \quad \J^k_1 = \{1\}, \quad \ \ \ \J^k_2 = \{2, 3\}, \\
\{[1,2,3]\}_k \Longleftrightarrow \ J^k = 1: & \quad \J^k_1 = \{1,2,3\}.
\end{align*}

Assume that the worker employed in job $j$ produces an intermediate good $x_j^k$ and sells it to the firm in a perfectly competitive market.
The firm buys all intermediate goods $\{x_1^k, \ldots, x_{J^k}^k\}$ from workers and produces the final good $x_k$ at no additional cost using a Leontief production function:
\[
x_k(x_1^k, \ldots, x_{J^k}^k) = min\{x_1^k, \ldots, x_{J^k}^k\}.
\]
This implies that, in equilibrium, the amount of final good $x_k$ produced is the same as the amount of each intermediate good $x_j^k$ used in production of that final good.
This is merely a technical assumption reflecting the fact that to produce one unit of the final good each set of tasks in $\T_k$, across all $J^k$ jobs in sector $k$, must be performed exactly once.
For example, in the case with $n_k=3$ in equilibrium we have:
\[
x_k = x_1^k = x_2^k = x_3^k
\]
regardless of how the jobs are designed.

We also assume that tasks in $\T_k\!$ are performed in fixed proportions.
For instance, if task $m \in \T_k$ takes 30 minutes and task $n \in \T_k$ (with $m \neq n$) takes 45 minutes, then producing one unit of good $k$ requires a total of 75 minutes spent on $m$ \underline{and} $n$ as both tasks must be performed exactly once; it is not possible to perform task $m$ multiple times while performing task $n$ only once.
We formalize this assumption in Appendix~\ref{app:GE} where we explicitly characterize the equilibrium.


\subsection{Consumption} 
\label{sec:household_GE}
A representative household supplies one unit of labor inelastically and has a CES utility function over the $K$ final goods.
The household's utility is:
\[
U(x_{1}, \ldots, x_{K}) = \Bigl(\sum_{k=1}^{K} \delta_k \,x_k^{\tfrac{\sigma - 1}{\sigma}}\Bigr)^{\tfrac{\sigma}{\sigma-1}},
\quad
0 < \delta_k < 1,
\quad
\sum_{k=1}^{K} \delta_k = 1,
\quad
\sigma > 0,
\]  
where $x_k$ denotes final good $k$.
Goods are substitutes if $ \sigma > 1$, complements if $0 < \sigma < 1$, and $\sigma = 1$ corresponds to the Cobb-Douglas case.  
The household faces budget constraint:  
\[
\sum_{k=1}^K p^k \,x_k = I,
\]  
where $p^k$ is price of final good $k$ and $I$ is the total income earned from supplying labor to different jobs across all sectors.  
The income, $I$, is the total sum of earnings from producing intermediate goods, which the household takes as given when choosing how much of each final good to consume.


\subsection{Equilibrium}
\label{sec:eq_GE}
Let $k \in \{1, \cdots, K\}$ index sectors (or final goods) and $j \in \{1,\cdots, J^k \}$ index jobs within sectors.
Denote total labor employed in sector $k$ with $L_k$.
Equilibrium prices $\big\{ \big\{ w_j^k, p_j^k \big\}_{j=1}^{J^k} \big\}_{k=1}^K$ are: 
\begin{align*}
\labor{j}^k =  \handofftime{j}^k + \sum_{i \in \J_j^k} \timecost{ij}^{k},
& \qquad
w_j^k =  v_L + \sum_{i \in \J_j^k} \hccost{ij}^{k}, 
& \qquad
p_j^k = w_j^k \labor{j}^k, \\
\labor{}^k = \sum_{j=1}^{J^k} \labor{j}^k,
& \qquad
w^k = \frac{\sum_{j=1}^{J_k} w_j^k \labor{j}^k}{\sum_{j=1}^{J^k} \labor{j}^k},
& \qquad
p^k = w^k \labor{}^k,
\end{align*}
and equilibrium allocations $\big\{ x_k^*, L_k^* \big\}_{k=1}^K$ are:
\begin{align*}
x_k^* = \frac{R_k}{\sum_{\ell=1}^K \labor{}^\ell\,R_\ell},
& \qquad
L_k^* = \labor{}^k\,x_k^* = \sum_{j=1}^{J^k} \labor{j}^k\,x_k^*,
\end{align*}
where
\[
R_k = \Bigl(\frac{p^1}{p^k} \cdot \frac{\delta_k}{\delta_1}\Bigr)^{\sigma}.
\]
The model implies that the job design in production process $\T_k$ (and thus human capital and time costs of tasks) determines $p^k$ and $\labor{}^k$, thereby fully determining the consumption bundle $\{x_k^*\}$ and the labor allocations $\{L_k^*\}$ in equilibrium.
Appendix~\ref{app:GE} gives the full derivation details and further discusses comparative statics with respect to deploying AI for completing tasks (either in an augmented manner or automated manner).



\subsection{Implications of AI Advancements for Wages and Employment}

Here we briefly discuss the implications of an AI advancement on workers wages.

\subsubsection{Short Run}
[TODO: Double Check. These are the results for comparative statics, meaning that only cost changes at a time. Maybe changing multiple things at once would have different implications.]

Only task time durations fall in the short run.
If the firm does not redesign jobs wages remain unchanged as only human capital requirements of a job determines its wage.
Employment, however, will decline for some workers---those whose tasks are now completed faster than before by the help of AI.

If the firm redesigns jobs, wages and/or employment can potentially increase for some while decreasing for others.
Assuming no new tasks are created, redesigning jobs will move at least one task from one job to another.
Since wages are only determined by human capital requirements the wage of worker(s) being assigned new task(s) will increase whereas the wage of worker(s) whose task(s) are removed will fall.
While wages for some workers increases after a redesign, employment may not necessarily follow the same trend.
In particular, one can imagine a case where even despite a worker is assigned a new task in the redesigned job, the total time requirements of all their tasks still goes down.
Generally, if total time requirements of tasks within a job goes up, employment for that job will rise; otherwise, employment will fall.

If new tasks are introduced in the short run, depending on how they are allocated to jobs, wages could go up (if total human capital requirements increase) or down (if total human capital requirements decrease).
Similarly, employment could rise (if total time requirements increase) or fall (if total time requirements decrease).

\subsubsection{Long Run}  
Workers optimally invest in the updated skill set $\{\widetilde{\hccost{i}}\}$, yielding a new wage schedule. Depending on the new cost pairs $\bigl(\widetilde{\hccost{i}},\,\widetilde{\timecost{i}}\bigr)$, worker wages may rise, fall, or remain unchanged.
\end{comment}



%%%%%%%%%%%%%%%% Empirics %%%%%%%%%%%%%%%%
\section{Empirics}

We turn to the 2023 O*NET dataset to motivate the ordered-task-sequence view of jobs. 
O*NET provides a comprehensive list of U.S. occupations, each paired with a corresponding set of tasks. 
These tasks are organized into three levels, ranging from the most specific to the most general: \textit{task}, \textit{detailed work activity}, and \textit{work activity}.
To clarify these distinctions, Table \ref{tab:task_examples} provides examples of tasks at each level for the \textit{``Accountants and Auditors''} occupation. 
The table helps illustrate how tasks become broader as they move from the task level to the work activity level.
\begin{table}[htbp]
\begin{center}
\caption{Examples of Tasks, Detailed Work Activities, and Work Activities}
\label{tab:task_examples}
\resizebox{\textwidth}{!}{
\begin{tabular}{|p{0.4\textwidth}|p{0.37\textwidth}|p{0.55\textwidth}|}
\hline
\multicolumn{1}{|c|}{\textbf{Work Activity}} & \multicolumn{1}{c|}{\textbf{Detailed Work Activity}} & \multicolumn{1}{c|}{\textbf{Task}} \\ \hline
Developing Objectives and Strategies & Develop business or financial information systems. & Develop, implement, modify, and document recordkeeping and accounting systems, making use of current computer technology. \\ \hline
Processing Information & Verify accuracy of financial information. & Review taxpayer accounts, and conduct audits on-site, by correspondence, or by summoning taxpayer to office. \\ \hline
Processing Information & Verify accuracy of financial information. & Prepare, analyze, or verify annual reports, financial statements, and other records, using accepted accounting and statistical procedures to assess financial condition and facilitate financial planning. \\ \hline
Processing Information & Verify accuracy of records. & Inspect cash on hand, notes receivable and payable, negotiable securities, and canceled checks to confirm records are accurate. \\ \hline
Processing Information & Verify accuracy of records. & Examine inventory to verify journal and ledger entries. \\ \hline
\end{tabular}
}
\end{center}
\vspace{-0.15cm}
\textit{Note: This table provides a subset of tasks associated with the``Accountants and Auditors'' occupation.}
\end{table}
In the 2023 dataset, there are 748 unique occupations, 17,945 unique tasks, 2,081 unique detailed work activities, and 38 unique work activities.\footnote{Originally, the O*NET dataset included 798 unique occupations. We exclude 50 of them, all containing the word ``Teachers,'' as these occupations exhibit significant task overlap with highly similar tasks which could otherwise overrepresent the same job in the results.}

In our analysis, we focus on detailed work activities as the main task unit in an occupation. 
From here onward, when we refer to a “task” in the O*NET dataset, we are specifically referring to the detailed work activity associated with each occupation. 
With this definition, the dataset contains 15,645 unique occupation-task pairs, with the average occupation consisting of 21 tasks.

We define the task pair co-occurrence score between tasks $i$ and $j$  as:
$$C_{ij} = \frac{\text{Number of unique occupations in which both $i$ and $j$ appear}}{\text{Number of unique occupations in which at least one of $i$ or $j$ appears}}.$$
For any task pair, this measure ranges from 0 to 1, with higher values indicating a greater likelihood of the tasks appearing together in an occupation.
For task $i$, the (individual) task co-occurrence score is defined as the average of the pairwise co-occurrence scores across all its task pairs. Specifically:
$$C_{i}=\frac{1}{n-1}\sum_{j\neq i}C_{ij},$$ 
where $n$ is the number of unique tasks in the dataset.
Figure \ref{fig:task_cooc} shows the distribution of individual task co-occurrence scores. 
To check that these co-occurrences are not driven by chance, we perform a placebo test by randomly assigning tasks to occupations and plotting both the original and randomized distributions in the same graph. 
As shown in the figure, the blue distribution (original co-occurrence) has a noticeably higher mass on the right tail compared to the orange distribution (randomized co-occurrence), suggesting that a meaningful subset of tasks frequently co-occur across multiple occupations. 
This is counterbalanced by the higher mass on the left tail, indicating that some tasks tend to be specialized and appear only in a few occupations in the original dataset.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.8\textwidth]{plots/indiv_task_cooccurrence_score_histogram.png}
  \caption{Distribution of task co-occurrence scores. Higher scores indicate tasks that frequently appear together within occupations.}
  \label{fig:task_cooc}
\end{figure}

Next, we examine how co-occurring tasks are distributed across occupations. 
Figure \ref{fig:occ_cooc} displays the distribution of occupation co-occurrence scores, defined as the average pairwise co-occurrence score of the tasks that comprise each occupation.
Formally, for occupation $o$, the co-occurrence score is given by:
$$C^o=\frac{1}{|\T_o| ( |\T_o|-1)} \sum_{i\in\T_o} \sum_{j\in\T_o,j\neq i} C_{ij},$$
where $\T_o$ denotes the set of tasks in $o$. 
A higher occupation co-occurrence score suggests that the tasks within the occupation are more likely to appear in pairs with other tasks, indicating a greater likelihood of completing the occupation in “blocks” or “pairs” of tasks. 
We observe in the graph that the majority of occupations exhibit a substantial degree of co-occurrence, which is clearly not random.

% Peyman: here come up with a nice intuition about what this exactly shows. Something like: "A co-occurrence score of 0.1, for example, roughly means that 10\% of an occupation’s tasks are likely those that can be performed in pairs."

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.8\textwidth]{plots/indiv_occupation_cooccurrence_score_histogram.png}
  \caption{Distribution of occupation co-occurrence scores. Higher scores indicate occupations whose tasks frequently appear together across different occupations.}
  \label{fig:occ_cooc}
\end{figure}

Another way to evaluate how tasks are shared between occupations is to use a measure similar to task co-occurrence, but defined specifically for occupations. 
That is, instead of defining a metric at the task level and aggregating it at the occupation level, we directly define the measure at the occupation level. 
This is the approach we take next.
Let
$$S^{xy} = \frac{\text{Number of common tasks between $x$ and $y$}}{\text{Number of all unique tasks across $x$ and $y$}}$$
represent the pairwise occupation similarity score between occupations $x$ and $y$. 
The similarity score quantifies the overlap in tasks between a pair of occupations. 
As with the task-level measure, for occupation $x$, the (individual) occupation similarity score is defined as the average of the pairwise similarity scores across all occupation pairs. 
Specifically:
$$S^{x}=\frac{1}{q-1}\sum_{y\neq x}S^{xy},$$ where $q$ is the total number of unique occupations.
Figure \ref{fig:occ_similarity} shows the distribution of occupation similarity scores. 
We observe that task overlap between occupations is meaningfully different from the scenario in which tasks are randomly assigned to occupations, providing evidence in support of occupations sharing common tasks (though not necessarily in pairs, according to this measure).

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.8\textwidth]{plots/occupation_similarity_score_histogram.png}
  \caption{Distribution of occupation similarity scores. Higher scores indicate occupations whose tasks are shared across more occupations.}
  \label{fig:occ_similarity}
\end{figure}

% Peyman: The occupation similarity-weighted measure doesn't make sense, and thus I cut it from the draft. First, because we decided to remove the "Teachers" occupations which motivated the use of a weighted measure in the first place. Secondly, because the measure isn't perfect as it overweights pairs appearing in occupations with very little task overlap (b/c the small occupation overlap score is inverted). In the graph the orange bars show a higher weighted score exactly because they appear in fewer occupations which have lower task overlap.

% We also calculate the occupation-similarity-weighted task pair scores. In doing so, we weight every task pair occurrence by the inverse of pairwise occupation similarity scores for any two pair of occupations the task pair appears in. 
% Formally: 
% [To fill with a "proper" measure if decided to include it]

% \begin{figure}[htbp]
%  \centering
%  \includegraphics[width=0.8\textwidth]{plots/task_pair_weightedScore_histogram.png}
%  \caption{Distribution of occupation-similarity-weighted task pair scores for task pairs appearing in more than 10 occupations. This metric accounts for both the frequency of task co-occurrence and the similarity between occupations containing these task pairs.}
%  \label{fig:weighted_pairs}
% \end{figure}

Next, let us examine how often specific task combinations occur across different occupations. 
Figure \ref{fig:pair_counts} plots the frequency of co-occurring task pairs. 
Note that the y-axis represents the frequency on a logarithmic scale. 
In the placebo test, almost all task pairs appear in only one or two occupations, whereas in the original data, many pairs appear in multiple occupations. 
Since it is possible that a non-trivial number of pairs co-occur across different occupations due to the way O*NET defines tasks and occupations, we conservatively focus on task pairs that appear in more than 10 occupations and refer to them as “highly co-occurring” tasks.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.8\textwidth]{plots/task_pair_counts_histogram.png}
  \caption{Histogram showing the frequency of task pairs. This visualizes the raw count of how often specific task combinations occur across different occupations. Task pairs to the right of the red dashed line indicate the “highly co-occurring” subset.}
  \label{fig:pair_counts}
\end{figure}

Out of more than 100,000 co-occurring pairs, only 588 are classified as highly co-occurring tasks. 
Although this represents a small fraction of the total co-occurrences, it provides a meaningful subset for analysis.
Within this subset, we observe tasks that appear only a few times in combination with others, as well as tasks that frequently occur across multiple pairs. 
Figure \ref{fig:high_cooc_task} illustrates the distribution of task repetition counts within the highly co-occurring pairs. 
While many tasks appear only a handful of times (on the left side of the graph), some are observed as frequently as 30 or 40 times in different pairs.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.8\textwidth]{plots/highly_cooccurring_tasks_task_repetition_count.png}
  \caption{Distribution of task repetition counts within highly co-occurring tasks. The figure highlights the frequency of tasks appearing in multiple pairs.}
  \label{fig:high_cooc_task}
\end{figure}

Figure \ref{fig:high_cooc_occ} complements the previous finding by showing the distribution of how often a task pair from the same occupation appears within the subset of highly co-occurring combinations.
The more frequently an occupation’s (unique) task pairs appear in this subset, the more likely it is that the occupation consists of different “blocks” of tasks\textemdash if there are no common tasks across appearing pairs\textemdash or that there are potentially more ways to combine or automate tasks\textemdash if the appearing pairs share some tasks.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.8\textwidth]{plots/highly_cooccurring_tasks_occupation_repetition_count.png}
  \caption{Distribution of task pair occurrences within highly co-occurring combinations across occupations. The figure illustrates task pair repetition at the occupation level.}
  \label{fig:high_cooc_occ}
\end{figure}

A somewhat surprising result is that when we aggregate occupations at the two-digit SOC code level, we find that our notion of high task co-occurrence is confined to occupations within two-digit occupation groups. 
This suggests that there will be little to no spillover effects from technological impacts in one group to another.
This occurs despite the fact that these groups share a non-trivial number of tasks with one another. 
Figure \ref{fig:occ_gp_task_heatmap} presents a heatmap showing the number of shared tasks between two-digit SOC occupation groups. 
Although many pairs have zero or one shared task, we also observe a significant number of common tasks. 
However, none of these shared tasks are highly co-occurring tasks, implying that they are more specific to individual occupation groups.
Put differently, these shared tasks correspond to the very small co-occurrence scores on the left side of Figure \ref{fig:task_cooc}.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\textwidth]{plots/occupation_group_common_tasks_heatmap.png}
  \caption{Heatmap showing the number of shared tasks between two-digit SOC occupation groups. Lighter cells indicate fewer shared tasks, while darker cells represent more shared tasks. The number in each cell gives the number of shared tasks between the row and column occupation group.}
  \label{fig:occ_gp_task_heatmap}
\end{figure}



%%%%%%%%%%%%%%%% Discussion %%%%%%%%%%%%%%%%
\section{Discussion}
Below, we discuss some of the implications and features of the model. 
%\subsection{The importance of task adjacency means that automation dispersion is likely}

\subsection{How consequential is linear production?}
If two tasks can proceed in parallel, we can simply model them as having no hand-off costs, of $\handofftime{} = 0$.
It never makes sense to combine two tasks within a single job if with hand-off in between because a less expensive occupation can always be created as $(C_1 + C_2) (t_1 + t_2) > c_1 t_1 + c_2 t_2$.


A lot of multi-tasking in jobs is really more like ``async'' in programming: you get blocked on some task, so you switch to some other task in the iterim.
Despite this, production is still linear---it's just not exactly linear in time.
There are still a sequence of tasks done in order, it is just that you can pause on one for some period of time.



\subsection{YADOLM: Yet Another Division of Labor Model}
We need to get into the micro-details of the production process to understand how AI might be used and how it might change the division of labor. 
Extant models are too stylized to be paired with, say tasks-specific engineering estimates focusing on the content of the tasks.
Second, the model is not just about the division of labor but also the returns to investing in AI capabilities.

Adam Smith attributed the division of labor being limited only by the extent of the market. 
When considering the production of physical goods, this is perhaps a reasonable description. 
But for most knowledge work or complex work generally, modern authors have emphasized the costs of conveying context to some other worker.
For example, \cite{becker1992division} provides a model of the division of labor, with workers choosing to invest in task-specific human capital.
In the model, what constrains further specialization is the cost of coordination between workers, which is just assumed to grow with the size of the team.
There is no notion of the order in which tasks are done, nor some notion of an occupation per se. 

The tasks and sequences of tasks is not completely arbitrary but dictated by the physical, logical, and engineering constraints of the production process.
Some tasks do need to be done in a certain order because some workers will be working on the intermediate goods produced by others.  
Consider the paradigmatic high-skilled knowledge workers creating technology products.
A product manager has to have an idea for how to meet a customer's need. 
That need might be articulated by a customer support rep or a by an analyst pouring over feedback data, or results from a customer survey.
A product designer might need come up with with a sketch for how it might work. 
A financial analyst would model out potential revenue. 
This likely happens in concert with an engineering manager to designan engineering estimate based on preliminary designs. 
Engineer actually needs to build the product and test it.  
Legal has to sign-off and the terms-of-use need to updated.
Once built, it needs to be marketed and supported going forward.
While parallization in tasks is possible, it is constrained by some tasks needing input from other tasks being completed: customer service cannot write a support script until they know what the product is and how it works. 
Engineers can not build it until they have a design.
A designer will not to able to design until they know what problem is being solved and what constraints are being placed on the solution.
And so on.
The \cite{lazear2004balanced} model of balanced entrepreneurship makes the point that for a brand-new startup building its first product, the entrepreneur needs to be able to do everything. 

This modern process requires intense coordination and considerable social skills in a way that putting a head on a pin would not. 
\cite{deming2017growing} provides a model where workers trade with each other to complete tasks; greater social skills unlock benefits from trade in tasks.
The data is very much consistent with his view of increased need to coordinate tasks:
various teams described above might write detailed memos and spend considerable time in meetings, talking and presenting to each other to accompish these hand-offs.
A person with a keen understanding of others likely does this better. 

While the product process is not pin-like, it is also not a free-free-all or self-organized process with trade in tasks: 
each worker is paid to do their part of the process and was hired with a good understanding of the process and their role in it. 
No engineer is free to say ``What has finance done for me lately?'' and hold up a product they are directed to work on.
This is not to ignore the vast literature on incentives problems within firms or the need for coordination, but a lot of coordination has because we have designed jobs with understandable input/output relationships with other workers and peope will do what is expected of them.

\subsection{What about more complex patterns of production?}
Sometimes what triggers a task is not the completion of a previous task, but some other event. 
A customer walks into the store; a vendor calls; a machine breaks; the load of lumber arrives.
And what task is done next could depend on context. 
This could make production not a linear sequence of tasks, but a tree of tasks. 
Progress could be more like a Markov process. 
This would clearly complicate things, but without formally modeling it, it is clear that these considerations would make full automation more difficult.

\subsection{The division of labor tends to create interdependence of tasks within jobs}
Economic forces create dependencies between tasks within jobs. 
Consider pin manufacturing: each step (washing wire, spooling, straightening, cutting, grinding) serves as input to the next, with failures at any point endangering the final product. 
The limit to this division of labor is not technical but economic, as Smith noted.
These tasks could be split more finely, but the costs of switching and communication between workers would outweigh the benefits.
While specialization is primarily constrained by market size, it also faces switching and communication costs when work is handed off between workers. 
These costs create serial dependencies between tasks done with a job---the tasks that make up a job are precisely those tasks that are hard to hand-off to someone else. 
It is unclear why this would be different when we try to automate tasks with machines.


\subsection{Correlated sucessess probabilities do not change the model much} \label{sec:correlated_successes}
There is some unrealism in the model that makes the presentation simpler but elides from pracical considerations.
The model assumes that failures and sucesses are independent, when they might be correlated.
If $\rho$ is the correlation between outcomes, then the expected number of attempts is:
\begin{align}
\mathbb{E}[T] = \frac{1 - q\rho}{q(1 - \rho)} 
\end{align}
rather than $1/q$.
If outcomes are positively correlated, that makes failures more consequential, as the expected number of attempts will be higher. 
This will tend to reduce the value of automation.
But note that we could just think of that task as simply having a $q' = \frac{q(1 - \rho)}{1 - q\rho}$ success rate.
This would, of course, change the realized sequences of tasks, but as we are taking expectations, it does not change the model.

\subsection{Constant management costs do not change the model much} \label{sec:constant_management_costs}
In terms of the constant management cost assumption, we might expect that subsequent attempts are easier fix and less costly, perhaps requiring less work. 
However, this does not change the basic structure of the problem much---if we imagine that, say, costs are declining linearly in the number of tasks, say by $\gamma$ each subsequent task, then we would simply have $\machinetime{} (1-\gamma) / q$ costs instead, with the costs still proportional to $1/q$. 
But in this case, we could just treat $\machinetime{}$ as being $\machinetime{} (1-\gamma)$. 
  
\subsection{Are management costs low skill?}
Prompting and evaluation are human skills.
How high are $c_p$ and $c_e$?
One question is simply how long theose tasks take to do; other is how widely held these skills are in the population.
There is no inherent reason to think that eitehr will itself be a low-skill task.
Most of management is deciding what you want done, asking right people to do it, in a way that leads to an effective outcome, and then monitoring the process to see if it acheiving the desired goals.
  
The decision to use an AI bears similarities to the decision to delegate some task to a subordinate or team.
Doing this well requires being a judge of talent, scoping and explaining projects in ways people will understand, giving good, actionable feedback, and so on. 
And conditional upon delegation, the skill of using AI bears similarities to the management of people and teams. 
Deciding whether the output is sufficient requires judgment, whether the output is human-produced or otherwise. 
But given humans are harder to change the machines, it seems likely that AIs will continue to be modified to make it so that humans can manage them more easily. 
  
\subsection{For evaluation, is the intermediate output a search good, inspection good, or credence good?}
The costs of judging the model's output could vary widely depending on the nature of the task and the person assiged to it.
An analogy can be drawn to the process by which consumers evaluate goods. 
Search goods are trivially easy to evaluate, whereas inspection goods might have prohibitively expensive evaluation costs. 
Or, goods that are credence goods---goods that that the consumer has to take on faith work---might have de facto infinite evaluation costs.
Some goods might be inspection goods for some people and search goods for others. 
If a task requires true expertise to evaluate, the cost of evaluation might be de facto infinite.
  
\subsection{There will be efforts to lower evaluation costs}
Economics classifies goods by the evaluation costs required to assess them, with some tasks like LLM-generated ad copy requiring minimal oversight while others like surgical plans or judicial opinions demand much more rigorous evaluation.
For some tasks, the human is the final arbiter and can immediately decide if the outcome is sufficient, with no further sources needed. 
For example, a model-generated meeting agenda can be evaluated at a glance. 
Other information goods require more costly inspection, like computer code which LLMs can produce but must be tested across different inputs (though test-driven development helps systematize this verification). 
Similarly, math problems often use guess-and-verify approaches or require checking if answers are sensible, even when following standard procedures. 
While critics often point to ChatGPT's factual errors, AIs that can cite sources effectively transform these inspection goods into more easily verifiable search goods.
  
\subsection{One-off nature of AI output hampers the ability to use reviews to evaluate}
Some information goods are consumed over time, and learning about their quality might take time. 
A person might not know if they enjoyed a movie until they have actually watched it. 
For information experience goods, we tend to rely heavily on reviews. 
But this only works when many people potentially evaluate the same good. 
With generative AI, the information good is likely generated uniquely for that particular worker. 
A non-lawyer could not verify whether a commercial contract is likely to hold up to scrutiny by the courts. 
A course of advised medical treatment might be very difficult to judge by a non-expert.
This will likely limit the ability to use reviews to evaluate the quality of AI output.

\subsection{Model evaluation in a work context is an economic consideration, not a purely technical one}
Consider the task ``answer questions about the text in a document'' and whether an AI can do this task depends on the payoff to doing it correctly. 
The firm might be fine letting a machine do low-level customer service support; we might be very hesitant to let it handle queries from major institutional investors, in part because what constitutes ``good enough'' differs.
But also, the next task might be follow-questions about the state of the business that only the CFO can credibly answer.
  
  % endregion: Division of labor creates interdependence of tasks within jobs

%A key point is that even the static assignment of tasks to humans or AI depends not just on isolated comparative advantage, but on %the relationships between tasks.
\subsection{Chained tasks create systems}
Once a task is changed, it can be thought of as a new, single task.
What constitutes a ``task'' moves to higher and higher levels of abstraction: 
From ``find typos in this ad copy'' to ``create ad copy'' to ``create a marketing campaign, launch, execute and monitor performance'' to ``increase sales'' to ``run the business profitably'' to $\ldots$.  
Note that with this chaining tasks can become increasingly large and abstract as models increase, generating something that looks like an entire system and not just a task \cite{bresnahan2020artificial}.

\subsection{Chained tasks can be re-factored by machines as they see fit}
We might also imagine that once fully chained, the system is free to ``re-factor'' production within the chain---it simply takes inputs and generates outputs.
The details of how this is done is up to the model. 
In the language of our model, system-level substitution would just be characterized as long chains of task automation.

% region: Chaining tasks 
% endregion: Chaining tasksh
% region: Division of labor creates interdependence of tasks within jobs

\subsection{Ability implies judgement but lack of ability does not imply lack of judgement}
Do not deny the antecedent.
While the ability to perform a task often implies the ability to evaluate it (as performers must understand their goal), the reverse is not necessarily true---there are many cases where humans can effectively judge and direct task completion without being able to execute the task themselves. 
This is particularly relevant for highly skilled work, where the pool of qualified evaluators may be larger than those who can perform the task, and mirrors traditional management relationships where managers direct work they cannot personally execute. 
Just as a person with broken arms could still evaluate if a coffee was properly served despite being unable to serve it themselves, the key insight is that prompting and judgment capabilities can be decoupled from task execution abilities when delegating work to AI systems.

\subsection{AI systems could potentially evaluate their own outputs}
While AI systems could potentially evaluate their own outputs, this misses a key point: if an AI model could reliably improve its own evaluation process, those improvements likely would already be incorporated into the model's training and deployment.
Modern AI systems do engage in more sophisticated self-evaluation and reasoning during inference. 
However, what remains is human asking and human evaluation.
This could be entirey deskilled, reduced to cliking a button and rubber-stamp acceptence of what comes out of the model---similar to using a vending machine.
But is could also remain a highly skilled task on both ends.

\subsection{Incentives for investment}
One concern in Acemoglu model is what he calls ``so-so'' technologies that automate but show little net productivity benefit, merely displacing labor: ```Examples of so-so technologies include automated customer service, which has displaced human service representatives but is generally deemed to be low quality and thus unlikely to have generated large productivity gains.''
How likely is it that a ``so-so'' technology will emerge?
If we think of technological improvements as being endogenous, not that it only makes sense to invest in some AI technology if the firm can overshoot the break-even condition. 
Recall that the firm is indifferent to using AI when $\machinetime{} / \bar{q} = \humantime{}$. 
Let us suppose the current state of the art is such that $q_0 < \bar{q}$.
Small improvements from $q_0$ provide no value until they exceed $\bar{q}$. 
If the firm can get the AI technology up to $q^*$, and let us suppose you will sell $x$ units at the ``old'' price, 
the firm's cost-savings will $(\humantime{} - \machinetime{} / q^*) x = C_{q_0}(q^*)$, where $C$ is the one-time cost of improving the technology.

The optimal investment is thus $q^* = \sqrt{\frac{x}{|C'(q^*)|}}$.
It will only be made, however, if profitable to do so, considering the full costs of $C_{q_0}(q^*)$.
In short, if the R\&D gets done, it's likely only to be done of its important (large $x$) and if it is done, it is likely to overshoot the status quo considerably.  
It also seems likely, given that nature of AI, that once it is deployed, usage provides training data that enables continuous improvement in $q$, furthering lowering costs. 
Human workers also learn, but that human capital is not easily transferred to other workers. 


\subsection{Disappeared occupations often just assign prompting and judging tasks to customers}
Although there are advantages to thinking in terms of tasks, most labor market participants thing in terms of ``occupations.'' 
Our training and human capital acquistion is structured as occupations.
People want to know which whole occupations will disappear, and what occupations have good prospects. 
The approach gives a way to think about an occupation ``disappearing.''

In the model, an occupation only disappears when all of its task are subsumed in an automation chain.
In this case, AI, but we can think of AI as capital more generally that can be directed by humans. 
Take an job that truly disappeared: elevator operator. 
The tasks were 1) ``Announce the direction of the elevator,'' 2) ``ask people what floors they are going to'' 3) ``bring the elevator to the appropriate floors'', 4) ``open the doors'' as well as some other non-sequential tasks like inspect for defects or machine failures.  
This got turned into an automation chain where the customer was given the ``prompting'' task of selecting a floor; the evaluation task is just seeing that the elevator was the appropriate floor---an inspection good.
If it was hard to know if you had gotten the right floor, we might expect that task to still be done by humans.

Or consider retail in the past where all items were on shelves behind counters. 
The consumer would prompt the clerk to fetch items (perhaps asking for recommendations) and then the clerk would handle the merchandize. 
It was not until Piggly Wiggly allowed customers to select the merchandise directly that this task disappeared. 

\subsection{Jobs many tasks and complex dependencies are more resistant to full auomation}
Jobs with few tasks are more prone to full automation.
All else equal, a job with a single task is more prone to automation compared to one with multiple distinct tasks.
Jobs where the next task is unpredictable are more resistant to full automation.
The model highlights the benefits to combining multiple tasks into an automation ``chain.''
But if task 1 and task 2 rarely occur together, chaining them together is not likely to work well if that requires some set up.

\subsection{Generative AI might allow for a kind of pseudo-human capital acquistiion.}
Substitution to another human might require a hand-off if all the rest of the tasks still need to be done by the ``original'' human. 
But AI augmentation might allow for job re-design. 
Consider that for some occupations, there are necessary tasks such that $\humantime{}$ is essentially infinite, or so high that it would be uneconomic for that person to pursue that job because their effective efficiency wage would be lower than their next best alternative.  

Take, for example, a master carpenter versus a handyman.
There are many tasks in common between the two: driving to the job site, carrying tools, buying supplies, swinging a hammer, etc.
But what is distinguishing is that there are tasks required of the master carpenter that the handyman is incapable of performing: 
reading complex blueprints, organizing other trades, picking building code-appropriate grades of lumber and building methods.
Because they lack these skills, their carpenter wage is essentially 0, below the handman wage, and so they are a handyman.
If generative AI is inequality-reducing, this will be the mechanism: taking people that currently lack certain skills and letting them ``jump'' up. 

This framing gives an interesting characterization of the human capital acquisition process generally: 
learn skills that will lower your performance costs across tasks \emph{if} you can make the job requiring those tasks better than your best job option.
The skills you acquire needed to make that job marginal. 
For example, the task ``read an MRI scan to detect a bone fracture'' is highly remunerative but only if learned in with all the other tasks in the ``Radiologist'' task sequence.
Licensing aside---this skill alone is essentially worthless.  
With AI augmentation, the marginal blocking skill might no longer be blocking. 

However, that task has to be marginal (assuming other blocking tasks are not also automated). 
For example, identifying a bone fracture in an X-ray does not mean a person is ready to be a radiologist.
I.e., if there was only one task that precluded them from doing some occupation, then AI might allow them to do that occupation.
Allowing more people to do more tasks could have an indirect productivity effect. 
Ironically, the harder the task to perform, the more potential for AI to unlock this substitution potential, as the pool of potential prompters and judges is much larger than the pool of doers.

% \subsection{Equilibrium considerations}
% If a sector has a large increase in AI usage, labor demand will fall. 
% Let $l_j(w)$ be the labor demand for good $j$ at wage $w$ to produce 1 unit of output.
% The product market price is $p_j = w l_j(w; q_1, q_2, \dots, q_n)$.
% Let $\epsilon_j$ be the elasticity of product market demand for sector $j$, with demand curve $d_j(p_j)$.
% Total headcount is $L = d_j(p_j) l_j(w)$.
% Suppose we some AI improvement in a task $q_i$---the partial equilibrium effect on labor used in sector $j$ is
% \begin{equation}
% \frac{\partial L}{\partial q_i} 
% \;=\; 
% d_j\bigl(p_j\bigr)\;\frac{\partial l_j}{\partial q_i}\;
% \bigl(\,1 \;-\;\epsilon_j\bigr).
% \end{equation}
% giving us the familiar result that the effect on labor in that sector, the larger the more elastic the product market.
% If we consider the general equilibrium, it depends on the elasticity of the demand for labor in other sectors and how large the AI improvement is, i.e., how much does the $q_i$ task matter in other sectors.
% If the net effect is to lower total labor, this would put downward pressure on wages. 
% How large this pressure is depends in part on how substitutable labor is across various sectors.
% A decline in wages would in-turn would in turn limit the incentives to invest AI improvements, at least at the firm level.
% However, if the instead the increase in $q_i$ allows new services to be provided, this might have an offsetting effect on wages. 

% Suppose there is some AGI singularity, where all goods cost just $\machinetime{}$ to produce---the only human labor used is the management of the AI and AI is perfect.
% The demand for labor is minimal, seemingly implying low wages, but also goods are so cheap that the demand for leisure might be very high, as all product needs can be met with little income.

\subsection{Agentic AI and the Task-Based Production}
Multiple AIs working in concert, or so-called ``Agentic AI,'' has captured the imagination of researchers and practitioners alike.
The enthusiasm reflects the usefulness of the economist's task-based view of production: many goods are produced by the completion of identifiable tasks.
Furthermore, those tasks often have a recursive sub-structure, allowing them to be decomposed into smaller, simpler tasks.
Those simpler tasks might more plausibly done by AIs, particularly as model capabilities improve and the AI agent is specialized for that task. 
Adam Smith and Henry Ford would both see the point immediately. 

% But even with powerful AI models, in designing AI agents for work, specialization is not just for humans.
% The ``agentic'' of agentic AI captures the notion that an AI working on a particular task should be specialized for that task: 
% The agent should have the resources, knowledge, and capabilities needed for that task and that task alone.
% It will need inputs from other agents and will pass off completed tasks to other agents.
% While engineers might cast this as simply reflecting good software engineering principles---separation of concerns, modularity, clean interfaces between sub-components---it also describes an effective production process in general.
% In short, enthusiasm for Agentic AI is partially enthusiasm for the division of labor---old wine in new bottles.

A natural question, of course, is how far might Agentic AI go?
This is difficult to answer credibly, as technological progress in AI is happening quickly and the answer depends on entrepreneurial activity we cannot hope to fully anticipate.
Predictions based on task content seem inherently difficult; as a close analogy, our failure to predict the extent of offshoring---arguably a far simpler forecasting problem---should be humbling \citep{ozimek2019overboard}.
Even at present, we see AI models that can do super-human work in some domains, but then make childish mistakes in others, with no obvious or unifying point of view that could explain the gaps \citep{vafa2024large}.
This incoherence makes the standard economist trick with new technology---treat it as a fall in the cost of ``X'' where ``X'' is, say, prediction, rote computation, light, or locomotive force---difficult to apply.

Although we cannot credibly claim to know what AIs can or will do, we can describe in general terms how they are---and likely will be---used in production.
Stepping back, the distinctive feature of generative AI is in the name: it generates---writing, code, images, music, and videos---in response to human requests, or ``prompts.''
But these model generations only become (potentially) economically valuable when humans judge these model outputs as suitable for their needs.
If the model outputs are generally poor or too unreliable for a given application, the human might eschew AI and do the task themselves; if the model outputs are good enough, the human role might simpy be juding the output and giving feedback to the AI as needed (with less capable AIs requiring more human supervision).

The key question---should an AI do a task instead of a human, given the costs and benefits?---is not a technical question, but an economic one.
It is also both a practical question and a research question: practitioners want to know how to efficiently redesign the productive process; researchers want to know what this transformation implies for the economy and the labor market.
Policy makers in particular are interested in whether technology can be guided to be more complementary to human labor rather than displacing it \citep{acemoglu2018automation}.

Answering these questions about AI and human labor requires a model of the productive process.
Although much progress can be made using our standad tools (see \citep{korinek2018artificial}), \cite{acemoglu2024task} argues persuasively that the standard production function approach (i.e., $Y = F(K, L)$) is not adequate for understanding the impact of technology on labor markets, and that instead a task-based approach is needed \citep{aghion2024ai}.

The task-based approach dispenses with a single aggregate production function to instead modeling the productive process in terms of tasks which can be assigned to humans or machines---and perhaps humans of different skill-levels.
The equilibrium is then some allocation of tasks to different factors of production, based on which factor has the comparative advantage in that task.
Despite the greater granularity, the task-based approach does not directly consider the interdependence of tasks in the productive process: it does not matter in the model where a task ``sits'' within some occupation or process. 
This is a useful simplification, but actual production involves the output of a completed task often being used as input to the next task.
A natural question is whether this interdependence of tasks matters for the factor assignment question in the case of AI? 



%%%%%%%%%%%%%%%% Conclusion %%%%%%%%%%%%%%%%
\section{Conclusion}

For those interested in AI that complements human capabilities---there are some direct ones complemented in this framework: asking and judging.
But it also suggests asking and judging has particularly high value when it bookends long sequences of AI-chained tasks.
Asking a model to proofread a memo for typos is not particularly high value;
asking a model to do foundational and autonomous research on drug discovery by pointing it in a promising direction could be enormously valuable on the margin if that skill itself is rare.
In other domains, this same phenomenon might benefit less-skilled workers where actually doing the task is the bottleneck.
This seems to be the case in \cite{brynjolfsson2023generative}, for example.
  
When we think of AI model improvements, some of it clearly the raw capabilities on, say, performance benchmarks. 
But it is also about improving the AI's ability to interact with the world. 
An AI that can control a computer GUI built for humans can do a lot more things in a world of remote work.
When we think of the tasks an AI can potentially do, we should be thinking not just in terms of raw model capabilities but also its ability to interact with the rest of the world.

Job redesign will take advantage of the fact that skills in judging output are separate from the skill of creating some output.
There are food critics who cannot cook; record producers who cannot play instruments; technologists who cannot program, and so on.
As AI makes it so that humans no longer have to do every task in a job, AI might open up jobs to people who are otherwise blocked by a skill they lack.

\bibliographystyle{aer}
\bibliography{rubin}

\newpage
\appendix
\section*{Appendix}


%%%%%%%%%%%%%%%% Comparative Statics of Investment in AI Capabilities %%%%%%%%%%%%%%%%
\section{Comparative Statics of Investment in AI Capabilities}
\label{app:AI_capability_inv_comp_stat}
The returns to investment in AI for a particular task are affected by AI capabilities in other tasks.
Before a task is automated, there is no return to investment in an AI that does that task.
Once a task is automated, there are returns to investment in a task, but these are unaffected by the other task's AI capabilities.
Once we move into the \(\machine{1|2}\) region, the returns to investment in one task are affected by the other task's AI capabilities.
The cost reduction gets steeper immediately when switching into the \(\machine{1|2}\) region but then flattens out, as the second derivative of the cost function with respect to \(q_i\) is positive.
These properties are formalized in Proposition~\ref{prop:comparative_statics}.

\begin{proposition}[Comparative Statics] \label{prop:comparative_statics}
  The effect of improving AI capabilities has the following properties:
  \begin{enumerate}
  \item In human-only production, improvements in AI have no effect on costs:
  \[
  \frac{\partial \cost{\human{1}\human{2}}}{\partial q_i} = 0 \quad \text{for } i \in \{1,2\}.
  \]
  \item In independent AI production, improvements reduce costs independently:
  \[
  \frac{\partial \cost{\machine{1}\machine{2}}}{\partial q_i} = -\frac{\machinetime{}}{q_i^2}, \quad \frac{\partial^2 \cost{\machine{1}\machine{2}}}{\partial q_1 \partial q_2} = 0.
  \]
  \item In mixed production, only improvements in the specific task matter:
  \[
  \frac{\partial \cost{\machine{1}\human{2}}}{\partial q_1} = -\frac{\machinetime{}}{q_1^2}, \quad \frac{\partial \cost{\machine{1}\human{2}}}{\partial q_2} = 0.
  \]
  \item In chained production, improvements are complementary:
  \[
  \frac{\partial \cost{\machine{1|2}}}{\partial q_i} = -\frac{\machinetime{}}{q_i^2 q_j}, \quad \frac{\partial^2 \cost{\machine{1|2}}}{\partial q_1 \partial q_2} = \frac{\machinetime{}}{q_1^2 q_2^2} > 0,
  \]
  where \(j \neq i\).
  \end{enumerate}

  In chained production, improvements in AI capabilities eventually flatten out, as the second derivative of the cost function with respect to \(q_i\) is positive.
  \begin{equation}
      \frac{\partial^2}{\partial q_1 \partial q_2} \cost{\machine{1|2}} = \frac{\machinetime{}}{q_1^2 q_2^2} > 0.
  \end{equation}

\end{proposition}
 
We will later consider the more general \(n\) task case, but note that immediate adjacency is not required for a task where humans have a comparative advantage to be pulled into a chain.
Consider a scenario with \(n\) tasks, each with the same success probability \(q\) and the same \(\machinetime{}\) and \(\humantime{}\).
To start, assume all tasks are done by humans and that chaining is more cost-efficient than separate automation, implying that:
\[
n\, \humantime{} < \frac{\machinetime{}}{q^n}.
\]
Now suppose we can increase the \(q\) of the first task by \(\delta q\). 
All tasks will be done by machine, in one chain, if it is possible to have:
\begin{align}
  \delta > \frac{\machinetime{}}{n\, \humantime{}{}\, q^{n}} - 1.
\end{align} 


\subsection{Optimal investment paths in the two-task case}
A natural question is how firms or a social planner should allocate R\&D effort to improve AI capabilities.
In the two task case, rather than taking \(q_1\) and \(q_2\) as given, we can consider the optimal investment paths, or allocation of R\&D effort.
Suppose we can improve \(q_1\) and \(q_2\) at a rate \(r\) per unit of time.
If we have \(T\) periods, then 
\[
\begin{aligned}
\text{Choose } &q_1(\cdot), \; q_2(\cdot) \quad \text{for } t \in [0, T],\\[1em]
\text{to minimize } &
   \int_{0}^{T}
   e^{-\rho t} \, C\bigl(q_1(t), q_2(t)\bigr) \, dt, \\[1em]
\text{subject to:} & \\[-1em]
&(1)\quad q_1(0) = q_{1,0}, \quad q_2(0) = q_{2,0}, \\[6pt]
&(2)\quad q_1'(t) + q_2'(t) \le r, \quad \text{for almost all } t \in [0, T], \\[6pt]
&(3)\quad q_1(t) \geq 0, \quad q_2(t) \geq 0, \quad \forall t \in [0, T]. \\[6pt]
\end{aligned}
\label{eq:dp_problem}
\]
where \(q_{1,0}\) and \(q_{2,0}\) are the initial AI capabilities in the two tasks.
The properties of the optimal paths for this dynamic programming problem are analyzed in detail in Appendix~\ref{app:dp_proof}. 
There, we outline the structure of the solution, provide comparative statics, and derive the necessary conditions for optimality.

Figure~\ref{fig:optimal_paths} shows numerical optimal investment paths to minimize total costs using the same parameters as in Figure~\ref{fig:two_tasks}.
We also set the discount rate \(\rho = 0\) and the total amount of R\&D resources per period to \(r = 1\).
We discretized the \(q_1\) and \(q_2\) space into a grid (so investments had to be made each period on one task or the other) and then used dynamic programming to find the optimal path.
Paths for a few select initial conditions are shown on the graph.

\begin{figure}
  \begin{center}
  \caption{Optimal investment paths to minimize costs} \label{fig:optimal_paths}
  \includegraphics[width = 0.8 \textwidth]{plots/optimal_paths.pdf}
  \end{center}
  \begin{footnotesize}
  \emph{Note:} This plot shows the optimal investment paths to minimize costs, using the same parameters as in Figure~\ref{fig:two_tasks}, with a number of different initial conditions.
\end{footnotesize}
\end{figure}

We can see that the optimal path features a ``turnpike'' component, where we move toward the 45-degree line and then make equal investments in $q_1$ and $q_2$.
However, it does not typically go there directly; if already in a semi-automated region, it will increase capabilities in that task for some time, taking advantage of the relatively steep slope.
In the $\machine{1|2}$ region, the optimal path is to move directly toward the 45-degree line, and then continue along it.

\subsection{Investment horizon effects}
The investment horizon can have important effects on the optimal path.
Figure~\ref{fig:horizon_effects} illustrates this by choosing about the same starting positions, but varying the number of steps \(T\) in the dynamic program.
As in Figure~\ref{fig:optimal_paths}, a dynamic program is used to find the optimal path that minimizes costs.

We can see that time horizons can create fundamental differences in the optimal path.
With a relatively short horizon, the optimal path is simply to keep investing in the already-automated task.
The reason is that with this horizon, we never get to the \(\machine{1|2}\) region.
With a slightly longer horizon, we just keep going farther in \(q_1\), neglecting \(q_2\) altogether.
With a long-enough horizon, however, it is beneficial to actually stop improving \(q_1\) and begin investing in \(q_2\).
This is despite the fact that improving \(q_2\) offers no direct benefits at the $\machine{1}\human{2}$ region.
However, it is worth it because it gets us to the \(\machine{1|2}\) region.
We then make a beeline for the 45 degree line, at which point we then make equal investments in \(q_1\) and \(q_2\).

\begin{figure}
  \begin{center}
  \caption{Horizon effects} \label{fig:horizon_effects}
  \includegraphics[width = 0.8 \textwidth]{plots/horizon_effects.pdf}
  \end{center}
\end{figure}




\subsection{Powerful AI means powerful prompts}
There are good reasons to think that handoff costs are similar to prompting and evaluation costs.
AI, no matter how good, is not a mind-reader; neither are your coworkers.
Consider the AI system as a function:
\begin{align}
f : \mathcal{P} \longrightarrow \mathcal{O},
\end{align}
where \(\mathcal{P}\) is the set of all possible prompts (inputs), and \(\mathcal{O}\) is the set of all possible outputs the AI can produce.
If the AI is powerful enough to generate a large range of outputs \(\mathcal{O}\), ensuring that every desired output can be uniquely generated requires (at minimum) a surjective mapping:
\begin{align}
\forall o \in \mathcal{O}, \; \exists p \in \mathcal{P} \; \text{such that} \; f(p) = o.
\end{align}
If we require that each output is generated by exactly one unique prompt, then \(f\) must be a bijection, and:
\begin{align}
|\mathcal{P}| = |\mathcal{O}|.
\end{align}
In other words, the cardinality of the prompt space must match or exceed the cardinality of the output space.

Using an information-theoretic perspective, if the AI can reliably produce \(N\) distinct outputs, it effectively has to “choose” among \(N\) possibilities. 
To specify which of those \(N\) outputs is desired, the prompt must carry at least:
\begin{align}
\log_2(N) \quad \text{bits of information.}
\end{align}
As \(N\) (the size of the AI's output repertoire) grows, the information capacity of the prompt must also grow proportionally.
To summarize, as the AI’s capacity expands, the size of the output space \(|\mathcal{O}|\) increases, and so must the size of the prompt space \(|\mathcal{P}|\) to allow precise mapping from inputs to outputs:
\begin{align}
|\mathcal{P}| \geq |\mathcal{O}|.
\end{align}
This means that increasingly powerful AI systems require increasingly sophisticated prompts to uniquely and effectively specify desired outputs.




%%%%%%%%%%%%%%%% Short Run Job Redesign Proof %%%%%%%%%%%%%%%%
\section{Proof of Proposition~\ref{prop:shortrun_redesign}}
\label{app:shortrun_redesign_proof}

In this Appendix we provide the proof of Proposition~\ref{prop:shortrun_redesign}.

\begin{proof}
Define
\[
\Delta\mathrm{Gain}(\J^{(0)}, \alpha)
:=
\mathrm{TotalRedesignGains}(\J^{(0)}, \alpha)\;-\;\text{NoRedesignGains}(\J^{(0)}, \alpha),
\]
the extra payoff from redesign versus pure time‐savings under the advanced AI.  
By construction the firm redesigns exactly when $\Delta\mathrm{Gain}(\alpha)\ge0$.  
Using the definition of each term from Equation~\ref{eq:job_redesign_direct_savings} and~\ref{eq:job_redesign_gain}, the firm redesigns jobs when:
\begin{align*}
\Delta\text{Gain}(\J^{(0)}, \alpha)
& =
\text{TotalCost}(\J^{(0)}; \hccost{}, \timecost{}) - \text{TotalCost}(\J^{*}, \widetilde{\hccost{}}, \widetilde{\timecost{}})
-
\text{RedesignCosts}(\J^{(0)}, \J^{*}) \nonumber \\
& \quad -
\Bigl[\text{TotalCost}(\J^{(0)}; \hccost{}, \timecost{}) - \text{TotalCost}(\J^{(0)}; \widetilde{\hccost{}}, \widetilde{\timecost{}})\Bigr] \nonumber \\
& =
\text{TotalCost}(\J^{(0)}; \widetilde{\hccost{}}, \widetilde{\timecost{}})
- 
\text{TotalCost}(\J^{*}, \widetilde{\hccost{}}, \widetilde{\timecost{}})
-
\text{RedesignCosts}(\J^{(0)}, \J^{*}) \nonumber \\
& \geq 0, \nonumber
\end{align*}
which establishes the first claim.

For the threshold argument, fix $\alpha_0$ such that $\J^{(0)}$ is optimal at $\alpha_0$.
For any partition $\J$ define
\[
C_{\J}(\alpha)
:=
\mathrm{TotalCost}\bigl(\J; \widetilde{\hccost{}}(\alpha), \widetilde{\timecost{}}(\alpha)\bigr).
\]
Since $\widetilde t_{ij}(\alpha)$ and $\widetilde c_{ij}(\alpha)$ are weakly decreasing and continuous in~$\alpha$, each $C_{\J}(\alpha)$ is also weakly decreasing and continuous.
Let
\[
D(\alpha)
:=
\bigl[C_{\J^{(0)}}(\alpha)-C_{\J^*}(\alpha)\bigr]
\;-\;
\mathrm{RedesignCost}.
\]
Because $\J^{(0)}$ is optimal at $\alpha_0$, $D(\alpha_0)\le0$.  
By assumption there exists $\alpha_1>\alpha_0$ for which $D(\alpha_1)>0$ and the firm redesigns jobs to some $\J^{*} \neq \J^{(0)}$.  
\footnote{This argument requires that as $\alpha$ increases some optimal $\J^{*} \neq \J^{(0)}$ exists.
This requirement rules out the fully-automated plan in which an exceptionally efficient AI does all the tasks in one long automated chain: if we start with the fully-automated plan no matter how much we improve the AI quality, no other job structure will become optimal.}
Continuity of $D$ on $[\alpha_0,\alpha_1]$ implies, via the Intermediate Value Theorem, a unique $\tilde\alpha\in(\alpha_0,\alpha_1)$ with $D(\tilde\alpha)=0$.  
Moreover, since $D(\alpha)$ is strictly increasing whenever $C_{\J^{(0)}}-C_{\J^*}$ strictly increases, $\tilde\alpha$ is the unique AI‐quality threshold above which the firm strictly prefers redesign.
\end{proof}



\begin{comment}
%%%%%%%%%%%%%%%% Equilibrium in the Task-Based Economy %%%%%%%%%%%%%%%%
\section{Equilibrium in the Task-Based Economy}
\label{app:GE}

In this appendix, we obtain equilibrium prices and allocations for the model specified in Section~\ref{sec:GE}.


\paragraph{Goods Prices.}  
In each sector, a worker employed in job $j$ produces an intermediate good $x_j$, which is sold back to the firm in a competitive market.  
Let $\labor{j}$ denote the amount of labor per unit of good $x_j$ employed in job $j$.
That is:  
\[
\labor{j} = \handofftime{j} + \sum_{i \in \J_j} \timecost{ij}.
\]  
The production cost per unit of $x_j$ can thus be written as:  
\[
\text{WageBill}_j = \Biggl(v_L + \sum_{i \in \J_j} \hccost{ij} \Biggr) \Biggl(\handofftime{j} + \sum_{i \in \J_j} \timecost{ij} \Biggr) = w_j \,\labor{j},
\]  
with $w_j$ being the wage rate for job $j$.
Markets are perfectly competitive, therefore the price of intermediate good $j$, $p_j$, equals the marginal cost of its production $w_j\,\labor{j}$:
\[
p_j = w_j \labor{j}.
\]  
Furthermore, given the Leontief production function, perfect competition in the final good market implies that the price of final good, $p$, equals the sum of the prices of its constituent intermediate goods:
\[
p = \sum_{j=1}^J p_j = \sum_{j=1}^J w_j \labor{j}.
\]  
To maintain consistency in notation between the final and intermediate goods markets, define  
\[
w \, \labor{} \equiv \sum_{j=1}^J w_j \labor{j},
\]
so that $p = w \, \labor{}$.  
If we let $\labor{}$ be the total amount of time (or labor) spent producing the final good, i.e.,
\[
\labor{} = \sum_{j=1}^J \labor{j},
\]
then $w$ can be interpreted as the weighted average wage rate of the entire sector:
\[
w = \frac{\sum_{j=1}^J w_j \labor{j}}{\sum_{j=1}^J \labor{j}}.
\]

We must mention that once $\labor{}$ is determined all $\labor{j}$s (for $j \in \{1,\ldots,J\}$) are pinned down.
This is due to the assumption earlier that tasks are done in fixed proportions.
Formally, the fixed proportions assumption implies that for some $\gamma_j > 0$ we have:  
\[
\frac{\labor{j}}{\labor{1}} = \gamma_j,
\]  
with $\gamma_1 = 1$.  
Using the definition of $\labor{}$ we get: 
\[
\labor{} = \sum_{j=1}^J \labor{1} \Bigl(\frac{\labor{j}}{\labor{1}} \Bigr) = \labor{1} \sum_{j=1}^J \gamma_j 
\quad 
\Longrightarrow
\quad 
\frac{\labor{}}{\labor{1}} = \sum_{j=1}^J \gamma_j,
\]  
and thus:  
\[
\labor{j} = \Bigg( \frac{\gamma_j}{\sum_{j=1}^J \gamma_j} \Bigg) \labor{}.
\]  
Therefore, it is without loss to focus our attention on working with $\labor{}$, because once that is determined, the labor for each subsequent job is specified.


\paragraph{Labor Market Clearing.}  
Since the household supplies one unit of labor inelastically to all jobs across all sectors, the market clearing condition satisfies:  
\[
\sum_{k=1}^K \Biggl( \sum_{j=1}^{J_k} \labor{j}^k\,x_j^k \Biggr) = 1.
\]  
Given the Leontief production, this can be expressed as:  
\[
\sum_{k=1}^K \Biggl( \sum_{j=1}^{J_k} \labor{j}^k \Biggr) x_k = \sum_{k=1}^K \labor{}^k x_k = 1,
\]  
With this, we can rewrite the household's earned income as:  
\[
I = \sum_{k=1}^{K} \Bigg( \sum_{j=1}^{J_k} w_j^k \labor{j}^k \Bigg) x_k 
= v_L + \Bigg[ \sum_{k=1}^{K} \Bigg( \sum_{j=1}^{J_k} \bigg( \sum_{i \in \J_j} \hccost{ij}^k \bigg) \labor{j}^k \Bigg) x_k \Bigg],
\]  
implying that the household budget consists of two parts: a part that compensates the worker for his foregone leisure and a part that rewards him for the human capital he has acquired.


\paragraph{Sectoral Employment and Equilibrium Allocations.}
The consumer chooses $\{x_k\}$ to maximize
\[
U(x_1,\dots,x_K) = \Bigl(\sum_{k=1}^K \delta_k \,x_k^{\tfrac{\sigma-1}{\sigma}}\Bigr)^{\tfrac{\sigma}{\sigma-1}},
\]
subject to
\[
\sum_{k=1}^K p^k\, x_k = I.
\]
By the standard first-order conditions, the ratio of marginal utilities equals the ratio of prices:
\[
\frac{\partial U/\partial x_f}{\partial U/\partial x_g} = \frac{p^f}{p^g} \quad \forall f,g.
\]
From CES properties, we obtain
\[
\left(\frac{x_f}{x_g}\right)^{-\tfrac{1}{\sigma}} = \frac{p^f}{p^g}\,\cdot\,\frac{\delta_g}{\delta_f},
\quad
\Longrightarrow
\quad
\frac{x_f}{x_g} = \left(\frac{p^g}{p^f}\,\cdot\,\frac{\delta_f}{\delta_g}\right)^{\sigma}.
\]
Define
\[
R_f = \frac{x_f}{x_1} = \Bigl(\frac{p^1}{p^f} \cdot \frac{\delta_f}{\delta_1}\Bigr)^{\sigma},
\]
with $R_1 = 1$.
Substitute $x_f = R_f\,x_1$ into the labor market clearing condition $\sum_{k=1}^K \labor{}^k\, x_k = 1$:
\[
\sum_{k=1}^K \labor{}^k\,(R_k\,x_1) = x_1\Bigl[\sum_{k=1}^K \labor{}^k\,R_k\Bigr] = 1,
\]
which yields
\[
x_1^* = \frac{1}{\sum_{k=1}^K \labor{}^k\,R_k},
\quad
x_f^* = R_f\,x_1^* = \frac{R_f}{\sum_{k=1}^K \labor{}^k\,R_k}.
\]

Labor used in sector $k$ is given by $L_k^* = \labor{}^k\,x_k^*$.
Thus, the equilibrium can be summarized as
\begin{align*}
w_j^k = \Biggl(v_L + \sum_{i \in \J_j^k} \hccost{ij}^{k}\Biggr), 
& \qquad
\labor{j}^k = \Biggl(\handofftime{j}^k + \sum_{i \in \J_j^k} \timecost{ij}^{k}\Biggr), \\
p_j^k = w_j^k \labor{j}^k,
& \qquad
p^k = w^k \labor{}^k = \sum_{j=1}^{J_k} w_j^k \labor{j}^k, \\
x_k^* = \frac{R_k}{\sum_{\ell=1}^K \labor{}^\ell\,R_\ell},
& \qquad
L_k^* = \labor{}^k\,x_k^* = \sum_{j=1}^{J_k} \labor{j}^k\,x_k^*,
\end{align*}
where
\[
R_k = \Bigl(\frac{p^1}{p^k} \cdot \frac{\delta_k}{\delta_1}\Bigr)^{\sigma}.
\]
In this way, the job design of the production process $\T_k$ (and thus the corresponding $\hccost{ij}^k$s and $\timecost{ij}^k$s) determines $p^k$, which then determines the consumption bundle $\{x_k^*\}$ and the labor allocations $\{L_k^*\}$.


\subsection{Comparative Statics with Respect to Improved AI Quality}

Suppose AI affects a subset $\mathcal{A}_1 \subseteq \T_1$ of tasks in good~1’s production process.  
This reduces the wage bill for good $1$:
\[
\sum_{j=1}^{J_1} \Biggl( v_L + \sum_{i \in \J_j^1} \hccost{ij}^{1} \Biggr) \labor{j}^1,
\]
which in turn lowers $p^1$, while potentially also altering the job design.  
The following comparative statics apply.

\paragraph{Price Effects.}
Only $p^1 = w^1 \labor{}^1$ falls; the prices $p^f$ for $f\neq 1$ remain unchanged (unless tasks in those sectors are also automated).

\paragraph{Effects on Consumption.}
We find
\[
\frac{\partial x_{1}^*}{\partial p^1}
=
-\,
\frac{\,p^1 \;+\;\sigma\,\bigl(\sum_{k\neq 1}\labor{}^kR_{k}\bigr)\,}{
       p^1\,\Bigl(\sum_{k}\labor{}^kR_{k}\Bigr)^{2}}
<0,
\qquad
\frac{\partial x_{f}^*}{\partial p^1}
=
(\sigma-1)
\,\frac{\,R_{f}\,}{\Bigl(\sum_{k}\labor{}^kR_{k}\Bigr)^{2}}
\quad (\text{for } f\neq 1).
\]
Hence, when $p^1$ decreases (i.e., when automation makes good~1 cheaper), $x_{1}^*$ unambiguously rises, while $x_{f}^*$ moves in the opposite direction if $\sigma>1$ (indicating substitutes) or in the same direction if $0<\sigma<1$ (indicating complements).

\paragraph{Effects on Sectoral Labor Shares.}
Similarly, 
\[
\frac{\partial L_{1}^*}{\partial p^1}
=
x_{1}^*\,(1-\sigma)\bigl(1 - p^1\,x_{1}^*\bigr),
\qquad
\frac{\partial L_{f}^*}{\partial p^1}
=
(\sigma-1)\,
\frac{\,\labor{}^f\, R_{f}\,}{\Bigl(\sum_{k} \labor{}^k\, R_{k}\Bigr)^{2}}
\quad (\text{for } f\neq 1).
\]
For $\sigma>1$, since $\frac{\partial L_{f}^*}{\partial p^1}>0$, a reduction in $p^1$ leads to a lower $L_f^*$ for $f\neq 1$, thereby shifting labor towards good~1, which is consistent with substitutability.  
If $0<\sigma<1$, goods behave more like complements, and lowering $p^1$ increases labor usage in the other sectors.  
In all cases, total labor remains equal to $1$.


%%%%%%%%%%%%%%%% Optimal Paths in the Dynamic Programming Problem %%%%%%%%%%%%%%%%
\section{Optimal Paths in the Dynamic Programming Problem}
\label{app:dp_proof}

In this appendix, we analyze the properties of the optimal paths for the dynamic programming problem specified in \pageref{eq:dp_problem}.  
The solution follows this structure: allocate all resources to the larger of $q_{1}$ and $q_{2}$ until a specific point, then switch to investing all resources in the other task’s capability until parity between $q_{1}$ and $q_{2}$ is achieved.  
After reaching parity, resources are evenly distributed between both tasks.  
While we are unable to analytically determine the exact values of $q_{1}$ and $q_{2}$ at the turning point, we provide comparative statics with respect to the initial values and the discount rate.

We reformulate the problem as a maximization problem, and omit time dependencies in all variables for simplicity of notation.
\begin{align*}
\max_{q_{1},q_{2}} & \int_{0}^{T}-e^{-\rho t}C(q_{1},q_{2})dt\\
s.t. & \frac{dq_{1}}{dt}+\frac{dq_{2}}{dt}+s(t)=r,\\
 & q_{1},q_{2}\geq0,\\
 & q_{1}(0)=q_{1,0},\quad q_{2}(0)=q_{2,0}.
\end{align*}
Here, $q_{1},q_{2}$ are the state variables, while $\frac{dq_{1}}{dt}$ and $\frac{dq_{2}}{dt}$ are control variables.  
We form the Hamiltonian as follows: 
\[
H=-e^{-\rho t}C(q_{1},q_{2})+\lambda_{1}\frac{dq_{1}}{dt}+\lambda_{2}\frac{dq_{2}}{dt}+\mu\left(r-\frac{dq_{1}}{dt}-\frac{dq_{2}}{dt}\right),
\]
where $\lambda_{1},\lambda_{2}$ are costate variables, and $\mu$ is the Lagrange multiplier associated with the investment constraint.  
The necessary conditions for an interior solution are: %% \underline{interior}

\begin{align*}
\frac{dq_{i}}{dt} & =\frac{\partial H}{\partial\lambda_{i}},\tag{State Dynamics}\\[1ex]
\frac{d\lambda_{i}}{dt} & =-\frac{\partial H}{\partial q_{i}},\tag{Costate Dynamics}\\[1ex]
\frac{\partial H}{\partial\left(\frac{dq_{i}}{dt}\right)} & =0,\tag{Stationarity}\\[1ex]
\mu\left(r-\frac{dq_{1}}{dt}-\frac{dq_{2}}{dt}-s\right) & =0.\tag{Complementary Slackness}
\end{align*}
Expanding the formulas, we obtain:
\begin{align*}
\frac{dq_{1}}{dt} & =\frac{dq_{1}}{dt},\\[1ex]
\frac{dq_{2}}{dt} & =\frac{dq_{2}}{dt},\\[1ex]
\frac{d\lambda_{1}}{dt} & =e^{-\rho t}\frac{\partial C}{\partial q_{1}},\\[1ex]
\frac{d\lambda_{2}}{dt} & =e^{-\rho t}\frac{\partial C}{\partial q_{2}},\\[1ex]
\lambda_{1}-\mu & =0,\\[1ex]
\lambda_{2}-\mu & =0,\\[1ex]
\mu>0\ \text{and}\ \frac{dq_{1}}{dt}+\frac{dq_{2}}{dt}=r, & \quad \text{or}\ \mu=0\ \text{and}\ \frac{dq_{1}}{dt}+\frac{dq_{2}}{dt}<r.
\end{align*}
The costate dynamics imply
\[
\frac{\frac{d\lambda_{1}}{dt}}{\frac{d\lambda_{2}}{dt}}=\frac{\frac{\partial C}{\partial q_{1}}}{\frac{\partial C}{\partial q_{2}}},
\]
and from the stationarity conditions, we have:
\[
\lambda_{1}=\lambda_{2}=\mu.
\]

The $\mu=0$ case can happen only if:
\[
\frac{\partial C}{\partial q_{1}}=\frac{\partial C}{\partial q_{2}}=0
\]
for all times.  
In this scenario, any $q_{1}$ and $q_{2}$ would suffice since neither contributes to the objective function.  
However, this is not applicable in our setup because, as soon as task $i$ becomes automated, the corresponding partial derivative changes from 0 to $-\frac{\machinetime{}}{q_{i}^{2}}$.\footnote{We assume $\machinetime{}$ and $\handofftime{}$ are such that some level of automation is preferred over no automation.  
Otherwise, the solution would be trivial, and no tasks would be automated.}  
Therefore, we must have $\mu>0$, and the investment endowment is always fully utilized.

If the solution is interior, then  
\[
\lambda_{1}=\lambda_{2}=\mu>0
\]
and the following holds for all $t$:
\[
\bar{\lambda}_{1}+\int_{0}^{t}e^{-\rho s}\frac{\partial C}{\partial q_{1}}ds=\bar{\lambda}_{2}+\int_{0}^{t}e^{-\rho s}\frac{\partial C}{\partial q_{2}}ds.
\]
Assume that at $t=T$ (the horizon), $\lambda_{1}=\lambda_{2}>0$.\footnote{Intuitively, this means that at the horizon, we stop investing in either variable, resulting in a ``steady state.''  
This is reasonable because, once $q=1$, no further investments are required.}  
This implies at the optimum, the marginal cost with respect to task capabilities must be equal.  
Thus:
\[
\forall t:\frac{\partial C}{\partial q_{1}}=\frac{\partial C}{\partial q_{2}}.
\]
Given the functional form of the cost function, such scenario can occur only when both tasks are automated, \underline{and} $q_{1}=q_{2}$.  
Specifically:
\[
\frac{\partial C\{\machine{1|2}\}}{\partial q_{1}}=\frac{\partial C\{\machine{1|2}\}}{\partial q_{2}}\Leftrightarrow-\frac{\machinetime{}}{q_{1}^{2}q_{2}}=-\frac{\machinetime{}}{q_{1}q_{2}^{2}}\Leftrightarrow q_{1}=q_{2}.
\]
Unless this condition is met, we have a corner solution where all the available endowment is allocated to improving only one task’s AI capability.

We conjecture that at a sufficiently long horizon, $q_{1}=q_{2}$, and proceed to determine the optimal trajectories of $q_{1}$ and $q_{2}$ using backward induction.  
Now, imagine we are in the $\machine{1|2}$ region.  
Let $\tilde{T}$ denote the earliest time at which $\frac{\partial C}{\partial q_{1}}=\frac{\partial C}{\partial q_{2}}$ holds.\footnote{We assume that the parameters $\machinetime{}$ and $\handofftime{}$ are such that this equality is guaranteed to occur.  
Otherwise, the solution would trivially involve investing in only one $q$, fully maximizing it before switching to the other until it too is maximized.}  
For $t<\tilde{T}$, we have a corner solution.  
Without loss of generality, assume that $\frac{\partial C}{\partial q_{1}}>\frac{\partial C}{\partial q_{2}}$ when $t<\tilde{T}$.  
With a slight abuse of notation, consider a time $\delta$ arbitrarily close to and just before $\tilde{T}$.  
At such times, we can write:
\[
\frac{\partial C\{\machine{1|2}\}}{\partial q_{1}}\approx-\frac{\machinetime{}}{q_{1}^{2}q_{2}}>-\frac{\machinetime{}}{q_{1}q_{2}^{2}}\approx\frac{\partial C\{\machine{1|2}\}}{\partial q_{2}}.
\]
This simplifies to:
\[
-\frac{1}{q_{1}}>-\frac{1}{q_{2}}\Leftrightarrow q_{1}>q_{2}.
\]
Therefore, for times $t<\tilde{T}$, we must invest exclusively in $q_{2}$ until parity between $q_{1}$ and $q_{2}$ is achieved.  
This also implies that we are in the region below the 45-degree line and are moving toward it.

Now, we continue going backward until we reach either the boundary of $\machine{1}\machine{2}$ or $\machine{1}\human{2}$.  
Here we only consider the case where we hit the boundary of $\machine{1}\machine{2}$.\footnote{The dynamics of transitioning directly from $\machine{1|2}$ to $\machine{1}\human{2}$ are less complicated than transitioning through $\machine{1}\machine{2}$ first and then to $\machine{1}\human{2}$.  
For brevity, we do not describe the direct transition separately, as the mechanism is similar and requires one less step of analysis.}  
Given that we are in the region where $q_{1}>q_{2}$, the following conditions hold:
\[
q_{1}>q_{2}\Leftrightarrow-\frac{\machinetime{}}{q_{1}^{2}}>-\frac{\machinetime{}}{q_{2}^{2}}\Leftrightarrow\frac{\partial C\{\machine{1}\machine{2}\}}{\partial q_{1}}>\frac{\partial C\{\machine{1}\machine{2}\}}{\partial q_{2}}.
\]
Thus, in the $\machine{1}\machine{2}$ region, we must continue investing in $q_{2}$.  
This remains true even if we enter $\machine{1}\machine{2}$ from the point of parity in $\machine{1|2}$.  
In other words, in the moments leading up to $\frac{\partial C}{\partial q_{1}}=\frac{\partial C}{\partial q_{2}}$, we will allocate all resources to $q_{2}$, regardless of whether we will be in $\machine{1|2}$ or $\machine{1}\machine{2}$ at $\tilde{T}$.

Now imagine transitioning from $\machine{1}\machine{2}$ to $\machine{1}\human{2}$.  
The cost function changes from:
\[
C\{\machine{1}\machine{2}\}=\frac{\machinetime{}}{q_{1}}+\frac{\machinetime{}}{q_{2}}
\]
to 
\[
C\{\machine{1}\human{2}\}=\frac{\machinetime{}}{q_{1}}+\handofftime{}.
\]
Let us maintain the assumption that $q_{1}>q_{2}$ as we cross the horizontal boundary in Figure \ref{fig:two_tasks} and enter the new region.  
In the $\machine{1}\machine{2}$ region, we have: $\frac{\partial C}{\partial q_{1}}>\frac{\partial C}{\partial q_{2}}$.  
However, on the $\machine{1}\human{2}$ side, the derivatives change to $\frac{\partial C}{\partial q_{1}}=-\frac{\machinetime{}}{q_{1}^{2}}<0$ and $\frac{\partial C}{\partial q_{2}}=0$.  
This implies that the task contributing more to the objective function differs across these regions.  
However, this does not mean the optimal investment path switches instantaneously.  
While the instantaneous benefits shift at the boundary, the decision maker must account for the continuation value of investments in future periods.  
This is because, despite the discontinuity in the objective function, the state variables change continuously.

Thus, when transitioning from $\machine{1}\machine{2}$ to $\machine{1}\human{2}$, we continue investing in $q_{2}$ even though $q_{1}$ provides a higher instantaneous utility.  
We maintain this allocation until reaching a point where the continuation value of investing in $q_{2}$ equals the benefit of switching to $q_{1}$.  
This point represents a kink in the optimal trajectory of the state variables.  
Let $\hat{T}$ denote the time at which we reach this kink.  
At $\hat{T}$, the following condition must hold:
\begin{equation}
\begin{split}
    & \underbrace{\int_{\hat{T}}^{\tau} e^{-\rho s} \left(\frac{\machinetime{}}{\hat{q}_{1}} + \handofftime{}\right) ds}_{\text{from $\hat{T}$ to automating task 2}} 
    + \underbrace{\int_{\tau}^{\tilde{T}} e^{-\rho s} \left(\frac{\machinetime{}}{\hat{q}_{1}(q_{2,0} + rs)}\right) ds}_{\text{from automation of task 2 to parity of $q$s}} \\
    & \quad + \underbrace{\int_{\tilde{T}}^{\bar{T}} e^{-\rho s} \left(\frac{\machinetime{}}{\hat{q}_{1}^{2}}\right) ds}_{\text{after parity}} 
    = \underbrace{\int_{\hat{T}}^{\bar{T}} e^{-\rho s} \left(\frac{\machinetime{}}{\hat{q}_{1} + rs} + \handofftime{}\right) ds}_{\text{continue investing on $q_{1}$}}.
\end{split}
\label{eq:kink_eq}
\end{equation}
Here, $\hat{q}_{1}$ denotes the value of $q_{1}$ at the kink, $\tau$ is the time we cross the boundary to automating task 2, and $\tilde{T}$ is the time when parity between $q_{1}$ and $q_{2}$ is achieved.  
For $t<\hat{T}$, the right-hand side (RHS) of the equation is smaller than the left-hand side (LHS).  
Thus, the agent continues investing in $q_{1}$ until the two sides are equalized.  
This condition holds regardless of whether we are in the $\machine{1}\human{2}$ region or cross the boundary to $(1)(2)$.  
Specifically: 
\[
\frac{\partial C\{(1)(2)\}}{\partial q_{1}}=\frac{\partial C\{(1)(2)\}}{\partial q_{2}}=0,
\]
whereas:
\[
\frac{\partial C\{\machine{1}\human{2}\}}{\partial q_{1}}=-\frac{\machinetime{}}{q_{1}^{2}}<0=\frac{\partial C\{\machine{1}\human{2}\}}{\partial q_{2}}.
\]
This completes the characterization of the optimal trajectory of the state variables, starting from any point on the $q_{1}$-$q_{2}$ grid.

\subsection{Comparative Statics}

The following lemmas provide comparative statics of optimal trajectories with respect to $q_{2,0}$ and $\rho$.  
We continue to maintain the assumption that we are below the 45 degree line in the $q_{1}$-$q_{2}$ plane (i.e., $q_{1}>q_{2}$ region).
\begin{lem}
$\frac{\partial\hat{T}}{\partial q_{2,0}}<0$.
\end{lem}

\begin{proof}
We have:
\begin{align*}
\frac{\partial\hat{T}}{\partial q_{2,0}} & = -\int_{\tau}^{\tilde{T}} e^{-\rho s}\left(\frac{\machinetime{}}{\hat{q}_{1}(q_{2,0}+rs)^{2}}\right)ds < 0.
\end{align*}

\noindent Lemma 1 states that if the initial value of $q_{2,0}$ increases, the switch from investing in $q_{1}$ to $q_{2}$ occurs earlier.  
This explains the shift in kinks of the optimal paths in Figure \ref{fig:optimal_paths}---moving from light blue to green to dark blue---as they shift upward and to the left.
\end{proof}

\begin{lem}
$\frac{\partial\hat{q}_{1}}{\partial q_{2,0}}<0$.
\end{lem}

\begin{proof}
Note that $\frac{\partial\hat{q}_{1}}{\partial\hat{T}}=r$, because $\hat{T}$ is defined as the time during which all resources ($r$) are allocated exclusively to $q_{1}$ for $t<\hat{T}$.  
Using this, we can write:
\begin{align*}
\frac{\partial\hat{q}_{1}}{\partial q_{2,0}} & =\frac{\partial\hat{q}_{1}}{\partial\hat{T}}\frac{\partial\hat{T}}{\partial q_{2,0}}\\[1ex]
 & = r \times \frac{\partial\hat{T}}{\partial q_{2,0}}\\[1ex]
 & < 0,
\end{align*}
where the last line follows from Lemma 1.
\end{proof}

\begin{lem}
A sufficient condition for $\frac{\partial\hat{T}}{\partial\rho}<0$ is $\frac{\machinetime{}}{\handofftime{}}>Q(\hat{q}_{1})$, where $Q(\hat{q}_{1})=\frac{\hat{q}_{1}^{2}}{1-\hat{q}_{1}}$, the machine-to-human comparative advantage bound, is increasing in $\hat{q}_{1}$.
\end{lem}

\begin{proof}
We take partial derivative of both sides of \eqref{eq:kink_eq} with respect to $\rho$, treating $\hat{T}$ as a variable:
\[
\int_{\hat{T}}^{\tau}e^{-\rho s}\left(\frac{\machinetime{}}{\hat{q}_{1}}+\handofftime{}\right)ds+\int_{\tau}^{\tilde{T}}e^{-\rho s}\left(\frac{\machinetime{}}{\hat{q}_{1}(q_{2,0}+rs)}\right)ds+\int_{\tilde{T}}^{\bar{T}}e^{-\rho s}\left(\frac{\machinetime{}}{\hat{q}_{1}^{2}}\right)ds=\int_{\hat{T}}^{\bar{T}}e^{-\rho s}\left(\frac{\machinetime{}}{\hat{q}_{1}+rs}+\handofftime{}\right)ds.
\]
Differentiating with respect to $\rho$ gives: 
\begin{align*}
-\int_{\hat{T}}^{\tau} s\,e^{-\rho s}\left(\frac{\machinetime{}}{\hat{q}_{1}}+\handofftime{}\right)ds 
-\int_{\tau}^{\tilde{T}} s\,e^{-\rho s}\left(\frac{\machinetime{}}{\hat{q}_{1}(q_{2,0}+rs)}\right)ds 
-\int_{\tilde{T}}^{\bar{T}} s\,e^{-\rho s}\left(\frac{\machinetime{}}{\hat{q}_{1}^{2}}\right)ds
-\left[\frac{\partial\hat{T}}{\partial\rho}\,e^{-\rho\hat{T}}\left(\frac{\machinetime{}}{\hat{q}_{1}}+\handofftime{}\right)\right] \\[1ex]
= -\int_{\hat{T}}^{\bar{T}} s\,e^{-\rho s}\left(\frac{\machinetime{}}{\hat{q}_{1}+rs}+\handofftime{}\right)ds
-\left[\frac{\partial\hat{T}}{\partial\rho}\,e^{-\rho\hat{T}}\left(\frac{\machinetime{}}{\hat{q}_{1}+rs}+ \handofftime{}\right)\right].
\end{align*}
Rearranging terms, we get: 
\begin{align*}
\frac{\partial\hat{T}}{\partial\rho} & =\frac{\int_{\hat{T}}^{\tau} s\,e^{-\rho s}\left(\frac{\machinetime{}}{\hat{q}_{1}}+\handofftime{}\right)ds+\int_{\tau}^{\tilde{T}} s\,e^{-\rho s}\left(\frac{\machinetime{}}{\hat{q}_{1}(q_{2,0}+rs)}\right)ds+\int_{\tilde{T}}^{\bar{T}} s\,e^{-\rho s}\left(\frac{\machinetime{}}{\hat{q}_{1}^{2}}\right)ds-\int_{\hat{T}}^{\bar{T}} s\,e^{-\rho s}\left(\frac{\machinetime{}}{\hat{q}_{1}+rs}+\handofftime{}\right)ds}{e^{-\rho\hat{T}}\left(\frac{\machinetime{}}{\hat{q}_{1}+rs}-\frac{\machinetime{}}{\hat{q}_{1}}\right)}
\end{align*}
Since the denominator is always negative (because $\hat{q}_{1}+rs>\hat{q}_{1}$), the sign of $\frac{\partial\hat{T}}{\partial\rho}$ depends on the numerator.  
Breaking the last integral into three intervals, the numerator becomes:
\begin{align*}
 & \underbrace{\int_{\hat{T}}^{\tau} s\,e^{-\rho s} \left(\frac{\machinetime{}}{\hat{q}_{1}} - \frac{\machinetime{}}{\hat{q}_{1} + rs}\right) ds}_{>0} 
+ \int_{\tau}^{\tilde{T}} s\,e^{-\rho s} \left(\frac{\machinetime{}}{\hat{q}_{1}(q_{2,0} + rs)} - \frac{\machinetime{}}{\hat{q}_{1} + rs} - \handofftime{}\right) ds \\[1ex]
& + \int_{\tilde{T}}^{\bar{T}} s\,e^{-\rho s} \left(\frac{\machinetime{}}{\hat{q}_{1}^{2}} - \frac{\machinetime{}}{\hat{q}_{1} + rs} - \handofftime{}\right) ds.
\end{align*}
Now we look for sufficient conditions that guarantee the numerator is positive.  
First, notice that $\left(-\frac{\machinetime{}}{\hat{q}_{1}+rs}-\handofftime{}\right)$ appears in both the middle and right terms.  
To ensure the numerator is positive, we require:
\[
\frac{\machinetime{}}{\hat{q}_{1}+rs}+\handofftime{}\leq \min\left\{\frac{\machinetime{}}{\hat{q}_{1}^{2}},\frac{\machinetime{}}{\hat{q}_{1}(q_{2,0}+rs)}\right\}.
\]
In the region where $q_{1}>q_{2}$ and $q_{2}+rs\leq\hat{q}_{1}$ until parity is achieved, the minimum is $\frac{\machinetime{}}{\hat{q}_{1}^{2}}$.  
Therefore, the condition becomes: 
\begin{align*}
\frac{\machinetime{}}{\hat{q}_{1}+rs}+\handofftime{} & <\frac{\machinetime{}}{\hat{q}_{1}^{2}}.
\end{align*}
At $t=0$ (just after the investment switch), this simplifies to:
\[
\frac{\machinetime{}}{\hat{q}_{1}}+\handofftime{}<\frac{\machinetime{}}{\hat{q}_{1}^{2}},
\]
or equivalently:
\begin{align*}
\frac{\machinetime{}}{\handofftime{}}\left(\frac{1}{\hat{q}_{1}^{2}}-\frac{1}{\hat{q}_{1}}\right) & >1,\\[1ex]
\frac{\machinetime{}}{\handofftime{}}\frac{1-\hat{q}_{1}}{\hat{q}_{1}^{2}} & >1,\\[1ex]
\frac{\machinetime{}}{\handofftime{}} & >\frac{\hat{q}_{1}^{2}}{1-\hat{q}_{1}},\\[1ex]
\frac{\machinetime{}}{\handofftime{}} & >Q(\hat{q}_{1}).
\end{align*}
Thus, $\frac{\machinetime{}}{\handofftime{}}>Q(\hat{q}_{1})$ is a sufficient condition to ensure $\frac{\partial\hat{T}}{\partial\rho}<0$.  
Intuitively, if machine costs dominate human costs, increasing the discount rate makes the switch occur earlier ($\hat{T}\downarrow$).
\end{proof}

\begin{cor}
The machine-to-human comparative advantage bound decreases as the initial AI capability of the disadvantaged task increases.
\end{cor}

\begin{proof}
Using Lemma 2, we have:
\[
Q(\hat{q}_{1})=\frac{\hat{q}_{1}^{2}}{1-\hat{q}_{1}}.
\]
Taking the derivative with respect to $q_{2,0}$:
\[
\frac{\partial Q(\hat{q}_{1})}{\partial q_{2,0}}=\frac{\partial\left(\frac{\hat{q}_{1}^{2}}{1-\hat{q}_{1}}\right)}{\partial\hat{q}_{1}}\frac{\partial\hat{q}_{1}}{\partial q_{2,0}}<0.
\]
This implies that as $q_{2,0}$ increases, maintaining $\frac{\partial\hat{T}}{\partial\rho}<0$ requires less comparative machine cost advantage (i.e., lower $\frac{\machinetime{}}{\handofftime{}}$).
\end{proof}


\end{document}


%%%%%%%%%%%%%%%% Extending the Model: Theoretical Propositions and Insights %%%%%%%%%%%%%%%%
\section{Extending the Model: Theoretical Propositions and Insights}

\subsection{Chaining with Correlated Success Probabilities}

\begin{proposition}[Chaining with Correlated Success]
Suppose the probability of success on each task is marginally $q_i$, but the success events are correlated with a correlation coefficient $\rho$.  
Let $\text{CostBlock}(i\text{ through }j)$ denote the expected cost of chaining tasks $i$ through $j$.  
Then:
\[
\text{CostBlock}(i\text{ through }j) = \frac{\machinetime{}}{\mathbb{P}(\text{all succeed})},
\]
where $\mathbb{P}(\text{all succeed}) = \mathbb{P}\left(\bigcap_{k=i}^j S_k\right)$ depends on $\rho$.  
If $\rho > 0$, the threshold for cost-effective chaining is strictly higher than in the $\rho = 0$ (independent) case.  
Conversely, if $\rho < 0$, chaining becomes more attractive.
\end{proposition}

\subsection{Chaining in Non-Linear or Tree-Structured Production}

\begin{theorem}[Cost-Minimizing Chaining in a Directed Acyclic Graph]
Let the production process be represented by a DAG $G = (V, E)$, where each node $i \in V$ is a task requiring cost $\handofftime{}[i] \in \mathbb{R}_+$ by humans or $\frac{\machinetime{}}{\prod_{k \in \text{chain}} q[k]}$ if executed in a chained block of tasks.  
The cost-minimization problem:
\[
\min_{\text{valid assignments respecting DAG dependencies}} \sum_{b \in B} \text{CostBlock}(b),
\]
can be solved in $O(|V|^2 2^{|E|})$ using a dynamic program processing nodes in topological order.  
The solution involves sub-DAGs where each is either a single-human-task node or a fully machine-chained component.
\end{theorem}

\subsection{Endogenizing Prompting and Evaluation Costs}

\begin{proposition}[Joint Investment in Capability and Prompt Tuning]
Let a firm allocate resources to improve AI success probabilities $q_i$ and reduce management costs $\machinetime{}$ over time, facing cost functions $R(q_i)$ and $S(\machinetime{})$.  
The total cost per period is:
\[
C(\mathbf{q}, \machinetime{}) = \min\left\{\text{production costs with } q_i \text{ and } \machinetime{}\right\}.
\]
If improvements in $q_i$ and $\machinetime{}$ are complementary (i.e., $\frac{\partial^2 C}{\partial q_i \partial \machinetime{}} < 0$), the firm will invest in both dimensions simultaneously, rather than prioritizing one exclusively.
\end{proposition}

\subsection{Multiple Humans with Heterogeneous Skills}

\begin{proposition}[Heterogeneous Human Costs]
Suppose there are two human types, $H_1$ and $H_2$, with costs $\handofftime{1} < \handofftime{2}$ and management costs $\timecost{m1} < \timecost{m2}$.  
Let $\CostBlock_{i,\text{type}}(\cdots)$ be the expected cost if tasks $i$ through $j$ are done by AI under type $\text{type}$.  
The dynamic program chooses both:
\begin{itemize}
    \item Who supervises each AI chain ($H_1$ or $H_2$),
    \item Who performs human-executed tasks.
\end{itemize}
The segmentation of tasks depends on $\frac{\timecost{m1}}{q_1q_2\cdots q_k}$ versus $\frac{\timecost{m2}}{q_1q_2\cdots q_k}$, which affects allocation efficiency.
\end{proposition}

\subsection{Optimal Partitioning of Chains}

\begin{proposition}[Optimal Chaining Partition]
Suppose a block of $k$ tasks has success probabilities $q_i$.  
The tasks can be chained in one go or partitioned into smaller subchains.  
The cost of $m$ subchains is:
\[
\sum_{\ell=1}^m \frac{\machinetime{}}{\prod_{i \in \ell\text{-th subchain}} q[i]}.
\]
An optimal partition $\Pi^*$ minimizes this sum and can be found via a dynamic program in $O(k^2)$.  
If $\prod_{i=1}^k q[i]$ is sufficiently high, the entire block is assigned to a single chain.
\end{proposition}

\subsection{Learning-by-Doing and Dynamic Probabilities}

\begin{theorem}[Optimal Usage Trajectories Under Learning-by-Doing]
Let $q_i(t)$ be the AI’s success probability on task $i$ at time $t$, improving with usage: $q_i(t+1) = \min\{q_i(t) + \Delta, 1\}$.  
If improvements in $q_i$ are convex in attempts, there exists a threshold policy:
\begin{itemize}
    \item If $q_i(t) < q_i^*$, the firm uses AI for the task to accumulate learning.
    \item If $q_i(t) \ge q_i^*$, the firm assigns the task to AI or humans, depending on cost.
\end{itemize}
\end{theorem}

\subsection{General Equilibrium with Multiple Sectors}

\begin{proposition}[General Equilibrium with Two Goods]
Consider two sectors producing goods $X$ and $Y$, each requiring a sequence of tasks.  
Labor is mobile, and the equilibrium prices $(w^*, p_X^*, p_Y^*)$ satisfy:
\[
L_j(w) = d_j(p_j) l_j(w; q_1, q_2, \dots, q_n),
\]
where $L_j$ is labor demand and $d_j(p_j)$ is product demand.  
If AI improvement $\Delta q$ reduces the cost of key tasks in $X$, the labor effect in $X$ depends on the demand elasticity $\epsilon_j$, while sector $Y$ may experience wage effects or reallocation.
\end{proposition}


\end{comment}
\end{document}

